{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2c0e81",
   "metadata": {},
   "source": [
    "# Task1: Play with NetVLAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06556542",
   "metadata": {},
   "source": [
    "## Work done last week (Evil version i.e., bad version)\n",
    "which we will show later it is indeed bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f77db",
   "metadata": {},
   "source": [
    "work adapted from https://github.com/lyakaap/NetVLAD-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb48a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netvlad_evil'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetvlad_evil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NetVLAD\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetvlad_evil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbedNet\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhard_triplet_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HardTripletLoss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'netvlad_evil'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "from netvlad_evil import NetVLAD\n",
    "from netvlad_evil import EmbedNet\n",
    "from hard_triplet_loss import HardTripletLoss\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "def VLAD_for_single_image_evil(img):\n",
    "    # Discard layers at the end of base network\n",
    "    encoder = resnet18(pretrained=True)\n",
    "    base_model = nn.Sequential(\n",
    "        encoder.conv1,\n",
    "        encoder.bn1,\n",
    "        encoder.relu,\n",
    "        encoder.maxpool,\n",
    "        encoder.layer1,\n",
    "        encoder.layer2,\n",
    "        encoder.layer3,\n",
    "        encoder.layer4\n",
    "    )\n",
    "    dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
    "\n",
    "    # Define model for embedding\n",
    "    net_vlad = NetVLAD(num_clusters=64, dim=dim, alpha=1.0)\n",
    "    model = EmbedNet(base_model, net_vlad)\n",
    "\n",
    "    # Define loss\n",
    "    criterion = HardTripletLoss(margin=0.1)\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    x = preprocess(img)\n",
    "    x = x.unsqueeze(0)\n",
    "    \n",
    "    output = model(x)\n",
    "\n",
    "    print('VLAD encoding: {}'.format(output))\n",
    "    print('VLAD encoding shape: {}'.format(output.shape))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24d1c1",
   "metadata": {},
   "source": [
    "## Work done this week (Works great! Yay!)\n",
    "adapted from https://github.com/Nanne/pytorch-NetVlad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b49bf3",
   "metadata": {},
   "source": [
    "### Adapt main.py\n",
    "Define a function VLAD_for_single_image for our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2a5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "from os.path import join, isfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import netvlad\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle as pk\n",
    " \n",
    "def VLAD_for_single_image(img):\n",
    "    cuda = False\n",
    "    if cuda and not torch.cuda.is_available():\n",
    "        raise Exception(\"No GPU found, please run with --nocuda\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "    default_seed = 123\n",
    "    random.seed(default_seed)\n",
    "    np.random.seed(default_seed)\n",
    "    torch.manual_seed(default_seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(default_seed)\n",
    "\n",
    "    print('===> Loading data')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input = preprocess(img)\n",
    "    input = input.unsqueeze(0)\n",
    "    print('Input image shape: {}'.format(input.shape))\n",
    "\n",
    "    print('===> Building model')\n",
    "\n",
    "    pretrained = True\n",
    "\n",
    "    encoder_dim = 512\n",
    "    encoder = models.vgg16(pretrained=pretrained)\n",
    "    # capture only feature part and remove last relu and maxpool\n",
    "    layers = list(encoder.features.children())[:-2]\n",
    "\n",
    "    if pretrained:\n",
    "        # if using pretrained then only train conv5_1, conv5_2, and conv5_3\n",
    "        for l in layers[:-5]: \n",
    "            for p in l.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "\n",
    "    encoder = nn.Sequential(*layers)\n",
    "    model = nn.Module() \n",
    "    model.add_module('encoder', encoder)\n",
    "\n",
    "    default_num_clusters = 64\n",
    "    defauly_vladv2 = False\n",
    "    print('NetVLAD setting:\\nnum_clusters: {} dim: {} vladv2: {}'.format(default_num_clusters, encoder_dim, defauly_vladv2))\n",
    "    net_vlad = netvlad.NetVLAD(num_clusters=default_num_clusters, dim=encoder_dim, vladv2=defauly_vladv2)\n",
    "    model.add_module('pool', net_vlad)\n",
    "\n",
    "    checkpoint_path = 'vgg16_netvlad_checkpoint'\n",
    "    resume_ckpt = join(checkpoint_path, 'checkpoints', 'checkpoint.pth.tar')\n",
    "\n",
    "    if isfile(resume_ckpt):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume_ckpt))\n",
    "        checkpoint = torch.load(resume_ckpt, map_location=lambda storage, loc: storage)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_metric = checkpoint['best_score']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model = model.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(resume_ckpt, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume_ckpt))\n",
    "\n",
    "    print('===> Running evaluation step')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = input.to(device)\n",
    "        image_encoding = model.encoder(input)\n",
    "        vlad_encoding = model.pool(image_encoding) \n",
    "    print('VLAD encoding: {}'.format(vlad_encoding))\n",
    "    print('VLAD encoding shape: {}'.format(vlad_encoding.shape))\n",
    "    return vlad_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57c40f",
   "metadata": {},
   "source": [
    "### Functionality Test \n",
    "Note: _evil indicates the NetVLAD model from last week, which is consider to be written in evil coding style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9c68f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c804cdee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAADoCAYAAACeqz8EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9a6xtS3Yehn2jquZcj733Oee++8UmJZKiRUl2bEnUwzStQJFNxTaMPBDYSZA/MfwnQvLLsBwEyY84QoIASYAogKIAkuIANm0HCGIjFhTJiqJHZNgKZEeURIlNspt92Zd93+fsvddac86qGvkxxqiqOdfa555u9u172HeOi3P33mvNR82qmuPxjRcxM1ZaaaWVVlpppZVWWmmllVZaaaWVVvr8kPusB7DSSiuttNJKK6200korrbTSSiuttNL3l1ZAaKWVVlpppZVWWmmllVZaaaWVVlrpc0YrILTSSiuttNJKK6200korrbTSSiut9DmjFRBaaaWVVlpppZVWWmmllVZaaaWVVvqc0QoIrbTSSiuttNJKK6200korrbTSSit9zmgFhFZaaaWVVlpppZVWWmmllVZaaaWVPme0AkIrrbTSSiuttNJKK6200korrbTSSp8zWgGhlVZaEBH1RPR/JaKvExET0R/6rMe00korrbTSy0NE9PuJ6C8S0YdE9B4R/ftE9MXPelwrrbTSSiu9HEREP0lEf4uIPtJ/f4mIfvKzHtdKKy1pBYRWWuky/XUA/10Av/5ZD2SllVZaaaWXjl4B8KcB/AiAHwZwC+DPfpYDWmmllVZa6aWibwH4bwJ4FcDrAP4DAD/3mY5opZUu0AoIrfS5JY0A+jeI6O8pcv9niWjLzCMz/++Y+a8DSJ/1OFdaaaWVVvps6Dly4s8z87/PzM+Y+QDgTwL4Jz/r8a600korrfT9pefIiY+Z+evMzAAIYlP82Gc83JVWOqMVEFrp807/HQD/LIAfBfDbAPxPPtvhrLTSSiut9JLRi8iJnwHwd7+fg1pppZVWWumloQflBBF9DOAE4H8P4E98FoNbaaXn0QoIrfR5pz/JzN9k5g8B/C8A/Muf9YBWWmmllVZ6qei5coKI/lEA/1MA/9pnMbiVVlpppZU+c3pQTjDzEwCPAfwxAH/7sxneSis9TOGzHsBKK33G9M3m928A+NJnNZCVVlpppZVeSnpQThDRjwH48wD+R8z8177fA1tppZVWWumloOfaE8x8T0R/CsB7RPTbmfnd7+voVlrpObRGCK30eacfan7/KqQA3EorrbTSSisZXZQTRPTDAP4SgP85M/9fPouBrbTSSiut9FLQi9gTDsAewJe/LyNaaaUXpBUQWunzTv8DIvoKEb0K4H8M4N8FACLaENFWj+mJaEtE9JmNcqWVVlpppc+KzuQEEX0ZwF8G8H9g5j/12Q5vpZVWWmmlz5guyYk/QkT/OBF5InoE4H8D4CMAf/8zHelKKy1oBYRW+rzTvw3g/wngl/Xfv6mf/wMARwiK/xf09x/+LAa40korrbTSZ0qX5MS/AuC3AvifEdGd/fsMx7jSSiuttNJnR5fkxBMA/w6ApwB+CdJh7GeZ+fQZjXGllS4SSSe8lVb6/BERfR3Av8LMf+mzHstKK6200kovH61yYqWVVlpppefRKidW+s1Oa4TQSiuttNJKK6200korrbTSSiuttNLnjD41QIiIfpaI/gERfY2I/vindZ+VVlpppZV+89EqI1ZaaaWVVnoerXJipZVWWunTp08lZYyIPIB/COCPAHgbwH8G4F9m5r/3Pb/ZSiuttNJKv6lolRErrbTSSis9j1Y5sdJKK630/aFPK0LopwB8jZl/mZlHAD8H4F/8lO610korrbTSby5aZcRKK6200krPo1VOrLTSSit9H+jTAoS+DOCbzd9v62crrbTSSiuttMqIlVZaaaWVnkernFhppZVW+j5Q+JSuSxc+m+WmEdG/CuBf1T9/N10445MuYt8zA0Tys3544aafNGC68JmMdfYT9rfem/UuDAaYMcvC4xcfw0orrbTSA/Q+M7/xWQ/ie0ifKCOAh+XEpZM/iZYX/26u8d0Q0YWbP2cgBCoSpf0Meh2mRqiQfEdUv2/poZRwrgeUv2n5XTnmwqRzPYvbM5pxza6zCsGVVvrUiZm/X2zt+0XfsZzo++53v/XGq59wyRdhSA9xROF71PA+sT+48G5ant7e8ux3+p4JI9ILnXP1erv6fX2eYtFQ/awedEG2zIyvS3f4JPqk+afFz+dKKNQBvtjaMjOYGTlnxJQQp4hpmjDFiJSy2nJi09HFZ1os4gOPTedLMJO9jEsymqoN2cr69gjbbxcMZyJazN5cRjv93pF8nhublZtjnCO1Z7k8Y85yRPAORHWOGISUM4gcnBrjdi2xz+va2ZTYOBlmR8+foTwA65h1vDZfznnVrWT/eu+QcwYDCKFDzgl95+GIEGMGiBC8g3Ny4ZgYKQPkCI6AEBxySiByYDBizGC7t96Xy/rY37IGznk8efwY4zRiHEeAGc453Dy6wf39PcZhBIPhyME5DwCIMWKaIlJOjT7VzlKdvznN9a32XS/zpmOlwojqFccpIcZ8ccd+WoDQ2wB+qPn7KwC+1R7AzH8awJ8GAOeINzoSUu2ZgPLc7Z7nwnDb17RuWtYXBVzfpXbDcb2svFR1/s7f6SwhVLYBiVl4NxGccwjBw/uArgvoO9mcBCBF3VSZkVIEA4iZEVNC4gxiQkoJuRkUM4NJX8zFy9Hy5fkHaPhSFQVnx2PxAT/w9UorrfRdEz/0Yl1CIr5TA5nxje9uVC8tfaKMAOZywjviba+Tl+X7c31oziRbYZpJv86N2kwAXbShWo1d/janw9k9Gz/Bpe8JqhguxktEVRmkRqZRFew553KsHc9O7uOcPJD3IoeKnKKqUMr51WjJmZtrAZlzUYy99wCLgljuxQ4EL/KuC+i7AOKEyAmcGJwZUxa55uABMLLKY+c8uq6D6JUZx2FASoxximfTS1jOhcpslYUGqp1hUtSs8YV36pIp167LzInUHkRyT/sHrmtblOeqJ8/IjhG943lGzGVypkdkHdsnXKId0wvTpef+Ts/HQut4Dt+bGc/fc83jkqV6me3+INOnUQ/0JaDvWE589Stf4H/tj/33AACZjH+68o60xmmVE9W4JjZe7NQITWBOs/sRORAF+ZwyTCARHM5AmJbPL/52zuGSGdYeszT6HwIC7NjKuy+ff34OwCw2SzUeo76nDoDT+atywTkCcwKzza8wR4LNMzXXlr/l+gAQL45D+H2Gcw5EHsxUnmf5/Jee+/IxJotcATOYRUZNMWIYBjx7eov3338f7/z6t/He+x/g3fc/xPE0IKVUwRC9ljw/6frrGpHYnSY3PbnCkEnvJ+tcx8XMSGoPxpwFTAEAOHAm5EwgJ4CD6QB2HhHK/Afvy7MzMxwRNl0HBwff7jsFCBwRrq/28Jyw33aIacLT+yMiy7olYnBi7PuAx1cbpHFAzAL4ZALuDxOcd3jtaoO+S4gxwfmA+2HCccwIIWC/2yKOE5iBmICY5HPnHBgRU4wIrsOm9wieME6MKTEmBrKCR13XgRSk4RSx6Xv0XYeUIw7DCOcCdtst+uDhkNETcLPfYxhPOE0RX/riF3D77AP80JffgM8Z7z8dsNtu8eTRDvutR2bCu09H3E8O3abHNgBvvrHH8e6A4Lc4jUd8+4MTCMC+96A8YRxHxAwkyB44jSOmOCJ0Ho+vrvHWm28ip4iPPvoIBODx48f4fX/g9+Ov/rW/ivfeexfee3ShB1GHu/t7jOOE+/sDjsMIgOFRdbWUkqyXd4gxzt7llDJyyrN3I6WkvxNC8IonyD5xug9iTgARfuGXP7j4/gGfHiD0nwH4cSL6LQB+DcC/BOC//Z1coAG6ZoqYATJgU26BT1K2Wg/tJaDlQX7pbIPW45kBzoyc5WUgGuG9w37bY7/fYdP1QFBFeZrgQMjM8M4hBPndqaABTBHOSDGJYp0zcs7IqphznoNZs7l56HntO9OkH0QYG9S2Vd4+QYCstNJKz6HnvZiXfv+E67TG1A8QfVcywhHAaiibbLhEbTBngzM0XpPnUwUhzi3nqvCqUr8QENywV+fOwaCLoBFTuY55okypJ6KiFBYZxEBKcuFpSmAedcxVrgAiq8ipwg4ATCBnRzj17hX0SD1eXLx3RIB3Dv1mi91uh5ubPfI0IMUJKWXxcuUIJsBTAMBIOQIgXO2v8fjmMbpAOJ1OuL2/w8fP7vD02X0NOiIqc2EKuwBd8jerkmifO1fhhJhFKUoFNVpgrWXB5+taHSjVi2YRWFWB1vUrnkn9buE54sUvdjvZd4RsQMml8fEF0KIBgNrf7Xku7ffvOxikY5Hxf4LuZUDfbM4+LWCopfqQP0jaTDvfn+78vTT0XdsSsu8aXbt9vzHnw2bcWxQCAQAxGC2g3gI7de5n7/R3QHT2gs/HvgSSCljznMgQO7daDHR2nSVoZKCOXVuAj/NqIrMoj+Z6zjkBxpjBlOEUPOIyVqfDyRp9ITZP+ww2F62R237fGsTt2A1oadcPELkHkK6xaxm/AhNybtd1uLre43S6xqObA06nEw73x2KEiwyqz1t/ZpBzRSYQCRRoc9CuIRTUmc+5fMbqsOEsESwW0cH6WeYKBgHi4BEwqN63zAURHESPoBkYWOOcnCN4R3AMhBAAyHNQpnoU2bkQ3aEBkxwA5wk+ODjK4MzY7Le4O47ofJDjHDXOMXmHbL7AVd4bWJY5qxPJ1qu+UXaMHZdyVv2HkXIuThNyXnUWh0AEhwSPCI+MFEdM44j9dguwAIEZTiOaIMeGHoDXMTBiyiB28E6cZnGKyAykzEjM8lNtdc4OaRrx7OMPkWLE4e4e05Tw9Okdfu2d/zvuD3eYphFEhOADQB1iFLBxmiYQyx7IYLjmtSbbx0V/pNk/APDeN7zC9DeUeXTOg3MCwCDO8L5bvtYz+lQAIWaORPTHAPwFAB7An2Hmv/udXMMcmwXT4Pa7+cTJPQFjZEXFpcoWmfSaho/QXEFv9baHn2v+NzXXGFOEG0cQOfQhoOsDut4jx4SUE1JKmGJE5IycJWoohIAudPCuA3NAZkKME2KKiJkxxYSU7WnOmSM3oJENrlVIwQsB2Fxlaed8V17GlVZa6cXp0vu11Os+J+/gdysjuHj5zkEVUxSqQJzzNALUkWtfzq8xV7SrYUAWuQkqv7dKy/M88y0YNfu7UXqXyqYeqYoQ8NCmEGCMxEGBhcHDMnYmwM1ONyeDxdqa4YSifJbzHAGdh+s8rq6v8U/8nt+Df/IP/hT+vX/n38b902eIFOGdR8cBzhO2/QbDNGKKDrvtHm+98RbefP115BhxONzj/Q87nA4D4m6H03gEm2wzwAfNvHKVYwbKEJoxA+h8o0A2x9v35iUzu6seO9849fr1PKjB4INXDxtU4ap6gsxjVcjrGmewepIzm0IsCjs5mnuqud0Tda+Qgol11b47+XxRrn+/cASqe+sScPRwOsaLUTUSF1ct7/VcJzob3EovPf2GbIkGIFmCDJcidlrgCBo52b4/1fAyIIfP5Acja5TQHNBY3quek4HGQTwDNcpxczlwBn4snq8CGBnSpK29rwElBtYsZU+VrzYXckzL+bJeI8/OJT2RkeGcL3yugGsGYrg5TzLQSMY6l+82bgFC5lE2l0p5mByEgTUGSC+AMYJkeTjn4L3H/mqHm0dXOB4PGrUxICfGpBkecr7wexEhVAAFA72dc6aEKLhTdQkbd3HsNCATseg15KnoN1Djvq5FfWZLyTLjtq6lE9CHWhkisitmkZ0+ePSdR5qiOoqgaVZOeDHnIo8ZCgipLe6I4Lyc5L1D5wOG0wTvvEQYhw4xCfjQKFuyf3QPFQy0vFdU5re1c5kzCBJtxQXQc0iZNBDEQCJGcJadI1fqvINHROcAzlEAJxZQKueEnB0mjcoSHTAreNLBUYcMidCS8cnDxwzk7BA5Ac5jmoay/1PKmKYR0+gxjgOG4YiUgcSEdJLvLPLNJF7U1MSUJPJQIthS8z40YClsU9f1Tw0YWt6jIu8k26iVgXKua/+8SJ9WhBCY+T8C8B+96PFnDBsAaQ7jOWO1F9wYtH0G8AJRNcqs16PLM0KLn3KtubJxZmCQLORms8FXvvJFgIHhNAA5aaiWAzsHihLW78ghxIiBo6aLyeebrsem60G60e4O9zgOIyIn5JhQ8XthPuZVlfBE1fhtXGW8hiJXxZO4voSXdsYF+fXC9KLhqSut9INKDxk3S2PIUpT4ofxwJvnugfN/UOg7lRFA5cGNDliiOAktj65yoZzTKDpy7jL26nz9TEWh5g9qlJ3z8Z1HRLTklp4MtDzTQAmLXDGjY2FEyKeoDo+qcIpSmg3v0vudG8YNnlXnTH8pKj8RuuCx22zxT/30z+Cf/aM/i//wP/i/4XB/j5QiAEbfB3TdFv/IT/w4ftuP/yj+w//Hn8fdPfD6K6/hx37kh/H40Q1inPD45hG+/d57+MIXvoD/39/9+/i1b5+Qsnni64Mx2OyNAuBUw2y+UsxSx8CBRbaDtWaDnuMXHn1TSt35+ySny0ZiErXNB5IIL3BZbXKiOGfOIEfFS+jIyd8x6r28RnCpd9Wrwg2Cc6rAOzFgsgJjUl/AvMOMlBqDc8Eq5obo2eOcHfOp0GU14vwYLI57kfNe5Pat0kx1j2smJQgaXfabmX0u581+/mZ+pu+Qvhs5Adj6n9sIM+AHC+P8AeDoPIVL/rXsRQw0KoD75fOw+P08Jap57kYGGNDp58/YnLt0TCydI/bM5mioBmOVDJfGmxX40AIaAPjsXu14BPhIek3XfKf3X+pDDY+3Uht2D4uG8N7Pjl8+uzyJPFRuQGhnzoJG0IhscCC1v7quw3a7xc3NDQ6HAx4dTzgeR0xjRNZIDm7XWm2rDIY38A8A5zzbNzVaKTfyfL5WzBoddOZUEIWFNRxatm/lcWDW1ZCHs7pA3ntJWVN54r0X4CNHkEYHeQ9MYyzrX+dGEiUFKJKROHIAMrxz8C5AY17hnaR7kQJ/OWfVpVSWOQEfcokE4/LPxlr3g/yxjMCztXeaysgsEToCHspnGTp/npA1Ss0TgBzRdR4pJ8QYNbooIqUAHwhTZkQ24ETmKkVGygq4kQe5BB8Y5GX9pygpftDnleeW35MjxCkixQnMSeoTMTSiKevSSVpeTCPiFBGjgUEK2i7wjllkOFc9MDfAoqRXKsCrSkpuwKCs9YmMBxom8BB9aoDQd0rZXoYZgqx4mjKLohSxbDpTn0s4fNmuVeElQq0F1NxvyYKXPJm5ZM82yJt6iFGVMFPCv/ylL+Of/qd+Bvv9Ht96+5v4xtd/BW9/85u4vX0GCkE2NhwiOYAcppQEoSaHLnToux4heARHyCmXWgsEAhIXp6bVZyCgCbtXsEeVIFOGDDQiZyGEVEIp65uICjY3TGo2N83cPVcXoYdTW+y8dpqbUnb1YWDP+vCufTE99NPWhlda6cXoob24BH7ss5WeQ1R/MDdgEDU8aqbo1/MMp2mVq/aCpixXpa6qs2yKZTsUmqcUC89tlLpyzTq+Vuk7U2x1vIWHEi2UAx1AVpCCK5Bj81Gey2RAYfKNal4egutckkJcjZwVv6HDj//Yj+Kf+SN/GP/Wn/0z+IVf+HtAjvCO0YUOzgX85G//CfzTP/PT+Lmf+/dwf3/A9f4GX/7SlxA6Dx8Ib731RQynEwgZb3/zm3j33XdFSbURlHpQVD4rY8/6yKmCR9XQzzLHbimzVD4mvvis5yRKFkAqR0WgSrpALnMrH3MpAilgjuXuZ6So2gc5NQJMaa8VDy2kG6VeoMFEVKKeWRXNsq+bR7voG1v8/iJg0eyc57GcT/q+0TUY5+MtYyhGR92fBQCsl5rddnGbot9IxqO9F/ItOf23OM8KptocWwpIqd94duflw1/6mPTBG7SJaRl4Jld+3vx/R6ye6zzy7NPv5CKfG5L3EJq+VD+fG+V6ULsHDRQvm2bOT+2Yek1uFrl+vgR/cq6Gsfw0o3Zx79kTWCRO6+2fR/xYJJBRicohNOekwk+y6v92b7lGRq0f1L5XjAoY2H1aAAFlDHPXCpV7cK5MTHifg6WLtfLWaq2V611wnLS0dJIQzUETQFPDsvFvWU97Y4lRIoRyzuj7Hlf7Pa72V7i+PuL+7oDT8YQ0JcQmbaeMsVknc1zMxqdjmUeDze0r23nsZGAGvFmaFUFAK+OrKvX1fjLnDi2YJuCJgwM5jeghBzgBcJwDvKOyysE7TABAHl7TuRAz4JwWWpYRusJ06zgcUQHuktYYIufgFJiwwAUDrnJOIAQQOThkvbbMmUQmG+BXjVKJaMklysk7D2SRpwySteUg0bi6lxwygndIWWobpUQYE8DkkDghcwKjk7QxZnHwuIDEjDFKPafOe0iwRkZQIDLnjMRZ0tOz6VqiNBFlcIZk9kRxlDHibI8b6APFKCKnAubl8k5VnZX0niW6CQCRQwaQFIzknBAQwGAFnlQPSQkuqOMq54KhJM4Au+fKjJcDEGoUGeM94plrtAuuvxagp30tTWErKnBVBo0JGFOg9mtT5heCFmTvQANGUX2R7Z7MjMPhgL/21/4G/tZ/+v/Fm2++jh//sR/Dj/7ob8Wrr72O/+Rv/jXc7K/wMz/90wBn/PIvfg2//u1v4/5wROh67HY7vPLkCa73ezhHePr0KT746CMACcNwj+iAUoScTCnFbBz2R2HKjYdibgmYsDhXhoig3k+bDBSG1j5vWQudQG7mkXk+qa0gtjVprraY8MXk248Le3f20fMU5JVWehmJ2l/p4nfLz1fFX6jFcQoQXj9CZVFz/l9lxtxIy8yo+cdc+NiZ4Q20mPXCqzk/zuRYasbLF+5dn4mB3HiG1PCbh1A33l5UO10UBTU0dILaMVW1q72hfl/ZvB7LlSuz1Cg6Ho/4h//wF/En/sS/ibfffrvU8dlsAqaY8cUvfgl/4A/+NP7U//H/hI8+foab62u8+ebrOB1vceiAq6sd3v/gQ7z/3nv4B//wH+Ib3/wmppTLGFqZYg8+cyheAHLqeuuI9QMNjpqvBdf1WGBGaPtsGBA3B5aSjpEapxNKDatWmajpGABTUn2liW5ukMP2PjUdUa5LJF7QdoG5+XeR+IE/HxKvl86nC8fRhe9p/hWgKQrUGGntvKLdX83/Zs/MRXfzTus10eL25rF2BGrqUEi9CvUkO7tuKRqAxFydYCwGsdWiyFnTJ00v+UT0rM4Boe5f080+FWr1XN1iRT1bHreKCAAyDRlzGBY4N9orUeGh5RrcpDMSYCksgKVKuQborOtjtcjsGuUOBuBAOzGpuxkN/5Jz7HiLCiqxiZi9N2i3qzzxHHCy66XmdxQHNjV1buwazAIKlVnjiHqp1mht5EvzoRVabucQ8DpmZzCRWGgtP+V6nTP+oU6Qh9Lv2nvNnUKVYZXUNpBGYaC8L0SEEAJyzthsNri5vsbheMDV1Q6HwxGnYcQ0ptrwZ0EMAV4sEg258rLiuNeX9iyCS4anEaJ6pKVssY29ysOqA8oxEnUqE+gsXcxRkXneS8rzNDG8gUV6nHfSbSszw5EHeYecAPiAzKnwVOG9rLWEgOCcFJ7mDEaG84SYIpwLgNZBlDpGDhMkGoiJS8CHJwJbgfJ2jR1BUrdY9ibbPpHn45wk2iWXkA8BN3VKUmYwJxASvKbeOecwjQljIhB7pMyIKSLEiDhNyBnwvkNKQA5SdDkb2EcE7xghBMQJ+u4yYGmNGjkljhzRQ2KMOg6ZK4lqY0QklU8ChiZ9BpFDjBA6MAtoxkkATO89YkwFEHLkJcXeASmnohpZ9k/MGZwY3gv/sfpWsRSb1mdIsYDGl+ilAISK3tdouqwKoilyLT9Y8oaiUCniVxmA/M88n6YDG89ZFnBqh9EqPuS0MLTePBekFwV1z8y4iwccvvFNfONX38Z//Jf/SqnwHTzh197+dfyWr/4Qfvtv+1H8/t/3+zBNEX/jb/5/8OGHHyC4J3jrzdfxhbfexGbTYxhGvPPtd/F3f+Hv4xd/+W2899FTHIexGiQPKh/zEPxqWMznau4x0RdAFaPK6Juf9qIrWmpF2aqgrfOfkhQak5DKuqTm3DbP6JknsR34Q5rNJavgkgK70kor/UDSmV5IkKgqnivgxheM37fp1nPF1pS5eh61x/FcFtXzG83cbmR/L8b4oB0yewyqKW3FwqyGrX3OLMZye9t2OMXRa9/peC6BVmbMttdrnz8zMMWM9z/8AO9/+MEMpDycZMxT/GX8r/7X/1scDs/w6Poa5AgffvA+njrCu+++i6997ZcwxYhpHPHxs1tRXIryW+9XFJzGoFl6getTyXq51oOk5Bqn+9lWaQ0NO7XZC04/T02ONoPQ9wEpasMH0ycA3RMGgjTGWus4aj3EBhgt90z5VSYkt+On8+c4o+UB3wkw8LxjL3znbEwKwBARgmvBmPnALPUBkHM8eaA1zFiU7lA80KQeUTE6rAue6BziJSbyDT7FWmdCDcJsRrRpKFrHSUGhzBkxOu3wo1F2kPMyU6lrZXvykhFoaYrLKapbsYFym/0l5y6niZ7z1/wOLd+av/TnY1xJaB7xOect9pkQzWVA+d7+BphaDnhBAdWoiYdSmiyCI5txrwX/c84a3TZ3A11KNavixWwjLu/j8vmelwq3HJcOv1692Dh8Ya7mn5dZ0O9dqd9T7SNLXc5ZZFTKBkw51JpMLc+390sE3ll6GPPsmYk0Qu/sc50zlRVLkM4MdenU6bHf7XBzfY376wNOpxGH4wmnOIlX/uK8UZGfrSxuHVKFD16Yt7qN6j6s3OeS7sB6DBeAb7bujaLjvUdQYIEhAFEIAd47abPuAyTrxcE7B45isZFGThkgZNEtAmFKdAoUnPA+YJgmKVBNBEAiroILUpXI1ia3+lM1LiXCts4T9H5sc6WfCxjE+o5lWCRNThlZ0wyZs6SxIQOcAA6YxoSYMlLyAIJE8sSkzgDp9p1SRE4e0zgixqipnywdUnUvO+dAjuE07DunBjwSBAYxW7Fp3edeItSy1mthyqXNfM4ZMWXdFwJaxijpaN45pCTXmWIUPcdZUXIgRblmCEF0tJSQk9yTCXBaXynGSbuPOd2TMDj2QXopAKGZ4NTPSscV6QFZHWyLp8kLj2B5YRphX25ik0ICBjmqL6op406ZSO1gZhvTavJweenlu8pwGNCQMn2lo9xnIML98Rne+/Dv4W///C9g3wds+l4AI+/w7W9/iL/z87+ALnhs+h5d1yPljOM4YBi0eNV3IfQLgNTMEaFRLPS7JQhkhkcxGtiYQC6cz4SX5fd2XUDXBZlXLa5mFdBjko5s1sax/GRri2zhnrMlvPws7XErrbTS55pMdrQ29tKD2SqPs3PJjlWQ4YFrA5XPm9ZHPL9Pc2iVM02NSbvfRVLLcza64qmq9y9jtnNgRSNz+Q4NLxf1TAWfPqxlKVzAzvQZqrJphkabhpBVEOckDzl9+BG8A/b7rYQzp4TkCJypesygShLUO1gWjdEObz4nNZp0Ps9tQwnLNbNnnT/PJcdR2Rd1qopOYCd6ssKVhLfeegM319d49vFT3N5Jbb8p5+rsIFP8udxjNq8X5pmXH7THLm0FxmJfzI95nix8obTpBw5pTL8yZ1pPVAwK5xCCl3T34ODVW01lfASCL0W1PZHoCKGD9+KRZxblV+ZedISYpdhmZqvNVA0duayD81LoGwb+MIvXWgdu72bmqtywRgblnNG5jJhUX9OuMQIKu2Jg2T/xztpusX/WIppq6iPba8xgptKZp2yNlk/wfH7LBr64lm3KkH5Cn7AnPudkemnL85cy4BLoLMCEGp3Kn8xJyu3bVAxwrsY/gCZ0EPXQClgAKKmpBSRggFxWGdbq+Zc2AwOIc76iG6zKsQvz0TxjW4j2Mthj83OBnzVzt6xz0s53aowyRgSIyxvjFPCV471GdNbr1khYS5+qXHr5jMu1bVlxDUCiApLo0bMxt3NktYT2V1e4vrnGaRhxd3+P4zAAmcWZYfNIEFkGW1OJOM0Nwy7jEkEKKJ8pckqVA3FEWKABA0jyAJSba3hoYhZKWiO16yayvtOuUk6fx+acIJFQfdfBgQRYB0mEigJHmSYkZhCcpp4RfOikm1fKWn+IEDXKRbpWecTjhC5scJwmifDMAn6Q2tjwHs66RJU1cNpZrX5szybnuaY4tiwsa8HqAnZmAz0h9YNAIFcSypBTRmTGlKTAc07i7OExYZoyUiI4ykhTRFT5MsWo3ddEzpFzmlrmtUA1BORJ4rTInJFjBsgraMgC2DABUUGnmOGc1BOKKZb6QzFb8XWtRyQlkLQzGNfC1JzRARqYojIrSiQVkUNOjJhZ5tN5kNrVMUZtwEXaEZ0AcljqwS29FICQASqmlBeQBRDmPNOGa+j87BqsyjHmwEahhQbILSO3Qxqt0ArG26kl/I8X1y/XbRhBeSZhEpZzmlQBHgFQZnROwvSC88hMGCbGMJ0wjbcY4ojTOGKMCVNqBnKBLs3H8+js2MXlz+QKNT/LFOmLmFmrrE96LXmLnSNFoyU/NQSPvuvnz0BW6EsYjhlPOXH1EmpYtwUKnj0m19uWMV5YW/lq1ZpWWukHgQpYDaAqlPW7FkGWDrrCv3O+wN/QsHFafDgXPYApZKp0lHOX8giXefL8s8awaBVd+1+j7Lfnzy/LM/5sQJD8I01NMMMFxVlRxnIGmiyFJlTpnQ++NR8YKgeieLm60DwAUZHjxRPTGAA2kDMjl6h09yoyuX02quMntKVLL69v+/k5+FSjg0iFvAPwxbfexO//qd+NcTzhg/c/wIcfPcMHHz3F07s7nKZRKmrYPrxklF/4/BPF9PKAFihodZgXuth3T6bzAAoCBTEGPAhd3yEEj6vtFlfbHfrgNZXQlXWwttUZ4l3tQ0Df99h0HRiMcRzFYQTGcBownAacaITLQKSkxnmApeBIwW0BnsDVEOUkRkXWKG7b94A69SCKuL2rFoIvQCUKcGTOQ1HOazRAzglOo5rMiJc0Czk3piwGrwGYut6XugnJfrDOsE3NE91zxYxulVhweadnXy/W61PcCr+p6bIj4Hl6oO4ggtYbWXzrSNOCuPCm5T2W0Stnn9dPdDzFYkDRXC9ExRi3baMooccuaQl8tVE7y5/z69vnPPv7UmTVWYTO2TyjAbn0/dPxynj0Oq4FmOz+VitHgaMzuTnvOAbYO9GM48J4DPRt29Xb/MB7hC5gt9vh0aMbDKcBt9dXuDtYG3og2ryCFGSu9Y5yyrVuoN6fFEAWGUMlCKG1aVmzKuylNjBsBngZw0FlGSWChxyCD3CQVLDMUp+260IBAkLwJRKKOWLT97osEmG57TukKWmae0bnBCQiZoCj1J+B1vFJAr6kDPSbHszHkqJkHfZM7hu4U23oGnBhspvqypU1cRCdyqtziQmIaUJbd8tSr1k7iLFFNziHxIRxikhMiCwRRMSkUTkZUwRAndxVAZ4JsbFDhe9ad/AppvJdnCZklsiilKLsqcjIKUlKXRInHWskkIEzrLWQpiki6/wROXGWFRuY4b0Wqs6MMWUEZx3tnKa9CfBcwCEGpigpdb06RmKSTmYCODtMU4JEb8WXHxCi5R8aQigCu4q/wqeUWoUQqMCLfaevYrPxsAA1lBkUpfxyitpseNSMY6mgtcegNQpI9XbWopQRkQHPgC8IhhMUEoquOki6YtLiXW5xk0ZJfB4YVPSNZqitjonmc0hq9OxzBkrhMvD5uXZyMdD075Qz0jjOhlpPkQXxDC0GWZmzKZbBhzKunFnyUEuoYH1pa7G8uh8uTgcXUfs9p+8WaOLm/99rsOp5T/q9vdNKK31/aWnYXwZe+PwYvnwO8YWaQQtGx2xewZkAUYNykX5MFqo+d17YNWbGXbEV2wilywVq0QypyKj2elR/OFjJSS3uqUomyMK3a6RrmRM0fFwvmXKTwtQo1Cbg1CYqIdDjJN09gheebk4aH7wUqnQ6N7kZe+Ntd77G+ZhhQs1zFeO4HVOZlLncntnV7ZwtfrdrtvrF48eP8F/+mT+I3/ojP4ThdI9vP7nG++9/jKv9Fu98m/Dx7TMMKWPK1vWDi5C1sh8z8I7P1+nMsr/0uZ7nvVMZWDclN99XNel7K0nIQYqDe6kfsQkBXd9jt93g8fU1brY7bLcCEHntwOZUjmckEKrnvQ8dmDNOw6BRwxHH4wHHPCLnCG3PJM+atUi07jnvPTofJAXfBbm+Rgh575FLeIAoADmlCvhY/QmIgZrNmGvSe4q3N9d9Z/pn2e+g2slFQaXSzpgFxDKPNSsamNkKluvd7ZwKncn1tK4EM8EiAapuUEn0uWqU208xNC53Pvw80hKgmXd3nL94lwCiCv47WItrWb9c9WLnzrrYXQKHZtFJxQhRUKKE1FUbRwz9SxqcGc7nSm69rx6zkEfPo6VD2Q639+N551+Kvi0pNhc81RVcsnE2DhZyyt90zppuV+3/fyPE7YI143bOlbov280G19dXOByO2O93uLraYxxHjYqxC6EwesNyRC7VSCaxUWrUl6RnCQBhdP5EIr2t8HZ5xxfKCDlfQD7juV6VC3IEHzxC8KWNvUUBdcGDVUabLbXpttiEDoMbEYVtleM9AGRgQmpStAFyHpSksUTKGT25OnyITZ2MjxlwqOtqbdMJlmochec5aTPvvQemCPK1xbptJeedRBspH/Q+ABxnQGXKUjNpShkZDpkA3wX44JFSEiAlARMneNZGTZnhQkDOjLGLyGmCc4SUMsZpwhQFGCIQhnHQiB/pXuYADGOSVDbnkbVuDzkgxUlAoRhB3ks0T8ragYy0FJECQHqepLElxBS1EysDpHWUWKKYAAco+DdOk4I/Cc4xHIv9nWMCiEDeIWbZi9Id9mF6KQAhoBFu+n9DEZe8iE2pLQxDFa9L/FP5Y8F7IHiHMdwSbk8AVT1UQMbZ2CzSRz9oAJ/ZuOrX5WfryYRugsCyaMRSfZzIoxRkIwKCoIxgKVyVGyFy9ny8uOH80SsYRJo92Cim5WpFMW9FU3OAKVstT2pvzSjeUpu/dq6oHaOezSxFV6UoQ768fs1DkRYZJ10rMyxM0JvQzgD4PN13pZVW+gGhpWEPXDD0Zwo4UIDzGZ+pgmHmBKAzdlfPYAas6wNMVlSjgYwhGjhw4SLnDgcHUG7u16h/+kvpANbw2BZcmskcNIV+Wc6WbsVqsDpRTtkKIML4ucgIcoBj0px4HaF6cb13mvIr4ilD+HhMCUMc0UePOAV0zoO8qfGi6AciBAIc6/25Rn6W+c15Jj/8Qv4T1QxohlzLntkcMWfikNu/G2UAKAp+AddI5MyP/cgP4Ye++BbeeuM1xPgIfeiw22wQAnStGIdhwilOmKKmOSnIkM2J2e65WWQAHlBYmrHovJEDnjy+xqObPe6efYwhRlHyWRVeq1mg9xGnGGGpN32nZHs5BEIXgOCkFmIIhE3ncbXd4Hq3xfV+g+urPTabHp4kbSN46VKTSdIRtv0GXegABqZpROeAYRxxOw0YhhExWuFMIBAk3N5LnUJHDqEL6Lsefd/Da7QRuVojwxxMIQTxxOYK7liaGGDRP9otxvYwiyEi9aGS1iMjTQ1gQGu8iMc3azqM7l2NFLF7WOpZCTfSPRWzRBfkxvsMkAIK6ugyAIp0bxRAQvZrMaR17YE50EQAPnw6/MYW/QeOlKupcjtPMaoKqhnwszO5nmfz6/R6TjsycfGAVhC22jHadp3mlYGEHzDIJaAp7LwEVT4JxGnPE3vG0tXMlqj7TLhsXAqd5h62x/Ls7xYsFXky90rPIofsM2D2LJdS9NQKK/WW6rEZzAlSWFjqLQk3M35dx7tMxVtGY12MWGIdodpzZzPsCOQ9Qtdhs9ni5uYaTx5fYzidcDoeMI6T8gkZJzMB5Ev6WY1onROBSlQZGVgkg5YIU2/PKVRB/xp5ZXxDAJSswQSuAOJEGd55eAdk0hReBXCIpDRJ5zps+oBhHLDbdJJ2hA16T9h6woEyJADTIzjAYYL3AInABiOB3ARyHoArXcyIHbJoQUBOyN6V1C0XfGlJbxJQZFRCZoKnTrJxGsndOynEHFyAgW6szNGDEUDydpHKGliqmciFzEBMhCkCzncAOzBNGCJpRzORnSlHxCQRaAkOLkV4R4gpYIoDOhcwjhHDOGGYIsY0wvuAmKSeUcoRKUuNnzhFcUyogyBoVFvMWXh8ksLQMRPGiJIuxjkjEWHKjClLZBbljClFTCmCIyOZzuOAhISoxbXN2RcnqYnkvEcsjSky4Ej2aErIkC5kefa2ntPLAQgtFDlgqS8tmaUcbaCRXaOcC8xblKIq0M7YsyO5TkEvaXYdy/MmOrs8jK+0Cn+Df5TfK+AigkNkAVdhAhSN1pQfqEJqCv1FWuIzF5mQHsM6B9wU9bp0PVcNCVNil5dt60/M5qMxVGzijH/zclIeGMNDx9lALNeYIIAPoa7x7JwLXomXm36Dmvt3evnfTFOz0koP0LlXcvlTFUTlSTN9sp41A0Rm3zQftKnE9nNhPuhxy0+WY770trdAEorzIMuwG7AGYqySyT/MxtGCQ87qsqA5tlWWuS02igJQOSJ0vagE0xThuBbjNl+F5btDx2c3TRoWPcUoni3uEBrF3TeFKolqIe9SpBgk9XhsuG4uw+Yeb31OG0MzD+38Uvm+lQkyaDbBaNdSwMsRofMerzx5jN1uiy4EbPoOeO1VgDNinDAME6ZhwtP7exzHAcdh0Lo3jBgThiiRrFpLsijzrWOoWf6zTcEQPWXbd/hHf8dP4AtvvIr3330Hz4LDECekmBBjxhgTxhQxTJOAQ1qI0hwjFff6zmWMOFuAEKTgaHCE4Byceqa9IwTvsNl02G967LZbrREUSs0KOGDT9aUmQ4oRQEbKHQ6nI06nE6ZpUqCkGo6+6A3iLd70HbbbDXbbHTZdh66TWhibvpOoJEZpeCHznovHtYBDCtaknNRLzBUUIjTNMGqhT7B2fgHrGC2KB2CWlnYpSb2PlBIim1lT6ytaqoOMR9cm5eL8q8BVY4BbrUZU3pO1yxWzGJXZjMmG8T29m77jdf5BpPKmz/hqfdGonbdLHHnmOVD+jMqH2ro37TkzQAJBQBoW3b6kJhljm91rDgotr/UQzWSgMktafC+2BmAF8C8/6+KccsFKUhjanqWdW+WnqPt+Pv+XUslYiwmLR78e09p4xrkenoeHUvLa5zqrOXRuLpb7S2qV8Kqu63B1dYXr6xsc7o+4PxxwPElko0TxLepRsUXS1vW073LOxe40G7CV4I4aJwdXfWBpxpgMcQVolOt5J+BMCEH5p0fwAcF7jJgketOHEmU5gNH3HW5Pd2BkbPqALkja2DRMSJDIHU+y5lbDR7I57B1idJ1DTgI0Jk0jMwPRabFwYtFHpBOX8UUHR9oZrVHMvBZW34QOPEV9HtM9nEQPOwfSum4hODjHRU/KmSWljyQNb4wRgaQtO8hJlM80IDEwxgg4j8xSGDulDOeBrgs4DSeJpPGE0zDgeDohagR0TCOmFEEkXcUYGQlcClWXDdYLeDXlhJizRPPEiKRFrZOu86SLbBGz4rirEUOZmwj0VGtUGaiYU41+sHkmltpDzjt1VFlHzU82/l4OQEjJMG5hvucMuwhHZciX7P6MRoGkGspvYIdZAKacG7BQbtOAHVWp1vO9bFjJ/5OVSjwfh4EUM+NAGQWRtPKNLiOFyhRaGcHMJdcUTbhhYbQLw+dBovKoaB/PxnbRYAFKSHT7/EXYKD9tPzcea+816xwYcGQDr89Xrz0zsZZy6IHnszkweKsW9DPGLAP4jXpIPw1qUfDzB/yUBvzJPGAlpRdVxFb67Kg0J2qEW6uEGqA9V86bEHya8yIDuUXpaEO05X8SRcrnN2peY0ZlgsVowJzXUcMr7X7F7myVv+Zcu11e3LM1TkwZda4aodYG1f62Z21ZzFwhlk+urq+x328xjiOOxyN8iug19FW8bqL4tM8kYI/IqqjtXKepQ+xT6SzDzFLDQGsJlAEUDRkoXmh3PsVLMGgmKpo1aXE7UzzNmGtrd7DNm8pkS1UGTEfImLSQKOeMzW6PHCMe3dzI8w0T4jCi6wJuDwdsQodxGgFIg4Xb4xHH06AdR1C6kWStW4Nc9wE3Y7aBE4Cbqz3+uT/yh/Hbf/xH8P47b6OP97jqAk7ThGEYMU0Rp3HCcRoxTB5TlIKXKTKmmDBqbb+cXtzANDKDxAeH4Bw8iQFQ3o1sSqYAPF1w2PU9trst+q5v9oUAOs5LhNgJDBoJU4y4vz/gcDxhnGIpMtuS0w0mzSo6+Rc8drstrvZ77HdbdF7Hp1FCWZCaoky3gFBiaYzBBgoZMKQeXKlTQsg5aoFSWReL4JnXBIJ4XlnqRjAzEqdScF2MIU1VUzAq6lhSStp2WDZ+ziid1OxepsuU1CDSY1DT98k+Y8BaVTu6f+E1/kEnLnvKeFDlI5Z5IJ81SqoSKYprGiagkekFTJbPl+DDLGJG9wAwT/2R7+Z73VKsLj/H+bs7v4/+LF/aj6oXG3Jvz9vaPQVkbJ7l/HfXzJcWA0atoEcqkPjCnFxOx7Oi0gypFWT1jZbOkYf51qXxLn8+9H2ZL5O/mTVq1WSBQ99vkFOWNvT3B1wfDjgcjxinCWmcp3yZfmHPYGvJyo8capOk3OYTAxJx3Mxb5TPGc+fPXOSW3ZkIwXlN05VaOX3XoVew3JNDVnDIUsYcJCUsMSM4h74P6Dxh2wccRwHJHUk0cND6izKPTh07ChR5IHGSDmXMpbGA2HsOzYOIHHBSay6zgBc++NLBLHjCdtPDEWG36TEOJ0kdZouE1P2mdeFII2SQIwgafZMYSesIcZxwHCN6TCDyyCzpVcM4IpNEPzOp02ZK2G2APETtKBpBBAyYcBpGDOOo0dISITpNE7x3iBrNnDMq2J9TAdDAQJwipii1jxjSiWyKEYkAyhLx45wrcoEoaZST1BRCSQ3MxT7nzKU7ockUAqRBlHZIIyY4lpjGKY0g1NpZzyud8lIBQktFsP1cFOMm8/oC8twCJiIg58q4KPh2PgqyWBXMEtRWC4VlC52WnEwJm3QSKp+hCvAkOXo4L/Vj1CqrrBso5gzPGhqt3tN5CLxoh4WPcb3G2dwZ6DJ/IKGmXoPJyPaSM57bAjYXAJ3ZsUVIyJ8OkFDxrIqTzqcYOOcDXxopyzG09yk/HzjHvBX1Ni+uAH+v6fm1ing2+dR+/rwHXOlTp4cUiZVeDiJUnn2JZsD84vOW15zxvHJcq7TbeQ3C0Pws/LzpJEbQvxdjWY6tfSCmcz5YQCVuvZDy8DYHEtxChec6MiNSji1RGkXR5Pa2VVbqfW8e3eCNt94EAByPR63RIsoeiDCOE+7uT9rZo0nVbZB/yY9PmKLIxODFkKgyt60X18irRoYsRdcs3VjPYW5qU88Ea5X3cmQuc2ILKko1CpAGSE0DcnXuCIxnz57h/v4ejt5CFzrkfoPr3R7TfsDw5DFOx6MoYgxsuw2iekr7vsPueMCHH32EcYqipGZpKGGFIkuDBDNIGNURw8Cjqz3+6B/+Q/jpn/onQGlAurvC8eYGANANAzadR4oZx3HCZgwSlaUeTCnsnXCMEup+GiJiZDVY6jo8jyTFgOE91a6hugA5J+RESDFq59AMBiH0naR0hQDmLB1t+r7oNeM4InHGOI04Hg+4Px4xaAteAWlyXWY1INprwLqS+YDtZoP9botN16nRovUXVSFvwSBiUfoTi8JdOrzE2DSukHB6uYamLIKRYiolCkrx0OIAdOBUr1lI91hWz6yBP1O0dsNaCBU1pW2KETkDU5LougKSsgFQNWqKipbapPhwve9KQhVUEBBjCSrXnxcACJZ9Q/pZqTF6Qbu/BPQsI16WIMss1as53z6f7afFvR5MkzLFfiFnaPYRN7zWhNaS49Z7GQggwIPT/UYA+/leYwA4r03SRt6087MERbjUgKGZE6E95yGpv7z2Q3rbg/pcsZuss6S1ZGd0XY/9/go3j65xf7jHQYH+mCr4A0bpKFieGY3rlyv/XN6/RMoySnqcDqU8cwEx230GKilhDoQuBIAZQXlgCJJWa0WkyQd4JxFAG42udE7q2QTv0HmJ2PGaFpwStFYbwVOVoSF4sANCSui6Dp4ixpTFViaNfuNcI4Gbh3FegQ0AzJIu5Z3XAv0k9Yo81b0pZxWemRkIpKm92QQnAN2nMeYaKAIGE2EUxg9CQkeEiRMGySNDZK3llq2j2STRTgCmUbqlEXkcTyeMSWrxpJwRp6iNlLgU7DaZMiEixgnOAVOqAM4UM5wnZI6i0xGQOGvgh9nKXNbZZCJR08EO1PAhLbFiDgSbMUaJHrXvzNlSZQk/iCEALwsgZGNsmbiuuXnXznS/Cxp2yzqIrF6Qfqb8sv5tGKu9hCpuVRG3e4hCS+g6j67v4X0AUYBpp5wThnHAMEwYRlG+crEOmns2w5VwZS75/561la4q/OJJ1a4d1CobzXOaPmu3IcA3c0nNs85bsDQThapgY/6x/O2qp7nep63iX40L7wiPbvZ45foa3gWcxhHDMOHjZ7cYYtI6SPVeNkWzZVzM0+VBoe7+M3o5I4MKLZQS2xd1Drj5+d09yMMhwCu9KF3iLSu9fFRBm/o+GVhgkaJAZXktJztzJrS6MaBgChcFz6hkGTV8rFyqlV8g9f4Bswglux9Q0noukdWBKdhGQwICuSK/nKPG+aFFfVUI5gJqtYCA3FwUDmCz6fHaa6/i5uZaa7okeO/RB49dv4ELHrd3t4jxPTWkoYbFwiPMkmoWOy2ImDqEUFt5FyURDSCEKqvbtbTHprp4Z2BQLa7aGGKNnDeDzkAgsKalNdclVtBD5848xHe3twCkaGUIPWgnER+74YTr0x6vPHmMYRzBnDFMET5cw3kJY/fBIY4j7g9HxJSkgCQLWCapZfIcptwqvgAGEEKH3/Nf+l34Xf/Ij+Jm1wGZcHz0CMfjUddPajFFJ2Bd3/lSfHKKcr1xHLGJEQcFdI6niCnxw2LzAjkF82YGl+o7KRGmSVLXmEnStRxhSgnDNIlnOgSE0MF7j5SidANLjHEccHd/X9Lcku1PvY93ToqShwDvO4QQSrfSLnTwJC2TQwjoNxtNaZOC5cziLXUpIWh0l216SxFLKQEsIfpmeGY2Q9kDyNIxB5omVuLWLf1F0ssAAX1SFCCQ2zfclG+rNwIUYChDwagkha6la4zsi5gk5TLFKNFCUTvUZCs6bZqwcDLpmChpZ6WI70qwtRJqeMOMUc+BmJYK3ylkQEh9D8qxzYFzICidff+8lKZllNHzooKWJCCWRkbY88uPhj0yNL5MPz9X+ksEQTM2ibCk8o5ymQOqN7igt18aa2n1zrUNvLMOoFTfP7v/MmqKLgjDT9LVLkUPXY7oki6KKXMBUqwY/vX1Na6u73B9POBwOGEcogC+9txE4JzmRmYxcNAoInR2f3CN2ILKHmue0z6jrY3IUAY5qdnjlBdyzlrbSiKEQghlvwYf4AnY9FLUv+86AU/IY9N16LsOxBO6PsCPCR5A8AGdB5zP8C7Chw4+BKTEGhFMcD4AaaqNgUh4okSF+sIXAYeu62e2jq1tTgKMyHPKexY1DcrA95RtSoXLCsjhCqDmmDFOEc4L4JQUMxhiRkZEcB7wCdM0YpwmwAckFv7pGPDkMUDWkECIkwFCwPE0YCwdvkSexGg16VQmaOva0j5e8/2Zod+JwwJJ28RDAB9Wpc1SnHOWuWOdt5wzWIEoQOs1sljkTvGBlCqfqQCs6pzqlOAGKH4oEtHo5QCEcEGppnM+w1zD513zzrXnudqVrhaKRqNkMmQztZ+Vn6Q8ThaJSfwxPngE36HzAaELIN+VThqOCDe8xzRMOJ4GHI4nnIYRoxUQxBz8MCVcFMQM7xJS8nBei3CRFIgT3iLCRUpLVwaj+nzhO0UBzs18mFyyuVkIscL02+dvfmcTGnb9ugpVWOp3noDOObxyc4OvfvELeP3VV7Df73F/POHr3/hVvPPu+/jo9g7DGJFYC5XSYs2b8WrJpXqPZn1nG8IEBDew1WLTmD/NKtzXOWiPo9mP7yktxi1pEdXYMyUTsHDROjGz8eqxZlKZcCzhxqTgJaG0toxcwzZr3rIWk0UVNNW6baa7KCpU9hmpYtEaba0yP1/IdoKboosLgHEpzs+X4NKivKBV0x5K7Z80axM+7+jEdV+VE7l+94ljW+n7Qc7V2giztTXZNxMO8rkr/IwK3wRDO4dVBdmJo6uEeVeF2O5TNEHlI1ydGDD9uxqIZ8o861VovqPKmFDKblZ9Ut9tYpFrvo1oIf1blUXVzfQeDik192ICQ4o+Iksk7PWjR7h59KjWh1Ew6JUnj/DaK68AILz9awxO3y6vR2mT29QoYkhXsiklxCkhhghHAT7UDiTkpOAwpUYRtuUyntiusz0/7Dsq3U4qR1PHhQFhZjTr3yXyl8yLaWaTrLV4CAlWuw/MWvdFQINtFxAdMI4drm9ukLNEdcQYkeOE27t77PZb7K/3ElYeE077PTiLospZYAWJ4hHwJmsIunmbJbqFsd/0eP3VV3C17bHpAxwCHj1+jNMwwCJC7u7uMPKougyXjludOIqlzs40iTxwDoQBw5QQk9UWqs9vSrqBTTInWqgTtdEFmzEIRmbS9MEMgocPneg+fAJnxvX1Fa5IUhSc88gxgnPGNI44HI44nk4SFQPzbopBIekLHfoulBQD772CQUGeKwR4Lx5y5wk+SN0igkQvyf4ksDNvqPz0IIRgtRQyghaKLu+e7mdXXx6VkzVSBLAC06LoT9OEqG1+U65FhAs/6Dr9SBV8vUaMUSOtNJUti7c5Jkm5lPQy3StRalCYwWDRVAAhB0ZOUTv5NXrZ554MuKgGwMwIf2CuHgTUGoXXZE45tqhOorRaW+zMSXU7KsbrktqULLuNpJxU+VK43kyxB4y/lWci07GawtBkloIp8VwKOdshDq5EqS4jluqYM7QTgbY/t7nQaytzVaii3F9Snubgxnxaa5qZRSLJefpcyCCEZh4+mZZRSc87xuauzuP8fCLpkLjb7fD40SMcTyfc359wPI0YY4RjTcltisgzs9hhzRJmzvDkz/T5Mha7uf49B4UuacRUeJJzTnQFixhyTmsGSQ0fFwK6sIFDwmYTwPGE7XYLkPDtvtsghIAcE7pA2AThS84TXJCoIAKp82GDnBkbn1RSeDAJ4BG0htuQIpwLSGzcXVInHahEycpDeDB5xJykCHazJ1NOIEdaj1D4nfdOrqn11pgTmDoJrCC1nbLsmJwZMVtNN0JyGZkSxnHEMI3oOq3Nnxg5ExIluJwwTRGj94jTCE/S0GGME6aUUGoLQGwiQGtDeVkrcoSkgJYHNFW7Nh+xxgSZJZI35wxPllool67vPUrtIG+AASk/y1yKoxtAZgEkFnksgTCSIifp0G7uNHjOq/RSAEK8+GNuTlbUS/8s5yzfeaJapJJVMYApxtCXjQkehNLWTw10QF9kEFjTnqBhxD5IDrv3AcEHQNvhBeew2+7QhQ4cGcfjEc+6W3x8ewc+DZiSbaBm3CI35EVgXzxXIXtQkINcdYGKgq97Ql6sZtKM5yuP5natF8bQMrLHDmmn1QwMoAGcmrmdLVOrwBOwCR5vvvY6vvD663jtlSd4/PgRUkp4tN/htSeP8avvvIN33/8A98MoyqQiqcvgWMLSQG9vev43aaij9zVv15iG7CXLt7XnaEM6Pw0NqkEgzDjRuRIQsU23UKNE51mUYNlbRMKEu74vYfvel5LoRVnNqTFUtVOLM8blgs5HFcoMp43dtG5BCbHPtVOOcih5x6qgKs9io+cq/hsTYzEPy08MoPukOaTFzxenZgXOL2l/UntkQ+V23929V/p0qVXeADP9qzzIpoxdkHv17wUfVHCpjeKhxbrP93mlxvk344kAFGhqx8lwTX2z5TXLNYAmuqjyXq+GgXMEcprqBJQaBRYJ44oyLnf1jiDYhilTKGHYm+0Wj588QWbGMAw4nU4gTthsNnjlyRO8+uqruL29w+2zWwzDOFNkTa7WiSBti5q081YC+yByy7ny/hNxW8+58McSQWR8haryS1ofwVoR2xrX21uIut3F1TWk8r+iBwBAJi6dUhw5OM4CGDnphnU83hf5G4hws9ujdx6OgRwT0hQxHE+YxgnbTYfr/ZUY9lcThmFAThldiKJ4ApjihJi8AGbalcqnRmHMGR6MHCXKJniHfrPBVUp4fDwALDUDokbnBJZI48QAU1alWgt4e4120b0xThlRFWXbcTGLQZMzNJpF96gHOufRe6cgpKytvGNaL8IF7PZ7PH7yGOM44m4YkHLGZrPBdrfTmj1y1jBNGKYJRy3QOWkEjCnBzsn6+tBhu9ujD77IP+dlbawehrcaCWRp/EHSEVj2jdf3ooJsuexXZl8+c9lC6eVnKfw6a08uL59dq73m8XRE5IQpR4zjKMYZeZk/56vuZgYbQVLbSIqW5yy1OlKSAqMigwPypkfStMsUE1KKpQBpjLGAd5lZQSlph91pishKRouiv/bpAgwAUKJiqsFe95BcyaE15kUNyrNrGuPOWuujBV3Oo1GXdXrmnxsQQIVvLZgdGG1NrwrKAJYmu5RU8kljQJh9BLV5HtBzBD/PMMO+gMnaNatodeQXY7RD2+sux1UdnFU/o3qcKseE8319KRXt0no/RJeisAAuUR/mGAnBo+97KTC9v8LNtUQJHY9HpJi0bTjK3LSRGuaEFY7Fzy/qa/L0OWM3gNscN4EgtYK8kyLQ3oGcQ7eR9N1xSvCBsN1ukJPUvJuiw36/xd3pCPICwBvo773Ui+t7j82mhwsM51kiNENE5ztMLqJzETlHTAkYxlieMTK0K6lE7lhsZc4MOIlwTArCO844jWpzAPAsqVKe3MwGiUma1wsQUtNsmVgiT5ngSOrmJU0lI+dK5GXOUr9wSnL8NGXkPEpAHRNizGCSyNyUEqJLQEpgL3ZjLlWdaw06AiElhhXVTRB9JlktN031Z41+A0gbGNSIIjaDnqA1uebrLFlG5tBH0ZHADb/KWRoUeFE6M1iaLIBKAfgAqExTmeoDHD3cjfKlAISAaju3H7QhUEu6aFRyPY+oKvWmFJVwehDgfHOCHKUpkDLpJAolIQM517bqztrtUemq0XXBoiAROeMwjjiNE0i7WBTZYLxP9jemlAQg8A4xJa250DC/wvTasEIdH3AW5VCFEM/mUpzoFZgo823f07nIMZBiBig2v+fmIqQK8ng6ou863Fxf4cmjG0FsY0SaJsQ0IueIoClk4zRhTOJRTotwdtI8y4I+MGrF8ToUEAHbTYcn13tc7baiQPcdcs5ScPM04HAcpQhnTFrnySbGzYCnpQH4GycTTtKppfNe8nWD19oMstayN+Ul70JXlNzgxMOarDBlNg+iGFrZKpPqnqnKoDAaKU4pzLoECjULmbMWKqMARlCvp+WwzotoFlRZt5XViEpZGHrKtZ4Bz7ceqinRqgONglYPwuxMBmpbO9Q93egP8yu1V+R6DGFWh6QoRu0Hi1uXISjvafW5lhdd9qat9GnSMgS/JQEe6u/L71rAvAW7WYv3kx13SbjM/rb0Kwt1x4zPt/vZeGgBixreXNXp9vvmGs2tLTrQaZiQqdKOqEYHkTUjqEq+gGTyUIyqbGRIm9Lr62s4otLxKaWEbdfharfHfrsDEeH27g4ffvRRNU1co/Q2Y7S/o7ZMnWJCCAmUgZxrFyjxpHMbXFSuYWHvNR0tg7IcDz9POWNiNRbq4llUL9HcaKj8WI2IMt9UQPRqJIjyPo6jrjXj6uoKMUZt8Uulo9ppOCHGCBc8+i6gCx5x2uK03yOnjNMYEbWDVUxeCj5PE8YYhc8Wti3OgOC8AHhZ6ixs+g3SLmG6eQRmYDie0HcdTt5jyjK3VtTT7DXnHHrnQNjCO8Km76RDShSlNKtiHk2JZusepwWWvUMgD1IwsbBUBey883j9tSd4683XcTodcR/HEro+ThO22y02mw18cBhOA25vbzGNI57d3uJwGjFql7TmwlLwtAtFVgQfJB3MO02JYIA0hcs6prAowN5p9IKmTbTGvf1tQFZpEV3kZa3hWItl53INq3nVGuvDNOI4jLg/3OPu7l5kJQGOvNajkigj5x06H0o6onju5V9wEj3Udx0YKDWPGDW1zcYw5fq3tTAWGV0/l7S6t7FSpWXES/t5a3zPgRgun0H5bet8MAhFjqlg4yyahixCCTNhstx7FZiKzbjmYxLFt9bwsojy+lgvqLeaEGpspPK8C92lBTSEqcxTx+qzLmtRoIzditeyRqE6i4ZAjWAnqvMgkQ7ttUz3aw2Qev35HP3GqQWT7PmddlWU1LENbm6ucTqdcDyecDwekFPCGEX/tTldjmupI7Yys3ymM0NYnjPP5CgOIKcF+x0EENe0MSJC3/Xouh4h9JimE4L36LsOI0dxqhDB9z3cNKLrN+i6oLyqA5GD9wMCZW3nrrVykhjFUvRePBhTmpC4Ri/GnDCmhMRJdYCMzAJ+mJxtGxywytWUo0SfEiBF/TWV2gDvZN3oxO6WhgDCb2OMpYvZqPXs5FgBSiJnIEq0smlbKUm0W7b0LWYwU2kwwCzAE2txyKy2vzmwalCFOtmJtLmU1oPKpDF5WvSaoBG8rT0leqClk80dDhnnEREa6a2RU67BCIyfOC+p6n0IRU/L1o4bGmzgZa98+/3Dg+/BSwEIXXqlz9Fl/Vz/Zwq9vSTNSVIQzhQ/1EkrdR1M2Vwg6YzauYHICmF5MCAePw3V7YJ44OS6qkCyhJnHOCpymc+MkvZG4jEUEChZeHBycMFVQ0E1PHIApQrSMCRNq/DyZWocz+ep/Xdpzme/m8HNjfHU/Cxz0xyj4g7D6YRhOGEYB8Q0oQsB+/0W11cSJTQOI3LMOA4jRh8wpSTKYcqF8YgMagz6xuKYj5Nwc73Fl954FW88eYKrrYSaExHuD/e4vTtg2HSI14wxRhyOA+4PJxzHCWPMTeV6bqy5S5bgd04EAJrW0XcB202P3abDru/RdxL+7hUQspa+zjl0mvtrqYtxijicjtJimBOQphIyGChIG0YAwUvNhmpMyTM4DWe3wpiZMzx8jS7SQp6ZK3JvXlOQ1WQwxif5vlarQRi61I1gSL4qZ5bot1jTJa2dr0Y7NoZzMYWLQavWJlKsra0lmmkOONl5lxSC1qAvW8c1e1+VGwuvrPoQNfutGu0P0YPv9kqfHlE18Ey59iDNk74gR9tTlVEVM7RZv/att31SIo2aY3WbnH3enrccr7GX5b1aMAjQNLXF9SqvVZCHah0ecWyIJ9s3qD2h/b0qV6b4iMELwBG2+x02mw2mKPIqpSTRGF7q5Rnw8evvvIM4jdJ+nQhd3yGnhGGcSm0UUaTqJEyFr4t6JEUstShjqh6xUuePLN3V5lgcNCSejpmxZDNJNqONgHIFATbZ1ExG87fUx8vFuVM6e0IVe2acDgeMw4C+79FvNnDeI0M8cTfpEaYYMQ4DokZDdV4iQ673e2lbC8AfjiUSJ8aAmCI2XZComXFE1BbkXhV38ZAm1TXkOXbbLfjmBuMwIISgCn+AS1GUQU4I8LIWRLACsH0X4Byw2/RSoyZay/UsY9IZMUU9JY3cIUIu09gAaUTofcDN9Q0ePboWoygnpBgxTdLyfLvdYnN3D+cCnt7e4nQ8IrPoBnd3t3h2uMdpmErqPzOX1vJd8PJuSMgSCE5T/OT+LVBSWuyaAZfrPBqo0xplZuCHEMp3BrDEFHEaTxg1ysmeN6esgGtVsI7DCfeHE+4OBzx79kxT/1LZnzYeSWmTrj5EAvz4IB3TgvfoyOokqXe/66ocMuNA58K621gdIfN8WzqOGRteO/asBAA12uNFgQMDkcUNXBk9qV5SjXP76Up2ATAHKtAcaYbk0pkxc+CiXOYCsDDXSy8BDjb2i9cHoMELRaaQKj7yip8DLC2QXqPLMfveIuuqRJt/Ls6LToGkcjkwWQ0YTYxme3/aSIk5v38o2qulc13wk9d9BthA07LBNXMkeGTusNls8Oj6CsfDAddXe9zttjgdT1I82BEon4/10n2K3J/thecXEbefzlV71msmQQhB7EEvEVrCc3p459H3G5D32G636DwhdB3ypgd5L5kvTur8pCyy23ghAUBOSBMQ44Sk4H3MGs0IbZIwTZiSpBNnsKYoZWn9HiUiFTqnCeqIyAnOeyS29FeWbl/ZIemzxpylO2fJbBCe5xhackQ+P2WLxnMl00b0H1dAKYDhvTl7BHRitsLLZqNT4aOWvRFThIcEapCm8IkaVsEb57R+EKPIkrZbXc5cwKA2UtXpPWEAm+4KcgzTUD1JtKpkjEinTtsH5lSwTpfSrU1wic2mL/phSlHrO5HoDF7gnl/6xvsPvg8vBSBUeS8tmJp+vQQyTGG0F56l/g6cFIkyg9OQyQoO8ayuEBovgeWG200kZDDAa0FDVqM1xghSTxCzhPHGKLnep9MJx8MB0zgUg9Z4WvsspuynLJs2pIigBnd2eTaGYifrv2TXaObNjGkD0co5Nq+Vt8+M8SWrvGTgtMBQ0b3159I/YLnxEtqeEYLHZtvj+mqHcbzGNEYMwwh3d49NklzVKUWMMWKcoiitWbulSA3KauBzeydG13t86Qtv4id+y1fxxddexdWmA+eEjz7+GHkakTcdHEmFd09A7wiPriSU/ThMuD+ccDieMEQ1JhUEMJvmk9WHS1SFc/ASQbbfbHC13eB6t8PVboP9rkff9doqUhReARgl3FMYScI4RgxgTJNDjKx7XIUCORDM2+iw6TtsN2IkdEEMC3LSOUAYl4bKQ9BnY6jVI5pgHY1qC1ydF82LJZ2jnC3hDsWjLL+rBwlAilYUTnLiizICNEW+uBg9bRcbMfj1d3JIjVFiebiy17Ma7RIRIMCVeNWnmFToSitsODEug/OqSAtoZYU8c0qYJm0LzPJ9G01FC4XN1vi73SUr/QZI95t3lpNflY5GJ7sI2nC7jISL8uWh82vtLj475hIRWvBzfu9LwNUlgFH4+LxWkCmETvl8AVNRZV2rfCbWKEwFdzPLPG36HtfX1+j6DoAoUzFG+BBgmFLfd/j4o49wPByw3+/hHGGz3YKIsN1u8c63fl1AfEIBMULopGDwJJExMSl45yKOxxPGcdRunQCxAFp91yEpKGVtkYtOoHNgQO3c638hRYbqWpUfRKalLXQJ+dsTlYhgi77yBBzv7kSZzRIB1GkdA6ssYwZ7Zsb9/X31Am6BfdprS3WpqZQ1EidGmZd9yjieTjgMpzKf234jIAdbipl0wtptt3AA7u/vsd1u0fdSSyeMDpGkDTBzjY4xz6Ajh466YqClIGtcwHCoh7SJ+IxJziU/V2RtHjehR/CE29tnJdTdQAsiwmkckVLG+++/DyKg6zrx4I4SKTTGpEXJpWW7DwG7zUbqJTkpEC1Fqd1MdzN5ZYWitfeRpHlxZc3VeJpHYdi1inOQRA6Ow4Cnz57h/nCvRUNFzplc8Sb7GBinEYfhhMPxiGe3d5LOwI3BzDy7ByCGmneyvl0XSpRZpy2Y+77XDjuSngISo47smZ1DR1Ra0tu4s3bfkfuKN9rS5lda2AxnQMxlg72mx9tnpoubsBCmxIySRtlG05ToQv3OomoAlLowdq/FaIuefR5ZMv9Zom/K/R96lktChsrPmuxr9Yvqddt3ptynHe0FUOYSOCPiuU0ONmBLk0mZ1JiuEZ02H0SX9/IlsOUSvWjk0HK+OVfuSETanj1gs9kgx4jHN49wuD/icHMvUbXpgJgT5nJpwXfs0ZWsPHw7K5epHmV2nofExFpkZAhBC/FLSZPNdoNN3yO4DjFmOO91H2fkOJV01GmaYF0Qo6W8Oif7gjNO44DotG26RsAM44QpM8bEYDiR7YwqCyG/p5QlnVZ18k5Bq1EdJ4EE2RJ7T2qv5QxEFrshJal3x5D6h1OeBJj3UmIlxgiAkb1XZxiX84iktpzMntgyrkSZOT2uLaGhjnPTzxgAib5EWnyjpCAD4tzGfP87yKvlmcBJ7QfUbl+BJPrUkRUFF8BH+H3r5ENJ/XMU1M7j0lDBxkKO0PcbsIJ4IbiSfdJ1HXJOomOx1sEkTQf0XgCk58iJlwMQuqgMV42dFocUMEIXyi28hECt0zK7iU5OC8oAKEyPkWvqlVZOt3+G0KlVi9B12PQbAYtyxpQnjNME1gXsO2ndGrWIYW6f04YCMXJTApITZU1eYIvAMIuiKslefzoizeOFfq/CoQWebEoe4jiLSV3yUHvXbK5m37OMJdtaQYwCD8ImBGy7Drt+A2Jg3G5x2va4ud7hyaNrgGReOvIYpwlDjDgcjzgcj5Jq4EVITG1KWbZ1khczpwxOCdsu4PHNFV65uYYhtYfDCdMk3XCIEhwBkXSuGQi7Ho/2W5zGEbeHAXeHI07jhMZxvRCqiwmcgVMoxqUdLkUvpW2jA0vRbe9xte1xtdtit9lKzj95BB+kgJu+pDlnjOOo7Q0TUpJaAsZ87R6Sstih7wOu9lvsNhv0mw12mx6brlNkuQIpZa/Z/C3D45MrDNSYmQnHNsfVmD6Vl7Ld1AYYyoRkRYKGQar7Z5buLvYvk3UR1OuzA6lX1tbaU6MIETRPWgrjyrPpnu+CpCgysO2C+iMyGKEZqzB0ZoA3AkwlVqU+y7ViyppeKN6LGKOeU4VO9Spc2hYvprAYV2tUoHpmUSZe8FKfF+IKkFhEgBTNk6+XcgKY8/nZpZ6zTBUEqmBCUYsbhLy99uw+F9jGQ6CT8Y0ZGF9+tsqgnSPvNakMcHryzHDWAecmpdO6XzAkRbnrOzjvpXOIKojjNIHGEdsuIHQdbu/u8M473wLA2O828CFgs93ilSdP8M1ffRt932OnTpPdfovtZouPPvoI737wAZzzkEgVAM5jHMVxsttuVZqJGvnK4yf48pe+iJ//+b8jxa/N7kJN33LO13DuBUhwyVNeDbUMi7ctHTOpWTxYajgKEOVUoQzkkOIkEUDThM55eZauR+ckNDsQScFkSOj+oNFCSE6dRcJbJuv2kRmgrdTtIcbm2MPdip5xtd9ju9kAAIZBHUtTRAhijIAztrstdrsdNpstgr8vUU1ibHKtO0XCWZyCK+bhnOIkiivMYBMdImv6mHgfBZjJzGAnoI1d1OZ+HMcz8NG+zznj9v5OQButw+GDR5wmjUQznQ0lFWOzEY+2pEKQyEOHpkB4lQcms1KqUaztGHxj1LYpOvKe1ZcwKxj07NlTHA4HATbVgLGoNgGcXE2JmCachgGH01HbJbvStU6Mkepptr9zzogMxJjQ90EAoBAQnaR5xxjRdb2CReIJFkePFtaWzS2pewHlmUsKWeN5flEj+PNApUV64aEtn7gkKQzUAVB4KJf5pgIGVZsEMACh6ihEXHhQ0d/1VsuuQLZ2Ftlt+sP8vSrDmwFOFUC59Cwo91iClefgjM3L5SgVuzpjef9zIdfer8jNpukDzd5Xg6RaPsJNit45ZNLWOnqRyJ8lSPMidBZlBIj957zUc7u6wqNHj3A4HHB/f8D9SRoIUVMfyOaqzj3qXppdew4uXIqCavVrp3MVgtd0Niq1+er6WF0cAV/gCNM0guMETuKQsPTwnBnHYUSaYtFrou5nyhlTlrTmiTUBKiVMMUs3SxBikv3vVV5YJGPMGVNOyu8BSfV1WiCakaaIkFn5KoNThqNJ09TEiS+ROR45a4FmyRqDRfhAgadMKGncpug7kNoVyps1M0LeLaC8Y7o4JRiAxbHitQxH6XDeAL52jvBbieYl8kWB885JUAoADwfnxHkpwWZBonWCgo2dWNBWV7ZTWRmcB+DENtQoIa/RPcFLR83QdQBE7nddABFLmZFOMkCck3pQoodZBgYXgOkhejkAIaBhAkKkSpxNdNn09o8IJfSgVZjRKNJ8XkvIQsfqfbMayJojyQAciwLoxLZNnEFRO4MkUawoJwQQrq72cF4iYRgS/ua815BsyY1MU8LpOCBqqpLkV5qFKtccicBIiDSCiBVltUKPqEAXJF3MDCHFrjBjNdSICZ24wmRMmNih9nFzj3KO8fLmpzBIKofZnDoPxDSBOWpdJSnETUQYtlvstzucDic82m4xDQOmzNhtt0gp4TSOkkvPDBoHOAVunDcG4yTkXgsxQotgpiiFIDsfsN3u4ILHq1rXIXMEblsLTRij1F6SF2PXBbgrh84B90fg/hQV/T5Xrpa23tl3BQwSQIiQAU5gdsWT55yE+2/6voSQW/ifCZBpmjCOI3KKmOIgLWlnSofdsaZidKHHdrvFbrfF3rytvkaxmeKRre0ueNbqUNob2jo3QAdRWV+7r1xPAcsG0ECrmBtgohvnOmcF9ORdGpMU4rRnHdWrPGXbq6og6b6zrmwyhxI1V6KKTDEiQeeJLMWsVX6oKDysqTms1++cdqhpxs/M2voRasTxTMGX9XRIEcWrbnEDlnoHBZjq9Nhs1ZS7DK4dKrh2ULy0yb5DveYHllhTbEDCa1uwT3V5ADWS8iFafrec31aO2N8Az4H95jqNzteosnMA6dJ90Z5nz6FbQkLExSNEqiyLzudgSH1m1rGqUkPWYluVLymBB23ApGPQbiTeIcURwyiA7TgMyDFh329wuDvgw/c/wP3dvRRM1MG/9tpr+MbXv4E0ZTy+eYQvf+Ur+OpXv4InT57gr//1v4GnH38MD4lA6rxD8OKo4Jyx3+50SgQw/8Kbb+Af+12/C3/jr/8NEGeE4ADYC2pjdZDyQa4UzjPQ2p6FlW/JLCWNHEYBeIxcM/mmB9h5DgSvIflO5/7Djz7Ahx99gK989SuIMWLTb+E9IbNDn6TgskTFSuTK4XDA6XRCSEG8oDEhADiN0qlEvHm+pLJsQ8DGSSHiTd+h63ukGHE63uPu2TMQOew3O2z7HsgZ+90W+/0O2+0GoQtSL29I4ClrKhuKEiu1FQR08SGIco4M5gSYUk1A0nmS1CWJh3HkpOlFzsjqoCLbx07iZgoY2b4z+jLavFrzgjxZpGoActKoNocQOvT9Bp3vlK9z03RBjGvxWcvTxWS1BxMSCMwV6NFgAynUrfvB2kJbPZMCEbBEeo/jiOA8rrY7THHCGCcBW6ZU9B3xdE+YUkTkhIwkKd8uQLrGiCy1VDV5nxtZqHJhihEpJ4xTktpI6t3f9D3GGNFPnUYJBVDw6HxC53ypKUXew4BUAAXok4h1QpoZ0J93EsOOinBwM32gTcMpUaacBWg3TVqXr8Yz6//Z5IxkGxTHbbmuAqfwhZGb3tBGjs1GOwNYlAoSU68pH2ag3LO973wcy8/qda1GifDaOgehXF9kkUVRWASRfObIzZ657rl8/hkRYO8ooPwnlq/04YsdI6C/zXidG4GwdRygIgPOI7/q+tZzH6blfM2+A0oRYXO+ghmbzQY311c43Fzj7v6Au+OAYUzITiLWBbCoUUaiA5N2adTr6WzUfXVOMqa6xibQpN4daQNqEl7laiFmiQBKGPKENCZ0LE4L5FE0cpbukNMktlSpZxsjQNZ9S5wXlm4+qWKek4BNKQITi33KOcN74a3jGIsNwywpt5wZkYHsXNFDgCx6eDZZzohR9GFyDgmElDX4oayRKwAMQLM1k8LSDtDI2Eya8pd0b2fZe843doXW5AEI5CSqtsgS5hLR5xpeIZE9TmWgBZYIeN9BZJpTx4aDrJUPUhuWc5J6TVD1zcmeImapKesU6COH4II4pvRapDWjGJBAAu+V21vpGpHfoUT+aF0hcqozigR1wcEhl45wl+jlAITOFGYqwI+h8naI1TgEFqHl88uUa1VD0jaPhivqNRjWIk5SuDKEZ0qBqgznWIU9Y9I2oJQYeYoYTgMOhwP6bQ/nfClMRUQlpE/YGaHzrkQnjBpSn3ICiIsnjGGeJi5t4rwDspcw/zYaKpDlJ3N59ksyRUC1FumxSePzY1tEiOoa5IKIqgHCMloTUmawmNcKENR2s9mIdxMoqOQwjjiOA47DiC5INXvzVo9xEiNvSvAsTCblDK8RVIGl3hJrHZ04TYjK2JxzuLq6ArF4WFNMmMaojDIiJfHiSq0mBWiI0AcH2m3kpfQD7o8TximV+grLGRKso7L7+p0yIQeQ51JpPqm30IAd5yQkvN9IaKfUqRKvZkqpFHaVtsYaSdPURwAg6D4YUxzgRmCcAnLu0XmPvhevq3mOmTVti6UYJbMAQpY2VtLHlsJR9cvmTQTQRhXJG5hZgdsGdFmSgVJ23k7vl5KkCU7qPZ6Stt/VdBPp2MEVMIO+x1SNuxZkqQBYUgO9iTaqFiTAFQCagUC6rwXwqooFiEsOcVG0FLxi1vosID3PIoiaezbAFGCpdhkJ1sJYgSE1fWTNk45Fjnn67OHOAJ8XqkCgTqwqNA0mVICVlhfOHQDLY0zgL85ThKcFz03WtMe1OmezXapcovkxBfR5YHxiyC8M7fbazacGjMk+1L3LLRCk0ZW8UDuptra16EGntcGC1j1JacKTR4/w+Poa73/4AeLhgOPxiK997WvIKWO72eCrP/wV/I7f+TvBOeMv/sW/iLe/+S2RWxp1I57DrPOo0R/q1Xzy6Bo/9bv/cfy//19/Be99+1sIVbDLu6fFE817V4G1qlxXftzOjFO+hSLD0Kx1tVUMBhLQyBNK5BUpKPHhhx/i7u6uRP48utmAKCPDYxhHpES4vr6e1axx3mOaJnWGAD54dKcBY5SIVSssDADbTY/tZiP1CpwXYEENr2kcS0SkAQXb7RZXV1fY7XbY7baYphFTiqCY6hwBRaE1wMEH6UcfoxmkVCJunW5WH6ikYXJRUn2V81yNFwLNPI9yPyoKtPE+Z2vE0u/Me4fsLaVKaumF0iGHdF9Cv6/FM9vIG6vXlKyOjj7vjDcDSE1qnEV829wgSRv66/0VptBpO2JZlylOCE5StnJm8AR0PhRlUp5V9rTVT7EaXTW9TtMzc0ZKUW8t+l9O4nSCAmrjOKLrOoydpAF6jdqbQkCvdT4COXhNJzPgi0i8xUU3mzOHlS5QBQ3mYEKxOcpHpksoAyeGtWxvJ9nkRgtE2PtTAalzYGIZSXMGRrBFJNm4tLuspssbRGXnX/r5IBjC9s4uZExjXAv52dwUHXcBQjUXbsZv0GsrJ1l5Q013a6OW2rWR4y+MnWxuGA+llNm9lvN6aT4uzftsXYCiJxpv7/seu90ONzc3eHR3j9v7e5yGEfmQMeZkwfEVNGQqUYSz6NT2mAvAVpu+5xzBKVhg06xlj8WmQI1QBGqKU44MIg9QgtO9Kp24Ik7TJHzSQJ9hUiBUoHMijY6HnsOEEKB16AQMill0eCKRa0mLhMY0FlmSWWt/UIC9dy0Qa/pUWXO1g0y3bueljRJuo3Zm7yRQMhOYazQ/kcirxDVCD6Z/syvXCd4p2K51BUOA6VrWvADOInUqHyYnx/nQSZQQibzrguhTzBl93wlf0Igf6QimUUUO6DqREfKdL3tFdCYZfwhdbRxCkqlkr2jogspurwWrq0OMQaDg4JBKNsolejkAIcyV4kaD0+/qy1l1ZS7/nynUEDXRUFgApRBu9STZiy/KSrROG8rvxYhuBbwoZh1MgXEIzqHTbhLH40lC3GAbVca8327w2muv4c033sDVfof7uzsc7u7w0bNnuLs/4HA8YphGxBTFExQ6HasqVhrmv93uMI4Tjod7xDhpzj4Xo3gxJUUZrkKjvlwzYwZQg78eZ28nkSDRxpDqZ81ME5Q5axErraMkOZ4yB33fqyEnCuMwjjgNpzqnnUfX+RI+LTmnUZBollBtT4xErPUbvLzsicFacd7Wioik+NvNDYbTINEn0wQ3TZJr6pyEDloqVdKCxsHDO0njutplTEkKo01TKikX4zgiCrdpUP25lSbyjsqsQvfsGCftLCOeYpCkiIUuwHspIm1h5laTahylM1pKWVryKqK86XvxVgAaXTMgTiPiNCGnCCIuaLEJiGwF2jyBeF493xRZztw8RxWmtUtLLeoZxxFTjpimhMgWjQM1QnxBpcUZpsqMqxFFloKWkjI93mrnAF+Kixu4GrMVaGcNz2w8AwqYeO+r8aeb3Pwv8vyioEGBG1t7U/DLaW1UT5k7EY5o3o0CihZDgEvLy5ijPGdmQLvDoQjyRhg6K6HIqucJ47EOUFxqlch3T5+9h889tTodUSnoV+RDwwBtuRY6X7lO0asx54EtD12CNrpsAFAjNxffF/WEoV2w6ndnw7DjuegZhVcbZ1c7VP5aoEktmCmA6TwqKMYskVKQi5PodZJfrukL1iUTOaG7ucYX3nwTP/LVr+Lm6grTOOCDDz4SQPLps1I4uOsCHj16jNMw4Od//u/hP//b/wUOVkNHeRs4I00jckLJWWcC2BHYEQJ2+Ct/+S/ig/ffRx+8ymSdeYsMViOMQLO6S6zXqgtM5fPCBWZaJqpKwVVm2tq4sk6qfKnHjojw0Ycf4e7ZLabXJhAB/XaDmKAt1knrsO21WDMjdB1inDBOI5yHpuV12OWMpNEcm80GDGDXb3C1n+Y8X9PO+410nIQqeCFIutF2u8XNzQ0Oh0ORb8M46Z6n0rGSnLSs32w2ICLEaYIn8b6acZe1Hk9wrqSqG593FpHVbFbblRblQApq2DL44Mv7mFKaOQqI5VmcLoTVCpJ5l8ggnhl6BKiHU+4lXvAYq4xMGuWatK6eKG8SCWteegFNUZ7ZkSrG5q0NHln3pB1aavVoek8IAS5OIoe1DgNrGlmMqciN7MTZwqyFVDPgSA1rDe+XKIla6H0cR+lYN00FxPNqeE4hoPPSgAKD8jknDKF0M2uNrHyByXxOaQ6M2BwBZgTKMfJdW/9wBvCgAnDlOmZbUE1fsvvNo47mxv48imgOELTG7bw+UPMuFH3GjsXsHsufl+ehaPrlnSha0sz4nkdWPnyfOi+XnolUEAo4Zs8lkYAP4VXL+1UAr33+eZZHe9/lNT6JzoGteq3MfJbm57tOgPn9HjfXV3h8uMbpNImtkDXKxfRhGQRg+6jZFwzAZeWoXFYFtZVAHYvxWfkb5VqZs0akk2Sx5AQkgtNyEzmJbUvE4BjhHGGcRoCAYRwAEp2JyGlUjygiMUsJ6Jg05cv+uREmOY1/Jb1+nuqonXOI2lQBNl6cr0Wxomw/NSCQdFeWbBsT6bYOLXAHQDM+5D7WPKq1yWQvORALEMOQde1ch9KcwDl4UidFCGW/Oe+ktEfowFzBG+cdJGBEasUyW2OgTeE1VhfOO1nZTgEbQIqBEyS7RaJjJVWNmfUcSf0i1SFM3bE6ezkxnA/oQgdzlpOlEFotRgIECPNFdjBPF98Vo5cDECoMeq6s1e+4CEEUZXkOBhn+QWT2fmMNGPOEafGyS6Oi+IUpNsq30xxvQeUC+q5D8EHboHpc73foQgfnpWDis9s73N7e4f5wkHA8AMfTgLvbZ3j319/Ba6+8ijffeA03j65APuDjp3e4fXYPp8WHg3Y0K4YHCbJ8vd/gy1/6MnzwGIYTTscT7u/v8M6338M0TaoPU/PcLXM0gCqXYwy8Ly/hDNxg06kEKIHyqtZ7yyooC4ikaCiJeImTFMI04Ra0SKmk0ySN0EnwH3yIqF1SGJISkNMVOGcMo7QszsgKpiTEiSRCKyeQ93BBHiZFAeJsvUxZdY4Q9IXxfkJgAEmiLiQjiUFkOdweLlkNiYSuk0gN7DpR5BhIKUr718gYhkmMrWyFWnMxSgO0EKV1slOOOsURd/f3cAScTgOu7nZ4fPMIV/srbLd98djHlDBMo4BSit4z2VowOGX43qHve1ztdwIeAthtNmLEAMUosMKb2QFZATnhc1bIWTqPSU2fSYqtUd37Fplj+asCrEhL6fv7A27v7qWAbJQ2jwbEBO+x2Uq+tRW560InipSziDIAwVcBkJKoWh3BIo+KhwGa4tbUTUgGamWJpBNwR4prklnZOv/c/BMWIJFT3BRlYjVms9WPMGS9AICL6yhlBYLM05K408+tWLd1tLH3sfImVsWoRghBn0EMB4veqszwc06mnMuvRfizWqRkHlRd5xKtgKrvUvO7ELeXr582gM9MxiyPpfn1DGRob/GQXtqW22zZsCuGt/JsNWRhfAAoKcdO95TtywTUmkFEiyYKIkM79TIZ8OSI8OTRI7z22mv4iZ/4cbz5+ut4+vQZ/s7f+Xm8//5H+KVf+SamOBY7Yhgm3N19E1//+tsKjtZoXaufRpyR0wjPmo5lk5clrefbv/YtEIDe1xpfVS1uopq8RX1QnSb7uxgfVPYEgCb4df7uGN9RFV3lBml0EBUgxZPTYsKEX/vm27j9yVvEGBG6DrvdHuMke68LSeoNeELSPWgOkXEc1LDf4jgMSJN0JCOikkrNO+FhwyDOi9PJim532O92JYe07UC53Yp3+u5eipqehgH+NMBFAryTSGQATmsPhRAKvyIGHCo4R1Z7AVADtxpBRT+w7ib6nlm6eA2S5ZLaCFqE8oMVuPNl/UvdFFL9ytIAy3taDUEZhys1g6YpwjlJvyrRQn2AszxgMxwK35wb9nJfD9dJwU6GRF4HZPXicwHGcpbIVUufY5JuLjFKEwLOGS7WGkPMAJMvTh3zKHtXHTPMrBFO1ZnXFr82YMjSzybnpeA01TSm4l1Wh4/zrmzx1oH5uSbdm2YIzj7U35fOJTtk6ewT8a57g/jhepxowYV6zSXY8BBI1J5vETy1CxejQgUVaLFxzozjC4BTe29Lha8gU2s7NeNWLml6J1CB0upoTJilNV14ptodNoPIUlXowjjNkK1jqPMCVCDv4eigJcD2vO/PgLLmHCIq8nUJhDnvEDY9dldXuHn0CIfTSToYH48SBZoYSXKUFDi01DMUe8B+sglNcHk2bsYyj/qiMm+gmiqetAmARU4STZh8RM4RYAK5Ds4T0iRAwDQNYEg3sZSTAEoMbceufCjFEsUeQgBn9XNn7apntQHLHMn6Vl7W8CHdbzElibykJpWRbI9R0fXJOqHq+2ZdvyWV8bzouYBl2nxJO6TaunVdr9976bhJ1f6QCBwujXmcd1KDxwd0XtO+vNzH+06vpTyXTDdj1a/knQyhAznp9maRvd6LHCDmElWUoZGgGliiSwpr/iO8Xfeey+pQowIIyXEkneJ8KO+uV/xAPsiNPSSAleAAjcy/QC8HIGTjYy7hUK0yV5hSozgSYY6aMs9aocPOsYgbpwWB9CIGoMzR9rrJyn8keYOb0OGVJ4/x5MljOC8KrneCrN6y5Qey1AAYJukMRaQv0wHf/LUPAPpFAFQ8vazP2HcOnYJOXR+q0cLAOAz45q9+Az44bBQ4AFgKQ3o1hGEGUfUsF0OIpIVmjZASIyNzC1hA56So1OX/ZIUTqc5VRWQFHXZ2zZwwTqOCCL7UEbLUpT0DKXLJX727u1WD3mOYJsR+g7iL8DRiCoJSb3LAOCWcThPcOCBmURJDCAgu4HA4SjFuBZ8673F9fYP7+wNCuJM6Pc4jIhfmYZEETkMAyXnAAyFnOGOUORcZTOSAEJDgkTsGdpIGl1mibKIa9JykkPFca5DwdIAxjCNu750WK84APPpui64ToCOlhJQlbcyAs1bJNtDodDoJ4wgeIbgKyjnzqDbtqAFwplKEV9ZU09mSdHQbhhHjMOA0DhiGEadBahdZ6KUg3R36vnaMOZ1OOJ6G0lFIWsvLfJ4w4u54wu39EZuNGDfXV3vsdjvxtupe876mKLReucwGONZ9LM+hQoukNaXNGXNNfSsvspPjmaB7viprVGoKzAW+/F27qlnUjhkX1pVN3isZmUXDgUyoceVXXA3bzDW9QHaF/q31RAT3MuVK7jHlCVYMeCUAoGKQNggCwK1SPH/3yplkist3d+eZXLFruvndPolaOYNmq4pCUPc/DNREjWQtIeLyAhQebhfN+t4k9RqSk6KElu7IysfMyE4pIwQx5rsQ8Pprr+LHf+xH8aW33sK7772Hv/2f/xf41W+8jQ8+0sggV5XYEqnUtAl2ziF0knbTaYRicEDn1VlAltYiCp9nV34v3zXUdjAUeV8dN1kBCgNjswjymcJdPfpUUTpgxgOtKLPNv9M6BfK5g4PDRx98jKcfPYX3Ho8eP5bCwBun9c8muM4DTt9jFueRgDoS/bnZTNjGiOF4xFEBGJNVFg1wPB6l9pCmL7nTUeomqYJtwHzfb7DdbrG/usL19XUBhMZxkmYBWefXFF0F9Y1HtnvVxmGb0KK7irLtqMi/Uni7AYoMQClGAQw0IhBr5JCBRPrOemcdLlEB3WKYVT1O9r3uN8jYxlGaK7CXehfDOCLGCTn39d5o+G5mkNc1deZBdWqUSPHOzFIjyTuP7AOoZ/gsnllrQZwzw6cIn4PIZ+8lHT1GfZ9SkSEJmmbRGNDmXDFZZQ5GcqLzWQTCmUGqEcPT1MopNXrIa7MT4UG1sPgqKFq6bPjMAYzZcSUfL2taKtDqwihVqOyTCv4YH7N7kHPFybMEfFqwoo0Mmn9mRrfdrv4hJhJDOnhhdt4nzQefcdr6FHX/2fNl1PpFldrUSEmBsaFdnu856FadFM8zTJeATcX/Hz7nRSKCnnfsHFBqs0Pm9cGcRl/urq+xP9zj6u4eV3cbDONY00jbPWYyBwp/sEYYO5o9nxpZZ2OZySzdJ4mlhqr3Hh6i/3qNogwhIXNU+Sm1ziS1i0qnscJjILpCdb5izou4sbOhw6Nc9rJz5hRVeduAZw+tr+1fVjubc5P2qjeist41us/4X3t9rynu3jt4BVMs6gc6X51G6nSdADEEKl0sXdAizc4yfzz6EDSN2Uq3BHRhI6tH5ijX51Unk3cyj9DaeFb7xzkJdnDN2jF1mhkCqZ3oba6opKuX7DR1tpiuYxklgNXP84VHWHQQoFGP5GbrUUN+X3ZAqKGZGViUBDz8DAYaUVXaRTGQ72SanRaYJhg3yix58pLqkZElyh1M1VNIJddONtpmIy1CiQgpRZxOAz7++GO8+957OA7SOn0YE9RuLSBW0o1jyo5z1TAhSOv5nEaMwwjvRHHypYYCJNyfGkMzM0AO3rdof3m0silQYC27X02kkaAfKi+YgUotQJZhaQx6DRNERcc2RZELSvvxxx/jdDxhGAYwxNjodBOTRhrlHJHTBFKQxBBOSRPayHyPAgo4v8U0RWy7iOMQcJpGMAOd77DpO5DLSDkWQ7zvelxdXeHm5gYfP3smLdiVoTiS0HDoOptRLh3kFH31XiKRkkR4WPgnQHAsc5tLJIJ4Hrusk9Npnj/bXuSyJlCF8P54j/vDHTw5fOvXfx2/ut3hlcePcH19De8dxjjheBpwGkYN95Tc5c5qDBg4JMUmpMW7y0hc0+dA8kwOpO0OSVquc54BQlE7zCQNfzcAqut7BJawTatrdBpGpGdRimOCwSmBlVFl6IZq9pes7YBhHHF/f8THH99is+1wdXWF/WaD/X6HDUlh1iI8uO5N269QoEvAE1svQo/aRcn2PKdqQMg4ap0ke4+rnKdqAHEdO0HrZvD8XRCjw2krySL+EEKQNs+Q/UWWI29gkPIhM7igOqela1QQS5gYq5KVc0bPndxrTQVQMm5HkGKVNW6EG8O/Ku/NmcZv6fyzQjQ3FZYiZ1Z2QTe6vU+5YejtclVD9/xeVmvo7Bl1HCWqAc2xjOZ7KtdNynNY39+r/TVilIK41mbV3jNWRZ/1JiEE7PZ7bHc9vvXOO/hP/9bfwi/+4i9jHCdxJjh5n5uuxbOOVqETpasLHsE79BqpEkyWNYocA2DvQLY8mjZUADJbAyIgS4FTK9ROLO9lVRxVGQPpXDRgvCOwRo6YwlsdSFQAIRj/UXDCQ4B0qWED6cA2DHjj9dexvd4LyJA8fEjwYRSFkCVKyhHgO4fjySN00lhhnCZM4yRgvXUqJWln7EMAx7buXihKqyMg9AG+9yAvdQr6TcBm12O33+L6+hrH4wnDaZBIYUeYtKBoSlK4edMFdM4hjiNyTKX2nnm6TfHPBSiHOhH0X8Ob23/zVvRO7ZisTSgaBd55VWqtICyAEtFSo42YUQAYwBRbA/64yKcxRTiWWngxTpimESltwRz0PRGDV2FAOK7PQ5ZWpiCZc5Kz651D8B4cghTYjhIN5CjBEyEBst7WHVOjf6xzWxthEDWlISkoZKl+KWdETbcMmpLQabt5A36KAaYyhnPWQqdW006NAs6I6v2VuaoMRIqkriT78bJhzWx7ukbfEJmTdq43F+bKKOCmiZkCQD8wgDaK3sZhAOEywmEZsVLHicYYMl3fikI/bNRdHJHpOkVmWJXMFiKy65qBknUuq0FeI6BszI3hVd689rnRzHk7bn2aEnV0vmbt7y/ytGcgUvvcF44zujT/xFRsH841kpap1nS73u9xuL7G9fUBj47iII1x0HxRnjlsXHtvlRXcrGt9/6tumVGjNUUHkCZDjr3OHQOckKJ022KIbUhsqamAo1DeB0lJ0pp+tpFNz27mwpzHXhuuWGCEdZ+suqpE+8pzuZIeC0h0j3PKj41HKlAqShLqusuNC7gSyEutOXVeWdevEDR9liTS03uprbbbdPKZyljLbnFOgJ0QArrgpXto8Pruc6nf6p0rNqrT8hzeAyHYfvVwPogFoOORbqS+ZmU4BcmozVahmlyjdpzsL6k5DGQQZ3hfZSR0zYtN3jgCzK6U+SOgAZFhgQ7Ky5yzF7bd49yAd5fppQKEbJhEaMB4kirguSrzrZHG3L5sc8XblHWvXiCv4dQgkjajkMKHItgzMjS3OycJvzZUTw21aZpwPB3BLEL/7u4O73/wId774GOcxlTu2oIm7dPVccPsUQ1Xl59gycP31KYN6LGNkLEq5WaZGjObARV1NtUoNYGgU8uVdYtBY8Z4HbgxDSuhYl5aI0vJUNEqkT6nE25vbzEOY1GeutABTlBZ70XRz0nS6u7u7jEMIxjAbreFRWedcELMErK46zeIKWG77XEaRwzjBO/EAOl7adsuyqwrbXq3ux12+x36Xuo+RQXPchLDofWGEKGkRSXOWqg2gb2TKBNWhsoS1SMCU+YgA8jUFhAUAWovsq1z9dBWo5aIcBxHDO+9D3r/AwE+tKNVYtaQQK+RT0E9vsZorH5DFawmrFkVGAHAnBpWBGf1MxR8c97BJadpkFqQTBXUxIDPvkRfeR+Rkhg6kedFos3gZH13bL7kcQV0TeOIIY64Px7Rhw7bTY+b6ytcX11hu+kV1Tfk3QxgKqBJ2f+6v4mknWPwQXOLPdhpx0BlpvYzIDfdvCw9QecpZ1GJ2rnTY4hsz4tCkNVAtULtcoYrLUetEwKyhGqKJ904EZeovCIeTbgahxALXcJkYRb+mgrQkpp3jWICNcqp8GlSvjRXDM9BmcKPuf400IOMvapOZ9FADLTZiEXmLnl7/WN+r5YafbEczLPvK4hh4KKD6AJ2MENTOVUZeeONN/D6G6/j/v6Au7s70FjrA9R3tHZFinEq3Zu+/e57ePvXvoV3vv1tJE7apYlrt8nm2Yig6Wcee+0o1ncCBHXeoSupWIAHA85pKlsW5aWkYbjybjKkHXtWOeUc6RpQLZ6rIE+rQNv8FHtG5Va2MGloipIe3EYWm3EvKbbWxr0qcl3w+MpXvozr62u4LoCDA2WPEIQ/CwTsYd2AhO96DG5EFzp0U8SRjhq1VfmvyblMsRghXRcxTaEUkJYOYR4+yLFSc86h7zvsdjtcX18JKJITnHM4jgPoNGDgjG3fY7/bCaCvnmsCChhidR6sK1kr8x1JyjQ1CmcbzWPRKCV1Q1NfTUeA6gKW6tzucEuhEj6Y5uuHxlNK1VCK2mQhMYO1/bs8U0Ix4Jt7tXqfeG1Rj1GjoQW4LGKLiJDJiW6SAFaPayD1yjby1rka2dpGqgZymCAthF2o9QFt3jqtQdL3PVJKEhFW5rnsJqkBYlGsmWbvr8x3BXmttt+Sv33eqXXo2N9C9T2039nSwapF3vBe1QvU2DJN7jyusdyprPkl0GgZQWHr2gJE1V4w5usMOtBzKv96XrTL+bOjXMOAD5p9ZvaA3quAJa1Q43LN+h3XsercySVMF5Jza80xXQMDn4wXU12beSSVykNHFX9qhfrs+Pa8+dy86DtiwI3pfXay2ApSayb3PW6ur3F7dYfr+z3ur/Y4jRHIEhRgMs3q4LUAiMglV3lpM9ZWzzVHF1k6HbM2PFKekOQeiTTwgAHfFjQniWQkR02Dh6q31ML9uhYExCxzSM5V/4q3MDDh+wSWTmFJbI1iIwKl467p1TPdger1BHSS1C0HCEiuxZQzWwaERvWQk9Iqzomtptfq+w59p3WAiEqTAmaGp06v4eG0mUPLt+263jn0oWvKjQDktAGQ8/Cuk2d0TjseO0A79AlYpRk7pAqP2tDBeeUpXMquyBp2Kj996aJZA0b0/ctJZKgCt7kB0MAinzkniRhyNYWvdTAzpwaky+X9eR69HIDQwijKxrD1y6o4UzUYqXrwi2JuvAHyu/eE/X6P/X4vtWwATBrZYN2cLOebk9RZkfxKiYogFrQ0aOeQZ89ucTge1SBJuL874O7+gGm0HHKaPwzkJTO01rAWeyGdKcwWskbQn20RsVyeSfNfACLd2A0gwAxP1VNtDAiQ+gaVEcnLZ/l1tj28GTbNOhSZMmPWJsSkcJVTxdYKRA7TiNtnt9LlQwtth+DlBiMjhyzt5h890Vx6h3t3j5Ojgu56EPoQMEYpTOmDtKTfxwmH4YRhMAWX0HedjqF2VslgbHZb7HY7bLdbbDZdSQMrtX3s0TR/1KkC6pjgSs9qKsi7KM3Ldn2SDpbZ1WPsurPc9bkXaCnsSCN1YrLmsVSilbquQx868VqbQDFhXRZLALakecQ5N9FkwOzlMKZnhZhZC1SXsWg4KVkNEqJiDHjvkLJHUOEskThizMVc6/sYOCVKqiuGtbULHbXF7/3xiM3Tp+i7Dr0aMJJiaMxa6kCJsm8CUYVpmYui3gljBMTb56wOkSDLVuAXXBUwMJBNYbeaQWqYmFcWKmRz5gLSmqAHNDDKlW8kCku9BqTXl+uiRDoZwNUWGjTDQQwQpxEOaiivgNAZlXfY6o8Q6bwbD770rjEuvBL1mva5XHbG/6oaXD83OfOQXbC8R1Xi59eZA0PteOTG4h2Kwu+bPWP14JglPeb3/t7fhz/wB34aX/va1/D1X/laCRMnolKwvxRrjxEExkjA6XTCBx98KNGu776HcZikGDKAHM1LbGOSSNDgIaBD12HrPXZdhxAy+i6gcyL1RI6VqReDnlna3OYIc3vYMzE0JS7zbEozVRBIeAABOcMtZK2EMtm7QlrAuBZAtjWb/W3yFhYNa7zFwRHj5maP1157RXiLgwBC8MWz3akRz9qJRd5zqV03ThOOxyNinLDlXhxSWrzfurBEHYc1VRBvpgBCIXTY9ht0oQezpgeoTNhsNtjv9zidJBo351wKhQPAzc01ui7g/v4e06TyUmsneO9FaU/VqCt8SBVaM7js+6zOGQMgWhnaGrOmmGMxz+0xXotkEklYNrM0jWivJ/JdC6YmiXxNKRV+HVOWgs5qaJb7Wag+nBa2tmLTl9MYbDxljNAIVZ1L0lReex+YCJSSds6Ra6ScJZqcLbpzI9HFTrrLkNYB6roOXS9dVbWFKgI5iVqG8RitKeEAr9GmxG4GKjEkejnl2vWzBcQ+98RLsOKczoEaif4wAMPIIs8v8fpLQIx9Tot7tPu/OHCbmjzL79n0HFCxfWYW9cLh0T5TeX8u7HVufzdghgEzcLnoTJef8xIAJdfNzXdUomRFizLpWbXkGlFrYO5cCF6a2za6Sg9q7mFzZN9nleUMQ7ylpX0j4IE6B4s5bH830MbWyDkH3wX4lLDZarTm4Yj74wH3xxOiRmxKNBeXOTabyopqt/ZAfSYbs0a22jO0B5QIX9Yal+okumB/2vXLGgEaQaI11Bq7xJ4vBF/GKkWnqRqI2QIeCCCWrImia+n55EukjHcEaJMk5y3ix8AZX2qhBYuOdb68O05TvVxJf5b6fkGzPqANdPqgDu2cxdYU+Abeq0PFO629Jg7n2qhAawVplChAGrnDmlKmgJl1+ROks3QUczomsRFqnUe2fUOk2TxZg/oUGM0okcVFf2v01Xl6oqSEFQeo2g9covesFIX8bu+bAUlc+ITcK/PzbYmXAxA6o8Y73wATs+r0F5Bf422aSo+rqyv88A//MF597TV4jSSYYsLxdMTTp09LS1m5thWGlQlLrIUMecLd/T3iOOLYHQXRJAnPHYcRwzSpx5YKel3HJAth76psMIIjhietzeIqCBSCk/a72YpBWfhzTT8poX66Qa0Fr4MoKx7mvbOZBNAoHKBa5GxphbTxP0smVTa8CSQLuyMrXqze65zx/vvv4f7uroROhxAU/FLhwIJ45hyL1+z27g7DOKDrpZBiN/UYJ1FufRckkosz9uNGQuXHATFKO0VXpLVUaGcAu+0WN9fXuL66wv29RCEFJzm2xuC99/Cd09BCMRymaZLQceF0IHMwtv2tlfGW7lqwdAWZBRV5C4FcPTFErsnXFTvGaQqMhWtKykHQWkmiUDq2eUdRvnMDxFiL+5yygAhNuGlGVRQKQ1bBEDRs0nsvXU8UVAKohMlLLYqp1EgQsKV6/YMMSgRnltDW4FiNPdKizWZ81GimYYoYhgnAPZ6GZ9WwMEPNe/ShlxpbfY+uC6U9b01FoFIPyhRm8cqwpvzJ2pF1p1DGaN3CvKY2yL6UdbSCvqVOSXX56OrW1LSgwpVtL9rCkoC9zFzCO7OmbThHWLLm0iGh7CC5xiUv4+eTlCc2OVlqxi6USRH2ss/y7HyTLbOrUiNOcsNe9SfXU0UBooYNiIZV9sXsWpgN6yLoc+nzEoWgfCblBKfGoap0TbFFwna7wz/3L/wL+K/8Mz+Lw2HE3f0Rd3e3EgXIt3AgjJAW9B4eE2UAGTExKBKOo0N6mkFqRHddJ4oFOSSKNbKHJdpn0wVcbQP22x7XXcCu67DxHn1gaduqssH2sqRxChBkxeK7TEXJZq3zFxODEOBcBZsZjI6odEQUWUSFn515gKu9VJwqLbBRlrUBMKTtvABIZOnZqjhutz26ziOmSeSqD8h2PVkVBDC2HMVQ5wSC0wKPAp5Eqx3j46xjjW0rAyXsX1JwfNNvEHyn8sqU9VBq81kL5GEYCgC/6zd4fP0Im22P++NR5GSWaFAGELSmX9Rzlsao7T/zRtvmXBpjs/P0vayYThNNZPvZrpmzdE1RHpszAZThVG4IqMuNbCNErXuRk7y74zSqHKKZoVYN3hoZxsrja+2xZu2b+j7MkuKVTT9ClgLUsQJiKhBQ9VO5l+eMnJ0+Q0JOCVlrZAFSKyilhL7vS9e3aZxAkFRu1ne9jdZirvMG8nDUFWOdQUjUGNWodaZWQpGZbfHhog8/iODb3tF103INxRgnYJmGLNet78wM1JFPz+61BGBbh9DyMzNQ25QtoBrrbZRYe+12XOW+RNXR3s5Nsafqs7bv9nmEzcN/m/HZ2igSoSAyq9poUcfXnmsGciNAG37d/i6ARCznlm/YF1VAXh1tIlOsE5FpcvU2om7p6L1MBqIYLwud6KTX11c4HY84HI64PxwxDicZY2TEnIptcmmdlut/pj+U/88jEksXKd/IUXJFFfENv678V7c2y7qII2k+HjTPdyYbFhGuKoxLsWjvfIn86YLTjl1enC2OBMix7AavBfPNRtGMD3E+a0Sv2oaWMmbpXwa8eA0iCN70f60hRJB6cepICV0ogJCtg3ON/dDIOLPvSXlIab5TsgMc4GrdnvK+laispmYvSOvXGRgDgCVymgnqHJrziHY/iK5r+6HZH2R2gSslM6joXCwONbJzDDg615Uu0ScCQkT0ZwD88wDeZebfqZ+9CuDfBfAjAL4O4L/FzB/pd/8GgP8+gATgf8jMf+ETR7FU0Jt/9rfxinx+uI6z/i52syzm9c0N3njrLbzyyquibGXG+++9h7ff/mZVvNU755J4XRxl+CY/PKeEEaLc+SDoJ+cs3S7ANbQdokzq+pdUX/M2Swg9o/cewQkS23kNLyaBErxzALsCvtRuS4ry6U60ekf2vJI/rlEuNUG1/M06gVkZb6kHgbkAanwIswWhMsfGYJUNszBZpwzbOYenT5/i9tkt4jiVCKuuD4jeI5CHd6MOj+G9KLab7RbH4xHH0z3GfkSnrRwzi5LeKeNIKeGw2eA4DBhOA4JzWhXeWthKGsNus8Gj6xs8efQYp8MRw+mEKUYEDy2Gbciwtf0ToZBI6i9ouZo5CPbAppX5WwqVqhTXPVoZrGNXVpNyDY+HM0+uGCke1vFNAUe9ZvAe4KQChNVrGktxZc6sqeA8YzJtKHMBglxNgSMCfIwlQsYnTVtLHlOUOeNsqZUZlDNiU7qAnENiAUko0Fy5hTFaASQFPLIxWjE0YawxplIziOioYIukHToVPn3XFWBos9kgONlLpILCCm6SCVJ7SLPfTbA1BpBz83XMUjhKI32qEPcgZDWyrBMOUA1eWL0AW2OqQiXTuWrZGogWEWT7+TeDov99kRMP3twUzUq2j6y7gikw7VRWI+HCNRvgx0T22SoYm12cv1TqXugRFso3kaVJKVdW/cu8c1lr4vV9j5/92f8q/ugf/eexu7pB6Ed8+Ye+iru7W4ynQQ1YkTsxeqQUC3Bv9UvGcQTnLMVqSQs1cgdHDpMjUXZiQiDC490GV53HzabD9a7D1abDpgvwIASvHjW22Loqm6SIvtTLY2aELGCAta/NTPAOSJkQc0JWxT2lVOSpiFl5j02m5WzvjcifVC2I+l6frbulD6nSR1JPiBzDCjo6UoCAE46ne+nOQtAwbg0ddxohmTNC7rFRnYBZvo8podfITZONFqHVrncLUIQQwAD2+z02m00tdO0Y1vmxpBF3vURW7vewrljb7RbBB5yGIyYF9xmQ5goaXXQ8HrWrY+VNZxvYxoWqZyz3aEl1KsooYAn8S/ANAMDiwLJo5nIpVuUYVDo/ZmZk1JTkqLWRLPVBAmyy7oFasFlqJVXdLaUktRbZwS9fVFSgy5x3joQh2fvn9TrWPIBzllbBoYn2YL2PoJYCzjUyMnOWiK7dTvZUyqBOWg6XVsqorZZlLDViNYsVAItM55zQFjSzAuWrnGjJ3JQttTr0PGpbR1cBxTbl6wIwUq64AGHKcSWyfz6OFzHKzsdbjUIbJ3BZL7h0famXuRyDVgg1Rj3DAy5c48Jz2k9mriUsdHwWF2Q1y4wbZI3Sz5yKE68+a41MLONo9CKUq9vxIg/t+rx8kJJmV6Ou6g2r0dxOwEOA10P82lJAr2+kptvheMDxcETMR3E+F8eGjpbbe5xfu8ygAQJFWW35tI23Bk44osZR0R5fwRuz0Vo2aM8xcwho6QqxMbTOWidRMWJXU6mlS65G8YcQij0RgmZvGF9iIASv19FgCO+11qncrwuhZGsAokuE4Io9ZAB+LexsUUh1DrwBSs6BfND0L+tmqXV5GQUQsn1RI1urbM7EmkpuMiKrfWDroolx5Iqxb+Abc93H0jUNkNb0AghwTpfNygXli/VDqdhP8lcbKaohCQtQ73sGCAH4cwD+JIB/q/nsjwP4j5n5f0lEf1z//teJ6CcB/EsAfgeALwH4S0T025j5E6vdmUHWfFAUS+OLDW7RMAChhnfo39bV6R5EDtut5NwzS6Vua/XKLF0+yubKqRQUzlpnyF5MhkPOgEUehq4DSCJMoip+peMNWREyEQnBETpH6ELARruwdEGBIadRNpqLWCxWlqKGli8I1Erw9vLL1DBAvoQPtuyGUNNWAKmZlPRzA3q4saYKJHQmLPWl07kF14KGTo/3WjAyBF88meIV67HdbhBDrMU0ya4p9Z36vpcOKqctjsd7HLsR0xhLWl/oVAmHw3YjrXwP3Qk5Jy3S2JXwPwGFpLvVk8ePcbw/YBgGxJRxfzwhW8cxnXsBBlCiSoBFGP0DCkEBE1xtE1j2YvFIzPdpMUbK3Eqle1NiS5qSzqu1JCcFg4owIu1U0IBBUZVPW5/WMm09WDaOtntC13WQgtmhABxSwyCWuXK+nmOGjQPDp4wU5b2R7kVmxNT85LZomjBEBYWSjFWUYWETWdtmt3NuETlTTqJkcMJpGCsKzwznVNgEBbqCx3bTozMjSj3rto9tPAZyMSz3vc6T0wewdbSoh5Ry2TuZMT+eLW9c3jE2pYAMNG3DwLka+jAFyqGEQT9HGX3J6M/h05YTCvyQ1REwvsy5bnfYO4ZyTO1MIe9knc72vZQbFGOsaYU9U0ZtH1y2oV8cCPqE47iA9nWvmMrYNjF88uQJvvSVLyNGRggbPHq8xVvTW7h79gz3t/eIcVCZoTzPEyhlSYnJuXT4kAiUGr1iXbJc9KA44fHja7z5ymOE6YTH2x6vbDvsNgF9EG9geUcYIKZirKek6axOCgN70pQfYknR5sawdwIYEYDIGgHhxbYijTCylypDKtAIWyGQNnIA6XsM4HLL6cpDizKN+rt97p1DIMJ4OuHu9hYxTuAkwp9cUPFMQOjheiCnDB8y+n4Ci4qGbgrg3CNHAYdjCBjGYVaXDszIlupsKSTOYbvdikLsA4IPEnEZvLaf77Q4sfC0zWYjneAgxTZTijgOB6QsIIYUq+5LB7RxHLXQvplWldeUWk1lquWlayOEaq0FU5RTmddL+//MyIIC4hYan+eGktPUukyMFHPRAbLKZ0mVqnIi54zT8YRxHECQlPOSBlDkISuwSA8C7USqKxEBSTz7TvdmCKHU07Nnd86V2hnBOXmv9PjTNJbaTSEEXF9dibMCBPiMxFIcu+0wlrJXOSfdRgUAqukwznmpi5Wdphpy2Te/iejP4dOWE0WXVSDDGd+f78NLgMr5Z1X/MiFj112e0xpg9WwzGIRqa25WnaUCkuY0cmqQL8GSS79e0tPt+u3nFWhp5V+u9ooZtpg/wyUboDUyzRar4IZVFJX7mUZdk+plNFI7aP4OlntemNfz5zP9W2UuofAfZhsHN9dtJ810BcK8U8Q5LUGwmKuMdM6Xem/73R7X19e4ub/H8TRIsIB2eogxtpbq+bO0gFSZx8XhRb/gszkzfm31XyVi0zoONzaDszQmqVUr+oCrNfQKMMSlrqgD0IUOfdcBnAWwcQTva4Sl1F/l0sFLIvhJo1F96SbsdUxyvp3ry/gs4kf041rA2dqwOy+NnjiLTLPn9Hq8NdwxR4/JLjJ9mwBHocia2mXT7N4Mq0/KVvMH1SYw51Nt2mRBU2aXG6emshZWZxVo6vBxOuNF7fsvxzYdiLndJ/X9FXsxw3J0iFBsKBSegqL/lnOeo6R+IiDEzH+ViH5k8fG/COAP6e//ZwB/BcC/rp//HDMPAH6FiL4G4KcA/M1Puk+LozMahqtMTJhLfbmzKTF2SDEA6jXHGHE8jBhHBqFDF7bi3UHA8fUjjocTYowFtY4RiFOGYwKTlwKDuQmDdOKpFTRRDGfvxdt1fXWF4/GIu/t7Ubi08JcnoPMe2+Cw6aSlXecJfedLXZjS1lU3mqB/2rmItZ6JMyVJMW8vKUuWukNgZFXoURijjp2t65JEJ3i1rNptUTFsZeczYSK/e30xpBBZhvkd6gssES1X19e4efIYV9dXuLm6xqObG3S9FCjuRg8/OMDrnSxCBIIa912nyquAOAY0NNG/4iUloHdOCk93HXzo4X2H4MQTGkNE32+wu97j8eMbxGnUdCzgOIyIKng7rS3FmZCQdb3PhXtBz5cCuPxewaiqoFn4cBVGpVAhmpQGB1BTxyDnrF0vRHVuu5BYJJTty6zpWWBoPawJUxwx5g4d+xJOCqAoG60ybECoFVDrPAMQb6vjrAaGg8sOPnv5W1P9cma4lOGI4SiCKEGq7VtuLcq7Y6lTEhVke9iBvBgHQUET8/bauUkVel/mRgqRcgbMZDeekKQoBuIgnmScgPt7J6mU5Iog2vaSBiLGlabkaU5zylrAn2oEHLN4qw1laFtI6vKJcahzmnOG7/xM0WOWSNOSFgCAWNJ4SgccfRYrdG074JJC9LLR90tOwKkXhB0EIzfFLxdl2d5bWa5WcTfvkAj1qii2iiMgvI1U7FB7iFwHrRI6H94nAUOzAs0NtR7X8qg6Bi47XcbhOBUhfzgc8c4738aP/8SIVz1hs+3xyquP8cYX3sBHTz/CYTxiiLHIE4oEghbAdfVda5XwltcBHr/lh7+M3/OP/SR+6ef/Dh51Wzzaelz1Hpte+LAIL6nCkzS6MCXSFFZGnAjJe7hEgEuIieETi5wFgZLKq9wY7cxSjD4ngKLWhdHjTIV2AJJ6/UjW1Ju+YC8PxICua2VKo/FBgCgXQMj4hDhnCJgiDs9uEU8S+ZMpAOhFeUSSkPuQQV2ASw5d9AJ8RY+u75AzY7sFXCTwNKBDkG6Iyue4hMxXpbyE03stpBkkstlpQUtHNbKz7zokTUWStN6M0+0J98cBd/cnnIZRNnxOGE4Rw+mElBnWf0I2mhVpn6e9cK7p2K1CSQ2fK/oAt7y48V4u5GbKGWiipAgWBabdIIlqBLPO0ZQmLYCdQOyER3NGzBljTLh7/0PcPfsYTh1u243UD9z0HXoXkGIUHUHT2w3gWoJCYiSUDQ3KGdShOEAMKGWoHFajwpFELodNj8QMP02wIireeVzv9thvd3Del7l0nJBV7lqUHDGQUgSIkTmKTIaDo6Ay1IFZvPaTjzg5J7URmRGniFVOCBEBHhkEr575mubXct8lqCPOHKv3AeVFuZgg0HqI9YP5dc50Q5j80PeH5xHabVRX+55Uh57KNYE4bUAFxCDKmjFxvu5VBsr7lMmMXuWeymdNUMnxJldkAqpBOZdLRb+1em2trVAuSeBsgARrDcdz4HIGnjX8x8ZEzTGtTn5ZhpZRzEAhoqj8OqBGDQl4AQOVHvDQtOOx6NwaPYYSJbTb73A9XOFwv8fxdMA0nMAx4Z4zkD2oAW3FcEdTV6ZGyDuUzCzUOkgo+0GgNFK8kErdxGDPrWCOpVqZbu+dORe81k31cETY9KL3hqYTtHea+m1AjvfoQgfSpi/OS/Fmr6AJqNolPng4kqwNrzXnutDLPnAiT1wDJoXQlW5uAMo9naahSVcwBVLJInRbHbw6zCrvNr2uyvicIwABjQSosWgh1glXUEcVNGYu6UjZ7KHmfmZfiwNeC3c3bMFAUqnDqsWjtRlAm+q73GPyw/Z7G1lmctVS73XOWCJmzYkvtXzrbra99aJO5e+2htBbzPyO3vAdInpTP/8ygP+kOe5t/ewFaD5gm3SdpvOjG7yIgaLgtFdJKePu7g73d3fa8coh9D2uux6vvPoant3d4ng6aVhWLowmk3lt0Bjj8s+URgEvAq73O/zU7/09+K//N/5rOJ0O+Pu/8Av4pV/+FXz967+Kb/zKN3C6fYZN57DvJTKoDx7Bk7a28yWdjBiiuCojTkkWOAIaelxTx5Klo4gOpzUeoJuC67wY+q+GdZlJqhNcjNPGkiktghvlkPSiTpeKnBbg0++D98ULsN1ucbXfY7vZYqvFnUPnZi1byTk4BDgY2kwYp2mmqIUQME1RhVdtkZ60WDU5j44z+q5XVLq2DgwhwAePvt9gf3WF4TRgjFEiTMhri1gCnIaxOkJM1WtjG+z/z96/xtq2bWlh2Nd6H2PMudbae5/XfVbVraIg2AUVh8RY2MSBKjtAUBQJWYqj2FLkSEj8sRRFyg87+ZNflviFZEWJYiRHihUIKWRsUIJVdkyQY8sONoRg8Qgu8KXq3nvu87z23mutOcfoveVHe/Yx59rnQqpKp3zPuHeftdac49FHf7T2ta+3h/XDUzsm9tlAEKTfh/PS+WQ/ST0OFGhYBbGgjUL4uPHmbosQz7TeQa1hmmbx0kk70BYOmdu6J4TsvFoLOldMSmoJgcQASzl6IpKQSV6k6ovmFyq9e9gFdNygwtLmW4Hd0xhvNcaUWOpWyQNAazVcIDWhZtF50/sm91aPZ/FAiOcwoEy+5VUSkIMC9I2xrh3r+exKzHInHZaDeA+hStnhWmWNlqLhJOShhuwamrW6VUEW6vvxN9forgpfO36YYwMBqbuGlqPognX4jXP8GugJBXDOyOzWJYcXpT43XZvd3Me1zByEwcVad11jYNQAxDCMeo62EXyhjz7tuLZrFPcNTWikCBHhdHrEN7/5Dbx6/Qq9S56SUiu+9MUv4ZOPP5Gkwqd79O0sbToTSivorTuwz7uMJOgLgJCi/8Q/9t/E7/u5342Pv/MtLD/1VdT+KGTQVDwXnhC3jNaB1gq2TeTCunW0KrrhvGqIkpEyKA5smNVTkKQQhHgQQsEYtBIOgVE0/12E0nl1DjMeECXmfRx3+WOsopiUF1foaOQQ4NXGjAx89eoVChHmedL8AASQGRQATzOwbChtwbxJrhssrOXo5d6lEVBFf7YtqhC1HhXfiMjDwSRf2uyh75JsWMvcltCP8zxj2zYd94IPPvgQf++Xfxnf/sH38fB4EqxQxSO3bVptESnsmyAyPvVNZwnltbw28pIWvhuG6yCzdqSR6QvJC6TAu3dPkiqhcHJOZ9a8O+FR27oQvNu24nQ6YV1XMel0bnZmbNuKr/+9r+Nb3/wWagWe3d3hxbNnePvFW9LnLCH4Rb2nDe9kfR2751HxJ2MQEwESelaHtWjzrKqRxQCmafPqbFMNT2nZAQ/SHw2g0lG1XPCmepu46gbLrOHy0v5aK5Y6iR7pHWWVNpzXVbx06Trm+A1y/KrrCVHRO8wrD1DZOY4l7XWGGsfF9EESzbYk8vmhV3iYH8M6Ud11SbqPpIf/JB1rEiN4QAFkzx2xx3BKJmo4ETJmcyB0GtuGV7rWdOSTxiTTsFFr7QkbI+5FTsrR7vxE8tAV3Zsft1O0F+fw2G5nUije2bkCJb3Iv29OhMX778dSHmOyo7XmXi7zPOP27hbPnz3H64cHPD6c8Ph4xqq22cahtziaJPaWP0/lbCp80xVviH4m71aCYOc6VycqJJxYqipbvs1Si3iSFiFxJJri4LpmnmSTYVnmJAtl89/0puXDszLuhRjzVLUv4DjecgMZrhYdKqQPUFCqkBxGVAGkyZzNewZu0JsMzljavjeM5cOZfrFiDYYPibRve9g9ArFt/ojN0nnTXKI5J11en4a9ggeQVhS0YX1YY3TF2viWcY1bG7PHIJHxDLHZAuT3zzZ6nvt5jY526369PSUr7PjVTip97UlXpQkR/REAf+TiagfmdjcDJNCxU7Cd0TbHaT5N1Gh4+fIVXr6U5NEGokqd8M477+L+4QEPD49YtzNaO8uOFG1oKSdIrUGOWGcuy4IvfvEL+Lnf83vwu37XP4a3nz/DYWHcHY74g//070b7ud+F73/3A/zv/3f/Gr7x9Yabw4zjRDhqzqDIpA7Jx9IlT0LT3e6tdWCWhFGrEiCNxGjuOpmNYbYSvaTfS9XrcQfQAC8jEhEydxcsPkBJ6PBu0hSyyT2SSEQKnrX/Sw1Abi7vIjAn2SEjUjKJgS7kbJ2UsX58xEojsTJNQggVNQTWrhXgSK5hZjHmp3koaeusuOZauLm9xbNtw3nbQCRE07Y1NGzYIJ5hsWspTHLruZz806adeXhxmruWODr37343KIQKeR8bEABSWAHCgDVypEOqxzHICaDT6YzTeXOSxJ5Ra/WdIVMu1r92jinzaSJw24b3niaAmuYyIBFShQo22lBIdylLwQZoMrcpjAGKtWgkj81Z69JpKvDSrjp3Wpd8G5U7uFhyQsgmHUdoJFEHF3YdL8QZALDuNsRzuHcUmgB9360xtraBtg0Pp5PsPihZZbsNkmcJXjUBAObJdlMQuytIldtUTtguRrMdpRRuAGh1Gl0LbnyRJQs313H8V7HK2D+QnqhF14ore/FUdFCgNxHPE7s+PTKDRXsoh0tvNnivHZkYtpfg9Hu8BZu5rWWKYcUhfyiGyADL/rkiG/SftqO1hu995zv43ve+g5/8qZ9EoYLb2wPeefcdfPWrX8WrVy/x8PoTrOcTIHAHZStoFDlZbH0SInnz7fGA3//7/mn8d37nz+L73/y7qOeX+Omvvgu0RxA2LSYQXg1ba9ia5FpplbAWlrxFjbDBKg9qTq0q8nzrQhJ0YtSqCdcBJwW4aQh1Ea8QHSHdDOliZLj1oSQHF/iuRWl+DatxTYBXFAOpF2Qx4MjQuiq+swqIrq2zPNNH22OeK3rpoGkGzRvqumGeNlmzSkLUWjBtVYmAjlZEp4NSzjGYvpv8X3huCiFkILlq/sF8HhHho48/wd/4W38Lf/frX8fr0xk2E0PvS5hGqeR6wAC+6IlI3lmKeksZ4cGqtyHhtYTYxc0rxoGsztPe5Z39e4hcm1RWAiLf2ibkfS6OwNxxPq+y+aDFICwP03ld8d3v/wC//Mt/Dx999CFKBb7w3nseCrdtG/qz5yjThANVcFUSTkG3l69OhqWFL+SKXk0rsVnuprwefSNlmpz8a9uGqsUgKsF1oRk39qy5Th5eJjijofaGXgitmwxjUKmo04LZvFgh4YnLVFErybph0WOfVlL4N+DxD6Qn3nn7uZ8WCMsCcwL1htclu7Fn85l95aSW5CdbGBgZPnuayAAMx42bceN316+1suBi0iRj7ofQI/kQU4r97U1PKdx5Ujdl3XOJgXUNOcsC1yVsRAt002xnDO9//zRD1c9Num+/YcIWN+Ivqfd1AGgNTL+Thf9wIpHG99+/e8YBRghN04TD4YC722d4dieE0Om04rx1rK2jtfxuKoOwI520DZ6Ko2hlQ4bm6qlqU0majToXTapcUcsEqhLxME+Ew+GIqVYsB6luOVXJrSqVuyTsuFDBPFt1LXnmNE2q34OUMeKk0KQbEoLZwZrzVrF2sY1+Kv4egsGDXK9Vir7kexs5tO/80QNonAv7McoALAhY2/gIzyOzc5xE0YqlQf6nVT/MLyRuwtqb8ICNU26TnsnJltvPd7PvJBLk2howXTO+P2m/eDU/Np7E+AC6umbfSPDiH5wQ+g4RfVXZ/K8C+K5+/g0AX0vn/QSAb127ATP/cQB/HABKIR6/001KxxHsn8MW/O7QTXi4kNPzt23Dxx9/LDlktg1UJO7+9tlzvP3uu3j9+hXW8yN4PQGt44QcG88OcGzivvXiLfzsf/0fwT/3z//z+Mf/iX8cN7c3aG3F/f1rPNy/xA++8038W3/6T+Cv/eX/N+4/fomfeO8tHJcJh6lgqQWa1lnj5tUg5RmtC/nTIQk3W+uoBSgbS+gaiwdLA2PTqqeedJQ1LxArmCgYd69VIHdEaXoT2kmUw7SDG11XJqcZr7Z4DDQC0Uenh0c83D9o+IDsPNRpEqVsW7LWv9zAODqALGYMQEFskcpLpCFFlVmF2UkzwjMOy6KhZvKvVEuGrOz9YcGyHLAcDri7e4ZSZzw+noRAaQbKpSJBqRXopElWi4csXTvIiDBdjCX3F0eZcgMbQWheF2oGMDNokBLRIyFgIoTZ2h6GhQgeM3vkOaUKaeOKev8ORG5YnNcNKJRCKUkFoUIkNuNBQJapsr41ITpLkbBMcyElc3HsDvY3jlxHUnHL1pvevzU3Nl1RuAdRca8uSU6qXgREWpUrJbzTf4Lv2decDQrbuFiJxrRomuYP2xpS+F4yIChgkCtAEqPJDItaqu6UwHf1zVW3lDI4UOedgk7q2ioz4GLMfgMdv6p6YpmKOpiUUUGWcG83h/A4IYhNopQjhSitlfHIZOibFGghi/OG3y/PE8OeBnWYoR4pb1bKRLj4fr/TkxX+Bx/8AN9+/1t4/fo1jCB/8eIF3n33XXzpS1/G/atXWE8ncNvQ2oYzrVIme4UktDfZ0QHeGr7y3rv4fT/338ZbNzNefefvYW73uHvrBgtuQHyDbZPcKIUZ3CSZ8dQkcfRaCOsKsK5xkURF129D6yTJGiuDIZ6H6qALqkVCZtCF6DVZQ6T3s7Emz60GGhykET54HL73rKFApAaRDkbR5W4FHQpZedqQHZY7LYfewmglt6yKePWVAkwTaJ5Qe0ftTZJzC5OJZV3AC7BtZ1AVD6XepmE83WvRvVwnLVFLCrpF986zeJ6Us1RJvb+/x7e//T6+9f77+PCjD9GpoEwzttZxPp+l7yDg3zjFoiVzbSOiVpHf1cMMKAwQ/c4M4WmuqFV1vuICVjkf83Sn4yB4qkjklP7r2FrD+bzi8fHR+9nu5X9Dc0hosu6Xr17ie9/7Pj748ANsbZM215cACrZ1A3OXHIbnA+Y6oW8FfYp8eRZeZ31uui57Ckk7ihs77tWlOY2M2JomGcOts3t3uf7chQUZqVQ4cjty2zAR0BuhU5M518XYMwOumC5RebatJ4Aa6kRSTKJhxB+/sY5fVT3xkz/xZRXCJovlHEqfBV+xM/o0GZkt7TdpXjc6U79nQjF7AuR2vIkAGjcg9d49/h4Au5JXGadnAme8/6gPh0P1YDxbPtx7FOz1otzNG6N6Ld9UzGvRu2Mi/WvvfZUsS+/lraeRSPHvqbtudc8aazdre9RWCVvRUl8YnjP8EO1CvseuzUAQ+R469vwZHk8POJ/OOJ9XbF3I7fW86jPYk3A7LjQvH/XUt4TLRJK0mYumyrDvS8U0aY6dohvvukGwzFWKrGiUxDzPqCWSz0/TLBvoWmrdEjzLGAG1iLdKJsqlOnNV3RFePrmPL0keG9fi5qTAoj70Xba3h7FOfZ/lc9bD7F6AMTdlAyWRn4j7SOivht4pZus22CwknOVbtMrCUZTEkqIbVjf8IM+D6iybYzbD7DvHkz2TQnLWVTJ4eNf0ueMOKVQFQIs1wCteZzmU+/LTiNd/UELozwH4FwD8Uf35Z9Pnf5KI/hgkCdxvBfCXfrhbjgvumtwgMvZOBLFviFAS3ME3iJLeNrx8+RKffPJSEi+SlDG/XQ54a30b9/ev8fjwGuujZoUvkngxDmEUb25u8FM/+ZP4Q3/oD+Gf+gO/H+++9wWgVDQAqAtul2dAmfGN/+w/Rdk2vF0rvvzeOzguwGGexA1Y7wdo+FNjbE1CZtatYe7A1ptUWCqE3ki8V5rkX6yFsbbunUNMoC5khngNCUEju71awQkeIgljRS3niQnOoDUB+MJNwlv7dK8YihnBiPAbIsL5fHY3b6lmwp7pXTCoEgiTlhLUXAnHw0E9psTYb2BglYRsZCFMzKgMLMtBknqjhwGuQlQE5xq7rfMsyTeXA7YbBlMBkxjk/aweR4U0xl92jNumsdKW4+jKQsqs7JsWWe6zNxmZl6SQfF6Su6GTNKV4efhNQ8nWrannUyR9Nu+gTMBnwGDMuR3TNIE9FZUQQ6UqGGYMgBkzq6FGaMnF03ZNCklss9FQa9tQmVFac8PByBSA3CtNSDD14GqrAHfobrOWE6dCsrkzKAmVC3XynXULo8zKpncGU3xmhUhhhmdjlx/a677mYvwAhhAMGzcFKkEE2HrxkNAahNFecY7KVI20YqniegJdv+GOX3U9YVXgxKlyB/jTuhqBNTQUJu7z1M7JD7tTGT+zXEx6y0Wn7VQFKfQmM2Pf7vxZBlH5eHx8xLe+9U18/PFHOJ3PeFEm3N09xzvvnPD61T0eXr7C6fU9tvNJCJeHe09CbGGo27aBtxW//bf+ZvyTv/N34PEH3wQ9NkzzO3j3xa16khTwNqG3SQjmraOtK6YipcFPtAEoYC6QCmJyTSFWg1UIYpomrG3DBAldq6XoRp2GTZUiZG8BqMvvpQJoENnNXYhkmNyQjpX8fqwimeFuq4oMrVIbhBsSUAgLEVOaxwG6SRPNE9A7mLt72oKNDC/QwrropYCnCmozSmfMzCDaQE1k1zSZV9YMNPWW2oQZMVKmpDCjaRZAL/nYJBwgl6e3vGegIMgbd5Rpwt3NHToDL1+/Fl0AAJqIGWShC12xkyXBtGouFRa6XItWg9HYAMIkRsgUod6TEhVZr1Ch2IRIYB8ASu/YNsK6bTgpVjidTc7bkAXhKaV7AVJ8djqd8f0ffIAPP/oIzQ1N4OWrB8l7BOD29gZ3qxQO2ZYDmBnzQcIpjZQZ111xPcvMqeBCda8kW5eRjJQH3FMgG0lbb1LkQfP65MSpgOAmS4DKEFBPvaNRA3UJdZtpcQOqFDHqrBSzyAAIebmesW4btm39jewh9KuqJxTG7rSm6e/Mn4QMDxZIft/r3OxjNH6ajNIr+ifrC3CELEpbsr3Dw7mkWIRNzmQ9o20x4zRjc+zun41KozwutQ/BQuiGT9P7PIVb92RX/rwUkbPZMH2qf/Jnbzqu4WYijwuBA11zyaV83v4emSSjRArBxynLr/zkPYkxTVIx0Ko+3j17htPDCef1jHNb0doG7pYfh7DM6gFqcpwKSp1QCzShc9V8PlW9biR0S7yRqntuzvOEQpJLzu5lhFCtk+qSSUuvK3GlpduFZBZZL8npm/ZRhJcQtB8RYVQuZwqh6GIz/JrH0uSyYLYCIiluIcWZUvSFpjvx4Td9nYgYGWPR2DGO/WLe7ucoY5ybET4eYWWFSPRIyWtJ9EHvzW8QHsI83GOP1fJn4g+hst+SRA8EULKxberyU1gWu78zoIWTQN6Nu7Zc65/98cOUnf8/A/h5AF8gom8A+F9DBPcvENEfBvDLAP5ZbeBfJ6JfAPA3AGwA/kX+ISqMAaOYupQLNgPi14vfd6ebMu2949XrV3ip+YI2jQWfpgUvXrzA+eERj6/u8fhwwtoZXF7JRKeCw3yH29tn+MIX38Hv/b2/B7//D/4B/NhP/IQYyCTAlxnovOLv/H//Bv6dP/2n8PL9r+P5zPiHf/qrOL9+jVo3LevNnjzL8rysvWFbJcRnWrXk7kbYSsXWOjbdQQVJniB5ZwFmtcuOVBNkrC7hmpgXkM8AVK2MVklcJy0uvXVJNDcBo7CjUFrBhPYwcIfVRUo4hXdMAaNtZ9zff4Jte0Tvqyykaq6EE2gm9KWhrStOZcVKkr2+zgVLm5VpFSBeoSFRSho0XaB1qihd4lqXZZG/3dXdyCHdVVOiSMCvhOht24bzuuLx3Nyt0/IwsWYTy7vCIeB0xSJciweMoKUF806pXW9ePEKiiSSVxR95EYglb06VjldjIYxfUOT3sXBDZnEjb0U9cHrH1tQzxwwAtjwdDJoSGVHEUqq6YIgZhcuwpLLwFoAbjL95AtRK6vIoAMtKUBbjyNVgs3tlt/yibqZdlQJ3RpuaAt2KzeraMxwImYeREI7C/Bcfq+I7LxnokxrjvXdNIJ4BlT6CC1DNMICPi20bGYBkAK2x578gXafcE4gywc8Ar82Flvdl4bTGWNZAkaShpYqviynCz/rx66UnmJuClEtQxyzpoG2+D9fpOi0UOygAa2JE8zi6vqOSP7tG1ETb0kMp7Tzp36azGLn5OrrJGH363Q1IdAcNgJA5333/W/jge9/F6fU9ynuM480RL956C++8fsCrly8ldOzxNbbtHJW8INW0WhPS93f8zt+Bn/2prwIffB0//nzBOy9e4O7uiMOyoExCxPSJ0DZGWwkbb0AXsoIJmFhkaJ0IU5NqHhtvaNi0pDtLjqBOmMoEoKM2rcpFCE8NhgI/dkxPTLAY+0IAiuzrMpuBRIqkMsDSHWsS0qgYCaQim0r2SFVZQQUziVFuueR4a5qUm9I/9ntDPTKpVAlvnQrQK7hXVCWUxFtVKoVRl/dDZ2zTCuoi711/FcsPpHnMSPrirH1Upwl1ahKerRtWpRT01jCVgrefv8B8WPDy9b0kYlYw2p0AYk8iDZZQC5v5jQjA6vM751OyfBBiyFiuvqqhnLFTDhhm0dC4buBY8xAV8Vg9nc84rWfNZxVmPOk6FUOYzAVUdNW64vHxhPuHe2kTR7j2tjU8nFactoZ1O2PbpKLa/cM9DscD7rR9VIp7i+7XcP57nytENhP68B3V6ok0aum+2z7VycO2c6gY7J2U8GeGJhw1b9Z9eDBrEvHqutJkl8i8gt7P6rj1uZ4AMHI7bigEZcDpe5fpREl00IVNwYO+kft5taFdt++JHdcl+vAsu6+RLpHHSkmH5FEBrYAJjs20zuzVIi8MYmYYdR5tMP1p4VLh2WNGv23SRaXG8f1ye917yfVrjiKQpxqG2b/v/p42Avkf6b0jOXgOtWFImLCGRejf3m6OEWPXIWH0+7uzPffyXe15lkIi6+m8ZmstmJYJx+OC29sbPN7d4ryuOJ1XkQV8j7ZtWJYZz188D1KoiK1CsFDgKDAglZt1Y6VGeBoBmvhZvIPmeVICaMY8F/UQmp0QKrqZUOqY38fChCO9QurXPIcIENwhVYQ9MXK/XEvyM88jeL9DaZ1ai+P5kuaYy2QSHen25W7jWsZN3oF2YC/mx2ivGpYOGy4wOkEqHVuokdlnUlK+awo9cl0T9oJhgUtPQSHD4m9oFW6XIIZPdmTrtTXMOj9HIimvHygpZH3DyEvKKpZ92vHDVBn755746r/7xPn/CoB/5VOfvL8OsoOYhbVhvJH9Gb/bv+P+zM4d63bGRx9/iPuHe93pIU/099Zbb+Ph/gGPpwesmwCh4+EOb714B7/zH/1d+L0/93P42td+DF/+sS9LeXACGsQ7oRPj4f41/v0/+2fwH/z5fxvv3kx456bieKiod3fgtw7o50cALJ48Boy2jvO2obZNcq9swsy2puzruflQt9Y9qWZR4mbiosaGZt5kYTjR2WPoubjzo+gP7VdzkyOSOHWboJaPyHYyZCwBI9asZ/PutO3e+e4m2Y4rY11PYDQNCWNduEVUg5Y4hxIXjRmNOlqvwCylWS0B71pWnLdNQ3iaVEljeNUnc9FeFtlRnaYJExVs6mJdlfU9nc/4+OOP8K33v433v/Nd/OCjj/HJq3s8anJkAjDPC47HA46HIw7znPIt6UIssTBLXpgULo3yjiHIrJ+yoDMXQhMkIn7YDUVuG0CkRFA+T8dK7yeu693L9gICuk/nMx7OJ9xui7p19otEu6HU1ICGGodVkkpXZrQSORssMbURSQLYZxWu0BCOs7qvah6KWtyLr/eOWQ2+cMe38LOqJI7G+fau96nYpgm9xXqww0L57F7mVdSbZfFPSUvV9VNc9DQ3TzcjxhLmXRIApugNowuOV8+6zuhTjL3s5nUIX2kAUPuGWRPGh0FBtt4sXI1Z5AJvrkgkGWu/AKefxePXS0+YLCKVKQwjeADmomumXQL6i9+COMh/v4kI+rSdzAHs6j8Tp5R+B1J4h8oT5r0h+NRxSRoxMz764AN85/338XB/j75tmKcJd3d3eOutt/Dq3Xfxyccf4fXrl3h8vEfbGl4DeGCgbStulgW/+x/9HfjiXcXh/CG++qU7vP3sBjd3zzDPB5EhGna6tg3gSTwxmoZIFdVHiuFtXcmuJqMUkdVEQnZYomgzdou60XXzwtCxKETCN3XZzKBCET7hAExcsAkFoIKCpuQfeb8DcI+iXOXN5LE02lzgATBHCVvS8DRuTk7BDTobazWctJ+oEcpUMbEA9947Wmm6E1tAyg3XUlGnqrpNPXKqhFfLjq7JUCO2hRiY64Rz3cRzSkO67B1fPH+O43HDaT27XFuWBa2JFzJD9K0Rab4MdnPa5thmhQH0nc/b2YE1KSE0az6jWivO66Y57VhCg1v3/IMGfqUwRpO8UyqbySsnqSGpeibGWa5vigWkgIQUPTD53iHveP9wwv3DCa9e3wNc8fD4iLffeQdvy8QEc2xMhOEOAHUgfYBMCkVIvHltUAljrZYKmsUbdV5nLMvi97Lr7CA1cKyfK+oF0WRVzUw/Wv9GFR5pe63qVTdNl2D4M3j8+uiJbAwlashFvpEdiYAzYX31bj2teSMX5Bvz/tS2yvdZduyMPVECl8/YkzmjQZcSPnM+xwxnxZV8eWPD8KmcRViPuoFsNsF4nb1Lcf16+R2lnz0MeX2P3nIOzv35l8+Td7a8MUbYRHsvrxsa5Qa2jW8YN1D9s38qebv4YlBG4s7GsaWy8/tKikQF8zLhsB1wc7zB3bM7La7QFCNuOJ0Yx+OCZ3e3uL05Cok+zypPNaFzIV/rlOS7hZCZp+gyVS25Xrxirv1clsXlxqzl38XmRcLcrglh1eVkHDa4bnNboZvJIucbWVIyuRFjsJd3Fz1PFuUTG6J7OZnXll2T+928xeW7RCYBu3UUbbOk0xmH5/lgeN25hx1Jk8km+Zz9fS9JoTSbONpfeMRwZnPv18i4zvL8NLLK7p0x7d7mlPe6PPf68audVPof+AiQFp+NbefdmZfnEF27vuHx8QEfffQhPvnkE5wfH8G643M4HPDs+TO8/fA2Hh9fYz2vqGXG3d1z/DP/zP8QP/9P/Txubo8i9gno2UAH4Zf/9i/h3/4//ev43i/9VfzYseCtm4qbmwk0A2Ui1OOEvk7gvkmen62hbx1bbRI+1QpWUMSFFwahgWc4aKkgsMY1WuSKkD0i5DtL+E2xHC9F8jV0K5eJApAK5h6T3fwOYhLzMBnl54WWGCZ93sUjKIjWIRoXmvYaCZHDYJSpos4TDsejQPiTLggWN+suLZcFTCeUYhQYo1cFZGzVsaonry4O0hSo1Yq5Vkya7PrxdMJHL1/iex98gFVzMllfP65nfPL6FcCQHWwFWoUIh8MBh6U66WTvLkZKB6i4IpJkwZaedEcymBtwtg4Rm16acgkbWXJhWfwOQNS7YVOSxsrvmiA7nU/46KOP8NFHH+EHxwW3twccDwtujze4vbnB4XDwMSYizXHAYK3cZu7ve8FBgHvCVAXBVGWuk5YHDlJMq+h5Jv8gInsRzyYoqeK7nkWq6BAJGO7coHlXwUYUqQJhCBmr7BiMHOuLVJ4xgwQshKoyoTo3q1eMsblj/aF+AjrV2b/ragyIc54pTV2LLIaIvDtL/ikOgW3eRUFcNR3nnvbtAmAS60YXKYmn/fT5YfI9ueAj5GDsrrKqSx50qE0XA6xABgt2/zzv2Z8Zz78E7flnvodCUmnjRd6KID0ulf01MDB8iywP5Gh4/eolvv3t9/Hhhx/g4fEeL/gFDvOCFy+e4/U77+CTjyVf3sO9EEKnbQVtZ3z57XfxO3/mt+A5TninPOKL7z3D288OuDseMc8HTHV2TL2C0XtF4+Y7li7fBj2s3hy0eZuF0FDwxAwJYhI5WUmSyjQTg2z6iWHZAKy0eVOZ6qFbYPEW6gYeTS7ofLEV7cZgPuTcUi1Eyq5hHzeigm09pzGmNGYBqGHvXACqs1TpqgBxeHSK94wc5tot4VlCaAjhY4S7EgfkjZLqprqjLCBcCGqTUzc3N3j3nXfw8SefSG5CAMu8aG4bYF6q7lYz1MaVexgZg/iMk5Fp66arfHIc0C1/zYRpC89PCxXrZPPdDD0eMEhTop8RYbueSJuSJ6XqckloKlW3LAE1K7lkHlwM4PHxjA8/fgUC4eHhLDjvxQtUDcHLBow9E8Cw5vbewaUUdBIdWFC1apO2R/UmmDBNsxJwES6397C1Z0uYxmhU2jXZq8h0pOUACSMt2kbJmPj8kOMCw+xk93XjiJPha9dpQlOmOIMsd8mnP3/QD+Oth++ywWnrzu7PCgxJvUMHrzO6fh8vTAFWHbTLSUKqF9lW4f5tiv80UsgMzItjp1Plo5FwuOiLYb7a8wXjyrNto8e+z3mI1Ev9yvs7weNVw8a+2bfTr7HvdvrYyQrVOSbf9ueYt880zTgcDri5uZGQ1dawns/Y1jOIgWWacZgXPHv2TNNaREjpVOWf5+ghCe1iwEPCiGQjvAIezls1NcYyLx4qlosU1DpFKPDOy9BKlrMJekzgHnieidSZQTwhmTtqmVSOB9IxD+tSCCXPNZVNnOeO6oaRlB/n1R4HZXkdbQWsMMh+PPd/A7ERkHPC+T27FSjJ83e3WafYDir/8eR83h+s97okrS4R4BN3MBshPSa/Q2xyQNeG/Z42nS88UMfjM0MIGY4bAfjuFAMj6bs9YHfyIc3V3hvu71/jk08+wcPjI9omhu2yLODe8fzFCzw+nHA+bTge7vAH/uB/D3/gD/4BlEpaJlXBp970fN7wn/7FX8Rf+DN/CjfrS/z0uwvubiYcjgsmDV8S+cfoy4S2rlpdZEOrHXQGQAxagWK7iAZ+rbz81MFM6JZDwRZUBUBFElJyk/AdglZ00kXGiOSqJKV8e+9A0Z041udDSC7tPQlXQvECKmO/xrL30JxiIA1OxITSyEo32mIPNWO8KoN94IMSQnIfJkmBWTVE7nReFVgCZ713QeSrsdwsFn7kCdhKkcTXxcpDTupNNKORenWYJwgHAGaW6mbreQUYuH+8d0NBKtUVHJYFx8OCWcvbl2Le4+SVVSLBmQhVMVjVZOURDMYUY2ws5IeEmQXBgSTYtrapW76EPp22Ff2BATyCAHz08Yp5qnh2e4P33nkb7/E7vnPgILNKmXUpca6EkK+x8AbqENrKdhcyIy4hWEJ+5J1NgjnlApZJVKrjlVjw2keknSe7TGx4K80jKIEkfSCJahVEsMyTDZJbqPZRALIBcmvrtmmiP3heH9ttNyEdOSRS4jazMn0YRm85+cWAU4xTT4rGvImkn8brxbix0EUZ195bNOBH/DACLu86ys+ReC1a4U8/FBBjTKtNGTagLzqDCE68ZVAeY7mjEgagck0PmRdQgIa9oSF/Rlhhvnb/e75i3w4iwvm84pvf/Aa+94Pv4fXrV+it4eZwwN3dLd566y28++57eP1KCKGPX70CAPz0j30Zv/UnvoTb7WP82PMZ7z2/w/MXN7i9vcUyzShUPQSgdSltXSEeH5o1S0ImzePP5PwORJkc7hqKiR4EeCkkue724AziSVIYStqblxEgYc2cwJhYBqL+KUCb9f0FWLRcQfYBa+L4qiQNeTllIoDb5oDZZHeMBaV/4qXEBaA6SW6Eyrqj2zAfFsUjXfXRhNI3zfPWfb6EN1BxuYWUh6bYtC3k82+aJtze3uL+/h6v6j0AYJkmbK1hBmNZhNj75OVr9EfdXFE3cssDwXJLuMcBWD1qNJ+fdNVOX0mexi0RINYtXdeOaPTmxI4ZbFLAwSp72vPtvUdQP6knJ7OEDNIkledM91XFacTAum14df8IAHh4fMA777yD2+fPsByOqHW6MB6fImBDBkjrJicENKcUdEdbxyjyekRSadOHTwFx07EAhvP37du3KYx9OAFFOxn1o3pcbmzSOJZJ1g4kDCw1gsylUdTmOTI+65rRujf8/PddW/O1mQDsnTRMRZ5N9l/qu/cZ77P3fJPPmso7V5g7K1TIlkGOAYBW6yRtg3kUWdjNoJ/YvExyeIu1i/bqM/UV+3dxX2tTeL6PqtDkJKScOAAq2YteyTuKzb6njnETyNVH/J3nB4ueqCDZmNiNvZE3tVYcj0fxDlpX9M5Yz5JHiIhwOCw4HBfcHo+4vb2VogYa/mXVvbyqIes6NxvLMLl6s0ooqeYYU2+jop+Zh5AQQvZ5uj69V06kL7RjJHvuvfumrJFyJp87Eyy82yMpWPSIOG5aZIRiA8/hkyIqks2wl81DDizKkRixkZfJnf2a36+FPK75Ob0DhdR7yFGMTk8NG7N16PgRqnMop9h4itox3BDt8D7Xp+3Xcj7y+waBG0dU0DQ8qwRsSmB9rR/2x2eCEMpN5NRnCc+7kHH2Nsk2wM5hHzC7Rn523N/f4+XLl7h//RrrenYj8XA44ObuFnfPbvCV8hX8zG/7Gfyen/850GTBHLmdjB98+9v4xX/rT+Mbf+0/xFeWezx/54jb5YjDYQbNAvIm0jAbu6pIzLqUIJWM80wMbmLAtqI7TNQxV3E7ngqBq1S5AlVQMyCiAlMXZQF7Es5OCtggQLpo4uQNeYdK+8lc9nVSEpR8sTYTIk4U6m6f5ToBoC7GvQsIUxZidBsQL6VKXqYSBgN18XyqpWEqFXOpaNMMdPW0KQXUZUeSFaQWItAmMZ4rJCeEZcu3imJTnURgV/FAqmdxy580hGyeZ8zThGWZpKJHLzivq7K9ujiLhCQ5cLC5qD/XtgKd8Hg+4ZPXkXxzmWfcHI84HA6euM28ZMxrZdyZYteVQa5IjiSxmzYhfbaGrVmCbh1H3/kxt/IJ/XzG6XRWUqFj22Sev/XsDqx9dXd3h1uEsLUka6VoJQFYRYi0C8U5hEIEZPasaa1hAXxXVLswvKjckCuyY67Gns9J99Qxr6EESjC6z18FEkX8VietgFM11Ip7Ry8VgCTeIzC4N7QaCbnNyGMFRW6wMHtYT8gWISq93azAMQlZWSdJoqmLf3fZJOuj6y5YBnIGplhJQKtm8/nxpkO9KBiSZ8zBQ0kKACASo5shup1gPigAW54VXeG+PgcFTen3ODIoHz/TNnEG6HAwsT9CV42G6aWhasCA/e/eOzo6vv+97+O73/0OXr16hdPphLtnz3A4HPH8+XM8f/EWXrx4gW9+g9G2E372v/aTeKuccfv4AX7ivVt84a0D7m5vcXtzKwkqSbxVrL9kPWmoHkiMBSa0ztg0/1qw/qn7dmsk+koqlbQuVV6YQyaJkR93Yr2Q00od+5U8hCb6iEebx74Zl6v8zl0S0Zu8QrSlFAllM5ljc2a8p+RRIqpAmdDLqnJCvB5LmTBVyYvWe0fdGnon1MooW0Gt4gsFkG9eUIkqUyian63K57LxzZInTds4z7IrvSyL9oUURzgeZizLjNubA7atYTuvOGsVrl45T6Ohv3W0nBCUTYJd+Es6n5N+A5TY0TU2uNOnh5jhI/fX55asM2KgzDtJZKmC/0JaXEBmJXp4d0g+oTOoAG+9/Tbu7u5wOEj4I+t47p8R4zl6J/kcg4Wri8FkRhFJtnSgwzedtm2+CI22OZU3ZIikcEM2zuy5134CsckAwL2MaD+xPz/8uJCpGImAQYYn+TTogjfcez92++e+qU37+8Tv4XFu7WIFpyLXOGRSwkUXGwpXjUwyJajrhWF7dIM1pgJ8bzxfa/P1Pon77fVZyIMks1OeEyOvskzPfQPVQeRKJr+fKFMXNRc6dGzr/rjW1v1P2SRVWZc8DAWLC0FjHkK9dWzrhq2toAKX1YflgNubo+cCEhhr+YLqsClBmk/FvORto1Y89WvIliKpFzxyYvAQmlKCe3tPsTlMX8jm8/j+uWR75MzJ+TflZ/FoCUFaTILNByvSh6D6GO/Dy7K8vDbfbG7FuouQrcvzxrl7HVeFbcvQFVZIvfW1qAtVGAIZrEEB9cP8c3vhCXnc+66dfBmwmPsi2pvXQJxjPy1frPSJFUGQjSzb/Pm01ASfCULoqSMYMWAvWPYD4NfYmRw/e2c8Pj7i448/xsuXL/H4+CiJNAuByoTb2xscvvYl/Laf+e34qZ/6zaBpgjmEkiZgW88n/JX/+D/Ef/CL/zccX/4KvnTHePv2OW5ujijLhMM8KcNLEkIzFdyvK7p6w/QiIV9WcpoU1AHspW77ysoQwz8rTZj9UgoqM2QXUyob1aKgvBmwYzXkdTJ3NcyL7VCRJPdELCRAFyQb0NZdcZCW+E1eHpwAWxGBGMY+3OgmQMBZUpbSMNNAcoG5QE51ktw1W0MvjF4qaumSw6ZWVGbMkypoIBQHIwm92T13Ckf2/prAtSV8XOaKwzwBBDyee3KblTRmLfUNIVLNis5kNXJi/vXO2LokQb5//QAqkhzusCxCEM2LA7fYKdSFTvD8CYJpRei0ZpW2pIKIhWRZJS7Pd0GkVQnEZV5yCnVsTXJnQcfg5njEW8+f43Q6waqPWXWDzh0k8Q2aQDMILEBzeUDKuYttV5ISFFC6aUhEay0Z5WNCUukrCYPypJxJ8JuSYpaKBMzAVLOLq5Elllg6xmmaKtrW1L1WcvmgAFtnKcGspCt3qXxWtw0MS/DexOOIZAYgPeOCWSf1VCJzIQ5X2FKk4pCRbAbYmIEptb+zrGVOgsvcVY0Q6twxpXxLnx+yFs1t2/QwIGa65XkQ75KmcnskT5jNnDfjiWCkNRB6xHWv40w2XsmfIeeN4/Jpu1D5s6cMkkwM7cHQ5bPY3633jpcvX+Lb77+PDz/8EA+v79HeegfTQYDpze0R77//Ptb1hN/6k1/B/be/jmVq+PEvv4V3X9zi7k7yHhyWRapG6XpcOWgYyWcloV7MjN4kDFr+bSOgN2OdhFCxBLuAVp/RKAwDVfamoqv0MQ48faABA2UuB0dwGP2Tf2YDX3UWYi6E4aSl59227iiQEFMjhVjXc7RZxxMVDCGEUBqodA0nlk0iANj6htIaqld02URvFpM94vmYq4iBcqg6vE911L1ajAP/qaK1DetZNgNuDge8/dZz3BwXvHr1GjfLgsdlA/MZW1di2q3B5MmyNyyhmCAZv/7PtCHFOWagwD7XPrf7DcYvFKhSjAp2a8faxcziyqthglBChli9ylRmNpYCC/O84J133sPhcPC5iM5D5a+sUzjpJl+fvYNqlXmsAL7KYOimj4SNieeWbGxYaDYgSd/zZok9wzZVpkkq2xJ0YzD1/76v7bD5sW0bzucTrPDH58fTcnmUqSo7TbBnG4Ivr5U/gPBle/p51/R1fvY18gYI7x45R+e2AW/AZQ+zLlkYoRJGbbQx8Iei5pCl4yvpNexPiQ7h3b+sDy/7NM/R0HOCF69jmMtxGm0G04WhF6PxNNwn43GzDa484kk9TEQe3j/2gz17p9sx2jch84L0necZd7e3AEtYa+ubY2IJ/ZWQr5ubAyx82qpfktqAMgzhZTO+o3xWQEmeyOhnMsjC2KyqmOHTvFHFai+ykeqqh/djbNXAmKt6nimON7lfRP4xtyD7TcYa8VIINh/3a29PruZ5s/cEym3fk0D7NbafowNhFOpfNsS9PeYhPnIQMjXU0k3rU99g+D2Ha+VjeD7HZ2aHEhmJs3s2ol9Mj0R/kesxn6Xdoj90fPnN9sRnhxCKuR+iyEEvYDPHKwF4R10/OJ1DxGjbio8//hCfvPwIj6fXWM8PaOsBx+MR7331y/hNv+Wn8ezZM4RotJ8d7//Kr+D/+gt/At//238NX5gZz54R7m4PuLsRT5Blnj2WkwA0AsAdS+/obQWTMsqpXK6xvFsV90YiALWD0YW0IQnRqaWCO8HcNU06kgLJ0oBCUqKXwSBdY6tVRXFgTD7hJZeP9lNeNEDyihLiKIN1AWxhEFUFsMRAZQXSAEhirwYvklIIvVT1vOug0kC9oFRGnTqmPmPeNgm1KhWdGrapAr0JwTNNmLQPwdqfSkIIA57Cx1jyM01FSvXO04R5WTAfDjgcFtzeHvH87ojpfAZKk5jglbEqaKsQjy6bYLb5nUPpfO5xqKJumYoZaKskzXw8n7DMi4RqFRHOEh7RfVe1c3hjGaB1wiOTSBRquyfPkdZLSlynCY9VMBQCTlvD/SrV1FraHXViEgQuLC/IUv3ElE9v4s1GlcSNmXX3iqJc/LIcvCqcebUw0a6MYwIIIH9fV6REWkmI0MmEnYZD0Jg7ASy5eLYeIH4iSeTaOmCuq70TCnU1stRDSOfurEZaKwRGdWfoUmI3xEg4C/Pa+gaAtDqYGZXZwGFYRjDS3RbbzXCjlaSiWwZ/foKNZ2voXDRB/HWA+SN5EJQEV+OV3V8EtmNlyVGYAjj0BpGxmpHG5Kdd63uJmURQeek7K1BDjsbdLDv2Bpt9f904AJ4Gw/m8EWzvn5tBNxNwOj3i29/6Jj768AO8vn+NbdtwuL3B69ev8Nf+2l/FYQYO2yt88PW/ha++WPBjbz3Di7sFN8cDDvNRvS0nNxIaC6AQwqe7nHK51RqwdaBp+C7NYnyUjr6Jq3zrUgqddN2I7IvEnELwddhWQsvvSgqMO/mmhHjeZDAPH//om37Rl6K7Rq+QQkWBtybrpBKekEogS8Jr8Sw08NYJmiPBNYPIZprlXUqHKGbWTRCZSxZaXWoB1Q1UO+qkBHgXsD1RQZ1mHJYjpjq7i30pQK+p7QDmUnEi8xCtmOaKjo6u4c6VCHfHA54/u8E8FaAd8XBzxnkTT8iHxzNWFu8y7rYW4HM9z8NxjkY7zDsNavhBpzYjyUUyk03myX7egyNM0Mi+DvNy3q0hX/MqNn0phY6RsA/Rqze3z3F7J7k6wIJpqMYGw96I8LAJmwcMcIm8gGLvNHXRF3kOnzORFW6eehgbJ/J72+ZG6F9yYC8Vf6DgXXSO3bu1ph7mEbIdGxYNVCIR7OfHpewcDfpMYLJWEMsyNTbbQhbJdRflK3fHBamBrCdIDcnrxuvYVtJ1pEnXbfNY11KU6fbt2ov3DPloBrjgl7yZZ57YQbgYC1Csg9L94Ofu5cN1ssv6a9+/l7ozy5T4IjC394nlDtIx212h9ysAl4tvn+rrfdvljw4JDCuQ5BU7I54sJHx/SKL7UoBagcNS0daKdZnQb27R1w2tbUBv2NoZW18BkkI6WvAUCm9gZLlh7SALNPF2AVAM68R34jVaUesMohm1SMjYVCePChDbWBJdCyFf0ZrKurbBcv4JBpbBkGtInzNu6nqVSI1nrsjJwfUck4c+lq5thnkjm0KBEYAxV04mp1hD6vYk0LV5lsd8/7sCed1k0I/UY8uUDFu6FbbogRHzJYSm9x+ffTH3AK/8jR2f0XWzrPfsCSgeS33IYVWBzlpMR+YBA47RDJ501lynv2EIIT18/GJc7M/095uF8sX7shhZr169xEcffoiPPvwQz+6e4ebmFv/QP/wz+PEf/3HZtQN8t58A3L/8GH/x3/3z+E9+8c/j9vwSX7wrePv5gsPtAbfHAw7LhKmI14mV8uPOWk6UBNxRUZDGmu9l8/Lj8SqyOEop4C0ScxEpHkylUVwxWH9B99SScSAeDPJcZnJGGIUHrwo5P2aiL5BEcuTznlKwtjhgDLCGzFmVAQsVYyJwAbjpYlC392mqYJ7AfABAaLyh9ILahODZV9zYtm1ICmx5gzyHEAPN8y8I2JznGcfDAbc3N7g9ivHDINRZci08nM54tJArJTQMmOpmjfa5kTIBSvO8s+5sgCRmY8kF83g6eTtN0bMaXCjR55n0YA4HRd8hcIEaRy7lLv80V49eu64rTqcTzuuKbWtOCgkglSpkRBYjHMCVtZw8w5j52I0vxUCtgNQDW1UVxrquDnarg4/Y5TSyy+dPESXv3kRmIHD0s4SR6fxTogvEaAaoFSAVLl4m2OYNQ3NjUHYrFdFZWFxaSQePbB0zwEpoWtLSbSto1iZTDundxCiQtWqVb0yZDzsVFFUeXAnqfXwsAWDbrhINP9pHyKrcKzYnAfWYzOdT+l3nL/t1AVI9PAb6PQmh2HVuSPLWEbjujeX8+37cBqC8f6srZNKb/s47QvZurW349ne+g299+9v46Y8+xhde3eNbv/Ir+Jv/xV/H+vAh/uZ/9v/E9v338bX37vCFFwc8fzbj5jjjMFXMRQC0hA/LpkHjjnXdlFwWr8XWGvpmHjNSrtx2AsNdOa93CQkrRGiWF4OFuDN5YXHuRg6wjYuCMNuNNfxogLJzPG/sX9tZj74LmZ3XYTrH/kPQypnFvXlba2jbqvluJEw7AgaSsSewXuRM0ZxohTU6g72Ee84FMdcZhZskemaWYhS1oE5ViSOpNAOWHAfxThaiJvI1jDwZPwt3k/LDE2oFjscFd3c3OLXm+gfnTYsraB8SaxW46Os3yR+R1yPNc2mAJ+if7hXn6JzRIWFmNwSvPttYk7R2sVtvrJ8t0yQEfOu+k56fHQaeYgWqKoP1PXqc4zvmSHMqrXlLfC7rYcKcXnwgmXbGL1HkJdzU004MsfFc02c555Al0fd++fy4JBYQ80TUdzIo0d3oMzIohEG+AcJIv0Jm7J8jd7hCcFzRFxk/DCf7OWmbNmGomBvhISAJzOK6a2TL9Y2LHE4S9oWVqGe+fFe7dt8XAwEGk8/XZAhdnbKDMZ/sozgs142RQ/EsvQHMMCZSn67B5om/L8aDxAOQmTUkYNQb+dwgpvceNIxSJHccTw3H40FzCXWs6xGvX79Gaw3n8wmn0wOWZZKcfYqDHY8M2DnneNLGJz0ij4+QtWky+6hgXiRNhuSykw2JuK95qWRCBWht8/fKlXyNgJHrQ+pPE12dI5FXilGn0F9DX2b9L78NIWDWF3kTNb6n4dpra98OsRPMitNVZXaX6R4bf7O3EXpL5vYYmub3vvZeQ59e6tGmqVr8fvrEPAfsp8j6hlJzUQEGq+d1byyyjGgoaODXgj2S5dK6j+OzQwilNccuBNIun74DuXCKhf0m0GJ2NLOUiP/ud76Nb7/7Lr72tR/HP/Lf+Fl87Se/BoF4RSuJMaht+Fv/+f8Hf+r/8K/h46//HXz5dsI7by949mLB7e2Cm5sDlnnGXCOZl9kd3dzgegd1yb2ysiaLZcbWdTeOU0UcF8TGQAfoIFLChcLdkwpQuKJzE/d76zv9mfuMETGhstDE18g6UXD2zoXVhejTcZDAuAhjB0OA6Lqu2NqaJqYCZWJQLSkXUgiDWivmZYEUQZHqWaV3qQLTuyQwo8tEYxfgXvMsMMFJoloK5mnCYVmwzDMqFTQtzzzdLLhZZjyuR7y6v8fr+wes2+bjYCRMcWNSvFh0xGBxmtLlsbglko/RuDmplFrphqdnbtL3MONH5gbUdTQqzuSdCs8joTdnQHMObdiaxY92nxhZuNn5owCHk3D2TjY2SNfaPzM8LCzRhHtWTjZeng+nNUDdGD30DYxMDAEF7B4FFjdtilghC5mh6IvcwfU+iWfuM1H2Sm4hLR17L0DmqK6bQuL1RyBMCO+r3kYgJz/7INBFieWKIDF/mbsan+I1JCSdyAUxN8SbrPXP8wgByfRWAJhhpyl3+4Y8TNbsx+5gzxeXXhLglyN8Uz4Q45qeAmaj7nnTzlQ84ml3+3yPa4bzfq5lgsnWxYcffYRvfetb+M53v4Pvfe976G3Ft77+t/GX/6P/B17UFT/x9hHvPZ/x7G7G4WbBvMxaitVi25t7RLbW0HomgzratmoIq/ZtlXBSkVthXIXRJTufbQAoQX5DnyVVPpr3q42kAXIZw9CP4rWT+2xHGg+6yzYgRgPb1MZkn3EH0RQVrUhk9LauaOsKVrlFWi0txkXbKiXGwFTBZQJVBrhBw/l106gM7Zg0t5Ww4ASqot8l/GtGqbOMR6S0A6CEsmmOQoFBqGCaZszzrDJcNqFuDgcsdcJpbXg4nbBts4RClQI6E1YkgNrVa/mJObeft0akWlJ+C2tzmWujyeqN5wYcFJCH8Wtk7dOoQ6eXkbtG3ubvWfRGrQU3xwMkxY96dLLM2b2BRzHpNIxaniHVLNnPIbYQasM6aTxtUiGRpHpfZsb5fPbn5cPCv5qOh4VXmgfqHoeVUjxpNSA5JFkTon9+yGEkqvxuv2YDMjbAzGPHDx37AWeZnIWOh93HbovAdwxIWCN0rA0PUGx+2XfX1lPI9Oaf5SPnXHFiQte+edDsj6fto9Ci5nEh79AheV7svpLz0HTNfg4zwruQ0t/7Zw1GNDO4IcJgr1RTzWXojeRyu0fbbfrcx1GEmPbF3rayzudEFNlGUOD3kE/+H8TcMY/V2BbI72i4eJoqqE/gLrlFuXecH89YT2fZoD2fcDotQtqXAk5RFrmCsxkiOi10zrF4oA5yTPG7E0WEeZ4wa2Vk2RiQfKv2cr3rRnJrIIJidMmJZwSQVSErJePqPe5psNyfhnmjTZIX1/IJ7Qm/UrG7F/t45ePaHLbzryWfzke1cLOMq4aRJX2mP8w7NROleYzDizPdaHfsyaD8bhH5YdeHNXJJOsk6N+8gi2BhKJ7qVrgmQsYkVIw9/UfrHY1bep/L47NDCNEwVnARPth7GSTH+fnnINc5ziNinM5nvH75Ej/7234G/4P//h/EF7/yZRA2sIXAdMYH3/42/s0/+W/gP/oL/y6e90d86fkBt3cVtzcVN/OCZZEkYLPlYAEBfWRS2UrN2kLeDbLkeWEHXeOE2b1/QGMVFgGkssAwAWJhFMPi0Y4gksnTIf1RSIHmbtIOw7KbzNcMHZvGMk7y/fl8Vm+UTQwNpsghVIqDZaoEbLH4hJAQQTZtG7ZNKmGJwGoD2ARCOeYkjVJ9pQxtFQE9wRIiR/JKxlQqlqlgmgoIR8kVoKzqGBWQVFACAVIK3SQ16SKNnDBpOP0au5F5V+3fKQuC2AXYeZpY9SnCoJioEgoqZirSxxBSZqoVpDsElrg08jqZoDOFX9E7oW0NVvIrs/RZ8dm1Uu2kY2HJp2RtN8ArOyRCEhqg5d690owJ9q7CjjjAeCVSw1X29IRki4Tqe6PF2ron0ZwkKMWTxtlnRm7J7+RjZ2FgRRWaVIPpTgrm9dHR3GgI7oF9IuRqSkjGhs0r6PyXpPcMEKOWmMc/6of0VZaBOl6urOWcXAWErGOJxUtR5bLI3/Cg7A5IzRCjYXy6j3OQQlnGXNs5unZ8GtF+7fz97+NzA4Q/PNzjv/y7v4SbZcZ7776D/+Jv/0188PVfwhdvK957dovndwtubhYshxl1kUpirP2FHru5FgLam+4stabVpFY0bhrWaMZWhFUK6IKDWPkpAFFc4oMgGIwh3v/Nvn4ML7ETziMhY4aKjCG8f/ZG1p74BqSQAhGhsJCx5qXIZmAUqTQpZYM3zNaudNi9ZNZUgCSPEBeRnRY+a2jfyaBaxVtWw8ospKxOBfMsO7qgKvrc5HKJksQwykCVbykVS11we3uH168f8Pj4gHUVj5NaxVNmrgVTLTjMFcABZesoteCRgNP5rMRaAbfLOZx3aPeEpRH+WVfZYVkmcKX/QRH6aWSQvQ9dgsJL3K3z4KldTx8bEm9Vy8sUc1DbSKRqjjVFkSRMtzRX+V0tZ1EYbkkvIwxTI4Usn0cO1zYdOCSYLgXUCa2IkWE4pICG5zddi2K8SXumOo3g90f5YNkxp7SWr50U3XU9dOvKbfVs+0vXLZEawOwnMim5mnkFMKzwij0rVwUbn5tDZJB+323eAjuSVXXWLgcMELjyciOC0j97tr1fCRvEban9PFOZjORdu294asdeLgvZfX1zJELarN3Ryuz1OXhjkX3bfEiErNYvCSBP70D5Iii3luxNQpBhebNGN4tYvu1OSkQ/Elme1BnLQTZVDjdnnNczztuKtnU8PpyxzCe1Jy1RdJJ71keaL9aItjwPst1QtfCAeQnNc8U0EZYlnBfyhogTQoXQpJ6NhI6x2bRRpY5ZNltt3toGTCkY5loQTkhtC+zGWf52DmztfSvjkWW35T19ah5dPi+8KJ3Mt9lysYY4/Xe8T+5jG3dmu29M8ULhsWwhb8Y/5MIwzOFtB9ZiCWQTTwme1A9ybvfWeQqLluWGhZZ1t2dMHxsRJHxEQ+d2lXi14zNBCBluVBwwCHDr8Gvkj57xJAA3UWGDQK3hdD7h448/xF/5y38Jv+m3/Ca894Uv4fbuOU6nR/yFX/z38Od+4Rdw//338e7thHdfHPH8dsKLuwNujjOWpaLUxMCS3bt7m3rvaB3YWDxconS1lPdW9x6c2za8YN4tyMlsue8WCOk7mdeAAVkwJkgZ167Jy0xAVyaPIbRnOaFhyRkxLpT9zmD+6f3ri58T0JXF37xUL6fFSJq/kkC1gi3JWi0oTRLt9kKY1C3usMweQ2ngiTs70LI27uPytbuGv4O4gP9dFKgtGpu/YAaYpSLA1nHazgoeoQZKEjzRCZeCRIkK66NucakcBmv+5wrEfiYC4JoBCJgn2ii08jXy7iLwCbrjrJXWUCyPRXHyZP8s1h0WVB4E1J4MstAnT+bZGgz4tB5stRFy8yxV4YQw3JwY2pNNriA8x+YVQQ8ayiDnnTP/m8VLzyamP4cFcNs+Vp7j+9/9n/WD7oRI4utEGHTJzVEACathzbsCdphkoWlFQaSHkChhYaVeK4kLaEfkW/r8yEZ+/nRU9N6V+Uqyc4xlMFIBMCXvIFh/JXuOGayAeDjujIxLMPMpb7GTr9cIn3ze/uidUeu442lGxraueP9bvwKsD7j/5GPcoOErL454527GW3cLnh0POBxmzItUY6TWwa2hFUbfEhACEiHUsW0Na2toveO8SpJ7UMHWungMcXMQYkDEZLd7OsB2vaOvJCQrxsBCmrvGvJqvnFQ5G7GCvfnTG0WjN2Oco0nhEevaz0ng0a45n8+4f32PdV1xI4+MbRo2oyTmBaECZAmmWYn3Ai4UOYGsXZVADRrOJJ/VWlGnCWRGPoXdUg30p/aa/rPqNTfLEcs849WrV2KoaMUi2c0UgvkwL5K/r3XM0wYYkGwCGLmEt+c1Qs3mp8n8awSn4Qyyd3hCl0l4+wjKBcRf6kG/N9IaHPTW/hnsHpbRZ2Mb/d4EsBJzzASqQFVy1Cwegq01KCEURQRE5ijqpPASykUccpGA3G9EMjeKbVYVlspyDaCuT9VzTW+aMQaaQPR5UumnDpm/CRsQgEQIXCOBrsloz+8COJZzUI5EllDMZdrd1+RheK8Kfn5KJ+xx3fhO8Z1UiTWQCb2nv6zPQ7vnGHKWO8b+Fg8hu5fJbNmOG8MuYd2wIy73cuNa+6/ZFPI+ObfRGBptAji0tbyz2zFIup9s49wAAcXfRqRx3Dnaoc8dGifXK6x0w96wh/WheA4CrQm2nucFzIR26DgezzifV5zXFefzGa11+fu8Ypok/YjltBvIO7WzBr+rdI5tZprcmWfxEp2mCcsy+78ghOzairZt6CU6wkhsmS+STsK8fuydZXxsjmabIc8h68PuatK6yTfmKJRbfueYv9jNh+ubaReErs7XSpHY2jeJd2SRYQ+Wt90NOA1zuQ9kyqUjBfl6MSxyie2EDCoOMA1jWooVwIojsI6TEEIWcVNoDAvjbnljm1esNL2c86C2tmn6i8+4h5DLVdPLwSDsToJtqsfE2g9GwvSFbKKYIGe8//638a/+b/63ePbsFu+9+w6++KUv4se+8hW8/vgDfPdXvoEXc8UXnt3g7cOMu+OMZ8cFN9OMeZqFuIC4vxcW9rmwLS6BNJt6xKwKojnlbPEXzYKQWeIALXmUG7jm5QJxUd/aUPnJ4lsFmATkdiCrgDqqOto9GaUzYLGQlhODx8U2KBsTnGmt23OL9nMxJeQ7JvDwDCKAK4MmvYJFSIAnYYi7JJmGGfkKsupEWGbzyFjRe9PP1TW/s7pCRlUW8xixfkYBMAnwNqBdtfxiKQXLtOB4WHz3mhjYti4eLifGad3Eo+vKvL3GTF8AV5Jqcf65T4MkeNKcDev2Uvjtf8/KiFVDkSpLgo1/cWUhZYy1BCVVTTAu+WpqIQUqTd0PtVoTZCc7A1mfI6Xo7rckFxfls8ABhBqOJqSWZfFdilIK1nX1tuf7++63gow9SWRGk7yyiPCeiJ/m7LyuNcvXgzAKBJgp4C7x+b6Pjfm3kIzeGcQdxBsqjQZMrcVJWJ60JLe6qdoQE5ByUuknHEQDSIw+3sZKOJ8fcgxEjP2ixuMAGknCUgNQWl4QlUsEdbkGiGNuuCcGIgzY16brnti96jzm1gqCJquvDBAuZQTwtPy49l0peY7GOxcQaiE8vvwY3zvd4+27I955dsSLmwnPb2fc3kjVw6lOIBY53BgojUG6K8ycCa7uhG3rmjRek9c3buibEOe9M7a1Yeub59sy0NGYsaIrAOxKmHRdqxpZwbYRwjsZox2ujAhnlk9dNy7JBu+Zi/4j1X+2Do2UAcVaF7VqYdYVnQmn0wmvX79CnRegTLFulfiOkGw1PJkA2iTevwNUK8BCCkylopeCpmR6Z1vnPcKba8E8FylYVTXsQfUTSHMKoWuxCrhHYikF82HGtBTUmTBN6pVF9k6yBqapgkrF1AE6r+DeME8Vh2UGn8X9v5mRtdNBe4NtLy+v6bWunnlmK18jOn2ETC4mmbk/b38lq6HWuYm5qjpNQnslFKJo1bti1VH1zh7SC9ak0Cozup5D5q0p+rNp0noPLS1BXMnOt/lIkHuwctpVX7ez7NiigQtj6ysqpMKnVQASmSPhP0Qy17nDC2m0LjmgzNiV9/pMQPnPzCGEYp6/adaw/YcUQyf5enFduoiN8EW6XxiTehPYxo5+m1sFCWMKL8PhESS4zUxa+ysTMJYaILxV7WfWQ9f1iJ1vWGr4TNd72EoEkOVBhK5H9ne3UC7W9015ud1+ibXJEG1tXo0yvaMUdrQ561b5rsGKhEi+G/ueYwySwX6VLHD9AVhxnpSWFZmUMBtKpZz8xtUGRwz3Hg4AsNc2SOG6U+wY6GZ9rYxlOeJ43LBt6uG3dWwbY9sazusZS5PwbZgNwykUqjXH9lBvQpMpEoolWJ60hL15JS6LhKQthwNmrcS8x9ytFEl0fYXgsPkaa0S48cDRmtJBvaNU8unmKQBibxs45oWYnGa/yvNal3klz3t6/nKyK30IIWugUJU5A5LN2N59/gDqzKH3ycSQpaMYUBtdbvQN6i3byzFbRKaoTMgpNMwbSr/QBNaMrs4hzOy2UktRKtu2oYDQ+qabzHLz3kSnt9bce3rbJEdQbw2NOza7D3d05SY+84QQsAPeQALfgQntxKfMo2GB2nU6METwUradO16/fsDp4REffO97+JW/80t461jx1u0Rz28W3N0U3N3MOC4V8zyhTLLICgjcZPds29hFtxsjmmthaw3rJvkXeJWBMcbOsnyLe1fzHCmAMfABjj2Zl+YCcOVFChAV4Npb2zmACuVkIMkcEokvHuqkkwgOYcyoMBJNV20MgCE6PSoRijHw2Cms3sb2CNMlgK3qjmCp4NK12orEp5ZaNfdNDGYkjx6JARRgXmZMc8THUini/q9tcdKqiLvjVC25mpQp384rsCyY5hlUgNsbNeTb5hPpEWuEQgCeaPrqPM5GYZIe+yRpA8h2GCmT9RoAv3ZfU1zOjsPEbV4LycOEQpB7PyaQLve2SicMLmZUXzrkByGlkKUQsmt8rR21SYjYuq7eB4B4Kx2PR2+HeCBEAuW9YPa5tfMiknMVLGn+C3CQoh7ipfNhvwsnYWMs7v9kO/TRF9beqqSQeA5ru7iIUPf2aW+rEumlKBdJaMyD26gOuo8WA75uAAzvuAdvP8qHSRJgB6QR893AtiTYk/MNdDppsyNoeiet4BqgGN1kHtzwYpWPYB7kkwNopHVK4d+wBxS5rXkuX7yvGw6j3MikEyhIjkLAcZ5xM1W8OC7y73bBs9sFN8cJ8yxeDwxSV3FITrutoXJRncS629xiN4kljKa1kSDatoa+sZK+Qgj13vxv7uplBHV15tRXusSlEpmFUHsveh87gDJdhOh3ssTuO5CW+2r4PcmGmEABLo0ckvPVeNG1Nx8W3Lx4Lu6vQ7TBCExjqEhDs3Vg/M0sYbVVgykDuWKEUNGKU0aQMIy8Kq6O5RwBuGYY1KkKKTRVCYGmMOiICPM04XhYcN46sDEKrSBI+eN5Ymw2Hmp8hfETu9XXNj3y726YGf7yYQpje7xBYD3z2nIjVVde1ngWOoH0WdN5JtMrDIDztnr5ZsM0FiqcB43ZNrXU8DEj117CbZnst+RX6zVyqukbQHTMZAYYNzSWPIqB/QiMgtY1z2DaUAu5zxJxj6LryuRXbBp8foyHYaOr3xGFcQYknAwlPp66o8olgs9jI5sMQ19cawALCIM+tW5vVOanZxF1sTm4e8wYzon0e9zP8NP+ufIIw7cWDhS5HRPFCTgJ4EhTzwqS1Vroa93XIw2kgKSs0HwzzAAaIvRu73Er13h/E0IO7DAy5TWaq4IqLhhu2aFV5uKzS/m00yMoaaDDpyTraictipD3ltfycDhi21bNH7Ti9HjC+byiTsBBSRsvopPwsIkmkQsiNUS2V5Q6ARCMU0oU25nnWQmhI47Ho9tI9h5SLGFTbAyw26bpuVSHvwFVgd1+j80w0qIHhEhv1LpUzmYySyw2ei2ypmh/xVCZnL/0mMtETsbUOjvUnpBzKxEa21ipV9xOj+VnSKh0i8X1hB0GJ87yegoPUvciYvYUEfYsyz8qNn4kiybtq7Y1j9ppbcPGUpypNzlv602xkZFGDZZXyHKarltszDEbcWSeRB2jl9N4fHYIoSsCLOu5TPZcW68GKIaD00/Degr8a2EsU8XNXPBsqXi2FNzNBXeHittDxWGRuMupRsJcYexIS7sT+trGBrC4+TZn7rq6GnNc38XtUtzoZJC7xv6JO19XIaKhN4VQWIAfqPmut00KEazkACf3U0z6tHCVIPAcRj754bteNH4ool0rhZlHUS0EsrAiMWldsJQiCZuFBW9aZjHCbRhwt6JSC9ArUBvqVNW9Wktua/eagKt1Qindq0jZYpYEnBVlIpQqhk4pArorFa3uUiVETIXkMosnS2sN67rJrmytqFPFYZ5xdzxCxS5AwGndfGHByBcF6/s48P1xjSAa5+/Tn+d7DkpcWAQPQfLvdk2IEBep9mPhjlSLK+rh8QZCu1WrIXSmAUx4G2icK0Tkiog5wkcAOPMNwJNgW/iYEUbZSyj3WTaa87ibMZXdQEWRkqxBinYBmglIx67tYvT9fjp/Lwz1Lgmg4Qk/i1QGso4AND+KHNXKwjKhb5usv67KjOBuwUSZ1B3HPL/v58d4XFsXRi6O8FTAZQYA+SACmKqa7zafu2A+K6WqhySbTffD2Aa7/tMMtOuyIsB11oX7W10YBroTORXCcZlxd1jw/FDx/Djj+XHC7WHCca5SdpyEvjVQct42MIBaOqgRJNcPgdHQ+hZEtZIEm25ybK3JPRo00bSBG3F7thx5W5NCANxJiTeGxYB27kKUaoJpcXlWMk8UlegRT05wBcw7s7YH7E92vIO9wWAkQk+i08eQxJ44HBf85G/+zZgOB+wL2PFuzHTRO2ljf0OTmlv+tlpr7P4lUkhCa2fV92Tx11Iq3WQcRL6UYc5HWK6HBSjIn3THGNyxzDNubxj8cMJ5PYtBBvEQnaaCqVVstXtluT2Jnt91P9evET1g+EokA2FXiCW2Oa/fFzK8IVdyNrfT4DGATu4QHUYLpHrpcjyKV/A0KQEnGz62iZffwYYMgPa1eM5lYt4LNKRxH7wtlDxixW4EAroVxpDx4Y2lweaZqtduW0OpNHiGTtOka7Cjb+xtKgS5Z9rl/vyQI0vtgSRQnE6AryXgyrx96r4D2WBrYocTyEiP3BqVCeA0b1kN2PhbyKjAFIZL9iSH67rd/M1yILd3j6nsHvFeHeHVFBuuFnJ/SQZnb4qdHRE3TXZa3uRT/BbCN4gAjjCxvL7k3nE9lFiSXo0wG9L+v77RovdL4yKvovcMBgnZ61Y8QMdQKIJ5qwom7K07Fu7AFawc2HiaKpbloETNLMV3tg3bRpKnbp5Rp2UYI+uDIMozAVJAKChlAkEqT5YS3kHLsuDm5gbH49HxtvXJtm3Y1FMf6Ohdoi7QO1AnCU3aSAmd0WEh5h2H8a0/LZ8tM3tVLOm6sDlifiJSMSBIVbteh1TwA6cUDQQUddG3XKFCxuRcQzrOiWgyG5d38zqP17X14rMmYUjpjyjcYzrFQ+a5h82o/e0bA02cMVoLEm7TsC4gchD1buHBEI+yJrjMNtA2JX8YkqpGiCAhk1gruLbN8gpBiaWn5d1nhhCKTg5ix383HIERhNtEsd/H++XFH8uZSHfDasHNXHC7VNwdKp4fDrhdFtzMM5ZatJS8TvguyW/XdQMmjaI1w444yJgOZ+l6Z/RNkj81JYSautfbzqu7cmmYTm8KmswQ0BcMhbATvKRAIU9gW6OAs5Puhuc7ayZodFIrCGNi9ATYoN9XDmMbgJektXvkBM6kAqFtDet51VxCkdwNgO6wqBthkRK9VCdQ66hV+qW0BsnRYgtKhF8tFa1ESEKdqpbptZ1VfZR7qGppdMA9WA6Hg/ybF1gi1NY6aIPvjCzThH5Qt/xaUB5OOJ1XMVDY+ineeW9sZiVtrHWtu0m6O64ZiteAuP8NcVqh4bsYX19TOk6S80oBrrrQyxobz5ctCAJtrGNEnjjdx7iUPKSyC2yhYyy7IcuygAhe6n7bNs+nYXlzSqmYZwyC1HYvhmftDO6slK4ZgTmptO02D542nIB0ASxMxIianHzPlQYrCcsWSa9zWPvcQhVCcctudCniWejGqBmb3u6x/cyxS3eNxPhRPZJIvBjzC9KV0/xP313uOhFywiG5v4Jv/Q/7uBskpeQfbOBe/2T29SbX7t7BFFpqVzz38r0u+oBiPkLnVq0FS624WWbczAV3S8XdUnG7zFhqVU9OEYhNgYSQtQXMa+wGpxxWboAr3hPPIK02ZjHpm7kgw8lf2bWypNQGeDSHXRc+dWvJE0V3yZp6J3WO+Q8EQRB6KxkmYZdflZ3XjvDGBCy6y+7dWYOJzEJRRfflr3wZ737xS+LRiv1q3c+rUI7MNrXYAb0Tz1USCBsZFLuvkeMBJmMLgTopGNewav1f7Pp1J/tbE+k0TRNmJd/71lAK4zBPbhSczytOSjBU1du1SK0CgaXs8/Lp+TjutA76KuEV0vshzfGrY2ZrihmdKHLIGfbTPrVzGDpvoLjC2kBZt6n5lAj7PGbMqhvdCFVDuMA9drwVudplkiXSnh0po2tUwkYItUtl2K1r7qF0b/PElcSuOS+UGWYda18BYjGEQOohFhslnx9xXCMxk7gIjxpKc8KuTddkHZJJpf0zKN3HvrPPXUZpfKcb9d68MIgJxbEG1EvPYwZJvBL2z8pkYG6zYaA3YSdmJS61LWa/+MZbepeB9MLTQsGwj78/4LgTVlExtQeWYwYVOYHu2I/7p9gHpoiFuMhYOEgoOZ+IhvtLPxTvf5kjdk0QFIayPfRI7S6QOQT0NCbFn5Wb6nK/CCl0OByxLI84HhfcP7xWr6EVxxuJrCi1qoSH2w9iLu3WOY33J5BXFFuWBcejeAfd3NwoHpd22aZ6URsWEFsVTcggk50SqqR2GI0yz+ZH2Q2O9bPJ1v13g1Ix/Z5JFvKP/ei9o7BVd9ytSysQtLNlehe9xmBJ81JJSj/jkvSRPm6p3QwLcRdbOgiksN0tb2Lk25Ow4DXsyi3KvMuGmhQCEGJGCBrzkO6Ks6CEkNhDm+ItrfbKXULHtIJ0a8YfCA+xbXJ/qxItYf+rX2+27lPHZ4YQssPxPCvZIB53Miicw5PG67KsGuYgmTEsE3eZhQw6zhU384TbRbyEbuZJEm5qMq46Vb+xDTpRx7ZByslXiSslAF3LiptrvDB7DPad0j1w3oTp03sHqFMW1OG4Tkjb/jKBplUuYiElNjytIgP24g6qYBqa5yQtKiKZaKGlyGP+HUx5v4uQKD4GbhXBwo0AllCh89nJLo9xJrK8mvI+hRIpVFB6Re1d8gK1mvJlhECtdQKzhiGpe/1UCBMRqraoAlo+uPg71VI82drN4Yjj4YDT+XRh+E+1YCpSjeW4zNIHumD5fBaFyZeANoODy88uQ4HyM/P5+8+eOvZghV167dwiHShj2I0Gxp0HIBSOMe3iy2bTr1+0rffucckA0ElIlWmaADAKCbjYNimVe942QL+3Msw2pvb+T+127p+9N6bGPvSrkmyIa6uyzN3cRGEGEA33zq7YpATTqsDfyFMfByJPJt6Vnb+CZC7miWzEjW65187/kT9Ultv45v4a5ZnIGEmyKccIDpGugZYR3+3gmh2ZpiJzhILAEsWTGo0OINVoTTJ0D2r35NUFQN/JlXxkHFUKUCuwqP46TISbueJmmXCYimxsTNU3LwBAwlM6Sies63pREUTCxQIUmy6LRNGaG8+BELCumwMNBy5dQJjpbSOJmn7n4AriKm2bKt4naeuH9ZyL6WC6nkea5oLgRpaRQdD0zlLcgJQYSpEARHHH9957D9My50foSYxMPPqz7Ou8I5rkvpDxUQ3GACYQnq2lSK6gXkgFTbybJzF2snKcPwYqD8sRxOIBWxg4HmYs84xDEYNzXRu2tUlYVduENCef1nLPvdG7f9drRJC9J5A8AazF+zEkJVmTkWj3VjzCzLjo4YAdvlYlv5t8YbkiiCUHXqm7ZNz+PtEG+2x4GAWJlw1JO3dvoGWj2T04EiFV1FvLjA07OsYk3oAWgqgTCFIFiGpBmQjM9WKD5vMjjkwKAJfz9kkdu9Ml17Dd/ghMcqkwxmvMk/z6Ooo2BN42Gyjfy/GR4a3k2bBv4143XtM7cbKtgYSBsjBM51/Dp6MEHpfQ+K7sL2bXyPcZk0o/XlyXSaZBJqTdGWufyRpmGGGCZB8xmVlgMrzrpkn0B5xCjLQeMc7NrwWpvuIIsSqI/myc0g/4pvSC481BPHXPj+IJ0jb1IlnsRbzvzQ5yPaaRJugSSQJir0Bpz/AiAzc3uL29xTzPfg/bcOW+ofca+fSsb6xYkOYxE6JyRwZpn+YCOjEP89y7xDzXjtj8l7QcQzGbvIGbxtk33Fsf8HveUAUziK0EO4+Y3XLwJPztSZhhnwFt2+Sn5uSR9C+BiSxyx/LEeYqRrvFAygNsvaE10nv1hKvYcZbJit4lr65vtkFIn3U9Axxe2c08tp0YghBRtsnAPSpnc/ciC9eOzxwhBGCYUGbjAtAdJ1tmJvhj3WSwjATobAlPE2GuhMNUcZgqbo4zDnPBXAqWuaISUIwtZYujV+CrbDCXAqYGWtXDwZEj+2Aw4GSQsXbNmcDI9i2lQ7UGESMmmhEoBqiRBSf5JLU3MxIKLvPY5ODeBAohu5O14qLOqhhYk64FY267ZpJ4U1g6eXXyfogdwaScOEYPtBOrhcDdrDwoSDbiR4mZaUJrkWzLQFitUo7XSvDWUsU1nqT9FQUTyHc+rT0W0nQ8HHBzOHj1MiIoGNZdUf1Za8FhWcS9r0PIrW3zUAfvwitKEsAlqbA759o1T302PMP62Z6fkpfBLGdrFyK/j5E32QPGZsoFkUVS6t0/3yU5Zl+jCcybYWKkEDOoVJTSHARkAgU6PssyY13DyM9ETxb81/plr6TkZ3x3TRnJrwWo4s0k6cVkDZcpPOL2pS5tZwWdPcxhPzbSvzIPC8tOt7xPllERT73fdcn3TI39/EDI9AAkQMzEYUXI3y6P5Oc+cTGZ7Ibtho7dTYXA5rmZPjdDkoany+HgbWi1yew9dL5c7zHv7ftdH5CQQVMpWCb5d5wrjsuE4zJhmYqQrQUQOc0Ohlvb0Imwto4+V7Sma19l6Lb1eJ8EVAwk+QaG7oCt66ohY7Iz1rtWJmMJn2aGlqzvEk7d4SHLHk8P9ZSFgBzTXz0BMuuXsBFGHXit/8Yj5KN0BbmnB/Q+e7Le7nU8HqVYQWvQNAnD2F2X/bt5KJrFCQYiIY97IrWzfovbGd4xw0bfT5/bFdxN06R9Lt64y7Kgc8f58R4vX71GuXuG25sDlnlCnScpJtAl3+HWG17xA3gV1/SqVT/ZQHVaM/m9r/09EiqKQEwlZSxwpafMiLO+iCSdcpLtWe0eDHBKsqt3Yg0Lm2vFoslUQeSbI93DI/O7iUwvhcRTwj7dEQPXCIN85M2VWrQfSUjA0osWadjlFDQs1ySnSqGCScM2xLZQT2WepMJs0Tlla9L64vMDADyUfo+Ar8wgAIaT/I9xTeu9MrYITZMxVHqK6hX73NbFXr+P5NAo96+19hqxdQ0D7c/d/z2sXza8WwYvELMD0gtdXHtBbrHh+rBV4kXSGlX7pKd3GNupa4iMbAgS7ILozy95IYZtnJQYSO3NGyIFeAABAABJREFU1/p4KAkiNzIJZKSbtCP6W/so6XfSNncSr1eweeaHTBCyRgo8rOcNh8MB57PkipGNdC22AtER+drezQtK2mY63ttpc7OUAfNnndJ7x3k9Y9skv+f5fPafrTf3AHY5XMQz0ggh8vnA/r6BY81rMeP10IV2jv2ebdpM7BkhZO3NGx+ZBA0PuCBznNzpTZMqG+HTNT8tnMSx0CzbSDFSKrxxIoIEsJCrsOGZGW1bwSjitQNxhjA93Degaa5RI282Dae3drYuYy/yv3kU0bZtIPPqUY+krTdsm6bYaEr+aHvEthJPJLDoS3tXqagcaWueOj6ThNBewEBlO1ECh0p+kP7eGVpVzM6V66r+Lh4kwFSApRIOtWCphKVU3Ki3gpALAkuEnBPgXKijGiNQpRSjEUSDcDQh14OBba1Jxu8u+Rd6U1DORv6Q7pzSwIraoHV0ZxilOzRETSdx6xK+1Hq4t9l5ukoHK8cWoPw/lFxhRsQ+y89Cl6E6ab8L6FXcqtUtvUCTwzFQ64zj8QbTMmv1jIKu5W97gSQBVoAmLpcQ9/BagE3uVblioglraSkvwug6OZUZU53VXV4NbXUL7QqUMtC2ZNO1FBwORzyuK6apYJlJ8kURo1fo4mHd9ZZJttSKbaoiKJQdHrT3bj7sP/u0nbysyLOBcO1vJINUL4blN2BdE9D3ryw5lFAmDYkKY9iM1GtGadf7TqiwHBicdkT3ibUvATKBStV8OpoIThUaNE6ZqhCx3KNUYo7B3h9GFhGNYWX7fgylFMlZ7RADzOacKE8oM39pfI9jAqh3UZHEvHl9ZJJN8B+hdK18kNpAJLmuTNlGCEK/+t78RF/8yB2sRpD9jCzFLpO6Wo0BEgTMmNIHLkGsJRgNuBrAX8aFbEH5NQLYbBcIsB3OaA3cuIWPu4lia9f1nesAp3GYPjOYOpWCuZouI8xF/k1aVrwUAaJzqShlQoHE0vbesPaKiSp4lZwlUiVGyAFPjqjypLfiwCmDLvu3rQKoWm/YuunNyAdk8rN3QmtwcOb5gqD5uxHgUBWsVAlhqR6F6FHtLDnH+jevz0s5K3NBgHn+nmDJo8HwEC6D+qQepkQFD68fcNM6agxnKjN+7VBZYONbJhWYEjY71QpsDSuize69SXJzwRjFSQwAUTWMCM0q5hBpPzKoE+Yy4+Ywgwpj2854vH+N4+EAqoTj8YA6T6BKWLczTudJ/q0z6LQCaGAIOcid0XzeXjfcrukNgk10TgaZTeI8p3cbVDTep5C4bHXAcxCKbiMdMg1F1PEDSw5G0Wci5w/HG8xWJbZYZU0JwTFjjnft6drRloPhKfIn63U3bCDGTAWBWHCMVTUrvaC1gtJlo8T7CgBYdoMLOiaeUFFRWDYeRPyTbpJVcAoFIhLCCW8A+T96h849G18jAGBjljbD9oSCHh5qTntPFpPhkk9O5ETMYaY+TnM1dI3EddN4R87EHLPPi89No0YTjM+S8ILkyOtyH25/0VMuP22DV/+GVGpiX/t1uMeeeKpG3Jgcp3h3W49+HerwfGl/AyC6wSrIClFV1E6ZXEa4/le5zu6tE57hJpdNBsuGzihvjNQxQkfaWMA98Kp5neQ5JHKIQydTUX2uqSTAqp7CY9jGQt5txjQxluWAw+GMbT2itw3MDdw3cGugLgTwtT5vvYtXeQd4FT1pumpdNzyuG+az/Fwez5jnR4A75nlG603In/WMbdtwOp3Ec389Y1UvJW7sOMBwkARahIdlSe2yYj82a6UHqusmeQfbiAl8JfcfCQo7x+3YRPJkT579Z+FIweKM0RrQtdCFEyENW7Ow9JS/p0u4nJ+jHrZbKgYltrakfWEjiXoDm33PrKQRYd00b2rrau9rMSkNk29dzu8MxU8coWWdxwphlpMR7OlhViV/2rZ5H25bg2069a46k0lzBIYO84rnTxyfHUJoxNt+ZCF4cUkCyYYJyPAkyyQuRao8zJVkN1XzLSxTxaQxlOIFsVfwEntXqYN6k10dSsSEuX27sGDDnQCzh3+1Jl5AjdlDwywxZ2vqgt9YdlA9VhAJEMstmyapbtCJx1IenVl3XP1/SO9gnj2WmJOd3d2DnAumH1dAIFHkRIAZ3vbS2nfaJ++88zbeevEctze3mA8HYKoqIA2AkYNulAoUAbOFCI3M7IEDOysrL6FIRgwEiBaiJ1zwjSEvZfRqybvAtVYNLWkoZcHhuMicqCIw162hb8LoisJi3XkvqEVJuvK0IfL3SwR92nn7I5NEwBgzbnZqh2TbJx+hyFNhXit2rzz+YygW+/njueG5Y540hUhIlj6+k3/fIv+TEXdEBSUlu9sfA+ufgI/dv5RyWcUL0d5rist3WDAmYcyKyMknuQAGHjqRKuA4N7fF+85AkF0O+D2LhowYqSfyp0LFNyz5vIDIv7958V/ZIxErBir25KGPL8Trxckeju/3YHaQ4cN9ZAwzgeDzL8fTF6iBGR6VcprDf30W/Oc1eXvheTAYFpoWrZrOIg1rrZjrhEn126R6bbL8IuZWzOouvW2SWLEwqDCokeaQCO+M0A8d3LJXlSREtL89ebSWot+S6/S6yZrdWk+FFhD3ZYCZ1OsS4inK5ACxu4Hd06hc+238600ydC9dvK91PtmueB47IsKrVy/x+HDCVCZlR5CLB+3m0m7gKMhpZHlN5GXOCSETLL8QO/WXPGVg7vdmWIV+NKMOAJblgM4rGhjLsmA9PaIU4OZ4xOEwo84TSiXFIA3r1nFeGx4eJcF/VR1ca5WSuLnjeHw9e2/rhzDA7P2vj4WT9nKDqzp6uEUy4C+bkvUWuZyvteLu9g6zVdeh8HmWMRnlAmC5hOIJeWyBWKNPzTOChqq7XKfxXVNr86YMkazDiWRzq5YaeaPQwdy0qIZ6tPYyhCqUT8lP+KN6XMcUVybxleONsiTPw6w7DB8nnYH0mzzZZi27gZM9yYc2J0xiz8rn7M8f1k3SJ/k6I/vzeeaJk+d79wUiON9zq117DuAb4rzv3rSRHyT5E+snv1shTQJMMWRMojDKjsjjp8fqsk/g93RiB/aZeQfFZ7Y++zAuiPsg8DfoWnGU0RMp2zLLsmA7rNi2Ga2vAEekSMalwBguta5CCnQ+AURYDiccj2fZgGGJrphLQYWMbe8dU13FK2hTQmhdcTqfRHdrESBLjmwDFik72OVVsZxoHm6e5LePs+j33P+mnzw/IEfVq7zRJOFRQfhcI4QsjCoTRHYuOqNvmxIo3StuiYcNp02qKNkO9QLKYe9rWzUBtIRkCc4Rg7w3SfDcPYE0PK/PqjlThfzRNDGa7FlyA23CBzA8f5BtPJgHEsMwW/e8tUYuMkfYvXwgY9ZRvHBNb5bXOGTTm4ggOz47hFA+DPgnluiSGJLviOAVgm33zI5qwLlWzIWwFPHyOMwTlloxFcJcC6pVeyBgzCovO58FOnkRQCM/LISuNDRVW5eBbcLstS0qirXWlWgQxyNnDJXB7Cxuy3nH1ZJTS7u6Go7wieK72JYANQnenM9kr0zeNFH2gCjtaXn/w0cJ6qrFuLu7xc3tEYeDlHTHPEkcfFfXw6JxnZT6EaQEWNq1A7zyU/4nBIO5lpsRGOCrKMCiMkwaB+LTPGFeJrTe8PD6Nag8w83NIu6cywwhOyRBZzudsSEqWVUqvjtr4PLaTumesLnWz1d3WPWaa4buU2MVn8scYJAn2uwQ5TppKF5+Zh5/2s1nV84c72g6kJhkFwMaNsm6C0rkhTj3bc35FsxzrhOhOXlXPM45z809YXZhgABOBO7Pr7VKBT/Pb5WvH+/h72jPhebLsu4qNCi57GG37zu48iyez8J2lgoVv1aMB4hQZ4CoSKWKyu6BROXp9fmjdJiB5SCLshE+GnclkTdgeLhKxo0XpLjLERWnPAJ7VoLIdiZh/+UMdBFrBKNxKW0bbNrhCLCeQSrcuKy6dicNF/NcZ7rpIecp+HTQIsUQShHDcuYCdKBhCzlJBVQQIVSpPTncfABk5nKtQMnCyJqDu8gXJNXGbOMCXsFK5FtsZMh1scFhyYLHSUBRrluNljcR6oNhpuvLyC8bF1mLBu1tnMKL4P7+ATe3tyh1AjMpabvHJ3kewWdIVj/s35JNMBnfInov8rt5RQTA5ySBETn6jM3I7bT5sywztr6gbhuWZQbubvDixXPc3h4xzRI+wLXi5jBjPS64PS64P0w4HmYvnDChYN0YhcWbEhoybqFWT/W7EVXApbfl/lzJhRId9sNunLBhG9VH/jfzgB3F4JrVAFMSvsMptkIFXGxTI3RT0T7mAgkX3euF1N/70GbX3zC9woOxL55HgseowFEEVfFapmKe4pt4XRAAlpxSpWh+ksKw7Z6OjoKodPr5IUvL+uO6h0z2RsTuu8vjSfKP8nzn5AWcz0/P4dj8ievk6z3J6J46PLTSr92rkKdk4DWslDe7mDny4ZkyQ4SLxXVieO4Xtc87DizsOjG9tyml8X1Cn9tYYcBPBKAHgcasEQUMq4AYevWKJ6LKBKa02RFXaLtT7jrL3zTIM3gVNNJ729yR80JGQ5rma9/xO132ZyaF5nnC8XjA6RTET84rR0TuWWLgorWOdduwblJ1ap5nHI6POJ9XbKs4DPRNiI9tYzw+PqLWoh4wEiq2biu27ewEi/WxEdoyXhI5I1MkkYolvKizDsyYqnfzCoLr6vxumcjZv7d59VwSQla8wsgb8djJxRUkBEu8dzYtatS5aRQNqSOGnH86naFgScPaId+3jo3PTiY1y9XToV4/1jZWz6NUyctIrd6xtuZzQZJMb7AcYIaHLG9QQWzoN2agkEdUuH7TGcwJ37q3uYYhc09eb4W8/0lBzptk3WeGELoia9ILY/gZh+4SOwiIn6J7yaqbY6pC/syWgFgriU2T7tIRILuTlm1cQkIaZJGX1jw5mAkmKV1pu3+xkyr/FEAgdkbNrSxK+OoEVa+grQGdxWtDqjJF4igLJTNhNgChXR+FMZO8PChk/p4I2ifmzQDnwuAlRC41Yr8xkcSzUhEjY9ZS8AC0uoIZwZHglDT8qyGUakxaEcRU2M9zsmfnFeBGDWVhrruB6V2sD2stqHPFvEjStYfHezw+nvD69T2mWnG3HPDi2a267wlzvm4S12nyz3+m/tn328Vs3QH3p449kfIUIZLPHz8ryTrWvExVEnRbou1SzOAIAuoaMSQKvvvYu1FDCGOhs1eqsPExL6R9/iRTgrYbwb17PgsgPIkkv1bza7NyfKpv9uSWzaXewjuI1KCUqgnR3v0zxHvMDOYRUBkAukb2xWeJEKr1+nnQXZaUYNQ+F7nGCYB8fgDQ7GVIGCzP/esEXXTu5TzJx0gUwAG5gHc18Wm8n7ZAfhpuhuoyx9mXz9obl/Z82LXRBInWLCb7oIkjST0J1DuyWPWFqEznYV0bUIq8Q++EVjumUp2otGdL5UBzr4eDLG+vvKyQQAmEmaeQbFjYcxFkkEa0WI4b8VjSJId+b5EykQvGdNxICVk7zGgYe0p2si8NwFEnxAA1J4OK5dCz7xFr+d1338Vyc4uoMhbkIDLYstkwABZXdkn/WtNDJlUiDfULDyL7J89ShcjJY1CnIwAHmbnwwlQnKTN/fAvvvv0Cy2HxXBJVvcsO84xlkvMOy4R5rli35nIv563Is3jUtfvj+ud74iiTszlE5xr5kvVTvodvICUcRKrzrDjIvMxq5OhmFBctnGm6Ka1B2CDZ+GBoUxigxfVENqby2w/9Q+Rr2E7qWu6btfR1qSQ5qgjorWGjLh7OfZLnuV4goGw+X12HPQ0pfiSPa3Mn5hggY/nm6mzX8J18wTu5HjpokAdEqjKUmNBQMzaiQ6y9q/gLiLCkOJQU5hEbXMPq++Py/vZ+UZ2LVchfncO5IfF68bnLwvCy8XsqkSE6+DIvjjMH+ZnMYG5us8jlOmbpuReYMF7OdUW2e0xwdyc08rXjuHLW97s+IU8oR66nCOKRD6YhtBNEIu8aKybUXEJLRWsztm0CcHBdTkS+AUNk4UvmQSJ25Ol0xqv7e6zbhlIrjscbPLs74/5hw+PacFo3nLYNrx8fcHNzo3nwxHNm2yRvUOfN+8Weax6KVsG0d5GnbSO371bG1Tlr3i0WBWabQ/4d7/L8sOXuCXKIWWyt1sJryWwFWNTN1nzzyBImG3m0Nq3MtZkHT8fWVs21A/VYFiJnXTdwN48eYNsk8kY2t1bPQ2SeOm0T26G13caYYh9OuYGkH7rPj8CdMsusUEbvHQUFTdeFbISxVAV3nWITVTbXqGS5Rb6WjGg2vST2btVnd/R9no/d8ZkhhNTGCrDEScSGfJCfdlF6N89RzxoqRpI3SHLLMCadyJJnSINpyMJBAE6CoDlrSRLmRIxa4LvOXWP0DChk0KwSLwgcHheDEUHGKBpYbo3RuQiQbhJG1jgl9YSnNhsEnIEHSy4oRH4wiDYxQSWA084gykplHBO6+M4YZDGWAgCZvDdvkUKkXkl2hk1qinuYQiwieNWEE9BWoLvWElFGWxAZvVsG+e4Jo0PJa0iUlUtJE8wNf7BXeZmmCct8AMAqKGS3+2aZQc9vsK5nnLcN57XhtK4ASDyESkFJRN2nHXtw+9Q5ud+fOv8aOB6UncZT+6Akw8PC7Ky/9uTa3piWf5AF1XVs847nzjDIpJ0ddv9MFGWFl59rIDufs9/ls+flto/tljVuIXFSbjiSi5dasbUgGe3+TvYy69yVXR0rt+GGQdiM/ty8I7kfk73rb+6LYvKC0nz14aArgPDzQ0RKzI/RWBuNTjk1PN321az2oMZl9iC37Lm600ekCY+jQQ44VXFlaskJBIzY8kljI72nzSafu0oahNdQ8fxp8d4CauYi+oaoa3ii7Pj1xmiFJQl/cmGxCmo5dEEAnhEwGppJpDqrh7dO19Lxqq+2pvntGBEPrx5D3cLErBw9S44hpLXEnOVP3gyxvhv7sndWD6fcD9fDK7L8sI6z+eE3T/d4/uI55uONhzw7hXDFwMqH9dt4LsbqKYPMkDkslI/m2zN5Uyw/A/l5w1yh4uHMuafmecbzuwPu7m4wp2qQRBbaVDHVCZPK3GkqmOaKja2IA6dnWkiV/J2NumgHua1meC73kc9ziru6Z95Oj+Tzsy4y8tDkcCbgLEceMzBNFcfjMTZAKMhHb8TQ/miN5Q2LdXu52XBBcLGt/YxZx3FiAKgFhTVxKlkuI+ksISwZkgsRQynldAfvv1oLWjN59flhx7Xxyt/lTZtrMvna/dJfCDJC8PY1GeBrf6dHYH/t1sZ+s2Js4yV5ka95Spc8qVvS+YV8m+XimguC6cII84sCf6YTLIefyYuye8fs1b0nF+x+8f6W4iAJFuDiutxuwwpZ7uTx81LyUNvTPreV/6TScS0wvI+3J7Up7BUejKVaJXH8PE2YJitsE3jU2rW1TapxanGidZU8N/ePZ3zw4cc4rWeUMmNZHvDJJ69xPH6CFx99gucvnuGtt9/G4XDA4XDQZPbiOcN9U/weKR88CbXqg5qqlEqoOrmNV2AkeZoaamfKuEofXyOB9l5COfzLyKHWrXJpJnsa0FYhbHqXnxZ9o/foXTynOrOm/BDCZ90kP5KlabF8hl4htavN3eCJpDtHgafejfyxglNADLNsmvvfzEEs6tyXKuXwPmtWUa1oKhWOtUUlol5sCrptDOUwMK5N80ojn98Ijzv9/Vql1v3xmSGEfL0SwBftDiHjNm4CWLY0dUNdKktpGfKpsDK2lmDWvASEzdsI2AiYasFGBWth285E1WotrRCAjgpIAmVkjwgDyzSwomZUGrCVCSafbb072dMkfFF3TTdwl2RUTXdeJcRMwaoS6fZ3sx1WyC6T5YvI/cMAOhVNpMWwbbkLQe+d/4RyIQBFdwr1sgJCdrMUwCz3eTw9Yl3Pyt42eI4NqgroGuxmBVUSPZJCPSIniAiEioJaO1rblY3d5WGBtq0TdOcZvoNqBlQhIXQqVRSIwLu5OQC9YZ4KJiqoBExzxe10xFvrhvO54byuOGlyMDiYVsVyBfxdU87+mY5ZzFvzSdXdb9v52y+DdJ/dwCFNEU9mZ3OhVCPTyEOzzEPIEhnvK91YH5sByCzryJYmEQnbXPR9dB0W65tShjCuTP5YpTP73g5TEntiKLuU2rP3IMqIgZjTonlJ56kbJna9CtaJSFhHWFI4bwyoVhFGPTyLRhkEz1+UQYz8LtqhEHRnsGo7N1X8YsxL31KqzMGSn4oB5iJK6VNY/R+1g1ROiZyN8F4Hi4CUy4bMRUYKHdCutApWdi4je6ck0GsKn3VXV2WrhfcFCQuQu+pC5sqwgG21j2OZ52uIY9b7QYzEAlBV76Ai3iQTkeQIIK2kCE1k6x3BCXTNaK1g1YSnQsDIXG2UvCC0mdZPRsJ4bjslCQC4JxCREBACyuxzjg0NJYOa6j+r3CH9be0gL5TQWfx2TD4aoAm8ZGOd13/XXAfXyOEA5sO4AhpvT2p4B+xyXcKMShW3z9/CdDxIhVEmOTcD4Su6lC6H2qURtBw9FwaVqh4E6iGp679URi/Q8LQRHBoZaZWwRFaOoWNtE7xyPEiC6XmuanQE0Sfndkgi5o5KhLnOqKWhlopK3aNJSPvJjFz3bqDQscKhSNtsTuU+ivGS/qNCca/dwcyemBWcDDQbZrJNN31nknxwE4W3zM3NLZZ5kSqXVFB0803mbA/sZvd1+UH+N6XxHQkry68xeiyXqp48ikGKkWeAb0D1c0ejDg+I1PfrnVGLuAhZGgPDkmaLZv0IzOjoQAGKert9fhim0nLcqDofIxMXYOuNkT2EZCqMOWRGrKVrBqOMiJ+KOWwK2dxNCXqFywjSFLs7+vqwtYxYT+yr304PfZVDHq0X9vDe2pA3qazDwttFitigkq7rp+cUI753fOVYeD9/aVxv+V3fcJh8MAMYScZdEH2ITY09iUV+vfX2qO8G/aB3C5/ObifCsABw6f0ej5P7VbYcsARmKb5g4agS9lkxzYvIY+44n06CO/VWnh5ka2i8oXfCtnWcTies6xmv7+/xvR/8APcniWipNcj9eZ6xHBbc3d1iWRYclxnH4wJwl/xCVcJpl2XB8ThjXiYcDguWZcE8HTx6xkgiGz/bbDcCAhC7E2QRMtF2sYHV/gPcljXixsqkS24esQ/O66pkz+oEkYdgtYZNk2D3JjkLLa9P61KhzXL7SLVUqQzaNGxMvI666zFz/GDD2jrjOhsJ1If5maN03EY2/YPApEYC9s6aD1DnC+u8I/aCTUQkUTAQYMYQj56mbRw3w6vPZXQW79G03piC6HaDMKX5LqTnv0FNfGYIITuMZfOGq5LOLG4WyJT/uaGloWKFJI8QSd4XrwOjD3FhDinVttImDHaVTN1TL6hTFXsRmu+eAthEKT81vl0ImgKAgy9zGfME0yCNS5S3aTqpxV2NEwgPhtKUA5vXEOuOKxJohhk2plgCVGUyyH7ud03tuGDsyeJhoYSF9IhgJxkBi4kEM169eo3HxxM2c6fWixlK9jD5OBJLzqQRQLMrulKqeGiVIBEM9FmpetIJQMrSuYdQeq3Mpprb5jJPqHQDIsYyFdwcZhyWGdNUwVxxe3OD588aTq3hYbNkb9IdxYz4nXEwMLf7fkyTlvIftoBpvFe+x5O7UP6xoHMb6igaJwZDochFYORoFjgZJAyK29sgJIaleTVyK5/YmYUwVUKHmXE+n12470mn7JUDjN4J9ozcl9d2ka3tzNk98s1AI79jIbh7b++2i6XrjknyTlAYldYfduSwgf29DcSUUsQrQsknSknp5Z2rgHtLPmvDSQX0QzD7PyrHfm0VIq8aYYcAT1MUO7mGAIbx2QgGibQsNcjlVCxOBd8qh8nWnIFna4h7F1DKY1aSITIe3sxkj2avIMuHJyFiEJLcktdSrFEjVRhaiEB1BHSH6kwdcyEwddeztSTPJtW5DGhSxgSEWAgM151klQHFO8gSULdu3q3d8wc1hn/Oasj7ZobrSfj3oaPhZFCs6dD+Bs736/2avNx/djEKOzkuVYQKnj1/C8vxOBAzIbv3z82Dmm/qAj8IuGK751Et0TYuYGwEkSdWZdOxnMhxBeaFZHPENqJ6E4N4nmQHOpc+DlJPy9Uyo1bJtTiVCfM0Y+vQ6qhsiybpeiSjFMN7xatepyeGjRLGxRiZTmitOZ4JW0z1oJ9suuPyeUb654aR6q8GTg4RSX8aTkrD9mkGrOE6a3fuEDZtoS8x6jxC6wXEsVlYtP5HudANI65w8sE2w3q/JlJ+pA8h68SYF7Ljegfl8tixPkZS6IIssP6Xb4PoSJ/7va4+c+cRY3KE7H67q9K0JF2Le0JEwr6yZwljN1Wv4iJfP45v0nf+vF1zHI+a57PM9WinefNkeXvdWzMbvXt8Z33Td/1l1+8Pa/+1PrdNJOzlBMYLfPmLIZOeOYaX6vZyfG9gO23e+caK3lXMSNP/0kdTncBTwzQvoru3FebdngkJy7u3rhvWdcXDwwNevnyN73znQ9yfNRcrIHilNxnPUnA8HjFNFc9uj3j7+R2ONwcsy4Tj4YCb4xG3xyOOxwXLQQmhWUihWmSzvE5VvUfF6InKmybvCL1pXrluulg9bFoDWKtqd83tw1p6vTW0bdMwrIatreKt08YE19u2+vm9d/R105LsPWzoLULNzN5uvQNUwWw6zsj3vBEuG4qClSx8PBfmCR1r977wSlU+gVE8f5TptakWJ4/MOpDNYXYbVDadBMexhaGS1PRjaE459cI2GxcMUB1TvXi1TX3e4JWm7yty8M22xGeGELqQgaFHAYTAsY8cBKd/FkYtYBoKnoXIqQq2LGhoyK8DVR0srvZFy1Ly1jVvUDxPkhVLKygbrxk0JwXjk1TLzgGWOHoMB7OJnScbKxhv7nZnHkVdXe3jnwFn6yH522cv9mTQvrNZH7gnH+KnsiB2D1WSAuw5VVyRc29uJIFlVWGi6XnDXmLb9TJFGkBPRO0OUOq5MdajmzeMCLIx5qyg4j1KIVAlAF1cyg834GkCoWGuwOEwYZqEPGncUWvF8XjA8WHBzbLgfDqLMNMEw41HgWHPukZcZELK2i7z3BSEuas7FP6hjoGE1Ott2E3xXEs+atdeC2myv/P4PPk+O0Xf0+/hjWRGX3gkmWIBwjsot8/uaXmF9t5E+cjE0pD35IphaGRV9/lEPvdLIZ/LrQnIsrRXXddRGLH2WbR3IIKiI0HEABnoqcO7799nILoYruw/P56Yc/YdRiBcisk1+48ZfyMFJDmJDDDqvB3KyCdA6R6R8rkBapghr8oYZIYFXETZLqHJPZMTg5Gr5xMi75XlsjJvICJoklxymRFgVeSgETlba6BS0Fk8UzozuDZJUN2a5AYo5tIPxTcKlBTMMiMVJbC5LiDFNi6YGb1Jf0u8PbtXEEPct10VsRBqvUceAOtH8wRhNrdza0MC56qMTZ/mpRZVUZ6eO6Z7yJS6zoFs9Bmxcjge8M47bwtJkecYIem8LOvtHXn4Ls7gNN6+9+3fdtVj9i2USOLcSrZQvj602fSQg2PYhkqJealtkhyFm3tFTtOMw9JwWjumNmHuHb1NWLeuYFVfzI2u+N0MreE9baJfGYNrxlw+9rI9jDnpKnGxH8MVwJxKIcv9TW/sdTF19opImZ61K4X4LNm2c5B97bjYPAGc8HcLNc2JaZp0PkuyUwnxF1tRMO+l3pQ1kUK71RCxcz8tF86P2mFj3rinUMvr8y7WKrCvmhvfJ/sjz6fhbwq7ZYffBiI6yTLHLQh54t6RV9bJXq5kWyGIoKefvceAF0SM4maFK2rs7tvvRtlAoAy6ufs33jfXbI8sH6+1+8nNx9Qfl4Te5YbiHiu43LqCicc+Czxh2NrwqzkHMPMwtXK/Msn8izG97CvzHAQzuBDatg6hVoY7m5ZEt3Cp06nh/mHDw7lp5VvoBpbYpdMElK3hvEnu06VO2FrHcphxOm84bx3b2nA6nYUkOs6YJ/EmXZZZImQ0ogBM0L2gwSa0sY4wMNVNLXL/rKuSOt1CvSwxtJBbzJxIIPMaFiJnc10mn3HvSkBVdM2/a6lJLG2K2aetW/hZd5zU2+Z6kpSY72x5jzpKkUJSeUg7GxFkOodjPKHkPcc8rlQgvr46P3RddsMNKSDM+5Khybt1nla1lwE0tGEe7zfRicRrmSg+z+e4nQ1g7wG5Pz4zhJAdDpj17ywT9/Ikv5ZhOwPKApbFJXwqmiC2mNt9CGEhZiALkYUMOrcOpoqJAfQuOWzAHjtpcZe2C2WGpRE/wy4ORqFtXgeCLWSX1LyCuk98LderHkKef6gJASM7rfCKLgZA2eKkjKBws+cKMEMIuNzJ2aDde4zYaS6Ad7fNu3LPnj3H7e0dlsMBdZ6BMkF4UfLQPosz8mHV5NH2Ae1imwsVdDRMpboQqJYHKphDySMFMcIlKbUZMmze+j5+87xIhQ9qWGbCYZkxT5MuTAFdhcTDZpkKlmnCed1QC6BppsbwkyvkwyUpER5dBXCPKwI8Z0DeFbmmKId7+vfsStqMKvuDABQNwbrmCXSVKIQaGRTGhrWT9bthTtjCzYZ1ifCxTNhcI5X2FVv277zv232fD7mNdveOno+jlIJtEwUhRK+WfVdG3oUKACMCSingVQbe8qtkMGPtrLXKvXcgw8IMBtJHySHbUQKU1NK1WT8H+37wbl0MAM+Zlx4yzRQiQn6ZI5YftJtvPodTuI7J+HSZVNSDiYlL4/xK+0327Od5rCclJhHeQYU04bBsVQiZ4/3RVc6TeNfoEpTwLIUUVo4VEySHUFM9Ca26pIIMlpMJXkFM2hw7XbarZkDZ9I/ILCuxmnUZsCrAsr4U8ijyDdnuVtOEidYaE1/WkaarErzW9knbWXX5uO5NH5rOybpYQjPde4YIW5eKhBUCFJd5wXI4JLt+mGmfSm7YHGVm9QZpNlk0pDx2gUV2RBj0xb20RzyPgf4tRgUpRojQXFKwKolBu+cQMDnbNQSWUFCrFIGoRRKWC4gU75RaipN2Rs4MczsZdd45Txx7mbzPDzfKdB/4pOPIcQ0D4rHWx1LJIAndOhwOgdPICBoZD0kqnbAMs+szbxvIK8vaLm2M06W3g+uopJutygvI7r83whNuUY8xIhkPubeF15NU/CPtbx9jxYBv6vQfuSMwRiljqJh9L8vd8qrtx5F97gMm49iLUNi5cieCoM2QKw6Fkk7Z44P8vMDRilNF2A7X+RmDQURxzYU83L1xmpNPkkGIruLdPff3wF6/ZYJW2VYaOoRDPadogLyO0oNS/8p9DGvZ8RRW3Ocz23/v32kfX2Lz/J7Zmyfez77zYiuaIFzaVFwf2rnuOWLvnt5kmioYFeAZxECzNrdNPIub9rR5LLt+lzHwqAyIzidmqT2ghlDT0KzTifCwrNiYsbaG+bCgMWE9rzgsCw7LhMfHScLJZvUOqobbDaNK39hn5hFklcvc66ZLDiDujLZtHtGyall2sWlFD27qydo8GTPAPUga+8xCzAzeQb9rPQhLS/RstqpvDHeovhAS3oxO0rYwswUFSl+aHra/tQ0w3MVpfhuu1DltOjeTqVxM1ojeKpr7xdZe7w1Egu6qYqzIORX66ylbMP/Mn+e8TWCTEgSMtxiOzxwh5O+VsIDZZsP3CADiPyntqBbJBWP604271MFgeGnc0joKAY06Si1SRUVr2kh4kISeISUyNsPOmDnz5HHQiR3QMcWiANV2UjMT3H13VXf6VDT3Zh5C2SsoXPClr4JQYs0bJEKv7+ZAGDcBs/bjMCoP+33/vQAd8wCSoxTC7e0tlsOCeZ5BtYKrZIl2QojhRJq3hMMDyIRfKQW8bT4PhBSKMajqSyR5NBDgkSiEACLTv7edNLk0SUW0qRQsS8E8T0IYWlJxGOPMmCbJw1BLBahprBG51rrWZ0NfmXZLhxE/ckrinffA44ryC4Au/eX7xekzy+lgQvWp45qRKl+oMgMP70EaWtW7Mu0U96E+PsvC/PKuhyluI4xs58Oeb4RkZsVNyFk7xmTuSABwBD358KSGer4RVcTSVw2RvN3Gp7COjMtSckPW2rHHYMO98xh6CdbLfr82Dp9mcP6oHRfrARm26SdZgTqoyOvmh3iQrWnAyeECBnPxzyWtij7VPWgAq0DDsSiuGr15fIkCbAi4DOPUjVRdiwmq6DPTGleQVInQiIGto1cGagWvK3qvKMSorce9LY8OSgpNzp0kgIVhxE763ithCFERZFDyZoVsgoihZvqOPeedZLBJBFMCgq7PWPvTbGEDOdm4wbi2os/HcTedwwlUW+jhpAnoFfOl+Rb5Xhyi6ONGEiOwwSBGba4QAxQ4wbygRkOxeDiQgx+CXqc5EMBoaMP89iqY9kzdeWYG1k3yK0y645u9hZy0L0XDEiMBfy0VvVpOvvGFMn7IHr37jaLomxiXa3L6wjAvITMl5FbnBAGWrNPmx5B8WX+KzkiFDLRPLGfY0D5pzA5gjrImG8PxOV2+G+L5+b3275jf1fAJO2DN/RZegHEupPevdfaP+OGYVqsCAnBjFv73bjML9r1u6qad9JHc2yPptCnhc/l6u64RD7z7u/haf9puszWRScXLOTq26SlsetknlPpKZaqXGA90ftm6jBH3Hq+hqwyv5mc+1fZ00ngfxFp6ivzav9u+P67ShDyeN3jkpfePdSiIu3jonGQNS3dB9EkO/RG70oiL2DA1HKkVqKytJr9IHR40X5xFmUgfwTGLiTGiCN9aW8PD6YzGHetWMLeO9bziNM2Y6iOWuXolbi82QbGBWagiQqg0zobFKwXc0Xl1nW1DZoQRcXFcImrbijYlsoJ1s8T0JlEiiST3YNc+L2btsGw2gTnZknJt15BjqF6sddKNFNVtVYk7TXtSKrksrerBqeBPNkQ6vLJ4zAsbX/mr+JZd3mTS9rCGdBGBuOlwKa4spH2qNhHZ+mYNJS6O76A2aafQfazv3vqlfQhQ8qRmb/NTx6cSQkT0NQD/BoCvQHDBH2fmf5WI3gXwfwHwmwB8HcD/iJk/1Gv+lwD+MGSz73/GzL/4ac/5YY792mdYEltRmKUo4aBkgil5ZunAuIEKUcC9dXrRRdgawMBUgE5CElERMKrLObWD4XF5BmCvGd6+ODnc2gB3qTcyyNzfOpS51HfsXSu46P29zF0Cwb3ZoOtwq4AwgG39ZSexXuff2L1y/+4E7lU235Sm9Q3EJfpWk5lN8wyappRN3freDAq9WkGuI3GEMZDvn+NXrWpcMdwM20236jk6Lmny+DvaM3pHL5KUtNSaduZ6zB0F4QTS7PsVpXXJBq85ZhjwMII9ozv0IUxdxnuBs7K90rsDSJVLB8MyfQ69/35HxeZmHr99la5rroj2zGzw2lqLd1PuuYRi3N8nkzUDc53aYt9Fmy/BSm7XtWfsAdBTIINUa/o7i2uB6AAXwOwgJs9F6QeLmw4voQzM9s824ji8+q4LZY4L/D3a1q6e+1k6fr30hPXo3qiNdkSokRzsn8t42TSWOXthhO6MPgN0RYFPrNecZJDCeHSiBrEeuQ9lQmOtp2fDcgapP5gpN4TxIsZCBygAYljI8pyu4GvrzRMWo4nEqaXI7wRYIEWlIqVSu+iykCkGJjQHHIWHRO5/22EDVJaqHuxQwgcMGw4PL+sM9qTTCH3HtlkS68PDoVk3NjTnXtZVYQBYr4474HtSloHdFkbMFFZEzQr8qRpgrFYoOslVbctVGZOBV/boguoSu9Zkn421EkFUwUaCyxdwhW26vVtZ2+iDLD+nSUK2GYz1vAIc1T97M2+hCqIkX3SdgBm1yo53B7D1RNzEq7t56K+M/EHqjd1Y7Inda0arIQXr8xCZkTso2hAeOEThDUvuLT6uZzMKg+hKhnAyaqN9BZZvJhN32lUohQZyL1RFfjYNn2W92K1/7TS7MZmhsmuj96ttkETFvM/y8euhJwQzFZ8fUBl0iW930MrCTfulbBl+51iGpkOukxMx5y6JGPjcRTIe0/JOzx6JJsldqRg6QL2+z9iGvfx7knTx51La4JJzYwMvrXZdn74+OD6zPiKbx4i1K+eXaEvqU7/4h5jH1m+U1wmg3t3je1/qAVtXaRwpvEjz2r16uE1Cu3GpkKplSYZpP8q9TeLo30U2WCy0lRWkE1muVCFILPcnle7Vvmot2NamGzgiIyi/kKB0WKLnrTU8ns/oLOHibduwTRPWaZMiFVUS2U+TFN2ZlKQitaktgTGREFJmr0kSfNPf8W7IVbdUXxthIe/FKVxW+qm1PmC61jTn0I6Ys7R2uvpglrKrHw6SBkSYilXXLCqrdS4zQFVI+CZK2TkEMEuoV9WerCU8BNku13BqI8oYAyEkfJj0/0RFi2mEbvEE8SDZMLN7uwQQAWEcAXeWEP/ewqY3DErhEeRzye8NmAyCemk9dfwwHkIbgP8FM/8VInoO4C8T0b8H4H8K4N9n5j9KRP8ygH8ZwL9ERL8dwP8YwM8C+DEA/3ci+odYfLU+9RDQHp4iWn3z8jw4XoYx6wKaIeXKIW51FYKhWStmdFQ0yK5/1Ri9rQO0sriqtY5eGL2Kh1GpBOqs+laJJg4DO+8kaGP8JwNgBw06aVMuISF65HdJzKkTHgGGrdSdl+sFJBZTe0HHeJeHwfK4GIBr3kZWxdh0F9vcGTOWGwUhh+IZlGpIcCIFZL0DlTBNM26OR9SpoNQJKBNsATbtMRBQvL12twKZJubrIrvSBt4KSyidxzf7ou9wl0qQ8EBbBzXorqKCRxamm1Al5pP97bD1jqlHjgZhXeV/lQqOdcKpbpjKhGWuXi2nNyGhwCoWKECCzWdXDmbgAcA+tGHft2nSm3gQhasCJV3ru8TgwI6InE+NOzY2YXQdGLyJ+GPSsug2P1LDevzqAIEKicfNhXCSI3v77AHXniwZiC++9BrKHkOZVPJ5vDM80o2dzGFAkz3L5wUS+tJ1XZjgInU/pxTaaHNLDKYxh8neGMgANBtGY24k3XUBqzLhlJT4M338uuiJgvDsMEBOUNXqXZ12qhx1q8z2zR1WQGlycvcgEmNLpEPVHDwA6TrqyLs2MMGpc0IfQbFrleept8sYZBY5zCQekCpQ4QS3zrVSZDeyJLOBScFYE8/JrVkulQrqDeCCTqoT0NFISPRm4UCiIaXCBW3SbqTdJ9PFpDubCjabVw+RdrgnEPL7Sz4AybfedMdP7rupJ5Iln2aQ/h0bJkEGxU/XY0lAhvw0OYHhu1EOGXo3ktfGmgA2oNshSLCgVPEykPeyEBOZideDAqHzaYxLZLawPXGH33okumQDsDQJiUcVvQo5KBUoWWfMhKL4pbdu+x0X5IrJk3meUWqRpJ4aSkZEkq/CALHOrb5u2LYmOkLJiVoKegWoxUZb9ojIUslGJWux/cHMXjlybyDnEBD/TEuGmhOM7IraardF3cUFn2w9h45ctxUAJByuVle8Hs6Yxk92XQ2U2yYStINcqaa+tlMvN1A8xYpiiAIJRTQi2KruBClUQJTy6pWiRGpPuoGcdIo5zWlNfOac/Z86fs31BMPmTOAoJzPZNnH1TArCw0jSy/MV++TpOSQRvvS62W882nNcjuqXYqslOVAUu3NcZ+3I4W9RNC1kWzZ6R5kQWCJXBR7aS5H7UYgNneBE4lGXsYv264AhKfeB9d0u12fG7LtnO8Yh8s05Tt/nsXC8pz87oFUiDQ+HTcFKPhh5C8UPTdHDSJbt22Ybho4AVf1RCADt295J9UPuV9Ur+v6C9YK0Nm8VZnNsaOAim9LMHa1rBc9mOEd0lNRlrqJPHeKKXRRcJivJ0hznTr1j20TNAVLVelsnHOYJYJJiSiioVUiXmQrIwpkkthpEHZQI05U3n6vheqDYKeldwxKMCOdsls9Hr8lVhi2nXx5305ORQNswEgDfoI65Zps6l6lPWAgYrhJyXNg3Bmb3JGKg1CFUmog895zYPurlpSlMSpIPnRA2uE4GmQ/NU4Q4z8FK2pT0vrq2zdvaMBE39afOmIbI+05Eh2rJLsnGO2QDLs1MPHV8qhZh5vcBvK+/vySivwngxwH8IQA/r6f9HwH8RQD/kn7+p5j5BOC/JKJfAvC7APzHn/asPOgD2EhC1RM5pu8KtJy2AmobfvMeKqqIbUet9xLZwjuDqWv5XbPyRCi1AhTFvKVA2dIAXiJQZMEgCSSyFpJkL2cosNZnFl8csQgkCWgCGFS0hJ4MeGNg01wMQmwxJCGWvhMzIoM6HOwyEzTYAebd5DoCJcBPUmAjmQGYMCNlv1Wl6AIIhhK6kKd5xvHmBvO8YFrmrEli+bvOE1MAhsVgSqkAlJNpwcfHcFsYKohKY4CWXdfnsbTblIfMCwV5NiAs86C15knOfIHp80otmKaCea6Ytwlra1imqnGrFRtEKZlBlGFxfnae6364bhn73eeRvXsCgRY+7oIBiHEk27HcrYPkXfVpx0A47cB7CBvEWKXrCkiI3B1YvvbcPfl0DYjl7/ZGBPBE6Fg6N5RUAtMU1Wz27zbcm7vPvf0/GwtL4lrUtbT37oaPARSPL2mjMZD72gwmJw804d2TO1WfoePXQ09c9IIZb64c5eOifd7Vqy27fuf5zH6NKO79XIzz7RyRVriYoyZEApA40ZDuY+8QEJEdSBsAsOTjhaSamHmSVNUrVgrYEv0yIptB0V3xqEQFNCUvBdRWNHRI2VO5RzPZjoKu+sXab+LRd8w45DHSeb4OwN6nTur4rqB5w2roM0eeIXGnjjBowHShyRBcjEs+xAAL+ZfP3VctjLGwK2J8/QxRLKpXxEgvtSLqZaaE41fklMshO8n+UchETxYajfK+NX3B9rn3Kw8y3wwdA9uSsFNDb0k8fAoDfet4PJ1VB5g7vOKG1rCuZ5zPJ9mxVRJUElwCm5bs9RdiPC2PPkVOPbW+Lkk7uDwtpThJaGuxqR60dWP94jpOw8vmacLN8aibU1VIzxSyy7t2pFe8OMZ2jUafeQ95m7I+ITVYi2w2Xs7nMFrytdkIsfnihlVaJ/nc3wjHr5eeEBtxzE8V38a6sf63cy6wztXPYhOYr8yWOFflKPZtEHw/nENPY6HUd7vPx3aG7DOMw3EKh43ydHufXqP75+X2XPbxiGl2Txuv31+b+zrhtQvSNX1H6X5mf+317thu++7N7x4EXGjtWJfFgD7MK2jfrmv3JCrqEFBAsOp3LE4MusFpMoxIPYXadvkO9o8BJna3hL38GnWR9HdvjFYAUEEhqf6FRgAJBui9git733qfWw6dJJc0Leugy7LOHWQVm4MCq30SHpcm30Zyji7Gz3Wk0f5qC1l/+bMIoN31lH5hCIEnlbI5bBmQpDhhcaNAIuBdFg+YU8kWCo89Zg5CKKZ46g/L3ad9wKlSro6RXdOwk/VDoQ2IvjYPcQ3BZ0Q6CyOHmKE5BJ/exgL+PrcViOg3AfhvAfh/AfiyCncw8/tE9CU97ccB/Cfpsm/oZ596XAoWxiCD9E8ToAXJ2GYjPNgni01eYAfEWSt7tS7Axxg1I4PUob50+bQUiEeJ5vQpSZjL/ZoTAEa8WCPtb5tQVs4YGIE7c7jGMQPc1R2QUqlesIP/bi70bJMbsJhDVuDENiG9bVlYiCkRhy2encAm3RnUPrey3CJMw2BiXQAFtkAryjQNRrH6svi9XUWzjZ/cJwCQvi3Ju0mYDnxBWbv9XyFhX4W9k35RD6u9oiWSxF/F43kl7E52seV8Z9c1VKQU8VAoLKReJcJkQtxyG9k8clOKhml8bTGG4aACsSdh5tIECiLEKEt5+XSMMCj8DFAtqTqAAXjmsK/sqnlN0ZswM2M7x5XvlWAGvHsFu1fwoxK4rOSyNxD2QHlvUMT4xj2vHnp+0YSpoWgipE08M4qHAuTnSbjgWLmt946tAURd5r8NG6W8MynUaf+O+7689m6/EY5fcz0RNMWgpAO0xRzM58TVO8B7RUlK/48Y2vFrBq3WHjPU7dlvaD1YCVuoUDXSJ+U6sTBo/2cApyR5rDkLGJovTl3Ee6HwxlFZXUsBNPSwVtJ8WRzEKTeYL7a3nbPxpCFjCpDAl0RLM33ECayyesJa/jCOPEcMyzEUhIf8cxMq+sz/zv0en/gavtbjet9aBTaHwXHFgAnmBgAw1QnV9RhGlfnE4TJcO0FAX7xD6GYeZMEgq9g1pXxnL5smVga8nTm8YQFQlUqZ3IGH84rXjysOhwMqA5sIJXApOK0b7h9POGnJXwZLPoVNeyOVSbY2vkke5W+eGgt/z2G87P7RF/IcBjFrgmcg/KehCNjIwPC8KJAwjLfffhvPnz2TdWVLDRR9RJfFG54iYS7GByP+2ZeJzu+IXX/p9NAbCF4qipeu9VWWXSSCwMc62n5tND7bx6+VntA99ZSzxdYckGclmcwG0jhfYuDAEmW4h+Bjf6jrlRh7u9u1NZOJoIt+uZh3l8TQ1dUVemjQaoGF3kQ4Xfw9PO+pQzcx8juS4G7StA77ew4ywjfe2M8NWYzh+v36u4aVDEOSdixdWX9PaeeBvECeG/aeMprcA2fYetTXHrDiuG7jOyraP4Z3NeeEEeDMBbXUKExSUjoUBgpV9C6Vufx10rQ1vJAPy68qhBPATb15a9eq1wRo+ZK2NbRasbncVEeCFHrrY6I67qI4gK25Lqk1QHJ3k8FE5qnKbot4W4viZS8YFM+zkLnwshRbmMzz1DqArR/I+wRdPZBJw9i5al6fyMXEvi7JZawdPXmuRc4ijVIAAyb/icJOb6NdJf/UhuuSnobMscPaqcJKujY893xtsJE85oDQtX1qv8I2CdnnTBSt+v8/ZMxe6BmAfxPA/5yZP3nS0HpSUl3c748A+CP7CzIwu/YIk8EESbBl4LxQnM9Qh27K91O8qySLeCN3nCEeQqgTuDUp7VtIQ9XCpTQ3pUGViaF/e21SAgCsTB5rksrwYODe0Tgm7sg2GoCWFd5Z3KS7kkNSWUzJC0C9jgzkhoIyQqOn5rEJNFNcFISB9am0I+J7HYPaAuFIH01sIJFGEqdE5vtCWn2BzAuIAW4g6u4+SAY2WcBnXsTSJx29b2Yy+D9J0WVeGJZ3gaSkfLNJwhfGho9D6+rxpFDT39FmZIQnxfBaCEek0CQKLzSrIBCRwjG52SfvDlQi+pks6XYGqCpsu4+i9ToNSQ6zQSxnRlwrOgspdKUCwzWAPwqvHSBWg5GooDxl0OyArAl8O3cf6nUNdOdn5xK8Q0UuXILmbBReI4Yc5EejnSwLcB/PL/Yc63cilDqhc0Mp/SJhNrMYJ11dbLOnUu4nA2vXwJaPaW8XIOWzfvxa6om5mnIPGcMQApwA7Hi2mHMDiFEvT8dxJGl5aLT1pd3jmtoTdK6cJUZrMBCGtc/pngxY0mkHqwa0BA1ohbEw/i770DYDAuwwi34rBLTGqGI1opMRTYAn84HmoeCeSqlDngmSqhwKgiVU2uSjft6byHTLByeTXjcqdJPD1gKbF2yTTRgHXiFrvfSrfafv3Ls2mUM3AqyJHU1/mC4lDx0w3ZUJQcB2LkO+dVKwBCHHqHe0ohtBRBKuVSQfTer6YZY+Nb9J2+JEe/7iyto3/TuQmEOMCkajE1CvWJ3b2sfaFahFPJrut4aPH864P3fQUkCNQZpv8HHt+ORhxScPZ2xb96SfpNVYu5ZFhxNDbzYOP01KMbN4yhhQ1bUrAPfa1Xl3mX1O2b2MMFK0kfLEEJ4/e4Z33noL8zyJRw/BDfNhHe/GMzBP6J/9mhcd4VomsBcuZYTngkz9JljJNviguKVg7yWU+1s+KxqmgAsj4TeSjgB+bfXEO2/dyXxNeiEM1kzmj4MfIULjJtUT7ddrVEClKAEY5qWQjfl8G8tAFenF9vMT6bZXzrv2NyUZk9u4v+9T97LPxqxxO3ml+pER3syGj8wo9nu44tBrn7hnv/L5UyQNpb/334/vSNhPofyu18b3GlEmN1f7jsImimf03Wd5zOV76wbWqBHtMD/XKkLaPKxlQiMN2SrAVCta6QA2oBSs6woSBxcYfLCnZ9uF1C4NG08awr2jk0jjrcnGedVxLa1jHe4ll+1llOkaAErwqP7QXKwm82uVyp2Gi8QmIFg3GL73eycstR8nszXNRmOuAJF703jCERG8MZYFQI+NtsasXk+koVgAPGSTYXa0EXd5ruUk1r2pQ4jpDIiHEDOjN/OuJe97WY4pnNw2x1jsXXDiMtImz7CGyLCV5GLy3IxJPzabk6DoF5NXTxw/FCFERDNEeP8JZv4z+vF3iOirLGz+VwF8Vz//BoCvpct/AsC39vdk5j8O4I8DQC3E2QiVh47nW6JNIkQsr74sGUwic7010Kn3KwE3JKRM2UtIB27MAG9SXaoo8cECisJ4MwBPoBJsr4M7eSkYs2iLUHIldEftsiNVfT7I3NOJrGXlBThLSE638vNdKBDu8PLCoHS9NqJDQwW6Gh/MMAZalJNZLAROIsSuz4osi1RrLDOcKTYo5oBICYpatRIXog0MzalgDyLLsWDWRyzCK3PFhSjb1mua2A76yQSKCCUosdfRImmpzTGxDKTPhClE2wSYUjEBFLtvvUkCVesfKQctsf8G8l0Py2R0osx57ivKh+06hHAkpDEgFVAmkZNy5d3PEPs2cB1gKSE5z7PnlNiDztzP0d/Xd6isKSYoLxJR23y6AljyYYn08vV7JdxUmObPcw6KayXmrZ9jTsTvFsp10W9+D1F8lqdhb8zx7hojqnJOpP372udDn/NIImSgNvZBQe+X7sKf1ePXWk/cLnWYRInWw76EsH/uuWLGueU6g9mNyKIANkNXFREXhxju8q/r3dzhxHJ9uJhJUK3EOGey0OWWyWCETAsdFoCn2Bo0GY+C1rokSQQ0v4C4nzcFo6CSQkkTiDb9xrrBwOq9BEk4TTT2nT8X4UUVO2xw76QcAs0IGWKqk12MczRH+0OAjoHp0chg039OKknMPhNQOjuxZONUShhrg0wDxJPH8oBUBmtOON9hIyOrwns3dVyMT+of61PW3A1i/9EACqUfci6AaG/WCa7CDSBbnxHUUAh5a/kGbCPmvDWs6DhTAU8HbFQxUUWvM7h3PK7A61PD/bmhb8K+OTGXdRrGd8zHJV4jT41l3+c5zrjsByKt+rNfu7b4VAebMTEY2DDP5Hg+ADx/9gyHwwHLIlVDKd/f5iECt+3fSeR2fD7ugF/qjv3v6S1krhbSuWbXxr3yIcUyyjA39m3zvtzN6Tfg/M/U8WutJ772419gA2KscsrDKpiHvgudcS3XyNNjG98b6aNrRQ1qOyePyUhcGN0S59tz8rjaY58ipq6tmT12e+pcO8+wVk3E95tIxviuu/wrLo8vZaHjH3sn+XJoRyZoKcmF/XtcyJP0Dtful7/L93pTv1zk+xvkVegcx24ISbnvt8C3BJM4zE2H3cZe5w+VAVPKv4pSOthzDxEsb+2mlbG740j4VLJzffMV8t2Qj9LmCcUmK1GVSIhEUE/TpGHTcU+vTFmlMqeF64IiCXapEUpb1WM1FKLqKU/JEOF5trERCfMNX9j3XTAMmfVf1fNY88MpOZuL2xQKTxvLWSheta7q3Dkj24o2znnT1zB9pKxg8dbmSKXRXFHHPGnqwMFW2ENlgG3mm/6Wmxq2Enw66APVhblNrZvXEXsVTVOfXS3nwGJPHz9MlTEC8K8D+JvM/MfSV38OwL8A4I/qzz+bPv+TRPTHIEngfiuAv/Rpz7kQJAmEFhcSmriJIIQ8kqughguZoxSDUNOAiBdAATdS7yCxl8VlV+7de0eDuuVxQWV4OXODH9K0MdRKBtwA8U5Jq1IKAQWAm4M6ICaiMYWtW5k9cqDXu7qBdZnwpmwEL5FP6Jaea+3JANmByEgd2KukX9VoSkAcaqBE2FvVjoSc06PSRefmBo8RI7byGE3zKAXgJ1QwmtzHoBozJJ/TpWeH6GIGlS4ETo7rd399EyHxtvtFzqX7wqJWZFe2seQc0P7uraM1xtakvYUkc32lVcKKsnHFbieErHfwd03J6NxWhcC6knl3vrU5zy+GKhwbZ4YnR5PnimfRPE84LgvmqWDWyjPx/BCceX5YHzMCmAyKl1mNJG27KfOhMlK48MY9ixrJ+52Gy3AxAyr2XFNudVc62fpjDyCy0U2JeArll4xz2wVJz/Z7lIKtRUWl3rpXEahU0EsFl0gKn99drlfIQHDCURqdQk2TIvc5qoJuXL+fzePXS0/Is9SVvBsQuyQTh79h+XWcwhbp1jtiOsv5lirYzPIRxBuos7WpyryL/DfIwmTA1q8c2kIKjMjuo7t8Js9llhSlZKDyIMAjqWfPZOGMZHNLklaCNPSnaOUQ1lxZRd5JjG9pVynhli1ep5m8DDLIdFgYThGOgS5edSbpvJpe654rIN6fxIMTRsTDiwRQrh7FQEmhcDAKr0BzJ8lJXQTTmHhYBAzQGcWSrKZ3cAPFjHySe7Ym+qZXoHQBddvWheBqCrTY5ESEfst80/h8ZhBWkObjKUoZiooWWWv5g/ZljSX0XFOGi9JU9cquQ5kgO62kG1YYAashQas6UoqEDEsYfAFpgYfeO85tw+PWsfaOdW26SyqTsG+koRHiQUuFBg+zvGbsLRQGOPIg21E3dGoJ00Ggwo4VnAKj0XPSsYO+u9HzvCNLbK4aPiEmzNOE5VChHQamBvMs1CWFCs3dQDuPGx8Pe7ME1vxNrx97A7b37huSrMabul/J+Hbz1JYJWqyrBrwSetrnCmzH17DGm4H+Z+X49dIT4mHJaiiEF70cZoSaTAeQ5p220+60+z2esfc4hM/DJ1sFKKFg8lfGnXyJ2BiP2Ci/l7Xxsk2jztNn9RHL2PEmsnFo8V6XUpqXxDFP0UEwYoEQOZrsHg1icIl8Q8JJ+nT/3v3r92Nh1+zaEUReDhG8TgbZ75fEGw3nX76/Kiku/u5Q2URkEQJmw22ifjoAtx7tX1fvXJN6BGDSe0s/SNLzTZ8fbelA6DYG1lV8eEwbZvGcCQ0A4oVcxLOxFEKZ1AupTpjrhHmqWKaKWgjLPGOaqhBBRJjnWTF34AUqwDRV1CpvUGoqfkAEsG5WqKyuRTBMZ7XPOI2hVQ4lwSngqrl3tYJZ76jVCBD1LLJ51xlEDcQFrQOPXYpwUOvg1lQuMjbDTb2pzK9oncCaXlyityJMGGlz0TAD68IdK3oVdeRQT1obB7UPRKaTRvh0XSc0eGGLR5LFgADm8FA0l3HkIuLBM4nBWHuTDUgwZtWe3VpCinOvrN+njh/GQ+ifBPA/AfCfE9Ff1c/+VxDB/QtE9IcB/DKAf1Yn4l8nol8A8Dcgs/pf5B+ywliScQ5/5U81OqHKkuK7rKuLA8XwcJE0QArYrbJJkczkpIC0FMAqCklpN6ghSl75haDGnwkHjocHIXTd1ZT93DD8WAkRSPM8xq/3ZrAf3Blr39wgaFrVRcCRQmIe41b9587AfxPjP46Bvo8tur3QhI2N7Z7HAOTfs4HN5JSID6yRND0JS60l5grcX9AWQ4+dWqIy5DICX+Z2gt71KrFiQKwxSHdGN42tLWBUq9DV/n/s/cuvdcm2Jwb9RsSca+29v1dmnpsn69xbdR91b8nFQ3LRsHk0kEVZwg0k6FhyjwaSO/wB2E0aJUGHHjTccweh6iAsOgiVcAPJYAlBGVWJemEDJeqeZ+b5vm/vvdacETFojEeMiDX3l1lI9zhLmfOcL/fea80ZMx4jxviNEeNRcG0FGxpqaa7E6Mq5gBpfcDStt3Qxz7sbsQYCn9sgf79bfXWamk6xP6vreD6fcFoXrMvipYithX6SYEJEBYwLFLY3+dwZHQxlm2188fdhD0RhG047XpiP2XgDYFAso+tqpPv4nuEnM5acUWq9ee5onmeDlpXV9D5wB+39dKRPffQcMo8v+Xw8YZIXjifYo2ErYShf8P29fmdyglXgGk83nhivW0MkYCvmgtoVghFUGyUzOvi206qZZDqNihLCgFaGV0+T1vy7YT/AMGDPeWf9NjBttZ0AIB7skQJJYQe2h2WQZiTIi+QNOy0r1pSxaNJ9A4RZARwRtCBDDCdVugMAFoMInH6zAjqZl1alEiYM6EFkWW4NNZt8slN0KZ7ASfhMzlr/sjVJfuw8x5i6MDNTf0XqhDUBnC85E1T+yAgGWB5d0o2v2ZTa/k2IyX0lj4MZgMVQZrwvgnmEdrUjrYCbJHGGYRIKhz5uCBgoSfvfea2fielUJOWbiZIbxRHaMqVUsApjSYAFxCWquMvAORMWe0stqGXHpVRsm+QQIki1msoN4lFmxnLJXzdfQtNd8rvoGfi6AlVuAC1aSS/ik34AIlPIikNs8CbrSGm8K5vM3PMz6fznnPHw8IBlWX2eBllAUGNVV6aG8bAdEoR8JDqObwPUURkNXYIZIMnWaLqPiFQuR5qSn62N93XjgzQu6+Zv+75fvwM5IV6Qkjy/T1Wctr6Mfc7ECx2qRPX7Oh3eGgwGnBL2bUC86PKJvB/SNnkb1F80juQGp0xyLj4f+iTt0c39c99fMoTEe2I/Yq5JHx2Jgqvgz/85TwwHKTKH0/6luAt171HW9QqLpz9fGpG0ZWsyzS3GvTnvvdjGbEgy/c6wg/EpHuQRhnViy+/HjHEVBi4Z3qPtpSTOCHlBrdU9BquZw5OmNEB1D3r0qdHx3OobKSfkZcGSCOuSkZeE9bRizQvOpxPuzivO64LTknF3d0ZOcv+6LFjyohERjEVxhRwu9dxBcsiMYV5ZdTfnYzx5tdQKogzWiBvJTysARv7W8vRWTKkJlpD9qbi8ipGlNMKlATtER0+1wqwuUqa9qeeMZHq1Ihamyt9G7HSZStSjFQBI2hftO0H1Ustwx3Yg1b2HTE+T/EV0c7BihWtU+RJcYTr9lMfI6Y3k0Iey4pokoYZdVJHrfy5bjd7x8vVdqoz9Hz/Rxt984Zm/BeBvfVvbwxUYNfvEaHutu076vAWG7ieLwQuTuaElqDePuvAnRmmS+DfHBgEN6ZXTHLKQEWVmFU1KsFqOG2fznSl6DhfuMNYMFQLSuoeQKRqsILhXWAk5E3Tc5nZvHRUra0OlSLxhHDhmUPNkv6gMT21EgdGt8eSGsWTj0k3AqmDkvEC8QFJgWAaM1ZzlIL6P0Ta+zZMJCAuNMKEkiXolvGEQHE4VYSMNjFrbYEnAtem/vTUsDJxzxpqSlJMHUHZG2yp4rximjOCVzcy4NSbgvHVLnYXvDAgsRMEziM4oOwyRCZ2m/MvAOFQpSioAliWJIMhJEsyGtQWLzYHtXzDVOW1xBBoBz/v7+ljs79ngE+fAfo905Ua/WahM15FL72DkCQxi7kN0C6+h4ldsayhf7/1tnmTceIMw4PAP5v00KQ5kpxrjeCh10PPSfox7//t8/S7khLELVi3L902oBBHa9t+b8hrbnhy+Z8ZYQdiecV6s9EKAhf628JABQ114kAI3M3AAUSExWcB+yNAHZDQknwkQVEWRyL1kc5IcZjnrvySfLZSw5KReQRmnVYDbQoSTnvQl41lJlSVN+hlzdMWrNUYrrSe7zrZHZVCWwJAInuq3e3KqN4wq8XLgEWQWujfjCNA7CTVuunbB47OpIYbUR2ewOxCIRblIujq2Nl1h4Zu9KfggVAYMvLvWKqeKdUfWhJQR0NsSGqWBK7hdAS6AhuqR9pvV2zEmH573fTcSww0HCK9Myktmeedu7uZBmRnMO1qroLohtx13+R53SxIX/0RYSbyor9cNT88bamOkDM2TR5A/9EetoGr51Qzo9rVk6OGbg05V8ixZF0nlHOQETuqHx92waeF1Dvx0jzs+sDkZ5rvTW/Q4TQDuznc4W5h0NHYi0oDQGxvgmBsfLnJs+imj0CwHraJpu/H8MKXZDLPqORFCXG8wTXy/jlsOySzX3Ivd+t5cvzN9AvA1HmTutD7hHcpLGFDPhMHYw7Z243faKhyv6Z+zcnxzGHDTTwSjSL9mrBN1H8dQiN93vkIvjPfIqGUenqZIxnHNczXQsIbpxDiKeXmZG1wNUCwVsbB7yYW8XPGVt3OoOgTH+2dvcTNiY/p8xHrRwDUbjmbsKlUZNX9YwJsj5rV1D++dvIoFY3d9R74L40wZoIqcF5RSARQ/YG+tonEBEXcjhbKyYenCZXKeVDdbcsZpWXBaV9ydT3i4O+P+/oyH8wn3d/3w+HQ66QFSxrLI6Q6RhJBZwR9/p82PCnnm6qFdhpE0c4kKEPnXUNCaeOeaEai1itKqVsUy71fWVCgRM3QDU2FgQ0JpBRVAag1gOdy3fJNkz5CmYTH3U92RJkuksu+t4dCLBzVWvCCh2XJgXDqtaoEh26hu0FfRZng0EKLaChS7kDGQcQ07faQuC2CHRNTDtC0fEgWvMrAm+p65z3j9c1UZ+4u+bP8ZiLJ/ce6Y4NXFkgp/O59isJfnNf7M2uAszAXT62mfb0pj/HryVkXzJSLxLNB7DOwkC38JXHpQ/CEEJ0QgnW+t16Bi1tNVmGGox62Hc0LdfPAxOhBzXUL7jVEg9HmNTF0mhhHnwgwRwQOIRyXLP9e/PM+OL1S3hJK5JRL1xJcOwFTwtj5vAtpHWuiFxI6VZTHAG6iyTsQbelLoOTzJhCUA7Am4IuERhKpJndcGnBthBVBaxmUH9p2xV7cDA5A8T1Y950hnn40jR5/rL6pYieJkypvd68yEwglqUFpIV8bFo9ODtCVCQE+Vdd8sek8L6zvMHRnTqd43Z0DTOG/oKHx+5MkTv2fmwfoe5ysaio6ei7+7MqCKbTdejs9EkBR/xr4aCLN3p5SAOQ+Qzlnjpq6gsqdyyjdzoKt2E+YGo3vufYjKIgDPFfPjJRcbD1Q+6qcr8R42g4PyMBPIPHkdcDfEO3fUX6xkfXix8ynhnbYHpb2uxKnsUIYpnpSu6mrfNJG5KyHk7EuEe/J9SmRGTAHtpCeGEtOv7tv6N0GMRUtKyJTVAMSoXAE9lV0kfkYST68W8tbASbxC7NSt8zWVraxhT+ohyZbXrtkcynwZ+InyLco74TkC5qOkY38P3HgESKJIqByVvpipR/jwvPYEMQqZUib3JgcDlCejvM59jl564dlSCq7Xq1QE8f5iAGzduNDQ2gbwrp5aJAhWjkY9TMgk+0vGIKnSGUChyStZbHX1lyo0VqUnVp3KOYGy5HKqdXO+l9FwykAmwT6nTDgvhIWkYs21VCQNK4YdHBADqJ57rTZbYz2zDnvHRxNoHyb7zcuIRlkl4+74wv4GoMY93W8pA00q43SDfR3agIYJEQHn0wnrsuK8rlhShmgjhhQ7TzY+P3hZRaz0CWBu998cAGi7MeeEFS7g8D6T7UcGWVO0bF8JiByNiUmx3PajfLi5evj9ES6+9RoBwjKTRAVU9SaW+wB2WZMw4wCo3jHj75Sy01NP00zOj0e6mbWd8TKjVbPoyAlTvWSsvDEGKU15BS8yDAnn987nMOKxGxzt5dfVu39+r2N4ncNpP41GNcPmxr9HnBbnyfQ5+54DhuqGmgpbqxl/Hxl9gFsD3PRW35cij2+r3rZWnQdJn4yvWL9l/RMBrcY+2aGH6oxq0JIcQtn1wpzTwBtsPWdaiGNw3hLmPaeE87ri/nTC/f0JD3crHu5PuFtWnE8r1vMJOfClRVNoxDURm0ugPzcGMdC45xJsggPE6FOD4Yf1u4RSiorIhtKKj7e24qHQpVRPo0KKNSS3K2Mnwo6eWoWrpCUxryAGa7Ut8VJ2f2OG4sLubCBAoe/jmTfLunY9w3R6w2rmRQayKnIUC5rqgXzXM6LcT0ob5ldmtGXyl5mBJLgosQ1E9yH4tr+OyzSQLArag+t7ZRCar67gyk8OP42RyYqqxwME/CPL7wm2rkIo2ZJ9Kt9tTd2CmdUrSBeyWc4hrYdhDBAh7wGEuMRziLtrjy2kxtxT7LgyWQsPg/5uJcSbKt9QpaeFDS5/o+dPYNuMyqRggPoYZPr8DCB2+n0SjF1A2jsA4ipgl7IItS424AAqiXs0hzYt54JlUY+nchEIduFsc5mQKKNALOOehAziNmgM9BYTkbcZq7HM4z6BsFLGq+UMSoRlXVHA2AE8bxt+u+14vG4olw2pFTs7Aijkp5kEuQmo+To6dZjXwKrGORAmAi2u2fgGf+kyQGvea9xYPQpy9wj4xPORQSUiMCU09dA2pRNTuMMMSo7aPALMdn9nxP3vl0B3BM/zfcPahu9n8BY9g45OeebkkjFXQLzf6NV5ER+P1a7Z2GP9pBTnLe5XafdHvK8X97VjdjGPyPdMyNaYsBcBnAYg1aCnJi3QYn/VMPFmyGloQ5ukYNoSwdp3ZixXDhX2pO1s64xiaZMzrLyPyAGLGImF3ze0XsFCP29Jcgpl6kYkAvR3O0WWfi7Ziio0DRsDyBRUlTlWrcIr+smkedJDz1vmhjbl3XZIoP1mtoOOJjx6QiIdfHcvPDcUkSZZJJHvZogyOdTCWsHmGLbv7TcD8Majm3oK2V5Pvo5d3oQWCShlR9l3lG3DasDbCSS+vYF5R+MrcpZnW2MkdpcayGl6Vb4ByZ1A42vNIGiKq9EIwOCc3LCSUxYjFne+0nMjZaQF2PcrStH3KdUZkiE0rBm4Py94c7fict6x7QWlFDVIJjA0f0EiJE5SRaZVNAXvsuYkhzsY5YbRjayvKItMkh8k6V6IjrBuMAmzyrZGgcfa+hr/7fNmtMdY1wUPD/c4n8+qQMk/yRDJylfJ+2wGs5nNElHPKaZfRnlypFAeya5IJY55Ah7xQ5MkXlQEMeb1eZhDdeC59V7q+49XxHz9M6Cvya2hwO5hMOqwRqMRgUd6mI2E9jbbA8Pfdset9xCNnR2+i4aTDtf55t6O317AeIYfI47k+N7bw7uZ3o89tKOHUL/XehI57Eyrfm/rPHmYsxsAxMN3UQkejUS2VuPz8d6jvXz7O+AVPS35MWGgic5/1bCjnie2Ft2IM0gq51n9YFZ0x7xI9aycM5a0oKCih3EnlL2p/pqQWvMoJPNEv5m3xqCsB8Ak3r45ibeQeKSwax2q6FpiQHm8NYj1IX7GkEMQ1Wtrl0MtGoSqeNcXS81Rino2MvZS0VgMXsW8cbmqfDFMMHoDyeyRe+o0EEoi7LW5B3GpBQtB0oFYDjzrH8HzryUNzJdwtH7oq8d2A8Gad2CcY59n6qtKpjeZ/hZkutzWIzRyiIxQgtNiaKR692i4TCmhcuv5VDUfHYVdFr1RI83L/bcH+vH6XhmEjH4NI42MQe8J99vkQwGv5AEIJzKhbBwAnZAMrmarZzDJiX7VzN+UWEqngyW3AZGU8DVWzhjKwUroUT+pokQa12jeFKPQMWuiWwcR9eumyaRl5NIHJX5IWkgDaWTgWTd4F2bHCvooKCYkZae+4Wui0EdS0JcE+CZI4i7ZUBCwr8RJAPa9YCu7gJYeJwCrLMa1qIJka9qBqifVQwTeQQn3Mdl6sA/DKCaCrKRlBW1zuWgiGY+kXa7IrYDQsPCGOxCYM84Z2Aj4uDd8fLyglitOOeFuXVRhylgysCczKAronCXeLPjDN33NdNRQQG+b2r6kuCl0fuy5+cQ5Jt1c1T10zVJt5dCDJQgP1rT7MyBgU0rA/WQpfm99aKMwjcacCBhsbWIllyhYYyhA9DKK+SCiEWAG4pj2nFVAsHbi6W1cm7G//XkwPL6ZDWTE+F6OOaz6eKwvpnQjUH3HZQIYohJg3wN0c0LxQ71MwWyRDwyA3nhEpCkLZxqVg+Cn4VWRopyQe+mGrmgACNIscQezY24UuAyw/oEQqm3IHYLB1MADPQxoIp8MKMshhVTRQpIyq0nDn8UTqOfCEVmob2bhpClLHiHJ5ywu0TlpyuDSQ078tMsyhAXjifMkPegQ93D4OE1RF9nBPi6RhN2zR8p0ylvC9nEZ5ocfUADNNk0C7uw94K5kmU7TjRDw9ofw1inWlWyNDHB1bQvMwPPzMy7PF7S9ALUCC/t6Wr/lqmi8I2cBjl6VDFXGWkX2GSaxk1WLqLq9upIYpB0smanJyqb/aqtg5XM5J9S2oe47yr6Ba0GCeH2VUrAsGhaWCOc14/X9GddrxV4anvYd3Br22pA0JBZEmjsK4FrVe0xBq80Zm7Jk8xIMFdpf0TtYjTLdSNnCCMfZkABMq5ISc6LQRDPSTenv/cMdHh7uJBeGlj8WvNHllHNhCzeVP2yWfQyj4hagDL2grCpT9xHpPRKGkKa242PUlYnW/D1G6/avG8R1P+gJNGFghT9e4ZoNJOOB0nzvS89H/NZxphnLj4yDQxvo/EoZVdjHJsecoG8UwdFw9V08gXRvTYd3R+0cG11sj+nYtDBGnMsB1w2MLBhCDMej79l5DDc/9X7re/TEgbfx8uFqHCu7vEu+/2cP8NtnRgzbjSDWT5HzjI4NTO5Z/8xIZroKx4pi2tKNEUv7x17JOHgCG90ggShL+FQdD09fphE7uNJRDN6aQS/iPiY77DF+I3wm6hakKRRG7GDGoFIbWq2otaE1+VnVSNS4opQCyQPEetAvXkR2MOWl2FuFFWBgFo8g11WZYGHphaQYU1IdmVtDI0Ed4vBhM3G0nwngEAFAhn86dgur73Yy0ZUIOYRLklAbGomOLAUd9PAYTfIQ6wCYxfjDREhW/TjQ/NElckL2lBzuJ6epWdd3Y6YaDj0v8AuIA/g+GYQMOTgh8yjkdJMlkklMSfInSIyjKv9EWLIl0NQKK3lBJsKaJWt6poZMwHkVRXlJllull6yX8nrAQqpEq3u2uWobo0RkBrp+RtT2QW0bgF6GWKymxqTJT9pKlaRTpRZnhLU1DVMi3VgsQJMS9tJ8kzaoNbbJyZGXz/NwNMMpnYF0SyssN78Ys1rIuWRAD50Ji/c7o1JFQrdmLgSp2FUIT08XXK8btr2glqZubeKylnSdG7EqyVVAbi3gViWZZbBwigFsA9RLpbJsNqlM42Y906uCTFJjGtuZoDDapqY1/9vpSTZZhuTuaFxwx8ArrnhPFUwVz4VwLQ1bqzgtWZJ6pYwlN2w1eByANdElBUUl0jqHzamUrtniGAqAhVNIQlTSsYZ97MqxC5uR2RkaX1PCeVlxWlevHjCDCYrSgg2Q6liIAhCPAmYSxqaok0TgzyeaZvToIASD0Iu0ORubzF3Snsk5Dx5FZuBx3nEEljBM39B/EwQjOJL16cqn+aIonWRR3asq6w3k4Tw2LruS5goCjCnbOrW+L2EeIZrYlQCOIWs/XsqjEqAlNqkFsBmBXLDaiAxZdE9CE9vqM/pwpr5vuI1hh8NeYQY3WXunU7Z3kB4UUAcs6OVe5T5LpGB0pj1skKpL3mto6kMNFTNPFgDMCVZpwk6RwFIVy0+VErwU7ULiSSK0LJ5TpIaFtldNOqjKdpP2Bd+zCI5kXghmiCX0hIcIeU10b3Ckb1MWWEGyAjtPDMlSYY1MwZUZsN+Zk4R/KV+NOYjI573zH2agUesGN1PAoAqZViHNofiALIHcb0ZjwPyJxE398vSEctlAbQNwBnjxOZL8hQWNLyAqYgyysZAaArg5T23MaLUoAIVI0JldzSDfWDAqCA0pqWmMK5iaFm0Qg0fOGdwY172hNnWzLzuIGI+PFyQiPDzc4bTe4eH+Adu+Y7sWbNeKy7WgMmNjSUTNvPTwPWaUvUoYfZsM34bVfC/Kz6Tz0CBrTygOnc1fQGjHs2xYCzIHpOEAaOColLlWiWCE6vT25u0bPLy+x7JmD7GgbvWFVUfKkNC60pryBe1T4743p8tp9UABNc89obVe0cwN1NwPLuL6On616p9BhsW3OJ6rDXutg+L4ktz7IV/Ct8JhlfNzmSeLFjBcYYqzh6XqGh2FCUqC9a4w9gTycOwVD4ScbnUvWWXI0Nubvh/9bgrh8Bj17/ozt2264XOYi6DL3GCgjlCh/NOGI3yPAKviSPFeNeMa+LX3a47FWWb7uMLfcczRI+mleZmV/LEd+z15oUMKc2ZzEQ+YWCdR1l7CrF3cmoFiSLI/8wMCzDuUCEIvNjeA5Z90oyTrgaUVbCDS1BviNWgFBYgWAAXbvru3aUpS0nx4e1ScASCJXpF1AcSDh7GVgrxJbqFdC020xiitIpcCU/5MtzCcLSFgrac8aWKQadWMQnJ/aaJx1VbRirRVzJAE9Vji29yhUPhhhwGNm4ZtM1rV8UVvq8pYVSaLE0dWj1TGovu5sdSyluYjvVBPFUnUK3oq4IiH0EoWABi1AiBGWhKs+lxTQEhQcePYhwD1MPI9oMKEdAi27keG2viZGDcFAyVQwGCzJ6MeFCQFS75Db2WXXd8bg1BKcNBuzuUO68n4HgvwBcAsv+QkxgVoFviaMjYF4jlLgk2w5mWBWe30FJWov4vEfatbwqVSBymBpZRQ1WPImJ+BemEO5JvTFxMCdMwN390hTbmkBEuQzAa8nHmpscOABZFuClloS66F1JmKVqvzBJ9GTG1m/oATI6MLPLuvW+TtxJTdACG5DWRRqImBbCWJe8yJsOSusHNrkuCqqQeNe1uynyqCAS5yutlqBTUGm+W7debSIKUDq65NCsItGhgQP0vGVFUBUV7rVuhJ0LIqPesqGf73vWBJwAIGVbFib1xRS8MOxprEAp2XjKU1VDRJHAqAzdVdWodBE1IhGSsIwXIcwSCtGggIModEsCLHpItsdye2U/9RwNrusRNjq1YgMclputcEfDdUOnPDKGSPICcpjdp9PbHcrXCPzwC9GlcMe5hBQlzjeM3tO4AjM8QF5QEmyHVPTG7P3aLeT0xsjiwG2vYhMyPnZZhXby8YfLpnk73jZhYA2L4f+xfn6UeDUL9igRkX5hz/HgUeA0Brzq898d4NIdsH3S366OQ0IaltewQIlNQjIgJTTajsxg+/Pwp3l3LOA1zgxfaNhkiAjeUgMohJrDlwWtwLGuKmIb6tFuXpzRWJBFFCBeiR6i3KY4g09Ur43PpvtEpR4SLvb1eqdD83RhPuLeDJ16Z7yjEr3wzzBEQFurtVM6h7Ztm9LlLYAbwZW6EcGKx52tKkCIAc9Fq4M7GU9n16esT1+gyuFb5cysdF9u+QAkhd2QSpPFYZyJoUU0rUyrMNtudFdo7UKAKdLdTaaXTmiX3Ojd9UroDy0W1veHq+4PHpCV989g7r6YTznczVelrx8HCP7VLw8emC85pw2gmtAqUBFVXlONDM4xeQsDVbMOvvzJytfxqm7CDZlGNSXOKysdM6bD2C/FRkC3BzkO05rQBPup4o4eHuAef1hEUNLGA93LBnBvoSeaHnsk4ThgEPRJdRbri3058ZdCKgn3nILOO8ElpYU9uTswHJ5JFM463X7I9XuBgdt76gYHkKgoAfKShPwx4DQpVbchnfZYeuD4JPiTPusT8c2ojXESYZx2S5QuByRfren+m97++Y6eNQHwjvnScyfiT4rkp+JLdI2T2BT8d3hbHMePHI2HN09e/55nPBZLfJwPs9gp2tiWgocvkX36FtSA6o3kbc+y8r1nYQ0PW9iMtjBas4J30twrxBMfKSgV2ESq0VWylhzT61962/9m7NfVor9rJDchxJiFbZd6SUcFpOWPOC2Zu2BhzVahMvIJhOBVg+wdZ07KzFe9TLx6arWYEWKccnOh/32fS9QYafxJFAQjObeuiYd4xI9sTwA2wzmtZqjhrmcUxQV27FDD1KgLnjKTs3iCmxRqzAXd6mTmutiYGGMqGEA+ob+mZToaNeRdNh8Xgd8Yq+up0KmuoprudAva1SCEv7xPW9MQgZgIqkzcZroPhbjQgC+IQAagOyeU0lU/TUairoWSaziTdIZUKlDr4tLfUCXUyrHJQSmJp7epinSdwjBkYI2RdX9HXzEIGvmAUniZ9MR5V61tsNANa+WMhATQ0LBDALIALbIS258UQIkt3QEXCVE0Xoue6L7mrcuLmRJhKuszH7rg2yowO5fidK2bHvAiBrreBSkKoYvgwEZlJlpTXEpJuJSWzpU06ZppnAEshPyG2ybDZt81muG9Lyykmr7ySlAxtPzgmlAFxZjDkkij9RwukkXmF35yvuTxlnYjyrRb4yg1pDpkWBYMKyrmhKV1upId8T3EhgiWaNds0kxEQhjlfByUQHzZWd7i4YT4oGxqDjFBKhXpHIqugMyqgxm7Hyg6x3G9rVm53GyIC6tyF3V249P4QKBevpkfeFed7FULGBwJRO06Q0xetGcTcASDTQSZwjQ4L2+833+rORnCKXUoYxZC3HKdXCxlC2CNRofrm3bwqDuNUC6PliDkDcj5dcg3BkCbMy5Vo+66Be2FZ0oe30EBVDb5P6F0dgnQOw6QbdwOt1vS3nDdrcDnuVL+mkhRHqP2bQDZ2LF6B55Yu0sH2kY6QAzQNwhebIK61qpUbxMEnhIbEPiWyZwXRrfe9EeUwGiB2oWT/H063m8e36fNLqnQoGWb8QJYl6qBjYK3oZP7FVMz5umN7X1A4rfP199mAAQzMoBf7H8I0a1txooZaCD+8/YNsuaFyD/Ff+oKFipEY35ix8nBloO7iKccYTYDaRF934zk443TDXXCGRbzpUjnwp2ckxhMcv64J923wNa2Nc9oJvPlzwzYdHrHev8a4RKhIqC/ZY1xXn84rTacFpzViXhL0WAfKKn9i8k3WfweWESaTOy6R74s9jVThtmGTPu6Ocjoz7bMq6y4eW2J3IvNiCH9Ekd0wa5pRxdz7jfDq7vPM2fI/r4Zo1xHpY5/2H/36ko858uSuHXZ5F8B35VcxTEWUwgJ4gnMd9RJx8XgGrWNlzVPjBw21Xf9iXYS1lFCPmAY74Vf+uX8zCZ5EYlFMInxGa7IopK5sZefggHpzAFP0P77094R8OGKwRGHaxzw8ON1l3k97HmPjw9D4fq4UgDpMQMJSKqcAy4TEGB2OR9wW5a5jP1sE6FOj3SPmd56E5vrL1TN4HWeu+LwUPNxD1ww8/tI7znVKXRd53O3GwuRdeYUUlbufd5GUwCKMnoDacDeryqz/f9TfHxjmBqlX6WrBfd1BK2PYdhljb0Eanb1JPSElU3DkssSR1LqViSQn7XgBOaLUg54ySN+QsmqobzVPXERN6qofSjDS6B2dOi+uikm+Qfc2J1LFibb4uSYstQcPj7IAGJPlyYF5TOn/2faAYMMQrugbss+QkhyOmccd8dAAWLEoDTfLeKo2aZ1A8yJvXeVxbFq/ngP0WymBPKG7J6FUe8mhgjT6usX+zHDkyiIpc1D42W2/zVjUcQ9PzL1/fG4MQMzScKHwWmI5H9DlgN4UX6lBM/kyHUHK+ltAZJ8DgJgm6rHoLkRlqJA+OMO4Y8qLvVuKOVb+0p9ofBerKQ+RR7v3iaDahzmMMTLEZLFwjQaPqG4rVzZRA4rbNnQFEizXrfPbcGV3LOWK0TvRhPv2smkP/JP258m8DKybofEUkgVgp2EuRRGG1IrUqxiQ1cBhz5L0ClsPCZlSlTashtI1JBK16dhN3pm8eWH1MHQSKhxAGAe1MOxEkOXZDLQ2l7Ui0opSC02nFsix49eoen+8FT9uG0h7x/vkqc09ApXbjQdVp1+bPmAu6gSjQhMt3E266HgkJibvxJZOWbjbm5/Sj91gvSNdI53JZFyzrIrSeyEEyT7QzGodMgE/z5WNFB/PT837SQp22fH9GkGsMdWKAc8JosfoLzdv30fBnRhrmlw06Hap7h70vOv2+F1OYE+het7/NwJlSwrqu3r6FlPZ+d+yTCJorqTkdmEI1jHOa40FRmBHqD/ZS87l6T4LN+0a+k6t7hgjLZec3Q+lO7useT37s0+8gO8eeGW1zbNP60endTqzM86PLJf1JY5vSWXNHJgWj6v6t8VY6RPUegtI2FHTqYQGbsdm8IZTOa/i8AYOhgntOJBVf2p8Iwlnz4wAphzETu1Ha9oPRfYP1lwMD1HcYT0c3TjWWgwK710Pz4jyRGQ1U7nGv1GhIzXBmyHTT93lQnmprWLI8XGvFhw/vcb1uQSrCRiDGIDCITrDTe5m7Ci7qaqNFD7wi4aR0dJqLgK/BSvtG2jZFNBrcklpYOqCUQ7FSCi6XHR+fr7jsjGthbBUoSOC0gLmiMqGwGGGkap2pECyHNCarvVcJxaoq2tq5XDN/H3gFLOHVtm7wb+Mcdv22/y4HgBbqWIWm+0ujxPMVIUgFlzevX0t4dPCGNRSUiFBNGVN5e3Ry2ver8Y8Ja038u/epXzNvj0YhU0aHCmOGZaZ/caqMVRivsWcNp/54yXVsnIj7K8pbW5tbjDh8p3LGjW+2B7knoLbvHdMMDD28Ylgq6t9HJdQOFfwz0xrGdY4Gr9h3M1ANr+ERe83YYm6ja7mmIMNVCu6lgNFDoI6rdDGzY6v4HptDk0FHBqXhfvtOmEsovMOw2e6PibxkSyoc5i7urZjQl0J/jJ9CdTDTvSwDreMLGg9XjR9GncQMUeSFeEz2dR5pql8ca0oZEoqcVOGXEVSNHAC0YtkBDzOvSYJ400gER0ZOEg2zrAlLIskxumasy4IlZ6yaWkKmpGFZFnWwqFhzr5oHymjmKIHIw8S4EwuAVHQcVszTyBwC0KMput4gUREiLytSE0NWNeMKBzpnDkYxVlkia59YD6gBibRo5gNuh8wAa8EDby/oYuMa3Xr7mNEoHqiDXXvuWNX3SaRPdNoH3Ltq1tFn42qXm93BIWm77iE+NqBvsMTWL8uJ741B6OjqPMMYZt/Quu9ccWWwmMU0Xq6xJE1k9JOmBMFsBQ0ZcuqfSE7Zss5g5SpAMhEam9FFmTGRgGwqvZPWJY7gXl7kgEkJoimjSNxPXm1TMxgl8eAGDSAYZMKENHQPJEzMzUAFkSsHR9pNLFM3GpUMOGGodjLyePLcNgaiPWwOjH0veL5csG0brtsm3g+qpJihpLYqLvhqjW2+zhovanvRppPUAkytM9y4Ofxv/YTEgGdGPxtr3yn6mb6/1Ipt30BoWNQ10Vy57+7OePf2NS4V2Lnh42VDaQ2VsyRphjBkyd8koNdTFgA9RNAEjpKFd4cgydBZU7mqQas6ZRgKHOfDTlOdzJQR2d8ESBWBlJAXA8fxJIVcASTqFunkzJwwAxzHp4HmjgDGjcGDggDVa6gaoIYVAG548ZViVi+v0RhkZWFdGUdn3NamE+4Bk439jO+K45GpJO+vGTuNcS/LgmVZRgOUgcHJwOWKkY0/CIAIRGIf43h+vOBJVOUyY5DOkwlnEIjCSZLx/tacb0TjTZ90NZ64K5++5QWgOp+w+u8O3nHTDtgMF7JBbV9IDiFrx0C1fBaNzeZhqaMNwMNnRPly5N+ddYiXJjp/YoZBugI48GXlJZaM0YZBqiA041Wt06w4ucl819kzCARmKZcq7+9AfjCks2Z5i8owLCzOpb8bk9xIrR4fBgTjjnHQbtw0gEkJHTPZJzzY0tJY/z98+AhQRspL590AJHyxIaUFhJPy/gqiIjc0lhBiOxgxuiPyKlHdYDLyT1IrhNnc4uGYjWkEibH6T1+D0qq69hOerjser1e8LQ9oqphct4rrXlAY2KuFxSYsCR6ebonGK/eQbQbBDEA2vwDUC0d92EyZdFk1htdA2wA3ZCLPFwV9lys8XknFDhj6etn9lrvttK64O59F8YmnzbaeUQmO+/hFd/pe+dXypcwyw9ZgDJsePW5fConuxS8sh4jmgZwUA7vHDh2FDvv30s4LQ/gBXq0137838pxu169fs4IXaDbgjM6Z58eDvI58xgCZ3hP5HiFN9EPd6KFbK+aJnDEZOT/qdHV0Gf6NB3I39wBeNMR3DiPI1jhTKme+S0i78ogZX428nw9/n6/GPLARfmHfSSdtxvRASFN3+BwHnmzjj1c/RLJ1nxQTHVsL46HU9Qpb646brTeMXnEMqvOMeoz9LmkequTGsdy0RQ0N1HmavV9wpx2IyGGsGYNOS8bD3Rmv37zCw8MdXt2tePVwj1cP9zifTzifTshqGFqWxXmszY+lY5DwYfE2LUXXVquJeWJpO6yF8Oy97AAI+14Ec7Si3rO9eqt4M9tnoqObQQi1uQy1tWZmcGvYSpE5UF6bKIEqAEru4b+3hoW6QYvUNtCYvUACyyMyr6V5aDkA5+NH+Uv7Z6MO0Q9uYqipYv7U32nYNF6eM+7owEIxn4rXTsMWJeWYoUcufJdt+r0xCBmPdv7AUd6xMx/nfmk6GXZgZX+qF4QZYxRgJLdkd/DBzKipAa3nM6GmE6jAlwieQIs9/0B3MzYrrOWWGFmyMAfhD1ItDIn8BEAMJtCKYoDlWEAQOH5y61yatM0+Bj959dcGpg5MhM1dS4AJOhqYLbMKVVUwWKbDnJU17Sk5XzJlo5Qdj4+PuF4vqOUZXDZd2ADESgOVHag7uO7IzBKyRQ2FG4pkMEABozCjVWHm5kHVIMlgpUShnqaqEkRcJAkz60kcJd8YtlaS3JPRasX1suN63XG5XMEPjNN6Ql4yMsmiUAJO64LXpwXXuzNKZTztO+peUNEcYFi4g6pwSsToMakitTuosHhWqxgHRtO+2umOucY6MugU5YvCAFpIsAsFNHJEQAAlSVipObIorG+nmAAu9J1JwztmcGu0NAt2+xcZGbHaaKnfYyA4gt65HUskPRt7UkqevJrDc+AQuy/EKGzCeAHGawAR4R12RUNNUoUZJCcJpRQ0Lir8E0qtOJkQ1tAeEeTJT7Ci4moaZR+frGj3Tuqg7keDULxoOMmxz+yKn1uONaYUDDzGc0m8kBHpQMwiNvefAqefWo9ogIHzzk7jRLGsOMEMRMRaZQIMtjzDrDSn1pC49+yc0cJULWwuoSedNp6YU/Zpaqz506rINyJoJTLjAnqQ4d0jV6S9uqB+VxXwknTPZRbi3EEZgHrJICg23Fofp8qq5gvT5X8Da4iaMa6wTjIhwl/8tVKooLGeA6py5cZ2zQNlwJ2y8qIsioLxkcRqaGuE169fgZbV56epG3uiVdvLMLQBLqBagH0D1V2SSNcdSbJqSk6FJkYjshwk1PmBGM4ymLJgAWriPU008AYdutAVMzIBKTPyAuxNvFuyKQZccbk+4/l6xVYbCovBaKsNz1vB87ViK6o+qMxbl4RSGyoBXpBBQ/XE25W60q37Qn6awmV01GnEZZk+ZEk4TW6iWfpocrd3u53lJAypmccVW/POXykBp/Mays1j6B+IUFHFANtCFSYy2rRDG5HrrAm0mQz7yM1HCmvSBemYbbwnGoRMPnQFTjZjPAiZCzOoUNa8gt0YLPM+G9t+yBeDWoMYcZXXUtAh7K7ZGGB0FliY4CHzqbToAYKFL3q4GMOZoHkbmhxJNBzr+QsYrEn9Zc21iCkc4UZMorg19r/jr0DkAenMBpf4+fx7NzpZcRCNrTA5wDoD3kk7eFEvCNWHorEpyitT3CPOGg7ubGxR/8C4PmHkcv8kFyXsfrqfydcsFspp6jViYWJeiZbHQzkz1MWZ9TUdsF0fU1PjtVgk4jzbYYvQkoVau0ydjC8APA8qkchxCU1uKGXTMC6lwVoFK6QMQlXvQZH7SfH0uq54uH/A55+9wU++eIfPP3uNz94+4PWre9zfnXE+n3F3PiHnVTH4ouo2u97CTWTLzuThYsUrkYkRqBRNFWJGcG4oZcdWrkic8dQq1lKR6obKFXupoCY65VYb9gYwJA9PbVJbG42lGmqThPoqLVBbRWZJil1YDD9VnQAYTSp+a97ApnjDsBdrou8G0QNlDIE/uz4edBT0PD2+bywHUqCHGNo27zdW/cXaVtQHR43fgvftoCZbBwx5ZQCNsKRFClSRuEP5AWEoZPTS9f0xCOlPxZhxnDClV77XzeaTJ0/7fprAkiRm7Ffn2wyrAmI5CZQfyORBGBhYq1pRT4TWqoIYzfshoJl7HxAAiPVZx1Q1x5F3KiTgHYb8CWDhDC20L03Fyev9OLbEmxIk/2VlxERBKLmySna79InstNU+C6gNQrCPHz/ier2glF0TU3bJ4gmkSxVG5hI4MF82TyFxK3TGGd+D/pyttw3NDD/2swv45PPfGmNvjPeXKz48PuH5+oxnMOjuDqe7BYky8pKw5OIJs8/rgrvTioqGbauoTU5+o1MB6wm10YN5hkmC8u5GbHlump1Sg3q2exuQLogZV+KWZhPGgS76umsy5Fp7Am+YykLDzSMoCG3oB93CPMbg2rMR3A7Kb3gPGXANBiFgdJ9nZvfKMu+f+TTLAEWLHTX6NzfaWt3byPbCbMgagSAfjqtb/q3PHcAzM/ZSkbIkV+QVbshyBcaBxORlpScoMF7GPSGira7d+2NC6X4ZsDMA1QX7yDdtzU1SIOz//p15ivT2zWtypjdvN7yDJrrqbRwri4CupWQa9vDb/j7tmm4ZG2tXuMO+on56LCnlmtNmPxEV0eJKgxsr2HO0xBNKY6N2Ehzn3M3bYY/YnFvfbT7jPPg8a+D2sGV1b1kxYOmD5S3AwMvsfTZJxPM8y1wa8LFkzBbG4DMYlDQ2LceKMkBkaoae+FGWiiwEfPnTn+LVq1cDlhIDk4U0Ke1oO8TiFdTKjlaKgkMNSm/NPWbDyDDse1ZMkUZDttG28XDzLDDaWpYFpWTUWtRAJCfK3BouT884nRagVXAtaKXAFKHKFoJMbiUkiAJiORmNNA3XjPgAE5+e9kQAuuOou/LlOEWWT96piVlt7LZfDYPAnAWNFxCwrqvny7MCH/pyWKi/82NrN/bVlFmQn7CqBufvTTQeZgDTKe6kIA6yKyjLURaasSrKz2HdI624Vtk9I3+8xsuWoBvoafh8vrosiPtxvJlxyx/t2f7i2AfhxzONDd+P2x/dmBTH0LHYzd6a9hxN3x2P9dZQNPDS4SvZcC6jEN43jGv+2zvufXHeSyPFdlxPOgMdv8e+zZhNfhGPziP5PKw9h6k2/M+GweY5GH+P45i/5+m7sVjJwL1lbHGeEXODMeAVyEZqadyk8rUe8KacUKsc1svhkuo1ED4OEt1iXRYNLdcQsbzg/v4e7968wU8+f4uvvvoC79484PXrV7g7n3F3OuHufEZaVvFKcr2W3YOlVcbGwLUBVfPbenREY5Qiyaprq2KMaZavqOBaNnAVvn7adlC5oLQqjha1iYFpryAmkZGtqGdQEXluxaC49egXSEhY07kVY03XKYikQve27x5VIfLCnAhY51hpM/J19/Lq6WzsgNyIiPxobtxvR3uv0y95JJDJ1hb4+Ev4Mcr6Qc9Sz1HT8xITuBWtQDYaZnsk0/H1/TEIBWU08r2brhvoQmQ2AJslWJ91rwYyb4wgTGNzDnd7Ykygn0qOSrb+5BEcG2SmEFsKYHCLH0R6rYMQ9wXifudLQoTjfyM4V8Z0pNjaz24l13Fbwm3QPC0BJHMAgp2BdcDvOszw7NPTE7ZtE28KTawJ3UiSN6hJdnmoohTCxFgTcNZSpEKLr114iSyqK3xx3iMIlBN5IHqoELLG1CZ1GQSuteFxL7g8PiPd3+N035CXBSv6SaNY6hk5MdZMwJpQdsZehYpKbZ782c4SmborcFaaZaUtYw79dhPGCj1Uw3FaCMqigXYDp64kQRUr1Q3XZQl5FG4NITOd+PQSaeJs8pPYPrfh+daTIB9dgwEmiQCjWFElJXUbHRPazsYgM5iQAnI0DSFEp/+Z9o+MKWa0iZXNIv3K9I/eT2Z8FZrJaFqliRtQa49phipUKupF4dXnEwiFJCSVW3NF3vaS54JQSiYXGOOp8Q/9ikIVgHt+2neRhhIsN5xc38WQM/+05476Eb+LQHA2Po4Xe+lbU3IB4SuRi4ooCvQ8k3KoomXmeYK4bbNWWRiwpnrekHqyyb3Gj0wsmtIdBbHONMUy2vof6h4WpHNt4LmfoBoQdv+9DmwoTYVMFLjbXDKr63P3uTSB4/6w3OnBQsNh88p2Lg/A8EDvkXgC2WBIDoWYWFxPIf043Z3xB3/wBzidz94/XTHtDwVjAQNcgbKDy96rZzY9vSUOHq23HpZuFNZT4dmJ3DwUTCJb5RZ7fskLvAy7DrTWgn3bsF2v4P0eGUBiBtUKArCkjLyekJcr1tOKq+dk0/lrApIT2PeTMUyRqwqMnfYnzBT2kyliYGhOini4N47VciIQ0PND2N9kS6aGURehhFcPD7g7n7GeVizrOuxF+5eIpGpk63INTI4dhYZoBPumaIF8jm8qE3lb3StkNvLEe294kW+7T8tluVUoMCehmR9DxvpFIC30MH0e1sL+BozNdQw88+3+u/FcMS56NEHYc2bQsXacX7wgE2IXw7HyzbejoZVu2rHnh8eo96Ob3cerG1sw/BQNy0I/k38X9RMMeztoNC/M30z/Yx/UuEyAeRgeXXN1WN9DQPdmDe8yXGXPNYt6OFApIi8e+qbjGxL8Ai/QyO310rj7s50GZz7oeIfFmyzlBctycm+XRGYEsgUUnWDJC06nk2DH2pApYV0yXt3f4bN3b/CTz9/h87dv8Nm713j9+jVePTzgfDphXVYJGVvysG6lFDn4boxrZZwaUJs4R5QQKrbvO9a6otQdpVT5vhTkvKAlQqmMEzesTUxVqEKbtQm9tagTIQEmL5t48bQqFcskN203/pRaUKsYh0wfkP1OmspDqya3oCObs8E066RqmFfFNr6h8CKpXEgpo9XuxTkbambaYJV7BJV9CRImzeLd6/vGeTzD/GWhONfkLQNDgaSBbhvEmYHNYy4c5H+CDoHviUFI5+LwCwMFgC2UTEhrUl1McUtn5vof359hQ48b2N5si5fUamdKmr7PwTH6QnHfwE4ABHXNHkFAVC4BPZ1tpvRNSkUEAmEaojGrxf7oEJr3hwfjkAPjwa21n4zFiWbxPXTl3sJdpBrYmBQYBP2sszBRAKQPjRs+fPiA58sF+75LLGljMQC1BlTJH9SFieZqqrUPpjatbmKGArHoylxqqAEEtIkA6SfQZsDoAtmETd/6CVIOdwGwAjglIDNjAWGvDY+1IpeKMwHb3rAXRqlCd2AWd71EQJZ8Q62WsIZJ+5oAyrruJl5Fyek5+RmZrdad9S6sDYvFN2mFtmrrwyTAngmNkmY6IMnNFBKXxkTMFg/bfP6MrDqTnJVisCpiLqwJrYnyUvcSaLHP+csGJ9kkDWrNzgncKjgJAOfSBs8g6/twimqEHMZnFvsjo1AFerWZacx2WcJnKJ35aT9rgvTasO9ierK9QZpjo7UmoYPLKqWjm1rs2VZTTcUhAaNpRlmljus7zA4uU8pgMs+9H5E+oLymAZpx1tcqehWad9mEieX3T9BA/PsQbAeePhuLosfbkdEp0u647+B7LBTIkjAw2CEDu1KchneT811TJJo1qsA1aaOVHVYI/216qiqfdMMp9WTBAx+Yxuxji/wCIfSS+4kiUQfEVgVDJ8pnI3o5DnKJulGENFSBFdiRKjlmDPLWGCJfcx/HsI6QHSklbe1wSU+/ZUNK2HOT/AHn+zu8ev0K1fKGeaXloJzpeAgV4B28X9VDSEGrhln1k9TRm4QUtDWdk5QzyEqnckPjaqkRYSKNATdodCN39vkAM2opqKWKHK0C1uu+o+07qIln491pxf35hO3hDlupuGwbLpsYupue+gpPal1d0b4YOJXhd+N2AF99P/hcKy2pDLDQdeZOU5HGamOvpuVFVg/W1PaXGITuhOcfVWkhqb7GasgjQG2lnRZsTGaYN7IaDnAOFLfhQENvmZNE9yshUQZBwgJTyhBPv1tcOI/XcI0ZH2JRgx+vkUYPcbRepjDKmo2fHz0Tcw9JRcGRx+uidJ1lUthi2/6Z9sH4EqA0yJ0igRb2UUeOR2MKqoJWPrK2jq8oTwxbDzM58X1Yn5TGx/1+LCfjnrCfXb7MiS5SfwfGNRz2Q5SDykOCSnfTF3lOPVAhePPIiDMbeWaZ99KefOmz2GY36nU+Ip9ZeKqh6Ns2mYGUVuSlAXRFrRLZ0ky/0Xw0CQk5AeuScXc6Yys7mCqSJo9+uLvDm1cPePv6Nd6+eY03b97g7du3ePXwgNO6Yl1PWJdFD79VX9AD271WlMrIzEiF0QpQSgNpufqeW7OpgYc9zUqtFZUb9lax1wIqG0rZwEW8h2qRQ/mtSpgY14a9SqgZqYdRqw2tFDSwGoNktvaya+5coPZkiqil+j5NKaPnGbR/JCG4cd0i7R7sW2YgR/3IwvsPMbrKtsaxaY1I0sJWbHeKrI+H2D2cmZSvsN0Zii5goCVmBhIhc09C7rhQ9YtPqRPfC4PQS8yK+9oG/MXj95aTgBCqivQbXDG4EbLC4B0EaLwd9F0EASsje9JJDyBjUCz13mRSgTsgdiDaYq6QFzZ/nJdwj+X3Yeb+cQS94XeJM5fBzEwmgkZ7741xKpyo+uj1vcZ4OTwbgZNZlC00RjwimlQTawxUNTARgbIkZebKYIgrfa1VXAm1KkttUm0lMlSN/JRpbuFUBqyVqdQThayjzWnHTzQspIBIAHetyDXjzADtBWVZ0FLC49bwtDU87w3XUiVhqgL5lCCl7ZtsPTnRNoAhm7zTSFJjSPe8SoKV9XRSBZyNMtC/Yllf++wV31T5g4s6aTcYHMHw/jJ1YW5raus+CzvvtVbeM2DuJTtJwinjs6PhNQBhc9/X70faIV0rmSszCs206ffq39FYZN/XEAssClw8Qe1CzoxJdsmJi+7tZO3JLDRWgaYn/r72uT9bWwE4d+8GMuWS0YjF6NWC51NShSOJyj8bvTy2vdbA2H7Yl9AMAARgZt8F2jVjdtNQUzsdPTL0YHp+WINJMTgydB6B/Xjdfi+SoLdnbsP6rMuwvl+Y+wlvlENk7uIALAU8+bvUM5G7jLP+NTQNt9G/LX8C2CqeBxnDnVeldDMP9g4fXwDrzOpxk7qRHsxDvkAzIjEHI/7wEwPY6utoFq3OaxqbXOl0AuqGM3seJHNAzJ5zzOZX+LMcdVRmpJxRwdj3HWdtYJDPhiG4ASjgcpX8QbWo92RyV/XatMCFryFg2aKb0mnKC9KywiyEJFaFoDMJvzDPOOPH5vUYEx8LmK9ulNj2gufrhrJvAFeclgVAxuv7E8p+xeWa8WERPlS4HyyI7JHDF4/T0nekOY7Z1k4BtdG00W4OZH5jYLTp0AWMxpl4jiuHEnoyyzLHiQhrXnB3vsP5fELKWWVjr/4otM6TUUk9VxtQfWzmkdsxUu+1YB2RPdqe70ULeZwMQ9NlBkCrdOvh1u12TuJ+MGPokaz+8Rovp0Hfz8d42w5gZl4fDeJ2kVWnO1zV/qyX+J7kxZE8ceiuvHa+Ty4rc2798FvDZ+Mzvd1buTV/No8zvtc2rnxb4UcUUV4izHdo59YIejsHXRYCHLxefS6MC1B/h3we20Dv58H7fIwj50bE2tZWxISOJUIY0dDewVhfwhdH2AFhjfp4pSpavEQGLppSUDx4WivIKaFWdoJglkOgJS1Y8orT+YSKJnlOEyHnhCUnnE+aL+juHnd3D7i7u8fpfMa6LBJym7oXP6AJpFWHEv1X8wVVqc5ca8W+7/1f2bHvG657QW0Ndd+xb1dcS8FTLSjbjrpt2OoGKg2tVJTScCkV1xaSUuuBaytXtCpVqtGahpnJeDnwQ690Z3PJVtggiZd+KAAEjZRJYZJZ9Smbxzatl+mSkruqF3HIGmZ9SxeitKmfnREogIacVe/0wwiCZgW6oaFomCMKeX5J6YWPeAxhSYJdBGdZiOQhefr1vTAIxctksM1plMl94xpwT754uiVceZbN/BKjixe7xt0oKbjtZXpjB8y2EGfV1sYc54mhFbOgREb9OQXQM8QYemPAOHxpDNfK6TqDDrxQQBv7d3baYCYCRmBWEbjbnMH6y+NpE5HtAPnTGS9gfkJm2aZkjszAw8MDTqeTuzQTy4kjXIFgZTrs89JqQ9FTydqqmHzIhIHMRGeeveesbVhYgiVJ1RUJilj45wo7tBJLRdkLEhHSXnBuFSsk+3xLCc8N2BpQGJLYttksk1XH7cIRBLXe9HsGimOnCRNINiLrNRP7GiLQYnahqN5mWUKugrbs60YkDNE819jfIm3P2fJv9gr194OnPEEMFxo8VftiVWDIFDLuBkx7R7qxzNue7q6XMdFfuG1QJlJKbqCqtWoYoBggdzUKNWavthaNQvZ8b5zhjtVEoJR75l1I+EWtFXlZXHFJyUBMQ60FCyX1NLDVZA0Z6XsqpYSUexWIzut0vSyUsfbKND9ect3SKR9+Ho0vxt+jnH1JLrxkpLffb054p8+P+xifN+Br+0Xua+hGi6hfM6PnAHM+qFUZ2Z4lzYdreQVUeWeI0YANlMDBNaChQyoL5vAX9t859CV8ZzkFWvNcaGzyp8V9LXy5h/2YHFE+xLHdUV560mB76TCXYU5hW7Rz/S4gzfjfv7adaTmWrB1uhJrY55GQUFvDtm3Ip5PG6ofXBH4NaqC2g9ouOQ9aVVmuPLBV9xSC8UgaeZkZdihZhVB5hxibWiBlnSc1ZgjYV/6GnhjTOptyBohw2TY8PV+wbTv2bcP5tGJJhPs143nJWAK4Jeq57VptUAwt3w0rIevuZ5Wk9mtfFO7PKHwxnBHb6tsl7CPDCib/HO90Y0unH0bOCefTCrDl6RuVsKZrIv3syqAYLq295viyK4QqN32f9wMwMw6JtyImesYNX7D+G5+3wzS2xR0nY7jY9wwP7f143V6O32H5Nm8VfWb0w91PGG+Gdu1AKIQ1jUb/eEBl7VEPIQzXKCNo+LzTlxmNepvyC0cwpHwF6B+i6y/hDTNN3vZjumwMxJ1Og95h++dI5tk4Xn5fNBjNHjtdNo2XvJXD+s5jcmPsoWINhMkC4TYnC+bPwpiNN850MhvZZnw7GpS8VZf/xnPsd5FH2heZRBAlMeosq8+XpyJUnpSJpCCOVuXNiST3jlbcZpL9YFXNamXsW8GS7QC/Ce4Fe7RG1bCvvRbslfGsxpuyieHGjECWImTbNmz7jq3s2EtBq+KV+rxXXFpDKw1tr9hrRSqSGqRWxl4brqWAIKkVSrPUDD2H7Mh/lSdD04JADnFsbZMWiRA1yTxu9XeClUTqoeImV5nVwWQ08jim1JxVlDKokXgMQXCdERWbrHa9O2BTtRM4ZFHMEw9A5gNro0nTEaqGyuWc1BNKNRf7qfmNyYqWqJz6Nl3ie2UQsv07lHpDB7Dyt+VHoO4Fo8jK4WvjGwYh7ZMr4fIUuXEipcUB2AB87TluSJrg0ME1SfIr+V78mZMC4v7+4CZP3bW+j7n30+LmmwFXVayTJZe0ymgsVvqbUwZXQRWEQiyT3exj7Vp1F1PaLb+PzEoXepoHxdpW5UJjGvzks7GEMEllKwGmb1+/wd3dHdblJLkN0CBFh7mDHwmA9ephldVVvahlGVqCWFYI7sKlc0ApRRMvQAymJuMJ4WENhMoEbspYUzc8JJ0P90q6NjzvG2rdcMaKNS+g+zOu1xOu2w5cd9TSpGfOWBWcKx0SOtO3ahSEeKJP6IlEoMDYqRdmsBkELBHArYcRNZIqAqY0GRDVE2sBOhlLyjgvC5acOv1ZhTnbGwqGXz4pggNw2P0a5iXCmQCuInzUTVESmiVUNK+gcnT5+6gbZ+IJsJW5dMNIGr1pYqWWnJKfmlc1PnJr4q3GPWG1jWVup58kyUqIMVLvSQyGhG+0wlrxwSz6nbdYTHMI/RWDKfXwRzNidQWhK9aZelXDoopTplEw/JCv2ejD4ff4fdPQXyFsMVZbdaojQ85gGJg+dw+WA4AXn/0uQNF4shmFZL/KPZKDB71ekCsGprxS1xvC2NW8q7xEXKTNhJ9YaNlgkrCdMFe6nz2/G9vJG7yqUsBYwSAR5mJaI1cSYLwwdU8lbcfywDioI+MlXbl5UU2hrIpxLy2t4smBmZ1v+mEB6WFNDiHQyMKnGMpXoTH9Or9EqAzcPzzg/u0bIC0gLZHrYE7bATYwX4EqLu6oOp8EcGHUsoPVe9HyHSKsi10pJV07oYLGFZkruBUBeSyejInEmEgZYlxWmdbAKE28kyzPScoZRAl7adi3in1ruG4b7uqKhTIWME4E/SehBWUtKDujWPo/1lLwxh0HhZgdc2XqxpKIOgxvGGZIIJlrp3seJwKCkzQK1/FH4+4rVHn0ViIi3N/d4bQsOC0rltSN8L73EgQ7mHwlLXkccxVGDMjRM07HQgA0obdhVfNM9dNc0m3FtwDcPIOMtwh7Z5dZsc+xTRAGbHuk9P54ySXeFARLvC62BVUUda8YTVridPO+OuLnAKbfLX0BnJfTJKfNkJOAntvU8GAgJmOFo6m1DW0YMxy9R7TRmH/OBgUAnJwX23XkqTIrvU53SefCseLYxyh/bSwRQwlGnL1rbmXtcbhjNxrH/tLIUUz1e1GW9/eqHsbhWb2nTgeacU48nQDiPNzOXfz9iG5GXG3PhFBA17uGCUU3FlRkai7PmhokMiRptF2Gg0934vHT9gygYk2SN3VvFc/bFU+XZzxfLliWFZkSWm1YliRV+XqAueQkVP1oaw1bZVwLsKuRqJaKbd/cS6iUogai4oai1grqvmMrFaUBrREKM1AqqBa0Jry8EtBSEnXUQrG4gWuCVXsGM1IWvc2qgXejGoOa7nOVhaoSISn/ZE2CJwV+FgmJTsrbGSA1iklURENyHD/xYpULyUJOZbpg+70p8Oc28mkLm/cSMm7rMLl5iyEHiqAeRp/UgWWxSorIALEm2YbaD8Tz1J55Qb3z63tlEHLd0BbHNrgzqK70qs1DFUU5HdJWhg0qJ69h44eEtpHh9JJ0ACyW2/vFHYArMZiSKs+aCgm0IaRtZLBHyrZbpJUp2OBdMQG81KtfdPs8gMFwFvwTOqCPbZj9x1CaAeKpbdIFcW8NBdbWD+k2eVlWVjB9/3CP0+mMvAgj4gZw0hckUi8KyHvDaXOtUrKwVQ3hU/nXuPaNwxQ2oPU1/IyfqzrUFaxuPBBh15U9STAtGenLXkCNcSLGmzVhvz9h2zRB57ahaAb92lgTC4cTeJs3M6IdLBCbgpQsdwTrSTs8p4GvkAPxsCcMeLYRIPSlkf9lVQaie7pN1K2gur1uFWXLcdPBjwDZ6D4fPSD0d+qM0b6zfBrGYOP7el6TCcCwTevtOwbjavAyIutjuHIaK5nN7SSW8sY5E7J3xfpd0BKDE4O55zZhAIUbwBWpde834xlQurDqP1Y1QkhDDd1Gvyz5u9wI/OMFQAExx30xCrkI0ICJ7TFrSN+YtwkYwf+njKKzsI5JLo+A9dAXA9ciSJRXmbISTjWn97v3AUZfQwmRGoH23PfK7J4j8aSzG6BYwZJr8a7QgmH1wQJ/Nbkyznn/Y/rOZFmcPyIPJ+rVJ8dx2/0xAbPPJZthDbdybeqXyS/uC97lJxlfJZfvJmOYxSvm7bt3+Mnv/RQpLVqJxIFHxwQoQNuBfQP2HVybryu00mMp1XloNB70Nm5637EG6zxpxRY7uSVSb7DU3cYdsxBAKasxSIBnq4zLVvDx6Rmvnk54uD8jn0UO5kQ4LRn3dysupWIvBVtpUkmVjfJGgSu0Ou4hu7qCbAzNcE1X6tgo2pZfPwsaslfvJMSy0f19wt+FNpZ1wf39He7v7sQjNCrbpN5POjkDXghXlK8vnabO+82M/LXWYS8cydd46NFz/8SKln1+rY3wZjkEC23N1T1/vOQi3/OjsRlA/xw9tN5CxY+UsEjftn59bcekxXZfbMdgn/GXI/lk+NRoNbzdBtR/j+M8/DQaTsY5aQd0MmPKaECJY+/8d5yXuR3vuWGf8Py8J45k6vD8YT/j9+Q8Q7WDA8xKt2OUG272zvzOuMZH38/viRjixgt+esbDXg+xhx3I95xz9o7rddNQa80TiI7rpbx8xllDv9ZlBbeGdV2xrAvAUrJ+u254fr7gtJyRU0ZpFcuyiL6Wcu+PebrWimtruO4NWyUpoFMqSi2eOyj+s2pd7CG6QquSOUHlf0rgloCkuVkTsKRF4t9RBYO0BCzq3dkYYHVQUOyTknjxyhoATE1yZ1nUkOol7nXPrIaekLicxEAEEFJLIYS+qRGp9dB2y8tD8GgE49pJI0fEdsC+ZwfaS+x5g2Y6iB481iZNdGG0m0C69pEX1fFeiNxPIAm5+w4y4ntlEDJZ7wzCFClHOQYiEBRkOOOyBeuaORxUENkLpKHONKBGDgpu9WNGFluEXipaAdYQW2oL0wbGNwiG6e8+bmHUlY+VC0uF1hsynuxoyYWJ9WWQEgMDhSvoPh8EeDK3mbH5/WEcqrgav2eY4iDP5ZRwvrvzTPWUEkAJRFmFrnr2qPIsm7a6dblVUfpahVTC4eAGH5UHFfTyDlXk0U96OmsV5unKvsXIqoLWlJm0Bmy14roVXGvFVnfc8wlrIrw6EV6dEq6nBc9LxrZnzQnhSTecTowWwnLBfLUE0HYPLGb2anRGcRYiUpVJRZoYf0Zhwv6yrnOyr/VIV3rfJCRfypJ/RLc2j2ZUaZpIO9Ka0U58DwD1dg4E1Gz+IijoezqCsDjXN2BFn7VxxHxCUbn0HEgzWEFP3JvVaJidZqwKkOYF0tDGhcW4kNMubeQFlOVkO1GSU/Uq65OUTnPKGqdN7tHUUMGV3aDY9/KPYL9fSueSqEs+MVAY5qhN9OEGRHd3Uf+ZaV/NSmCk+0/x7vj7pwAgmeY7fEGD8ZfcyiEdZ7ALfoe89k7SULP+EoHH4RVEkmieVDm26oYDjyfqwCPIRmMUDeSJokk/t2HSIGyiQtFrZMUwY+NUXuFymNMu2RmmS3TP0EEmBVXIxMFQwv52AbTf5oEkINBkl4V6S9LhquFhDT/58kus5xPMywqhv6IyNRA2tP0ZVHakKtVYjK+11jT0E5r4ksFu5O15AW5oy2S01LnVZOAtHMaEpPvxd+WVPc+dlI8nAvZ9x9ffvMdnr+/w+dtXqFXGn5JUoLk/r3i9n3DdK54u2zCJzBVuUHQ+bn5oMu8uu5x8ulJuhQysGmYcs8hAn1SYmHfPIKeFMHYKuea0zfPpjPu7e5zPZyw5y+eJsJj80OowrXZvn1k57ePlTiu4pfO4XDlnl5+xWuZsSIhtjvnv+Pa94W/vXyL3BE5kAQ8/Xi9dgsVmpWk8zPKEr9OzN9jgRTzPh99Huhnw2wHddd5vTDJ6GBut3r5f+C0GwH9j4Ah9/TYUcWPUOLzrFgdGeh/6NzUwVwjzMb/0HpoPVWweU5f/wxN6uNL6gb4V+IiGoPjGYR2Mrw3f9SfmPf2pcXyKZuZnxvUasc18DxGh1OIHW+ZIsCyiyueccH8+4f7+HvfnO+w5u+fPmzev8JMvPscf/P7P8Jd++hN8/u4t3r55jfu7O+RlFVmQM9K6emWuuhe0Kh4+zIyKikoNDHEdTZyxLPDD3eix3z3hRb9bWMLPJHwtAWqsIm7IS0bVarxymQ9NQ6ITmpanZ5bcf6zeodwaKGdVIVi8Thfh/cVDRc2BgFBzc7nPzKhklbjsbQyi7HuRiLR6la59DntJvXsMVhp6ETnY8yMOh9OG94MxMF5OY2pfiN5fTsfKCxq67UPwFnvlWCtQwVPb3yYyvlcGoXgpDxTh6YqzKdv9PlHg9DPuChVBEt5aqe8eU8wKTsPGtE1vwHXylmFVFim0wWpttL6aK6gRiF2xnZeMQ7PyHZVyCVuJzE+FGjrYMhjM3EHYEJb2wrsZ4wmpOF6NXNwUZVOjEnfDAUNcuBNr+WAmMW5Q74crGJQkljWrxxAxoNVPWpOEvVVPV1nNJwmMxgm17jKmZnPZmaMlQIvJhQ23woWxnqy7cp+CUSgyb8maLxXFIFnuW1Wm1nDOwJoYyyInr9Bka7VJNv2mcwJ6YdcRYGFjEVzKf/VvNgHUoFEuoowEmojPudDpqwtjTVEo2XxFWjz+/lapHZTeaUg2l8zseUJmY60Z3ojUY0mTq1oybVYCMwFsJ8sGluPYZ7BtfbB1lXCt5HmNQDQAETNiIYBCY9wAwClh0fbWnMHLgrJk7DkLTaYFXDZADUOVxMOiavlNyhpiQfCyzNavnCJngCt1BvDdMEhaRcGse3l67gd8+R7jW5DLwM0JaDcKqT+C0gNH9/6J5l8CqRFY2u8DgObbPTf0Ybo6v4q82diHgnzuhtKjdwPw3HJiOLIDk1H2GKBJ4i572ycifxd0HslKn8G4ivVpnifqXrLzfATZBJjn0ThflufL2pTPe9XIo9XwgyHbu2RgWuUjdUnm/O0GIJkSJuYMmz+ZU7n/1atXSGnR8FClO+JuXMOGWj6C2ubB7HAwJoZjqfwoc1prPBkGort7H8vtiC1liPXf8jaJgTl5zggB31KIwQ49xBtW5vPxcsXj5Yp9L26USznjtJ5wfy647BXny96N360BWuHT6CDp2G2UBJUD6AHqcdG6gikVNcdFFaU6ikMjkVt81GWlKQCCt+Tzt2/f4vWb11hXOenOanwH9UOfuVSvAfX4WVwPO10eMRwjDtD2YjzhJR3I0X4l6pUviTDQ6UsyzhVcCB70vF3Dszdk84O9WPlXxzZJEsXOHocTP5rbmI1It7ych58RY0FxW9O9KLpHcr7Y+fy83xX4TR/PxqDBihr6PHwS/nZufYDx5ufje47470ttjDQ7dM2/PzpEuTGQRZ3HeUGXN0AedEG5vbzY9suGp96vF2bE9a6Ik7/L/B0a+sM9Lr/D4WR3JxtlqRn+2QqepITESeVWwrIsSCnhdFpwdz7jzet3+OKzz/F8ecTz0yNSYvzhX/4D/PV/6c/wZ3/1r+CLLz7DZ5+9xav7B/EKyguK4uKtMq57xbZtopNtV9R9w3UrSEsFLhtAu8jLvSC1fhBhY9r33ZMftya8rljkB2XBykXxihnRa5Wy85WnfKAMNPLDLAnvrZ6TFuiHgFWLsLTGOEOKM3g+Pi3y4MWZ9H9J9Q1JpcFOb6U1LViQ/NBJ8g3BDTFRdwQYjauHQhvNzPycAcwHj4ZdyE/PJNx/lqMR65j89RzKzdLtACaZbf9EmvzU9b0wCA1sbpgAuMCc+WOyCQf01Exu9ooCep+U6w1CHraYzZN4NvVsiKyPQwe6AcXaVeDpuMeEv/xu4NaqlRzzjvC5vdvGYQuqVlCyLI0cKOQAcFFkog4WjGxGgUBgV8RJhSIhAvLxp7XUDRDUbRf+pfxda8P1ehVLNkPdAwmUshrX1CBQKlppKNuOsolnULOqYhVoRfNiWDoQ23w2Vp236PEj/SOAR68S0twzCEzV5kISL2fklLHvFZfLFZenDdf7FfWOkZLQ25oY6yJeI5L8M4NSyL9kCb+Zb9YE6ApV9goo7HqfK2QGUGxdIj2GPs9XB4ZdYckkgmJdV6RQiYZsn7CA3VLKIDwHZTa82QGU02o3xtg1n3gbUAZRxy9D9zvj9PXC+P3Rd0enLiaUDIB5nHFADnNbLoypeyLVWn2uEsnpS84Lcq6gVEHIaFx1gbQfyoiLKlqcF9C6AOAhD5LFy3clFR6vzE0BpNJ4Uk+mdLDeP9TLvTbRDZCBK4/3cqeTgaYVlPeynS/RXhfCM9CM338XoPhpI1PnVZT6fjAQ7HJQ+e7ctzhe25oUn7G9iBhiM48DLg+6KOoZK1KQIeZF9/IYI/jpkif+fjR3UVlz4zKzjyPO8Us8kELbc9+ikp+znDIzxMcn+Tskw5AkbMx49eo1Tudzb5/62wgMbleAr8hJZRYLMJO8CwW1Ft/TdooqpeibhwuZh8nAKyNDVy/UwRXfxoVwwIFeDbF4vjJbaxlfbQ1bqTA8aq70KScsakRxj1qI3DMTh4TS98p2NuNEmjtI9yXZ7Nzsi06HcV+qqTaAV2th2tMGBk1GwuS3lG1/9foV7u/usC4LliDvPI/PgUyOfwsNMlrrIRCwPUPZ154P9tZQgY96+HsM6TI+YuscldwYFhK9jObLDUNhT7si9OPlFymtkO6lGdv4mqDPZZs8tyONetXduE/1su+7h3Xng9HAO1dB8v0wGS7Mg5A57h1pz/Yb+Ij/97FFWvX50Csqo/OhRrws/4npTPaOyI+PvH6ivjTYcPoNgzEkXjb+I/wc3z/MT5AssT833r43I9TvMMkLolAtFmDLzxf26jxnR3M4YI4DmXWjt020OT9vPdj33fmeGIQylmXB6bTgfD7ji3ef40/+5K/ib/7Nfx3/+B/+A/y9v/9/R+Idf/JHf4i//i/9Gf7qn/whPv/iMzy8eYVlsWIJesAJ4Foqni8bLs9X1OsFvF3B+xXX647lsgH5imXdUGtB2QtqFV53vV5RSkHO0p/1fJKk0q2h7CtKKUgMJCbkVsGbQLCV5JA2NykEgyYl4wGRo6VW1JbF+YAykKuUoyfz/BEHjdI6D5S82Dwc9lJOqHtRLNM032eVei9hj5tXmeMF9HBeCwu+iaZQZ4jI001Pnfn/UHQjXBLZ0tTTOfU9FNpx/kHQaCjy8DtolWuiJNXLCG4bMX6VQv+Oru+FQQiAAxBXNJGCAZz9O8+rHNAZJ636lOAJmdVGowITiGUbtUkNJUtqy9CQDjVAyOeWUOyW8XE41bUp9pKpCm5aABoDswinVF0YcRAj6Iq3djYSxpHiDvS4w95HR24Dcdn4zTDk3JQkiSZx926I78wO0VRhbQTKyccsTFrCw3JesK4nrMsqxJiyGmIIzBWt7FKGvhRwbdi5YueKBomErNzQSD1vNPlaC5sKgJQ9R3fLr5owzHIBeaUyXQ9zYczeBve+J9lUzMDHxyd8eHWPt6/O2PeKdV2QKGPNC8454bwkXNSo1HTdO0jUn54/QaeWYaoHgOob05zt7QTWyJQtb42uVyLycIOOMdifs/nPRJqcnLGsCx7u73F3PuG0ZJxyxpqy5K+hbqSYTyJc2CvdmZHKeozwRldISMdheYSy0EFSUO4HwyTJ12OfSWlveE8AHVEQz66WbvDT5y0ES05TZL1R6yD0YxtmvG2qrC3LAkpmnVd6aYsoF0vCui7Y9iJhB26tzANIdMXPBFRrWAjueWT7LjUpwyzDDgbnRG4E+m6VEn8YV99NQC9RC8TwJJsq42/9SfNYDPPpyqidbtnHt8DuSEmI17edvIzgTwE7NSStzGhKgKt5vl+C7DIhqKdcKYzF97BG8VjVpJQELHF8t8+FXEn3oFXdMsOIKB4JfpIG8goc45rIO5vKEt/PallKKi8sZxEDocKeAXv7u7fsfaY0rJnc2vqChfG7YmDzwgzSPANE4sGSIckgu3BsfT5YDiKIEvJCuLu/F6OOGpgrTFRWMG8ACpa8IrWCxpt6BInXaKlifOLG4nav+fEkn1DTOV5ARG4o1noNmj+B5TS0Mag2pNpQ2MLOVP4rgE0gNUI1TcbM6nFo4FTwkfDB1LECAwsTNkCAb62eNwgqtynJujQFVQniFUnotGC5GkfKYOVrClrN0KR812kc5KFkjcIe7hyxk79itGp7UW/OifDm1WucTyvu7u7cA4dtYdUjVbxuSZUBhintpHiLuUz4ysB0n8u+N0f6c5mKl3mGYRCJoleFoo0yeKbp+T2J8pBzKSohP15yJU2uzw6mR3nKkX6I9PPkPAQ4PtyaDTDu4RvCNQGeeOl4vbxSgufceMEsh6hOeqIoRqOpPGaCC37GYUrq0PoLBojZsDHrGC8bMqDoVfcqkfL/aARV2eoYTjYhB73DK7DFn74ndGDQMDFd1xT4hHSv+rzNMtGw1KwteR/Qjbk+F5rofV69Tk/xSv45ER8ajOb5n+f2yLAXf3fjFiU8Pj7pPBOIMtZ1xbqKMejd27f46mc/w3/zX/ub+O/89/5N/IP/x9/H08cnbNff4vd//yv8/ldf4qe//xUe3v0e0vraPaVJh5yZsTCw3u24e3jG9vQR2J/A2xO2a8WyFdDThrttQ9s3lG3DVuTg43w+S9qPq1UY21GbFHUppaA04NwaTq3hUgo4L1hOuxqCKpbWkItW41xEFpVaNP6qAbUiI4mTh281BqO5McZpu7EBDmQWlFdZvHWt+I0ZEsQLFhB1v0oeoon+Z2OyzJm7mqB5ntHoWSsRNcT9QC1RQkvqf0wEcFOnJNFBWfeQYSHLl8TK41kT5WeQRxRYf7KGujESkuVb5gZiLW+fKHDC4+t7YRByMN+MyRzfcbPJWCfLloX7+ZTtdTu5EmZiIDcwKN+UjMrVbHOwRJ5QhWMUzoEZS8ccvB5a2ifGK2O8ZcpuWIC9MySsPWASNwznYG5nr6doGGJPnnV0KZuP/QuVDwz6cBOQnDKhsZy03t/f491nn+Pu7h6n8xl5WURhMICl+RAEZTJqqZ6TxYS4GHIaGioq1+7yzcHSCtsoHRwxd8OBJTmWXdDd57NWQutMnPwnEWEvFZd9x7ZXbPuOu7ZgXTLOpxX35xPuTjuerkVLPgpAl9jTXtXBlDg3l/kyBGBpM23gzr5il/+wqiISPsQ3i+xC0wBDkJIiJE64O59xWk/uVnokfI4MjAygxhMcZj/VJozdSZTQoPmEWkMtFTlDwgQ78vc+2xvMzT6lriQcMSzr242F3vbU0OueoM1OiS0mOo4/Mn37V0qFWeWWLKcvKTespxOWfUetjGVZtIrbWK47xlAzM7Z995CLNWkFtJywKNsdgJYxfF1840MyoqOd/QO8OBrmA2iF0ceBgSCCMHQQaQ2qFJC/DsBvvCLdHJ3iHXZ5AhFhKDBOzJYTiaivOBvP6J45PPwSOcnUT+WfgCZUnGVN7ATchjTcA9i5Rc8Tw9QNLjzd63MzGHXkTgnR6/IHOgQzBtnP8f19XT28gptbHcSgMlf1YVMdwtshuXfc2qc/tLqICthgzdAT6iD7KOW+NsS9DDyaGO6ZwNXyLVQ1AFU3DJdaxF1evUZiotBYbXBQOB0sqqdJbVq6fvYekYmtrRs4+vyxhqqQy6Wk4WMp90ptu/Lr/VpQ94ZWAOYEIEvCz9RQuKGwAEY18Zhp0WquqXFC+w7jzaZqCH0zsfpgYZCLnf58NaXfBJhxkn0Dy/sTd5o6LStePdzj4eEep3W54fFR0S1e6QkQw7Iarg72c8d7t1D6iP6Nz3yKPyTNHye/k4bCj7yLlAHcKCFWnZQ6zzOl+Ucp0S+Ze5sz+Ww+XDGPbWbBsbbnOy4b578FvDwbEAYjC5nxY/Iqch4y0lEMIY3vJfdkjf0d6aSPFxj0kgNimPWTI4PjS/Is4sTOSyO/UZ3lRq+JoXG6Bma8GQw1FObUcr/It8InDGyqIToY9M3b3qTTkSyz/nYdyHDyqCMNc2FyOFSqA+K6dxz70jx92/zOvGnW84Y2iMANeL5cYI4MREDOC06nEx4eHvDF51/gj//4T/Cv/Kv/VSynE/74T/4q/vRP/xp+/av/D37yk5/gJ19+iVdvPwetr8HpFZinCm8E5MS4yxXr6R73p3vw9hG8n7FvO9LzjpYv2LcNKOIVdNp3lLJjXaX0/LquWEOlsVIkP+xWGdQKatmx6kouNYHqDrQE3nfkZHpblYqodVyb1lh1QzW6Bjl9m5TfDgQkO7CEpgtuYLaUL+TLl3NGrZ3vpmSGYi3qEdZS9A9N2NzUuKiKHLPKXecloxceQ9bMTXHhc9FpobYA1pQaepjlhtbjXMO+gEhqQ2tiOmJNYaHtfQLifj8MQgACAAbMwOJf+K9HzCqAqXQL6itrNnKSibKN3eeP++Rrc1W/zKRWaU4d2zjb6czf3AuHPg8v6f03g5QTkN4vf0cDkL5r0mLsN6m4Mc1EFEovXE5AAGa68Oeoe6zEy7yYWO/pao2UdRcB1nB//4DXr1/jdDphPa3IyyJ3WZutn4C0WsEKojtDtK2hxiAY2D1g3KRWVU1Iwza3gGLQ7jESE2+aocAui8kHSchbKQ17rZIUmBtyPuF8WvFwd8bD3Y7Hy46sypn1zdZKxtrBSJznwYoNyIm7lXCnLrDIboAKPLLx2L9O96J0TWtOJB5Np5O40C8LlmUVxSYImU8BWDut8jmajIesaygeQA0p5cFAMnQnBaZIPe9T0zhdP2nibrQ5asv66Nn4g4JkOYlMeRMG38FHJvIqLYOhwNtUwVJJLewAiDXp6oL7uzvU+oR1zag1oRYtV3vg4h/3oldTo6R7XJK4mkbEQoBS8rOJS62B05TmXfrDvpgxzjWNANAUx9kYZPdiWiOhxx42KD9eAPpDP6a2MT4X+3PUXmhJq2ewmQMDj+jgPnoCdBnXT2D9fehyyJQEF3U6/DbxR/k1KEdBO++BQNDfozeryS/jBTNQUTdr2FCklcbsvZoBdDQee/J5q5QJ6MnxNIOTfOwmrBcuinPE7o3Zewif+vv7Bzw8vJKTemj4OYW1Ysihxr6jaWVKrgWt7FKdpEkFlabVxuwfMw/GoJ6AU+WVzUlTbxwFtmApPR9lqBnCurwTA30mTYpvi69teqJrrZDZ7BR3r6hIeGbCUxUDEKeEouIpgUCtTsU+yA89+ocqv52EzXhHDrYNY6gIFSpT5cyUYaBpaJuspq8a9/1iyZXPpxWvXz3gtC7dC5jHcdvaJ1gYXM+5IHzc9vBIU+OevVXK7V4z9FAbvUrMMDAkXEVPbzArjnEfzAcYfv+0fz5lyP4hXpLEvHuJmTEozlNrzQ1vjsEB3y/z/UdVo46UfUVkAHXFUW/+ll53A4Mlw5X/977N1w3fDONIzumPueFLNDOP+wgb0qzfsBluoHLA+m/5WSwcR/Sflw+ip3ENHVburjhZGIztoeh5HvqsfZvbDopMX/cop5HArGFLPlfR269/dqSgz/34NqPQ0ecRA/fPdDXNU2RdsCwZp9OK+/Mdvvj8c/zhH/0RfvrTvwRCwqtXr/FX//RPQfyEt2/f4dWbd0jrK7R0D+Zj9b9plEdKCfmUQQuhFUJan1HzgpYytusJ5bqJnMkZpdwebHSsLTNaUEQmtYSUmubHlQIsvZqlVO9iInCrSCRFERokaoQMl9tBzITX4hr4cR+rnEjiOUNEQILI1rDnEghNdfAeAmzrILljwXrIZuOz8M7W8xaa5w7mQytWPRNJ8/DZ5Mh8VT04I2/HdETz6laU5tWJ+yG0GKWUQLRPKeQepSbjHXDbwfW9MQgFfhb+1o0yeofrfXETt55n56YNmVx3sYeC6/5mERj6ts6ISAgwWPdiLhCz2FovB5YbGcLBWL0PBoyCcHdLcOzPNG6hIcuVNCZEtM04n07Ee3zzBAE3CAefwFswJApDMCRM/SIiMQStq+fZ8XGo0i6AuYC3grLveqqqHhfQfAtN4kSbxpASaxUraGJgZZTJFH1l8K0VNy6ZtdbGF//F+ZDx2ukmtCqa0k1rnv/BYj8zEdbFchRIwmkpUxwFUlfmoOCUjpR7CuEN0NO/qNEpjVhCNU88HITIjSEHQl/ndcXd6SzGoHUF8liiliFhjSNoIH+tJS5vhGHedIAaPtINovIvgcjKH/YylImyM1r5UpNRNz3JNsAfaDfS5czwoWvDwWhkxqS4Z2I5TmOacb5cQZpiz7kxCks8NKlAyWoYOq1y4tH0tP+oX2M5YMmJsu27C0cRpAZOdN5yAlERWlQjAZhfjDn+YV6KiLgGUDjyO5tzu3yPmNEWEUSM/C9+P18vGXjmvTjT7gujmO5zhBp+Wl96+KntF/1iCH+kyDu8XTvl7GMX9+owLnQexIGrM8Q4afyRU29+3qPEJmP7XHUlvJ9C+qnczRiV97iRSY1GzN2DaVJCmFsAbjag3vbRWrB0XvMmdIxg+WJIjQWJgPu7e7x+81YSEvhpfZM7LOSrNdTnC/giJ6atVM9Bs28bKrPkWihFw8XKjaeB8QoiDRUlPSFlcZPnWkGtBn4qfMcKGTgNWKXNlBx82kGIjd4NQLWg1CIV1RTkNhCeasHHuqNmAmVC3QqYKzIYuakMD0qUsmwPJRzkrS2H7lkL8U6KcST8Rbxp4+l+xFiW6JtZATSx5oXU1Vaj0utXr/DmtVTMWRbN02bgOuxLbg2NJP/bXPmr/x7Dkl9WmiOdx0OKSNOzsueGHjJ/DzOzjs+lkGsu9r8bsTG051P94yWXspm+Nua9PHp3elU87qGzBPJqxbPknenJX6frGz2XJcy/AqxGPZX183VkcDRlFAw39o5S7daAIMOePJf6p8Nzsww7+jz+fYS/5pH0e/qBhXwU2gsVtIT3ZXsE5GW7AT/gHbznyEUAkyrbQ/qBeS5uP3XpwLcGqXn88DIB9lTHCH18ca7GdvydL2CJ+b2zYWPot+mFDDw/P2PJGVXzzKyrJZJ+jc8//wJfffUV7u/vYE4Hb968wZvXb3F/f4/ldAJoBbCITLMErUPnzNCh70wn0HJG5oK1AXdFvDN3sMw/MQgNrSS01fKjAqVWSRmxiAfNigVcGpYkhxVICRkZiSVCYMkAsxiCliWjFaisBQqaxlGz+k2oWaVJjlcU89yXdCGOeZpmBbToDciBVM4LeC/ImXyfUpPQbZdjWsWNWwMnDdMnUtdpY8Cit+UUDpn8Z3P6NIxkBORG6sryLANpMYyheMSS4Fs+Ids7zpckF6LoXIyWut67UEYFe85BMdApwvqEoPjeGIQ6EBf2xa3Hfs4DeGmzCbPv51WyaA2KOzQniinYmqxVAc7MOVg5MVF0/TxOOif9nxRSU7RfYNry8/b7I2txBEizQi9E0ob+xDbm5Hf289A4Ea8D5sakXlPa7aTu6J1XyhwsixmDQllVFiWbawNKQytiDCrbjlokbr9q6bzWKpjlFJUrwEXAv/WlGqAWTQZmACBToDUxdZuEhXsBhU9duCtQTSl4XxEkcTQyuAHFXP613C6lrDlyqmauN3qSuejCtCtkg03F1oXC3y5V9D8KHM04I0pMF0ym6N4wdZIqWad1Ve+gxdfD3tt0Tpocjd4afWz9QRO9mCHNaLlb6onIPXPkHabQseTuoCSGViJhuJ5DRdqzEtmR/iPdz/8MaBkNOAO0RKvhWQPZluxzfsdsKOqASSreEaSs57JknE8nNPUkM2UgVpmxZz2xqfKQ1hr2fVdaZCynFYDkfUo5AWkRgaq5X4il1OePl1yOL5N50Y0gH7hVvjoP6waFDv7gfH2s9nXLt1/aH0fXfF/sCzOQ88QIbP/glibj4EX4t2EfD3y/6+kvzMGBUmHVIf1h06YMeWivGg8PzzIKSO79E/fOuJfs5NbkAsVl8Zbiqbj1zMJhowI97zeGGRsCLVA3GBKgcfrGP7p8ba3nO2JU3N9LyDPlBcjZZZycUDekxqjPG8rTBansGpom8uO6XaVqC8GTS5tRaFBIgweIGdRtvltrSFpm18Zi9FOV56D1Qyvh4aLGpNQ9YpeUsOTsa2FeSvu2Y993rMsJtCRAiyfcn87YC0MgP2uooPAiKwU/0rfxX+GSQoaWB81Wmgdl1bzMEtlBTweALhfjPg5rFW7wSqEPrx7w+vUrLOsqSmbYqzeKLZmChd5+mN/53fO/SP/RGOSykrphbq5q5TQY+kShH47XqCdZtzXrfVU8c+D18uPVrzjvQqNjHlBRkgwHaNhRwGhm+LR25mqls6FkNE5HuaAYSTp1I6tuPK8jr7a+aztHxoaZVqXvxkN9s+DIaGLvm9/9KaPGsI9wm1/VdCW5gbu+wYxepkDbCgYfbyfsBybzBjCcabIphJSF+faxHOwJH5e1NstXjHvaMcEg84AeaVJ9Pxpfnudqnt95jme8eYRz43q0oAdlTSads+Q3vb+/x5vXr/HVV1+Jt7nKq7v7s0QHsFTBcmzwki+tHzqbPNVccnlBTg2nVVImtEpYVpF3XBg1k3jO54RaZd1SMtmUkImxpoySqhiFlhVUGEgNa86gVsCpgTOjVkJaMrgmoPXy9pkFvxdUXUPB/MuyoJaqOqo4IdTK4CTYOmuUD1NC1SRESQ97SZ+RBLohF6+WQG6lAmA9GPePhWaZsSCBOQ1RGqSyuEr8tc6y6iKWs0gWQQ/GZb6cHpSXtNydUCwpfVO9cMZU1qlmSZask6zvo+QH6C9d3xuDULyMKRsbtP3OfCsEhaHaRjfXqqgQKNokuNLOrO5h2k6Ca9repl0dA/dTJMEn46mN9ZbdAmfcQfuOPqb5NKyP+1a5CCTmzHAE2PYSW/9ba/6RshR/j/2w5rpdnMeeBjAtR3WdWcuVcDqdnFFZXh2wWJWbKrliPG3Q7IrBvV4NR5pmqFX7PWSQVw8e77AusbnnM6Rtrg0WbeUhY8FAICCra1AvMWcpPStlE6+loFSg6Oa3vhgDIO7zaYkyues9x+tLzoMRlSUzWMa1iWDSP3WFlp0Kc8q4v7/H+XTC6bQiL2kqe04aZ6qecxPoHeaA4HvLaYTJDW4ybyMzTMkSrtkzCup1dEQkHksMEKmHTiP3wvuUQn0EgGUeO23G/s8gO1ZkMRA3J6uOBhwyUBPW1OKLb6qN1OY8yLENEZacXWAwWE5PagIXse4vi4IPmyt9GYFuAOMP/ZK1nZP8j/QHvv38lmcbySR0Y9C492/biDz3ll/H/XN0OR0DWp4U/m7hEwQLkYreNjP9txb2ETpf6O/phvt5txhv4vgBjNfr86YOdfQcJqDLwS6X5DAmykhrM07FOC/qaXIwVSYhmRmcBi4ivTwID+gaCne37TAeZh74sCQjNyNW9B4DQAlv3r7DZ599jldv3yoStMloQKuol2dsHz8Cu4QPUxJj9+V6xeV6xbquYnjZd82lULy/se/D/lYmb/Y5S37J3MdZakUtRcK+ggEiAlVSwLtYCfZFcr81Zmyl4LrtuO47XivNpZxxOp3w6lzx9lrQEoESoxKjACi6Kn3uOk02Zq9UA99XSZFD8+fEiVvlCAcEZPRFZImr+lzIyxxjkYbTKvELIF8y3r19h/P5DsuyAKn3IyrzgIVgabtJQTzBK0xFQ91srJmvaLAxCWh7aBjbdA07gKAhARgSE9fWw7WtTPLA00wmUx/rj9e3XNT3UFTkbdO5wRJw440/g75ugeMO8qDrZBPP06c7j+59SOpZ4N8F+WCN8ExEet/M82Pv7Lkj/eIQPzmta86xYGTpxBd0H1OMqD8ff8p7oM+IvJYbAm6dcsB12dkNxGz5wzSZdi/pjX6P7j/qm7UryDSg1vDU7dzN2GC82/CDsSr2vW4YnmEHt7cYdTbczddLeCFe5h36/Pwk7yLB8En593mVPEKvX78ZMvw3Zuxlx9PTM54+PuH+zQaczDB0hKVtHvvwzdtSyKKB2HQn8ZjNCcji9CNenSQ/q1pRKJEkQm6SEHlN4p3Ukj1EWLJ40leWfLRcxZCYKYG4iQFMOyWJoRNaLW7AMYy9lyKkmQlLygBnUDMsn7C3pqFqoi942XkyGtX1E9dZWO7hRfPu2SG6YzSG5M/N5JMm+KoBqv/agb6FpVneVLAaiAieGDsZj4IYf2qrot8iOQ3moLcYbbnXqRWPgB4MQaqYNmawHpa8dH2rpkFEd0T0HxPR3yWiv0dE/2P9/Asi+t8T0T/Sn5+HZ/5dIvrHRPQPiOi//W3viJftC+fT0mD4/hiks+YoHq1m+njg5gaipfx5YL6TAtAFPTuonfdsvE/aJjds+DhAoSKEvlMTA3IUNAHAxMvd3ppYCGttUz9mQXTMWOa+RkkR329/dxEmWd2bzq3kP2jB1bYLnaq/57xoKFXyU0K200zrA3fX8ZqAylWtzg2tQv4VO80snqm+BaCkMh2VGI0TmMUyXNi8jNg8GrtyFeYDJG7xJEmmFFTLZr3uO7ZSsZeCUir2VrHXistW8VgYzxXYmLFzc6dLA70EuGGoKzLBpVCOWWWOA9M10SWnIoEugdAYBdqeTi1VACcC1iQeQmsi5Kw5k0J/AMiithYA9yzQ9W6GhvuN+SxE9zJQHKlNOiv5HQximGIjACEpaKesoVKJXIk5ypsAdMAcDVdOr8ocGfBwEJs/U7roU23M+y58zhaaxpqPTOlJkk739pgZVAGSgOe+kbTSkAgpqfBTuOGy7bhcN6ExzTPkRiEVDP+i4P3fhZywdR6AYABxs6EHUw4sfWdvzwAe+lq/RA/6NGTPWbz8uDBHsunob1K+2RrATYxRckvqCROtCsrRPDTAhAqRAX/2xkfAy96SywA1tst7bbwmq4yXiFGlQk7Gem/UNEw2H9yf596Ho7EPcpVfllXaiPYngZSLMMgrRjLNcw8oMpMxszrD6wYS72A9CGCtXOmKCqEiobJU2axgbNzw05/9DF98+SXSKl58Ep5UgVrQLk/YPvwWvF+QM7CcVlDO+PjxER8+fPDxbdvm/4Ce7P4mvIh9SUUJbfDwCrDk6JNcP1JW3krOul7lc0peOSblhLxoSeJ1xZoXNGY8bVd883TFc2EUEDhnLOtZKnStGa9PCXcZSNSQiJGZQNXwi7E1m1/pcGWRuxUxDFlRhMtE1oMPApBhFchM2LkMZVt9aUJwWPPtlpCQKHu1rbwsePXqFc6nk3pZ4ia0epxr0n8S/u15lsIVw/CO8rjd0DLYdV2rxmclf4FbJTAqvQSpDppjjsNgHALgCUUl9Em9maHK0k3vvr/X70yfmOVmwFlAxPJqxJbaeWAkz1fSEA6WIEqtH7kpvxbDuxnC4X+LjOiokyFpBcxIIlhIPnMMHQwa9rOZnOiZZoWWzDIRLuPtHkYNoEuGT1OJyRGo0g7OwziY4Wkc9u2KWnfH2J+8jM7jbUwI5O999zGEf/Zul3Jknv/z/TqX8uGhmWOWObO8ng+BjmSVTHkFJTWgWV4jKzJw8Hx8x3e54jOW3w0QPsFNKmVZRFdO2fORkfKQ83on9KJGnL1WPF8u+Prr93j/9XtsT49A3cHIkOIB8z/FOVE5YVb5xyoXGoia889sxindRZTUUUM3ohxGC90nMBY0ZGIxIpEYeIgs910WvpuTH+LnpLnqjD/aO1OSCAjXG2SNliVjyYRTTlJZOSeXh2nJoCz5hLK+B5CfpLn8cpbiQ5ImIuO0LtJWlirNa1okH1JesKSl56TVOScZWPCQMrsDfGzQ332HqpxrGtVUUXWP6aGKGzKCRypNnmYQ+YlWkbghg7zKWaKuAb50fZej5yuA/xYz/8sA/gaAf4OI/msA/h0Af4eZ/xqAv6N/g4j+iwD+LQD/JQD/BoD/BRHlo4a/7XLbhaD2wCdvXfePTmX7RBkw6QouXkjKHJmDv4NvGQQwJkbrKT/IDULNjVR9LFb56og52SIPJ09B6fkUuJ4/u53L3s5w75SDJT4bFQmHTG5LiMal0GeoYFGgaPGYNi67t7YacgWJQmzJd+d/9eC7wXARFLoavrfcK309RvdtXWjADAbUT/el4q8a34wvNqkIUkrBZd9xqU08hUzIk4a52ubXObTc5MMrgyKlVspIic5EHD/rKxD2gP28+QdgWRbc353FWytbvqN48jMC1UNBqd8PXjD637j2cX3n9ux9o6FpPH0FuqEmJemreZjF0K7RGHjLA+y9I23Etvs/Cm1E77HhOerl35m55wDR0MYjgxJDY5gTOx24pTDRQGO1Vmzbhuv1im3bsO+7An4jy9swhe/x9TuREzdzccCbOx86NqZZGzGPy6eMOZFvjnw40vTtOkU58ZKhaXx3VFQ6j52NWPF9M6ufxxHp0m5tED5VVYntir3IL4YmQuXuFWijbTBZR/3+gUnJ753DzLzgYA0/cbn+FDvB2mFTxmAKC0J8vcFa9TSFljQHSV4kPWRpbKaNfkpX0EBLxh/9yR/j9ZvXSEtSA10F6o52ecL++BGoRYwtywqihOfnZ7x//x5NXdj3fcflcsH1eh3yBpksG2Qxel4ZSzIOOzhQvicysnnuIDPOtcbuUWKyOucFp+WE03rC3ens/zJIqmdWwqVmPJaEa2VsDaicfO0LEwolMZQhgVNCBVAJaInE6JM0ObP2OxN5skwL33ZDELqqIYQu1RytYMKNMTfy4olPdxnWsBDh7nzCw/29FE9Io7H2mOY+rZyZzDM5ETHDDX5CN7jKIdDoIeBePPbmQbkcxxi9l2M/8iS7bAwmJ+zg4F+Q63ejTzjujhj604r5EcaWNVJvZ4YrVb6Oyo8sVQX737YgHZPd4qBOp5/qk9PdRB+G3WfZY/zEOeAL5efnv2OfDb+DCa2K5/N+3fH4+ITL5TJ4WevIbvru7UJxFI/0b/fcFg8JslL7LvfY5I7eobJ3xtT2ox7TZamsYx/vIe69WaPbfrfG4GYHKgngpKmCj1ZU+sxoN+87mo95Dh33khzO2+GC0ZkUJFAnAw6pPCC6yjdf/wb7fkXjJhUhLarB9bTx6scuajgnoKfh7x6Q2eeSUVtRZwhxiKhVD2CGsRY03jWvluTXEdlgxqbOL2VrMCx0IkHHyYxV9xORGFay6je2XklDpD2sE9IOE7v+TZq+gkgOeiw02xyWjNY48Fmhq54/UPiDGpNIEk73PEFd1zXs1VjyC9YqefnEQxku6yL9edEc5xlkKiay0q2Hnh3IJ2+HOy6YD6GOrm8NGWPpzUf9c9V/DOC/C+Bf08//fQD/IYD/kX7+v2LmK4D/lIj+MYB/FcB/9G3vovDLJ/j2J5XCY+OJWeHmUACBrhyeO2xrsHD3cJB4nwNgBcdzXgtAYhrntvvIj40+A3OcxjdbtLvl4laBkPmKeVNGIcB87A4usoEc8DAZS5hwugndlPDw8ArraZUYTfMEseeDUCi1Yq8Fe9ndA6jWoHhbzp5gKBtAlDIPDu8X8Bxj7xtM+Y6GjpQT0iL5bhb1nklJrMgMSQB8ue647gW1Sezr6bTi1d0Jl+uOLSdUIjyDUfRfdO+3K1HSsLV+gjijNysFaKFZ0kf+9CbQdR4ECJv3DrCQhO6dz2O5+ZcU3w6WDDhpk4KID5VaD++DnZaEUDNjqNyC8sj+MldmpUY2ACvxKM+9ZBw9MoTZ30fjQrwnicjmnEEQxSwmJ2dr1x8dwYD1pdam+YPKDd+orHHlTfIHgSSG2XIVxHWw583IWVpF4xVrywr+VRin/7/s6b/T63clJxpX3SMSIx0B3kvA6ghoHh0gAKOSFuVMX+db/nkE6o7amdu/vfjmr5iod/xSx66xX/EOU0pT6iDcWowAZO4rc7/HwdlBnwi6X6ZuBSlojCOMavqvKhy3Y+v3kfbVJRtzB1zociiuCmBVRRCqoUl/iAEkcm89Hykb9DMQBrx9/Q5ffvlTnO/v5RkSt9V23cDXCxY0cJI8DkSE7XrFN7/5GtfLBafzGaUUPD094enpCcyMZT0BlFHKhlor1nX1eZ8rJvqaMbsXp8hC9tx4DNIDFVHWjJeRQF2wJvE/nc6SHPv+Hq8f7vF4uaDWhg/PG755LliedjTKWBLhWoEPlfHNXvFYKi61YSdCIcJOABNpLgbWhJ4ytUQKjH0RFKDCXOfhHqAI9GwywozmRKqstE5HAuaDWXLGQWA9QOgGfTvZjlhjoDCVt0eyIxrs7btx/4+U2rjnQ3Kv4Ol5C0ebn73hCwwMxSms3dDPKAflYwdV0y74fl6/EznRYcaAednnKHj0GswluqGXqFgrNXf2pvPOpB6TIM9N1pjVBdP4JHsbx53tgMswCAL9yBfm72O0YP/pCuOAgbiPfZZjw9sd6EHoTRi/9JXhIa+lFFy3Z2zbFaeT5KQckuPrf+cx2vuTe4jcGi+78dT60OW7AePu72RY1UrcT3vVhuI9sjw5Mh/k42WXg6MW1v82bBFn7EZeOa2R71dvy3nU9MgLaxJxLk/rb23V1rDvVYxRWfglJ/287Hh+vuByufhYnp8e8c3Xv8GaM372l77CV7//M9w9vAHS0quNzmtm+p7yF1IDTqtVq1Mqdi4Fte6SC3aXEvMSUdGwbwWlVf1uB5hRS0XZK8pWXHdopYDrBjQpLrTvBXsjlFYAkESMNE3hoAmnuYmn/t6qyG2ld9cZakXVeW1V9MGq+7KSHA6hNVBtyEHOmOPAsE9sPTQnUgsYpLaG1LKkP+GeK8g802srzvu9TW3L+L+FfpkpcSRPl5A69uZV+qhFGSpXY7u7e8tZagFVtlAPqofH6zvlEFKL/P8FwJ8B+J8z8/+ZiL5i5n+mxPrPiOinevsfAPg/hcf/qX726cv2vu7IyDRMWMrv46Y8BMv+IDz/i4Hdm5fCmP2RgSU0hHFzm3Bw0GrChkemOG9s+ax/d6RkxHEf6wK34GR8V3/HDPZj20SIN77AHuQDid0XAmxgrezVXcNtzDlnnM9nLHkRhVaFnQHDWHp328WVPnoA1aKnoOG++UTV+p9y6uOY5oG5+amAGYW6QQJ6XCljsHK/fkLLwF4KrlvBdasoRYTPaVnw+u6Etu+o24a2Qf7pBjVqinNpxhClIIhtus8/qTYnDHj0xInGiVs67wBgqG4GAaA5Z+REWDQJ8pzrZgTKHWR08Gl7UcF6OC2d25nBtztBBqFroECUOgO03ZBk9xjNR2PP3F9rKxqpYkLnm/7FxK24VQTsiu3h4D7mbjw+8lYShUbGb3HUIAmhdJdSfb6UMhiGGhi8Q4SJJgE3Q94hjvweXn/xciIoPRyF5y3fNOGoFpBw3+0pCtFtede5vcg7BrY5AUa7/6V2XjJEuaJy8GnDrSuv8eLRoNOV5F7tJvTflYtbsHnUGwaPPWIzak/t2fjQJYzLBtN3vN0JcnuXjmSfBxQNL+Hx0UE2yO8C1ky2ykkgBNC1UBGRAa6MlprZp3xcX3z2Bb788ivcP7wS7z6uQG1IzZLlkxQcSAmlVHz9zdf45v1vsa4rAKkE8/j4iH3ffS+LASdOpxxgeMJglQ0+Ne52DK2cOc6TlI/XELKwpjllMFdQzri7O+Pu/oxX9/d49XCP5f0HPG07Pj494ev3H3C6P2FdFzzcn7Ex8FwrrszglJDygpQl10GqWn1N81sRBZzDMiOytzJM9U3SIZezBAAK5i2kqxcr6G0ZyG8welOgrvQjYQhJQkcIOJ3PeLi/x7Jk5LzAYPIsr6Jh51OGnsgjzGhwg0f173a0d0xeWW8P+IF7k4SxS95dMSy0uJ7BEMQvKPVs3sz/Alx/4XJiYHMd4xiu0Hf4jaMBz5KcU/gXlMNxIPKxyaUXAHTEcLeYotNWa81LdRsA60asWUcgiFejeKm8BBFm2pN8Pp2rmtIfB2Z+oUU9mFtreHp6xPPzI1ICzusieNnwkk6RVWEyzyXDOx17Uc89BEasPmlzOxrDUtcLzWjm4zGGEPJOIuz3ZJqJyklwr3Cm74uyhfzeOA+jRjYbZHvXw2F67APCmusazbnK4n3zZTjT+gIApUhkBWt+VTs0v2xXPD1d8M373+IXf/7n+LO//l8AOOGbr3+D3/z6F3h3f8KXX/0eXr17A+Qz+JOqv2BzYAPaFVyfweUZ9XrFft2xXXdcrzuumivv8nzB9fkZ21Zw3RuupWHbN9WhNpR9BwHYLxv2sqsnPEuFzn1HrRtYQxBLaWIQqhZO2ccMwNM3tNaNPPa34/LWUPciRYqq5d+RcOYCBiyfZxEvVRCwB8Hshhh1LiBPyuyz40aW1grEi67rmMmqgzG7PcOlgXnDKf2WViWlhLZpuZp8PEZb1HVZjU9QtMAuS2qVUS5BZiohaSXobw8v/k4GIWauAP4GEX0G4H9NRP/lT1LTQRM3NxH92wD+bXsgGjG6guzvd6h0tIlmptdBn70rgUIM+m1Hb41BZiQCoOVODSx2hmIDi4yIiDxUaQbrsa9d+e3jibHqR99/0vgF3Nw/A6B4vdSWl9YL73e7e1gXsZS2wa2aWcD36XzCsq5+empA1pjXvu+eV2E2+ljM7NHn0ajhoC51th7FddO8LfJ8ANMEwJJ3JREmp2XFkjNOGotKINTK2GtDqSJAGQmZJHHZaV1wvluwbAm5ZPBexH0+5Abq7EXAxZyHgFW5IkjmfHmGO4C273mkI6NVaUM+8SpWsPWRcS35NiJ0NqzMBpBBae0N9gaU/mMpdNldoYoPImi+PaG1qmbxvbeGpj6+lxRsMwzNxsJ539l9AG7crM3VNAr6I8Dtz8gnweOMAvAJfZ3CdXPOWJdV9k5tIgS0TGRtFa3YSUR1JbHWivV08sp+3/frL1pO5IRAuy833DSvlxsNDpW+Y4B+8P5OF97FCWQDXqBg5u+xnVHxuFVCDTZIf5N10vfc0emry6WpzabeIkcTFY1g3zZ+89CwPg652GZZEwxUzovpdi5mGfWp62Yv+nOTzOVgBLN2dd6axtK3RkM7iaXUOimxNJULlBL+5I/+BJ+/+1y9/CCyDuaRIzLFTvfef3iPX/7yl2iteYXF5+dnbNsGhoTvEiXUskuFQ+qG51qkBHqnHeX9rXnuMeNNrVWZ8yhP1cvQ/iZAcy5kIGesRHj18IAPdx9xOolX0l4Knp4eUbYriIDlvCBnwikRzmDcMWMnQs0LKopBTvGC1TW1tXVFDt0LGMFYZAAXAFqrkh/iVtVy5ayFz1kXWoZsawMtJWxQuIeT5GSAt+/RW0x0S3dRHvZn5vv6Gpn8aogYyYnS54ZBvi5zVcuO1Ue54zLEZFbgPc1DBW/7beH4/yJcf9Fy4vN3rwFEXms8aDzwEbqZeDnZK82A5H3W6Z35ev9e+zGPFcBxJTG7P/LiuLUac+h757G2/w2a0dRm78e8zyLdDWzddgvM6x5gXK9Xx+ofPnzA8/NHvH7zSkIYFfeknDxNQ2tNKqKq3M1LVuN09GqjqTcqV62Sa5C3cT7NV1V0cxY+oDqI5DkK4x/hanjbyBeO1mO+Bvn/whp7qKdObDT4yLobGFSUf4AvZz3xyGBERLhcryilgnlBayz5TXWNfvv+PX7+57/AP/kn/wj/yn/9v4H1fMb/6z/9f+Kb3/wan/3lr3C+kzx3jSR3EHklm3GOhHJ21PoILo/A/oR6fcTlecfzZcPlqqHQlwsu12dcny/YrlfspeGyV1y3im3fse079rKjlg0EYHvecN03NYI0oFZwLSh1B7ciXkaNUDhh3wtMdyiluPcrFHebTl71gMbwOLcmQQckHrNJth9qa6gEeCrsykiteal2j+iB/O7z0iSPHiC4Xfao8Odqa6R6n/GcWk1+kHoLsNMiN8m1CxrVqsbSb8qpj8U2KUul0p6L2DCh6Zs0bGyt1e14x/K/MlcJBvyEnPjnqjLGzN8Q0X8IieX9ORH9jMWa/zMAv9Db/imAvxIe+8sA/r8Hbf17AP49AMiJhh6ac6FiY138KQnjpPDFTWruiTbu6sxcyoqD9ERQT2MYzbOF2+SyrRgHtmWLENjMDKzt6xm8f9K6HBT8vlajC+tLz8zXzMBeXnyDTqaA8M3zdolVO2n2cnLQWZixgEGcnCE/vH6Fd599joe7B9ydz1jz4gajUoska9427NuGujNqBVoltALUwtj3bggyw9Bweq8ucCkl9VpRJYVCrHBjUE3gCk3QWqXcoropSUJJBlpF5oR1OeF8PmO9blhXSSjWKuP5WvChVHy9F1CtuKeEvRK2lrDXhNpIUiGAhJaQ0JIxkw5OJWyqC29mSN8ZvuAEFqUF0FNA3QcEp0NbHwMskZMTdQBhLswpVHTwfGQBoJtnlBk2LN61keWGMGVKdyT1M2wmUaCsryRak6m0vn+NXsXw0cRbRxkqkSQIZT3p0iaMymHga1b8rM34M9K/fuHA2t6fU0ILylcEHZEBW8UchhqVcxYBRlLK03II1caSrI4soV3S4g5WuaDvNEnqJgYoMwSJ8KgAk5TCZEZLVU+IJTkryo6Wv/8hY/H6i5ITp8XStApsacacA082QGOfdsGsH9JIM58SjhxoxwwFFhZqlzf7gsFjbi/+HpXNvlkIgHlZyGkTMfvJ8SAPTDumoza1WbJC6kB3sz+WIYefIUo7MaAAYwW04eaQb8MebIDwIlsLwOX5t83ViwY01+z1nkSeD8nvbOzFVsTmwwN/aK5NmeAVvnpeVvzB7/8+0pqk8gczUmNwaWhlB3OVZJSU8PjhPX7+5z/H08dnvHn7DsQJz08XlEtFLQAtCWk5+UEHAA9taq2hZQGmlLJ4EKnSIAcBBf1ksYiLvfLRnoi+ioTTJLjmVSNOGOJFuZ5WrOsJtRGen5/RasPlUkA54+2be7y6O2PhCiZJ9MkQw0NlabcwozCh6lSZ8kOKk4hIQhd0Og1LsOdVkVWxPduV7q7A9QwV7Php1QpwTdtq1DwXlK0bEeHV3QPWZRXZkkz2HZIV6MC43qAnzSExbcdBytejlykRUHk4rDGgzpAtbLkq+nunanJ8kBjUuNewh8mVH6MdDvIqHqK9zMm+n9dflJz4K7//JSczIACIRoBbPB05hhz+dYyF4TkgHCwdYOxBB6Hs3FJKUtv3posk3we9wqn2x/cVRkOH93jWB0bjDsyLz808vV3SgjY2M92YmcLelfCfp+cPaK3h44dHfPPN16i14s3bN0CWkuBmsDTP/n3bBC+mjLwsSNwP6wasZZ0yvWzYQ/bVweEcCS9JREhqxGdXjDO88iR3Y1nn6sf6Up9DO6ClqIT1+dN5ajzO/YwxjwxHxlNmfWzGs/Oh0ZwrlRkoe0MrJIVnkkRTlNKwbQVP6Rm//u1v8A//0T/EL3/+T/H5Fz/B3/+7fxe//fpr0B//FGk9oG3mgHUZxBXMF7T6EW17D74+oV42PD9e8Hh5xuNVjELPz6LD7dsVl8uz/L5X7A24XsUL6LJvYsjQg5Gn66YRIAVcC4ilatpedrRaRPdjQuOEohWgExHqXtQID7B6C1lFz6qeL5bgvOqBKgItWVGkBtFZJfxbvGtJq2S3answ+fo3ZnAtUgJeGySuYuNR7NBY02ZYSXdSVxJWe4HmSTG9pqmST2Zn8MrDem8tkmaERdcqXFS3kvub8g9Lr2FVMjsvgvZFCgBZLvqOyyKzuL2+1SBERF8C2JV53wP41wH8TwH8BwD++wD+J/rzf6OP/AcA/pdE9D8D8PsA/hqA//jb3mNMwsvhuvLavzf2NoNDGibkFkjGktL+uSq4XnJWXzIIC+MqDqkP+s3jyaQ5c3VrdQTg/Zn4035nxi0TxC0Yno0+R0acY4v8bd9DF/u7pnlMSdyzzdAgn8MZJLhi0URln3/xBT7/7HMpeX4+iws9A61WlG1HuQojkfwpYnW1MLF9FytxNATFhHMmlPsA+l8CqJpvEku02ThUQrAxNXOhEwJbFinR/rRd8erhHu8/PuHx+YrH7YrfXDfsT894nwhv8oJdGeLHCnyDhAslNC2xC9YKKQR4KXiwClsNv9A1Tj4UAid2JSGBhyoKcsf4iy7RQOMdyMCFV5+mcPIY6GneI0TBjZ2EkyTqydrinhSDFqvrf5/XWVgO9BcEpwzHd15/ZxhfbMf6OxtxXrrGfSzrzVPf4r1Az/ljNK+PKp+Q+1pvAP20AFrtQML0rP3aevuRB1llhForlpzFQ6jKKYcUmCM9CdPTw0+M8/ty/a7khNGo4MgIrgJfnZ4ZaOmFdmc+OgM744tHYPVTxqAjJeTW8BI0PuevhET91P+I1g10fAvUDe87pv/jPh28S9uzXXt7d/QohfNn+cfO+26G/C3Xi/3yKSNvsncYrnAYeDtaC00n7c0RxAhwd3eH890Zy2kBcxN37L2qQi5tX54v+PnPf47ffvNbnE93WJcVpRQ98NjBYJxOKxiMXUGtnarbnLbWpAytCdSAI6DKjnu6Wm4CC69WTyXzHOmcWDxSG8SAsK4LrvuOf/bzn2PbC4gSzucTPv/sHR7u7rA0yZP3XBgfC+FjS3iqLDmEmDX5uOKcQE8cplpVCvips7Neq6w05lOxv20/G5ZIBsiD5yc124NZTldRnJ5TItzdiUfymHR5pJ0j2eGyqDHmioRddpHzbGvH5IOEquhecHrqiUKbhgLeGJNsnSZlkAFf47nf5iHl5B3yThle+hfh+p3pEyHsK87lvMZ6d3yy84zbvns78ecR/2+slaFuci92ejrui38C490DPaDTZqfhyFfZhj0KPm9PWjnEgg68GE9Pj3h6egQA/OY3v8H79+/x6tUrnE6rh8BLGGwDl4J92/D8/AxiaIjsqthx1nG6QkpEqvyyz1W42e85MpoQEIzLdr+ZAZvzKZszm4NPiRxS45wZuuL8zKFbMH6rmCDOo4X+3crs8e/5+5fo0/QUANj3IrIoJaTWC5O01rBrrp6f//k/xf/h7/zvsCwL/v7f+7/itDBOi1TGAswJQqWdD6gAvIHrM1AeUZ7fo14/Ynt+xOXxguenKz5sO56vOx6vO66XK67PV2zXZ5T9Krl/ShMvoasYgp62Z6A25MbY646na5GcQFoWnltDLTtK22AVNIGMWiU/UG1NVtTDr4RXm4emHYLYHEXPGt83LIilQSthwuiHwa0CWo5e1j27Dkl28GDyFqTJp0VGNQ8jk4IWLoPD+gnPtn6IzKjMEgpO3S6R1ODECmxFDihqMh1DiU8oXHMjASDKw34yd5qsNNx1FjF2R7lzdH0XD6GfAfj3yY6cgL/NzP9bIvqPAPxtIvofAPh/A/g3laj/HhH9bQB/X6gM/0MWF9HvdLmB7kWga66ccRKOrfTan/6kgRjueRnYGCVUQZ1eems00fcacHcmG4QL6d/MgyCf2bN9Np/czgLAqWScBlcIDIDY36A+pg4R59mMjNrmx4hy9hDiwUoOMY1K3jfAXdmWnPHF52IMWldJZgxIMrF938StcNvQipGD9NlA9FEI2dE1GNyqJjtLi2aR7xXM7MTPEjWKV3UXooC4oKdEuL8742G7w9P1ioeHOzxertivG/i641QJ55aAu3sUynjaCzZKWHjBiXYB+DkBXHwtGazuhgrOWTc5JQfrRge+5U24wJKOHe+AGQTMgo8QhCtJacojUTgDJatcg/Bf0aWE0aQ063FdBYltzmAj/l5r1b1kvkbG7PqOOHruJYU1KucD6J8UAwDO+KPAiKcwNrb5/cytV2MKQEDer/1oAFFSN2lxE076PgLdKCqmGFISr6HGItCJkiQNZIIlqltP/1yOnP95Xb8bOeEkN/H1A5BuhlLj8pS67BhAwwHNdgPpLTCN16eMKLE/8zPOq2/4M/nnHB1nX6B/4aG3SWtfMljZK17q00t7bPpE/zspQhQAh8nAGQTHv7nf8ZLctd+P+MCN8S0OTZV5v2cCawDQOIbySjlcZgl1eP3mDb74vS9BkPBhsCQv5lJR9oLtcsUvf/lL/OIXv0BKGfd39wAgeRUuF9RWJWw6Z0nKuhensznM2nLhkPe7/2ytqSfQaAzqFTjl31x9k7khJwkFu1yv+Ge/+Dk+PH4EAzidVvz0y89xfz7JIU0CnkvDYyVstKKlFUybGjuSKm4Whmhds3kVzGb3GBMlU0jJ9qINqy90UgBB/ndXml0URazH3WtH+LAAj3U9YV0WnUOraGSnsPrT6XGkSGY9LGi3+9TkHzBWJIwHVZqMwOciKnVZvb6yGgCtYpjJepfXE2+Z+VkLfMtpX0+4Y1++hRV9X67fkT7RDWnMHad8N6M3gImnOg7gwIPcgBLfaR/RzfNeKxx9bY8NQYAJutGYr6b4+MyEA8lon7ocCYR2q0eE/tmhZCkF79+/Ryk7WmV8+PABl8sVX375Je7vH7AsJ+S8YllWbJve8/EjHj9+RKaELz7/QrzKmwx5TpcQkNYw5/HQjPTvIU2EjoFhRnw7wDSdJcU7dT7634ca0CxDTA7aPQf70vsR8MONIedA3rx0zc9z4ONm+Le1sYqVRJqiQo0gdh8R4ePHj/jP/rN/jPfffI1f/+rP8ZOfvMUpScoLaCYdgDzBNqGC6zPq9gH75T3q80dcP37E8/Mzrs/PuDw/4+n5gvfXgste8Xzdcbluerj/jH27SgXMxrjuDZeLGISu5QqqDalWbHXHZa8SMlWqKb6oZQdTl3Hg5MUTDGebTioGoU7+ey2Dft1ULzKjOliLHyTB1xZV26y6EVhTfZgjQSAH5lDMpe9BMlpD9/YBA6z7p0Z65hZkGtS40/VllqRxYtgEkCDh6U37BWhVQytWBPghBFymBh4DV/1Fb9O9IhE0UiXUciy+dH2XKmP/CYD/ysHnvwbwN1945m8B+Fvf1rZdFP4x4i82qBEYy4+YBOo2v1D/bgS6LFErapnW5tLIUA9Bp1VN0Q6G7e/v0V/A0Y7BM+ANYLqj11HHIVt+Coh5/B5Ew2fd1XrsV2zWOnMM+vs9XWEhUM6+AQYc6DJWhS6Jh8XDwwPWdUVeFoBIvX8k23zbCxJDci+0hlKLl9ve990NQZJ0LIAutbbPlaes03FqLY+PWGwbYC59rYM5GwexKOUpExbOOK8n+Xc6Yc2LuBFuO9a64w473rZnfJaAV6ngPTZ8SFc8pYpnllPUloDSzG2fuvDSECMrTEnqSWOGIOWNndkowRyrf0ZPnT4bICWVmbydpsnScsrKUPT5I25AWkZY+0s6h56yjAiU+mlO45GpmCXe6MYSIZvF20LTPAs+K6CNe4cISEba054KNHCjBM7C1H4PYM3XPShZR8YAE0Ad/EmYkCtfrQ7vsqSHVjGh1uan1Dlnma/E48m14kLKSdyq94KE6uM2Y58lQped/d2AxX+e1+9CTqiNVeblICeXXTKPcF5H0ISt6Gts988ntfN1ZHyYDUiHoPEFA5JdknRc9wOZUQcYFIZulr15V5dLgG8cRECDjg6sb0lO2wjpW8d/tM/CH3pIMHkihjlGeH1ieAhqaCSMTvgzKD79svI2G39fUqb7CwnTy1XBjvnMGJb486uvvsKf/bW/hvP5DtDytADQSpFDjecLvv7ma/zqV79GrQ339w9Y1wXbtuP5+RmliNv3elrBLN5B3KQUvfHCqHDEtSTj/2Z4UBf4G/nXmri9t24QsjZkyBKSspcdv/7Nb/Cr33yN616QcsKr+zu8uj8BvCOnhGslXHfxqLg7ZfD9glROaNdN8gYxBIijK5TdoAkNwTaFre85Tse8vK9TV3Pj8rh8D/l17VTW0gk0dOy2rIsaW7LCorE9igYmXXyb99o03I7H0JbYz7in47+cs8iV0B418fZtSABJFRtqYkxcs8Btbjx4ELhxGloTSduPMisqxu41rXSQiJCXBceI4ft1/U7kBIzeFB8S+37Xbz+pzJNjMXTjI7eBX2vHOt5BPGg0vur9l7b1RC3ijN7X/v7et/E7MRwbrhEV0u4b5QL5+F2fkk9dsZ2NUUJ/8vN6veLDhw94eLjH+99+g+fnK4gS3r17q/nQyPOiERFqbfj669/i8eNH3J/P+L2ffNkxV+75c6JeoW/VdZnoNtxzszb22TAOYEgpEtJfTNpPF5AB8/kUsbkHjCoXc/fgj/M1/x0Lm3D4/AgLRL4/yDHjM0Hn8jGj4Xp9VmyahP9zr1xbSkFKCddtwy9/+Su8//rX+PDhA968eYWn52f89utfY3l1h+VUAawgLqhlQ9kv2C+PuD59wPXpEfvlGU+Pj7hcNmzbLiFhRTyDLnvFdde8RdcN+/UZpWxozOIhVIF9b3Jo0nakUkG1oXAFcz/sJzUY1iY8TxwcSXmy7j1AqmIRqRcnD4cpCXLQThoimUhSQrB7z9geAcCS8iRBcHrn4zMGioUdRnpIDCwahs0EzZ3V9Rcz+PfKk5KixvIaJU05UV0fUUwW9mzctwTRUSuaHA6S5C2ilFwXm/cwsdg3wBXm7cxMXghq8nO7ub43R8+JbcNi6O+wkYKSJ3/aZL7kCtr/jpuOocyVJVcDtw4+XtzA7WDzHrxLdPpgUSSCu6FRX3yTDMOC4oU2p3GzT9TBdQOiOxONyvYRMUVlxIQdtQ7CnEi9HVWwWTbH27dv8e7dO9w/3ON0OnmCzRgrL1ZUQm3VjUH2M5a47MPpAtLG7gBKGaj8aN2Dw2nJvEDsXzxFlU1MqrxbUrFEYvjImZDyguV0QloXpNMK5EVyodGC2hJQM1qrKBCbewVQocqSbthERlqEAnHRzNTdAIXBhXXXvuVZ2bJBpZEWtGkHyY7ZU0LOywBk7anZdT8C5JuGXTmF5zOi1k+6jbmaQtWfZDk5hhlDureRlK7sWfiT5n4AZO4jvbxEB0f3xHvBnakm/eUlxdfnCHFXqXDad+wezihVEFrV9ULnK6019QJQ7x91dTRjkBmJTBEwUJNzQqEEQnVwZcqA0HV1gPPjJZcrkwe8rK9x8jV1A588/TLvnq4Iso9o8UjOxJ+zwXF4XtL7TX0GJoiqvF9+jR6TN20GI4/3LzQzANCDPt4Ymg7eMc+Ly5rp2UGpsREdNKWSu+d74dv75jbn725l2PT8MAZ2oDgqFuzvpkT4l//G38AXv/cT5KXnWCvbjv35iu3pGR/fv8evfvUrXK9XLEvGuq6oteHp6QnbtklIqJ4uiht7TGQ/zjk3BjI8Zx7XBmhpX65yZNnYDD/FcyW4Iah2QxGHe7MqpI8fH/HrX/8Gj0/PQJIDgrvzGXenjIfzCWtaRKygIfOOFQWNGvbMOC/AviTUXZNx6nxFY9Ds+djFwLECNeyHHpnRTXfUw2nk5NSDGySBLVVNlikhAIlID3XEM5PUAxcQxaDZqtMtrddaxZsYYdcd4KcjmrN/IgOrf+dyGlAlRTHFVHEptucyjVnzD0XF/7hffQuSVrC89W7/IV+zTOg8G4715vtsH3n2x3DwJTx75C+zXtE/B5y7OfMjdMemW/kVev7iePRRxTcY2rD+DPcH3EDBvPCSMYp1Dp6envD8/IxXrx7w8fERtVbc3d3j7v5+2McWrni5XPDLX/0a23UDvSMPiXWllyjMCZTddjk378vDvk3fGb4f9gU117/62Kc2eJQl/u5wJ8G8+cn/jvfz9LeF9Mf0Fjjoe7ziZy8Zi2aPT4Dx/PwkB8zVQpbGudq2DR8fH/HLX/0CH9//Fk8fH/Hr33yDf/CP/wmQKr76+T/D61efIecTgIJEjLJfUbarRGjsBXup2LerVAirBfvlqlWhd+yKf1spQNlBLLmAuFY/NCAwUgIyEpYsq0VIoNokR1BKABM4ETKk0pZ5kTVm5DUJjyeAOPcctmApE8/i3QsWb5pkBX1oEYmhuJsSgSsAWlBtL7fqhruURmcDQVHGd1nzm1bNpwesOSOzsWYG5YQCOWBLhiOStCGGrKQHkVEvgtzjMuTWMJigVVLlw0HXJrJ8q8kPIuxZz5+nhxCWHy2pBu/Gwxtq7Nf3xiAUdyQzPHTsU51/CbDfAv7O4JP6NUvb8tLOIJICdUsOJQR+o3D4+jikf7GvA3MI+35kSqGXNPZ/HAsPbczXsYAJfdH/RgKbn/W5Uu8HgD2JIUEBNilAM08XApAIn3/+OX7yxU/w8PCA090JiwFqO9GEkOheCq5XMQRdr1cPFSuluHeQWb1vAZqepKkHUOXuWigatOQNas3cqY1p2ylqn5ue+FfL+an7fW1S+eW8nnBaV2RkoCZcMlBqw8e94ZtS8b4VXFvFzk0BM4GQJTGnGn3MIMTMyInc6OTzDvaT9QaoeVeGYswvuryTn7QY5Ahg1pIfN1vnnqdB7V/ju4kGZWKkB3h5eKeKAI5s3xhzZe60Lt9ryI3vEeu/PF/De8RVFEicUIhv9pGXqw/0PYOI3i9EtCygweb0YPPMletMZXaloTVsu8RMx+p34mlIkCSNNjeMuhdsLG6xOWXknJGzGYbI1yAhobaKlCSJOQpgVFCbCCBAaGb2hvkhX2ZiYF/qmRYIYAUcwZgZqPiGTx4ZG14yhrwkZ4730KgwjDJk5AGOQw6eY1UAFM2ORpYAUF7k+y98fjS2l4ysn2rXILp7KHzH9/mzhF7JE7fy3MeOYxl3eO+k6ES+b3RiXgD2NYPw9vVr/Nmf/inefvYOtC6i9GwF+/WCqxqDfvGLX+Dx6QkM4Hw+I6WEp2dRoogkZ0+iJMmKa3U+mshYRc9VIUqYhE2b/EvLIgZyZfJs+fBMnjXNIdBErjlP4s47WwNa3fHb9+/x24+PuO5SLWzJGW9f3eP3Pn+Ld6/vAa6oZUfbr0itYmmMwkAmxpoJayZsOWNPtSs/BF/reEIdiMFlzuFlimxcJgZIgb0YcBho3bPDaDynjEZV8jukBEoZS16QEyEnGZ/IJvheifRiOEE8PrvClVR2duXgWDGN10vGHWNDKal3YiaknDsdBqVWkoSqt5K5lk/GoAQxXuWcwzvGPqaUBpr/oV+RHG+N3Qz2Qiid3xgeVFEejBgzDx9xu3w+y6FbJb+jNcFvlhi2Vz9jN0KNcsNbQQcb5kVWj3H/sP3I39n7PutIonCV0nC9bEhpQatS5IWInM91/UFCy0qteP/hvXhLlobP3n0meEvng9WDIrunkPQhehu6QeYTxp5YVKF/GHiQyeDQ/sz3O4blQXZCrWsWijOv243snvrBjkrC32x9eMGb1dS5aZyWhyb+U8oAwLhsm+g/aOKZSeIZFLH4x8cPyKlgu0qly1/+8pf4v/0nfw+/+c0v8Ac/+xK/9/mXePXwCvcPZ5xPZxCp4d28W9Rosq4ZOUmJi1Yb8rJgLQV7YZSaUdcFra5iNCqSULpU8fjZNKF0qgzUgtIquEo5eGagFoknrK2hcBE55nl4AOaMCsKuyaXRpPx7Ij3cr4zTamus+Wg5obDoQaRYu1YGKCMxULkiq6HJQ0JVP205I6GH0fU0LloIocohi5f7YPaqeNAcso4/YTqbMJhG7AYjVlrue5E13fO4P7PKVGZyASj0kDp/4G6MJJIID7QqDgdJDkEtfC6pvM0HNB6v749BSKuhMHg4OepMw4T58XheOhEwxsncNNadlZH6g2CGEJKCGMFiYl3L0zucpQ/gmYZD/Jt+hEzikgQqerx0YGSMJb7v5vdPyPzvBPypJ6m1u6PNkF3T6H+zCzt4fL7+IXtV0BzevnuH1w8PWO/OWM8npJzccNOaxJhue8HluuP56SqJya5XTTDNgzeRzWM0Wsjv7KV4GzdUYklnxLJm8l1DY0ni2Qp7EmkB1GMehqQM+3K94Pl6lX/PV3Bl5HsRbLQQOAHX1nBtFVciVJBUKNO1LwypDgX1ejGPMrUei3BsIAqx6QSp0AaoMIIoukk8jfp5EiAVrJRhsXgXVACc5P2JyZkpAVjS4iBHXBzJyx3PxpSYtJgIum5FstT7PjQaSGqzkp2Rksx3tb0LUXCTldokkgo0zD0cghJgZ7emyLIYX6JyYZb+kXzHDXCYTDMahoi64xLPt5mxrAN/n5OmJ8ilYiu7xCubUZE7uEiZPAwkESGxVLcrrWrFuU7DjRsWFsWQSU7reWFQkbBFagBlOdm28bcK1O12iD/Ei0FyMqRGwxGcqfA0AWq0BQOcLwO92fNmNvB8m6HkRePE9H3cd6oqAtBTruDyPrfXWXIHzE7iCn7dxfw7KIVNK7XMISaH/TzYG8NYXS4xKHgIusGud/vmInkMmkn95hrepwaD2L/Yj34gAAdPROMIB74XFAPSEzQG44/+8A/xJ3/8R3jz2TuRa6Uh7RX1esXHD+/x69/8Go9PT2iVcXd3wul0wrZd8fz0jJRIkqkuoqiJMaiHkSYFoo2Dh2PKoCZeRKWUkKfHxtq8copVrpLwZ/LDi2KHH7XnwqlNTnk/fnzCx8dnlCa89OH+Dr/37g2+fPcWr+5OeLpc8fT8hOu2I4u0QmJgBbCSuJkniFcrg9CC03mAvp0mFRoQJrmi8k2o3jBPVwqh91eurhBGOofyzarnHTUBzAmZFpyWE+7uTlhzxqLeMsziUWRyK9K2GbZGpVjySYk8iepdp7G4F2aMN1YE4n6YkghpWZwPWailAEnW8IKxKg5P/MgqG81JU60fKRHWdb3Zzz/oSyfTVvJWkRd8T+qRLDy0z18MUR95hl0RVFhb5N/156L8sPdbeFH19WuheqUphvEZX2/tvtzzidxxrByN1fAUvwu/dyWW1DDNeHq6gpDx/Lx7qoXzeYV4OEXPRzFkPz4+4nq5ghtwPt+JwktmlonyWec29NnW5kZnwvG9thesXddlqHOk+C7n8wBs8lz+Uv+4h+N1vHmkfw3y0D4nxZncnGfZO0xsh9S+QS7pwe7Em2bsIbylgSEe6pUEcydkT1xvz9dasV03bKcsHu2tgjfGr371GywLY8mEdVmxrisecI+8JJzWFeuSJb0EEZgLQGK0KbWiloJS+oG9yB1JAl3LjlIr9lJxLfK+CmDbd3Ap4FJQi3q2VvFsqiqnSpViQhJuVlFZcwdpSFxpjMYnNK5Aq2hl13VHnzdisKYkqpxArUdkiAyp+hchtQwrJ04kpo/GUtQhQ3IsmUGoMJwfEItMTrpu1ES2sO59VnsBI+gTrQGJ1H8opCmR2vJCu60KjbhK3WmYVffiQG9Oe2APFElOP9GgKfSYoO+x+qMk/kOfkhLfG4MQUy/NPeFOgWtWNAABg36LccSspq4syDf67Oz507/7/7H3L722JVt6GPaNiLkee+/zzJM361bee1nvMoqERMCgRImUYAJuyaZJd2y4YcANAeoYsAHDsMQfIICAAYNt9QwYhq2e3TMgAurJtC1YhkGLflVRZLHq3puPk+ex915rzRkx3BiPGBFzrnOyKFY5C5nz3pN777XmjBmPEWN8Y8R4CMEYWIdb1zZPwT7w7pEBhxs6zGEGK+8HNSbxbd7zoeuj36MBkdhufJ4V1TOjxUxC4jtJO81sYCyp4UGzr2uyMXmWJSb18YTT6YTz6SSZ8SEA2byDorCK/8w4YADKwr2yvrdznfd3qiFIPx9BVWVgXgpOlxnny4zT+YzT6YyUhVEmQsv/sJuwLwVTreDzGfWyoFwWgARYcC2u27jgBqMkABkg1hhyBizcyNVCkg3N5uETqlV5f3VNTEhmwLCIJk5j1CrhdpN7p+Rg+IDmN2jCZ3UpLhE21p9Cyu+ijNCVPeDCLtC23xOYXs4Zy9InDXeX7WAUWiUWDPt2zCu0UlhDuyPgAEKiUAXglhNCmildGIe/x3gKkSeE9nb0P8wiDFrfWL3WCNXCGYBuDlPKSKmAl9LxjcItRO2HS4CVgQIxtgNA9j2l/oOAr3MAlIE+Il1F2tiipZGutvZN3KdX+f6VdklR4xarvmaUGUF0wpq+ty7vp9x89b6xj2M//LPQf2/NQMn1RpsxgIb5DnKzva+XUVfn1MFQ4L8fWitSmtHTwpwTfu8v/h5+9fPPJR+NPjovM96+e4Ovv/4S79+/Qy0Vu2nC8XhEKQX39/dgMI7HI1LKWMqieX0YzLa3Gz9rdAJwLVhqn8eATUgA7fDDvFcst1iQZ8anYo6zWgseTo9493CP9w8SZjCljGd3t3j18jme3h6xTxnv5wXzZcHlMgO1YpcySpnFtZ6BzCyAmCA5GPQAK6Zv5bjN9BygMmuFF3bQKx6zIoeiMahRC8GqizGZLFF+ac/URhAJwEQJT25upcrbbtfRBqu30YgjKreccuZ50Pj+NZJdyw1L4noN6xFpbp8r+5GIPCm1GzQHXhTlXBeSonvPDGDiGfXD5ZeDENJErHKNRsD2O7rf432i/AcPSKSr621XW78+VxTQcEa7t7076iFbfYm8wb4b5UPrh1T5ks8abYF7474rlIGfpJQ8J43xRjtQjQmMa624f38v9+wm3Nzeipdj2q/mouG4YIgKW2NLhjbUS6HEPMPV/iuyIGJOM8LE7/0+/a9UUt5Yd24G36ZPwr0L5R7DHQwDdmNkyTjGUZbb5SGo1AxOkmBZ7nl8fHQdBil7xUvro0VGNMOC8G2weFfe3tzg2dOnePniOV5+8hK3twfcHI/YTxnZ9DZIO0swBJVScD6r8WeeMS8L5mXGfJnlnlqxmxdc5hmVgX3eoZYZZZ5RyoJSF2CpXkUaYKTFcgclTFPCUtRIpEWBMidUAMsCIBEoT+BFI0Jq86aiSe4jZizzgjTtPA/RFHRRQNKVcK3OP8kq05Hey2K6y9VJDMQk3kF6+E4sh3hRTqUsrREkrxFUz0qyqO5IwVowqDIwqadQytAKa+hoTfBBj6QkHHyb37hPXNCjnAZ1/B/DfN8dgxAa8LPLc9dEXqbffQw821Vrm2jJFTQC58a4AWMCgFjfzQAhgJvCe6zNj129JT58VoPRyYVDGKQlRgPBjltX41Oe2j4PyJnbLVHArJQbACbu9CWx84AKwpExGqhrFnxCzpJI2kKvalHvIGaUCpzOFzw8PuLh4QGn08k9gwBhsKWUBvxZTtm2jAQOlrmd+4tBSH4vpeUNsvtiZZYIrLhK0s/z5YLT5YyH0wlLXXBzc4O74wF3xz2mRCiXC3bMOOSEw2EHPHuCuVQ8zBdc5opFcrh7iFiNIINbn03hsXEwSUJoE/aszCkBTp+2rFLtyhKp6dqYUU5QuG4iOXWK+WskdpTMohPmTI0+Bki1j25ANXCfPnz+2NFls3QMn0OYcxCudjLG3Ff/su9HD6EILuLPHmCxC8ktBd1ojIg85MG+sz5FYw4gylsFxAiUhG2mnLy9Wlu+D64snkJEYJaSlTkaJmAKiMzPNE1y4lIW5JyBWrAs7IIxju37fUX3eSPX5HtB9ore4woBgHDyuwbN28aOeG+870PfjaBz65l4+f0GJPFhubZlmHLvoITGxaMYGfq2+f4NebYyrm7spXYv4DFf/mZ9LnSkfWsnp+z3MtZz7+1f6evY71X/uLUdxWI0QBhQTACeP3+O3/nd38V+t1Ovy4rLfMbr11/h9Zdf4fHhwXN8HY9H5Dzh/f07ANC/M8qyoMytHDwg8lDYQ8wJwdjtdu6xOuXJq23ujwfsuvAg9nwdpTaZagpcJ9sgoUcLV5zmGW/evcPD6QRmYJcIT26PeHK7x3Gf9eRV3O/FhV/yFy3lguVyEUN4LQqehbbM9Z1UjhgfbbLK5ITsQzuJt3BpI3CCKioKUk0RtoMSUbK83iYyCeivEONUTsKQD7sJz+7usN9J1aNWaainQ7v8cGhQRCmOq/usP5yyNuNhRMwj5DRKEO8vitU02aK5/Uqgjma3eP34md1rz+Zkytzq0e/15fxAczI13aHxi0gtrsAZRDLFw/kKjMQ//D52hKFNBI/FQf50mNoPBSKvGw+tAcpAVPrjmGI//HNlwhG7g2noqzy3LC1lwzyfZa9lS1o8g3kH8Wac9bMFy1Kx3x8AaF6hUpCXGURC/3Yo6f2DC2j/S0J0Esis8FHfC3zcvmRNJGz8QpTttXyQ17Zk3o07tR0ZZWSTEYqHmcFknlpruRjXmrgZoBXsGqIP9wbZxW2NYmUx5zWD3sgs6Tbc0A050EbwrDd6S92BJLDbT3jx/Ck+ffUKP/r0U7z69BO8ePEMt7dHHHc7TFmMFoZ9zVvVCv4sywyApAhKSkhTBp2lUylpfqAqY12WRQ6owepBUEFFqoelRMhZ3pPViFKKGDlMMhAlLEUr+9aCnIReUQk0yeFfQQVVQnSZS2DxtM/qyVrJoyN8jVkOcLmUBllKsxGYtSl61ZVSQKZ/asVh04kBlQWaA5QA1KXIO0N1SCEekZ9FXIRd92BNmB3pxOVB0P0NB0iBhR5PEFlkAYewN5OrEF3D+rwWi359ZwxCxmhlEdrH/zwy7oNWWQldVEG+BsvGRByg0Mg41+B5czhXQLh8JyMbmUu4owmBGvu2GunwoT0T3q1MagvI2ziiYaVDzbY//LlGaO4BpGDx5ctP8Ku/8mPc3d3heLzBfncAkFC5oFQBp+8fHvDu3fvOym3vX5aluX8Ghmjz7zmFtJNykrG49doEawRtsa06Ame9t2jM9Plyxib/JLwAAQAASURBVOPphPP5gpQIN4c97m72uNlNOEwZtS64P12QmJFB2BXg5W6HdHvEl/MF7+aKCwGFVDFTQEGQ5GpmiwGqKv3sIRDuVRQMKPZ3t/gKatjBCSNqgETi9mwVzpyJUVtrDHPs8wzuSImI5LSWWz6tEeB0BqWoicJO3xvtuAecimTpYgJgCTn79YqGnhxOP6Mxz8BGlyzcaCq05fNqe7lWPxmmGt2u7bS3d8WW3B+N+e/y5EmimbmFbDB7BTUiDTdN7QS5GYc1EbvugZwzdrsJjANAhPPMoCqJZftQhB8uIrih14Jdm+JmSUC3jIG9cXIE5iO/jkD9mjFmfO5DPD8+N94vXQ7g5tvOBUyBMaatCjm1/sUEqnFszfL+Ld5zZUzOT9r2EdAB2S/cPtauNf5gigA+sg6we+TLzXXqlK0PjMOVCzJmTP5+MPDJixd4/uwZcp5AAM6Pj/jqy1/i6y+/wsPDAyxJ6vFwxPF4g/uHe1wuF9zcSMn50+kkVcYuVfPitfw+lYvIU93PeZqwm3Yoi4SiTrsJl1kSUt89fdLxZzP8WOgY14oS8u3FUGsr11tKwdevX+Pt/QMui7im55xxezxgv89IqSq2YFUwoIBeqsUs6tJvOGiUreJwEDw3TeNSeoghiX4YEWjAf7LIMyIWOciMxKIUFBivZCmZrKSWLeIYjONhj9vbG+x2OyStMtbWu3lodIqVyp5RcY77PH4XPRt6smzeO5EW5R1B7gajEoVnm8zq29xqL17Ol7IWK5gmcDLj5g8XYNs8ueItkLsZXHwtAoSqarBrnqZtvSxCYTRMjzTR6Ga9HnEt+3a2MX7jbQkSriX7lLjxT+/vxuL37/NPV+8yQ0LREB6jTTECyLvMY0QM3QVF7MQopWK32+Pm7tZDbOZ5BteC3W6vuWh2Q7/ae2PdI/PU5NjPrTmUm2VfhmjjLdkR8Wo3EWzyKXVGhWhAtNvZOgjenOfYT9f9ucZJ375U5Ef+5D+jNyCAlDLmy4LT6eyPFxacbcYfQHjDNE0A27MMSgk3xwOePLnD7d0Rh8MOx8MOh33GYTdhmqQ6lizMOipA1rlhqVqrVo9uKTisKq6FhZmxwkLFUJqHPXt6GEMwmp+usHvEUCLRkXSSalH9xA9rzVtOME5F9RxsRT1zmcXRAKoH1YHXCl23eYt6M8upOyqL907WqIBaFqc3D/ctRSINdc3ksEYPgxiuE1guWQa3QgRgQA94QH2UCwDJaDxguGUpaliSSmKGu+TXKKejUbBh5NWmCtd3wyDEaPF6xA2rsg402obbft7cb1GYjp/5ZmYMf7O211y57ftOyKuiH3MZeL8cCG/3x/r0rZQ7wnBfD6K69uP86MKnARxs+XasFJwg/LAhrIwxuuusZ36X5MyfvHiBT15+gqdPn4pRaH8AIBvydD7j3bt7vH37Dvf39x4mZmDKwO44xnEtTRg4UyrVXRgBsSYvRU5nTZmOG6yBc27vr1K9RdwgZ5QqXhrHww43+z1uj3vsdxMKtJTiZRGjCwNUZ+xQcTdNqDtJ8iZu+zr/lGXz6xgokSsjTI3xUrZxRqDMSMzuaiglS6uWG9RklLBwRnIQI++YsL89SmzwbifhbilfEZiWpV9AeaRgcfHPK9Bic2f5LhIlZcYjTdl/WjhkfD2RVKSoZa14xzAvMwrFtTSjUazgBTRBGoF+DOmK7Y601YR5ozvxCBIFKmk+EFPmLOcEAyipaK6qMFUN/fv4UkqSByN4qsktUjZ5miYUsFbusxLT+OHSy3ly51QZ6dNA/3ha256P7QBrZXBlZNhS+ML34+fjtVYi1uOR+7Zlw2i8suF+CG52NEw00Hn/+7X9EP8ef/fnQ3/8uW9paOoM1Vtfd7LXFIh+fON4jSxSvGezfZORTbbvJuGVt0/ucD6f8MUv/hhff/0lyjzDjC3TNGG32+P169e4f3iPPCW8f/8eDw8PuL9/wP3DIx7ePeBeq/NYBU1PIs2MaTdhyhNKWVSWMZgL/rW/9lfx+eefNxDH7VTQQ8Y0p9BioWLz0oxB4dDj/uEBj+czLksRiZ0Sbo9H3N3e4O72iGmXUeaKlLP8KxmLVlMsRZLLzsuCWcPfXA+TyYYb8szA78vRzv/dq7SL91d6ZHsoehkBmdUvXOWknYjaMiZTjjV/4fF4wG4/YZomD5uKy87Aam/SJk1E44/hQVNYjMaajLbvR7xiCq1XlQygvNtTQVH18Ts19peHiKDfsyKLcihd/MNlV+Md5p9lnryG73u+ZvwFWGN2/ywUKrDPlEw3ZMQ2Zm+HQjx83n5v39lOCvfBKiq1PtktWwcYzqONuFbyMuLponyKUIrsX8uRaFWBl2XGbjf5c6UU7PcH3N7e+Z6QJMcZufY5Icd5MGpfHd6E9XF5tSErImZbz117NiaJX69TDFFbHziOa8SDZ1b3Xh1SHIsZImi819Zy9PKo1Q+TraIkq37sKQy8HY0YgHoJ1xq8uRblG6Ij7KaMKSflofLsMl9QVbexSFzBnFIUxSrrXi4zLrOEiMnv+reGg10uGkI2i0yatUBCqUW8Yxc5wFiUvpalaHVMKeazLAtQxdBRwbgUyUhq5dulr5KOQ/LvkhuIahWvVmTJ27lAdLBqGJs1t57JhMqeBoTAPv/mpctohvpEli+r5aalsOcrM5aliBHGUtM4/RTPKUvMYlmqsuri+aSyrxIIku6DsXT8wWhHoICMwQ/KTaagxZTlCgBWwMkO7FmMeSAQChDobev6bhiERKcFoPCA/WO/bAixMtSHLF0fAua2+Q2nmKCXxNMOObcNMISeA/nddtrbC+cPKQtb4Nxe0lg2C3DihPEyxccZhIg86Z6esolsEs8RUG91jr/H09Um9pJPcTSUQY12YPm530/49EevcLw7YrcXUD0XqfR1Pl9w//7BQfP5fHZl3sBr0U20KmEb5tDmpoA12bGcbGqtdyCZ1wULAwqVV2qtnrCsapI0Y65LKVhKRSms/4DjYYfjbsJ+SjjuJuQpo85ALQlLsdMUYYiXywW1LECdMfn8C9Mi9UBjBjIyqIp5SIw7un4MVAqnSvoPCSgs4WQtFERLDYJQCUiWOURM0CAwCgnD22cByaSlbYjg/bE5NeHXhyx+S6UUaoxSV36VYcNDBlpC8wjhdHrSW6lXIqNAHZNM23qOe8zzS9l+G2iclVZl3MqMjdVwcze2hK8+JykBSeKvuYoQN+XFFDYCkCkBmTEXiY/mDEkoqvHDjdETgJ4+43xOKYHzBGQGJlnauc6ba/J9vLhu8Qg7kTGeTqBkIGDbUN/LAu5oLq5JzGl2zTjSgdnYq4FGXbZw+4zNKEE9vY7KpseD+1hExaGwd6LscaXTmm9TBWyA3Q+NYRz/9sFGatzDlGU9wfN3WV+dWQz9BVoSxa4T1I3bh6EBRdjoT9XP2zhii0E70v4lAL/9O7+FX/3VX8Gb11/i/fv3ePPmjZySM+PN27d4eHwEAXj39j0eHh+xzDO++eY13rx5izdv3+H9u3t89fVXniOPAU+eyWgGbOm/yC+CnPT+9PPP8W/8m/81AbKFkRgSzlUXlOUiyTs1pOwyzw74XYYOv8/nCy7nGfMsCgRNCTe3B7x4dodPXjwH0YLLfEZKjKyFAeZSsdSKMs+4LAUnywlhIJfglW0aOUk4fTLUoAvlud1tbVWpMwquJtMs9AoMddnWvJ+WpFNWqlIGoSIlVjd6Ofh68uRWPYQy0tTuRwW4SujAmlbXmIu5SjUdsHvYjlzDDiaYsdoP3b9ErSqSKg61lGD46hVBQKq/lEFBjsZA+5eIMOUJU0oeFs7MXfj9D1dUuhksp7gAYhgghG+QohdG4MHmbUqi2BlT88BvkxHsba0N6LW9B/HeXr4IPVh46RjuaIZEgKhVRRPo0e/D1lZ/mGF/C+Yh56VxD5j8JCpgnsEoAC2QQHepgspcMM8XXC4X7HYHCfch2THHww1u9ifvj+VOixUIR/kZjacmpx2zsfJ2lRHJN7XuyQBTTXeLeHbMDTi+s/9M2yUzBNu8xrWF6k5CJynlsA4G5K1brHMQcMPG+8UTZgujineNFeKpVbyyiAnzPON8ughvI9UVavO1YWLkJHN3WYDLZZaDZVJeQVrdthQslwvm3YQTPbieIJ4retA+F8xz1fxyF8zL7AWALpZDSOXErHrURXMMLcuC4t6rkmOo1oJlvnihllKBWkTWFeWF81K8GnSxfUcJZREDj+CJAmZL61DBrF5tibAwoyBjIfa0IUxymM5F8wZVVt1JDEdgMQrNVRwJEtRJABIuzWqUyYr3q1Y60yAxlMpaBdL4s3ojwfS56NEuciaxhYMbzSyIlcqM5sRwp3pCQECWSJy5YiKCpY1eSg0YjLwKKUjz/W7Q/3h9NwxCAGyHx0PSyCIDFP8XIvi6iTFjUPgoGieuGm76Bl2pjM992z6smHunIV9tYbjHBJt8x4HBRsPXxy4efmkGLTMqNFhOCbi7vcWv/Ogz3N09wW6/BxFp3OmCh4dH3N9LSd7z+ezhXcYAo1IclaBYacOAkd3D1ICSJXcT5mCnqOzPRWsqwjvjqepSJMO9Afecs3rVJExZQACxuEcuBs7CKW2pBuWUNvSQ06oOeN4FVqNaCFkChKGIrqR5q3T9bHmF+au5z6zOSKjq0ZZsPVRwppSwmyZYWfRErSTteCoR6SjSRnfCFIBv/J4UsPvJ/fA99B7re3uPa7DwWPaw8UcDUOxP/N6MKpMm7jTDUFzrZmW3GHoBVu4+GhTeUjUO2uhD35UM5FNv4MFAt0RSLYxByFPGtJvCdzEJtozDaDgatIg0gV3OyF0uox+utVlnm8cKf7IMdNv3NqC8rtRyjebWoL+/1wyY+k0w+PhHMFDbgWRitNDJKwcR3pDyEm9yMLqENox2vw39bL3zY+ChjQlN9HT9GNqI/RiMSwas4xtdjeL2jM93OJT4aBc3bnEZRgBXxtNnT/Bbv/Vb+PnPf44//MP/AuezuOZfLhd88csv8Md//HOcT2e8efsW796+w7t37/D6zTdiGFoKlsXVeQfo2ukwTSWy9fY9yUHHUiQ5p4+crRpL84Q1QG4GIan2sqwOQJZaNLl1QSYpzf7i+XN8+umnUrq9SmmWxAyuhLIwlrngfJEk04sWWajV5qoZ5fzwq1sPWyL/xf9VpXvJRdfW0uSeWoqEZ2tb5EYmgM2zVjGOSRRKCU+eCOaYdpMnD2764vb+jXvG9kqo9enYK45xiydsGYmdl1NbdzvpTkpr4zOWh9Hk9Hjw0XlQ5+wlia1vlu/jh6tdEUPEy4wMpvSz4ebww5YnrnkLDWycd9wDo+Gj4W2lrQ122tMQoyWhbv0cDZeGt7b52uCJZj8HPm3tdPJP8WnqPM4kKT5AmOdFvEaWBRbuX2vF4bjH3d0tSi3yrCrAhmM+JEeajOhlQ2MjzbvbWiHlmVHOXdO7tmR1V4xEF8m83WO//Hfn5xTmJupXTT/yo/QQSroeNMJoRgyh2BQD7iPCrDnkmCH+AeHAmSDKPHPFvMxi2F8WTFl5keadkTyuJxwOJ1QGzqck1RgJXjmslqKyYMainkHzLAmkzQNIjEQL5qKepPPicnC+XLBcZlhVXtHTVFfSsMNSZA6tYlnRnK+SH6+0OVb5I0VZiuZLmlA0Xw7bvSQl5xcumFlkTlHwQERyGO8RDYQUZEEpBXMVx4CcMlAt/Cy3w24z3ZQFUyIkEl2wsCT0l0ppS0s6rtEcou61tBrMQOHFKblyCx3zQwSlywIAZhxUUm1YSfRFqawr9yQ26ShXqQZy2HVR4hEV99d3yCCkzFMH7sowAiOguMkaE+3b2Abu4wZ1C3VgKvFzc/GO7Vw1Btl3GwrLf/nrQ8w0CCIgMP0rCkUQDN8G69vsd6pIVWbteC/hZ3/hZ/j888/x7NlT3N7eenjPPItV2XMrLIv3tw+XaZUgDARR+DwF5huBksItOeVxSueOEbm7fTAgGYheFkkm/Xg64eHxhMfTGbVKfodpt0fOyfPHMFdUkoRihZXBVTU2VXg1GHj5UHZQC59FDQEzSuF+IQji+pltKSnsBRID6RIrRFCCeX3Zmidi5JSw3+0lXCwnTJrzxmPpw7w7bfh6t+8kZOyaizPpK9upWxNiTcHjQD09EB6E7gaoiqdL47ujF888zx3wIKKOubLSnYBrYdqFm8HHhEWpWqCxSrJVMzaCJLGiAKZWVcw+L6WCckImOXXIwRPAE3qHuR7jhPs1kD7lacKkAqDUH8C+XKz7vDcsjsZLRgv5CNj6wy2vDDrX+f2WAXtTIVMw0kL+JF8BwfJycTOC0Fp5Gd/Z94W9/TgX9jszd/MQv9u6tmTcx41TiNr3plFKWLJrRtbz+FjrM9oy1e79suZRZtvNY3+vj7HHDWbQNTDNAP7RP/p/4qsvfomsSVvfvn2LP/iDP8Avf/lLvH0nee9qETd46aOkJBX2lwU0MkvF1BXgl/GZnHMZp5/LKeuCScPWwHZSbG71RT2EZpSlVRUzo0+UrYkIqAUPD/e4zAuQCHdPnuCzzz5D3u0w14q6sCt48yLGpsssIQESKrCIfIszZ/Nr/9j6r36tFGQBEaqZWUSYy2d+4CF0QdDkyKwHFWB/gclIAonXjop5STIqIbb7wwGHw1FDePV9bAdE1pUBb4BapVJqHp8FehDI631jdGYVmLaMAX14jNKkHh5VdUePB57jQYHkTiXvbzQMGR4lIrB6IMl9HGThh6D+9+uK69RC+Me7xDunU+7HOxz/9JjZ6Hybv17XEdYvGPFXO0iItLVKLA4OvK9/35Y+Y9ECMYfIFqb2MHz1/pFqsAlWpOVyES8h4Z8kuVESIU9JKxCKArebJux2Ow/l73DcCncq9qWWk5QVADcjHPkajHLpYwagUS7YvjKZw+E7l0vdYifl9OaTSq6frLApRsyLbi3ZrTlN8e/HYGvV2k3Kn5ZaPG/QiNiZ5SCTpqwl3wu4LAAmVPUgucwzHh4f8ebtO5RScNwfRFYkAmsBk/kicmhZJFRMQsLOGvosXoiXy6KhxRVn9RYyfa8Wdi8gjp6rXFErYSnmlSMyfLGqz7rW8rkZQNocSHGoKjIgZfGSEWavtXQIBYSFCXOtKAxwyrAwfKrmyQ/MZhiCFCmoDFyWimlPmBexQIkE13aYsdOUG/Myg3NCSoylqn9s4MOAht2BNdddjMohNXCG3EU6ZiJCrpr8vsY9GqvZ6VgDvVhIWmIAMG9bNBrkFp7GzO6ccO36ThmEDJwZj1P9Hj1DWFuv+40vTN42oe3ryATa+8bTGvnPSsEYFLcPWbyvXddOLLbua/3++OluY5gIP7eZlRkghJ3Vje9WnZF5jKAfTZFnAo43R/zsZz/Dq09f4fnz53Jit9vhcrngfD7jUauKzZqHYctg151QeDfbmOxXj5tk9tNRgZDmNFdV4QplevWI0373xJzanoWMzUvBZZ6RErDf7XDc73A87LGbEszUZ4mDJfyMMeuztZpXkqBYq/Bpmd2bk25DukbLcT57fU8+TEHBTZANS6HMJTOLq30WwE4s/T/sd5jUUyjHULxBAI3CNBpImwtj+9fT8do12V5Rq+SniErbGqgEUksa84ceKNs1GlFiyOHYN/MYikp+KxEMycNhz9VWaaQZhNSAyA0kAUDaS3CEVLMBLNmdKXuFS5fTyP6Jy678W8q6v3bJyTIkoTRX1JRRc8X0g0HILyLIPkdfzjfSlu03O136mFEHaPQU16U7ScS6na290xs2ASKpfMEKdCmZez6c3zIbIL4Octv4FMIOQ9qUUdz/vWU4+ZCM+zZyrrvDEHucD9EbXJ4RqVcKAiyhYKjemFNAWNx22PTH5aqBcvm9vdkTDgN49+49/qO///dxd3PE7e0NHh8e8f79e3ErB1DT1KSs97eFPAj7N17QZqUlhJTPauymdqyyeKUejwc8ubvBlBPsUMO8Q6TaS9E8djMuy4xz8BSyNTMF7N03b/H27XtcasWSCIend8iHPThlXDjhMjPePc64fzzjPJ9xmc+Y5zPmMmOpBTMzCgnfrBSkmBlSvPvsFVkAaD4bEs+iFEL8idwwpDBEeLw+WBduxiCdY5EJEu5t40ukFYMSg3LC3d0T3BxvVLkJYYuGA7HGcau9pf0jIo9q3NLpr+1Jk1WdjNK9wFWSrBqetX5E2WZzUdF7JEVFHRB+NE0awgMLzQnhQFcMEd/Hy2jTqNUNsNR7bXJTMvTvno/0xpr2cwxBbcnLI65tOGcTjxuLNppnwDx3PnSx8Vkl1sq1YczwnmZEMlm5DqVqtAan4ynvcKHFcUxKWcIvK/shLyChUwRgNyUcD/smd/SgIncG0kb/9lkMq/I58LBqmytLr0Ar8jbjtxlLzdNurddty+1un27Jcp9r67x+P+hZtVvX5IZscNND+4IRrbFxj9ta2JsMoxIlnM8XzEsLY0IV7YdclyDUUvD4cPIqWkSEh9MJ37x5gz/8Q8Lj/Xt88URyvO73e59nkyHzPONSKpZScT6fUTV3lOtNDDEG1ar0sEByHYVUC0xYioXwW6LlCgm0Ur6shQxMF2tKke2B7J5m4t0SPbgozJV5jAJMGRUk/WcGU/LqZQQxhlQzjMB8sgGGGPrrLIbPHO4rtSKnCXOR0Otlqci6Lkspcsa3ALPmayLKHl3AmspDVSXXmQTLCA0QQRJl16qHAQi9MrnQ5JTxFNZqZ4Yd5QU6N0qA7O2Q8ivWbFHXr++UQQhAc26JmzAw3y1jzRqwk0+cXVuhAWM7Ek4SN2R/fej5CMCvPbelCPYGEtb15AaaEMEsAdRyBNlnW8LmGkD28dYGnWCgiC1XozFDWJaGuF9bW2Ac9ns8ffoEh714pBDEY+PhQfIGvX//HpfLpRt3HP81pd9KBVIiJ2EzBNmJiVQwW1DqgomzgmhxWyx6clqWqjmCSvunjMviXc3QAyTscsJhN2G/y7g57nA47DAXdRmmhFIumnCzSDWWInljqva5TY7E68KUUnXxjPPImmTMsFwDL6pAKVhpzYoH0USEwpJ7AgRNQizVzxIB+2nCzX6Pw2HfDBNa6aWG/RLp0QyLRBFIrIFSJzixvSeawmUgoJ2o2jvkPXHvsINyo5Gx7RheNe5nN/6hV3S9r7ZPYCEYeqLOYul3bzJq7QHwSmJGpzlbcj5R2pgLEidkZtRS3VPJT9ogbsbW/5EH2E9T5KaUUYwg9NTcTv9/uADbDx/Q/xUkXFcAx3vHeyKgHulwy6C9ZXDxe5IJeYblFzPBFvfctxq5KzUf+D70IVZ6uiYPtvbvtzEE+TuxrYYy2A0Ancxg3rzfeMAoy0RJN2jTQI/ZWD60tt07B15hvECeE4/Byzxjvlzwzdt3gR8J07byr3am3BmiODlwl3KzRlP6BLc165fB5oJxd3eHVy9fYj9lBd4aCrY0GSWHLBeczlIRU5K8LiujwZu3b/HFm7d4d77gzIzdfo/j8Yj98QY87fDuXPDwcMa7xwvO5wXny4KzuvyXClROqEhiHFcXep11nfs1X7XfiwGXlP0gwiiedS3F69Zyg1iuB1u/5h2ac8ZiSpvPFYGRUOqCm+MBT58+wc1RCiikCJqJ0YLORjqBrmnjxSbLCHpyzFLa2IEQ1nsoGm5GmQrAvZJtl4jSKhV9xr1qyi2H99jpOiDyIeUMyn1Ymc37D9f6MuzB3HDmaBw0WTImZB5/j+s7Rg5sGnvM2sNNMRu/tpc3QwpccbT3jO06zUS61j03yqH2ojYPpuOMhx9A64dgmISUMqaJkfOkOWAWTFN2j+xpUrokwm6XUYp4C+13O+xylvAbvSpf4e32fhJ11Y0/IX/p5tpqe9ZuDPEfZfqWzO942LA6Y/SCzY98CT+gdeU8rssWjzAlwN/dj23UY0cjpCXnX2ZLliz8bXU8orrS+TKjLgVTTtjVHe7vH/HHpeCb1+9wd3PAfpqQE2E37UAgFM17Ke/W3KWWVoLloFT6aAmMFR+xHIiKPhnpXLyiZX20KACZviLtJE3CbKF6HNoVkrU5a/ioeV71WC1T47cFUgnMZY7nH+SGxQJdsA7a51/7aR6kieRAV9J8kFRehiYkYKkgTUygnMHFZImmmWA1VhGBSPYHISGjdmlASOoFIasMlEMV0xXUg5bIw60ZetCSE6hIbiAQebEjzjLvpIUXxNCsnpLYTopu13fGIDQCSzvIiyABgE9SA9kRIDeiJupjYa9tWFNS7XnZsEZMvWAYGcnYbtDhV0qpMAZWxqejDcSpb4diFQeKjaHbrmgnWn1/Bsbl/ev+9PmzZzp+Z55V4RnvogPw8B3DQRhr/Onj6QRmxv39Pd69f4fH06Ocsg4KMMFrT4EIXqLXR6xyrqp1XBI1yrOenFNQpp+UASbcNTfQUlrsqrsuimW31JZUWhIJS2LgJ3d3eHb3BHeHg3gI7SfM54tbN+ZScV4K5llCB5YiJXqFd3KjWaffpMpLM+zYeStDTk0pkWekl/wJGqpGTXlyRSSJoSAptcgJfAxDEAv3LhOmHGK4jeRobSw1gnPsG4kmKBoR/DpDt/Kaxlx1E7SwKh1tWPfQrFrtlcl9AABt/W5ja4YWGZecmFZ/mYV4uGXdmK0uPLMk/SzMngh6miZ/TxTW0zSJ8YYlKV6iBEqsLupiaI0hBSln2OYxt1KuDK8Mp7yKoGFp2md5bgGjgst3hk1/Ry47E9k2pjSZIX8bSY0K2PZzWN2zZdDfMrBEI6XcA2XHNew5hSdBRugb9fMrSh6bwjrIId+vg5eU9ble309bRtNr10ruDT+BXm4Ix2KAebVG3qNuHObVtCFjU5xLa6GN+UOHLKxMaWO5XA57Po04TrJDksa3vN3VeCTpY5DW7Q3ce4N0z2lbCYTf+LVfw/6wxzxfYNVlLLzZqpWdTmecz2ec3YV/9pNde8fpfMbXb9/iy3fvcULFtNvj9nCLVy+eY393xLkSymXBu8uMh3PB6SQGpmJu9pUkN4JWm2maD1RMCK9v0ySSyIwZYAIlUSgpzIMovAnJqmva+BUXiWxX3qn72qvDOF2Thvoy8rTD7c0NPv3kE/GqUq9Qm3Nb33hIMIbdkK+xJF6thBCRyl4SemvdIjYcZerqGVbFOXgxjIomqQy1K/bVjGNWLdQmkAPuGXHf9/1ydsFtV25fth5bOefi9w17Gu+259dGADhGN6TbdBY4r3HAZI+TaxAAmedPuw2Ae6OkRL433eiPSHuiALocguWoEg8O6UsLTZGuqiF2J5UULdRuv9/hcmGfD+M5cdzGf6acPV2B5V3sZpt6Gee8u9ODVkvhulEbXZMbrAMwnrIln+M77XvHtBv32dXnWLKQNpvf7Xf4752sIJXhEHnDxkc7CQqTVa7nykYHQ/L/VC6wynJ+uKJtSp4glmTIzFiKeq6A8P7hjNO54O37EzKJwSKnhEmLzgDwkFvTCzn0JyUpaGM6mH3foiAwjEPWppQqCchhXjwyL1Yivq2nGQ05KiL+L+43+81ygjLMO4dcJ/Xem0HKFEoSpwdAvE0Zkpc1JStEIWNLTFBTDBIBacpyr9INJSBPaHoozKFEcgrJAXxtQ2Gp2ExEyEoIUnis8acupTy3+WUGkOSAw+kcEqkixkKSojZV+UMCqMrY5PChaoEFaKgxrl7fKU3DKih2RYc2hGyvr65B4agItOfWFmq73078TS6TAdrwjrEte0d73/bpZ7Q+MtoGNODTxre9Uj2I99/Gt1x5hgGKSoQqo9Z/h7LSeDXQp5RsTNjnrZuHhGdPnuDmsAe44nKRELF5mfH+/j1OlxMKNL8Keq+OyowFopRfzmf1KLrHmzdv8MUXX+LN27d4//4el7PlRhBCzlm2zYtnt/hX/spfwe/8zu/g1atPMOUJRAnLUj1TfimL5wqyhGcWz8/qpldVOFcwaNKcBPsDjrs9dpSBwqC5IM8FtWjpxXnBZV5Ql0VCgCCnLhRPUg1DkxkmonAWcGwHBYvyPatuwkh6wqlWZvsn2AIGsCf5DQsgMRUa5pQnCRWb8oSkZShNWAa84B5K5hlDRF7OVxepE/zjPqjqtoiUwCSlgKtmPzODUXRlXht8lIGDXLFY06+RZq8ox5+tJH1zQTYjIVEDMG4UVMMjQ101WXNlkMVr9//iuE3xqLru4NLxqKTl46ltcjBJNQI3VqmvpyU+Tqo8EeQUgNIkSkQSwyAGReaHK+qpWx5DwvPa52vI0tq5ztvHe0bjYLsf8r7Uv4d8K4UOej6LAMTtno13N0OquYY3fkzqdsgaWB4VDoRmk+UkIJWxfP099vuWnPS5gMO02HVVL3pjlfwaD0aUL5qsHIxC9j7jV9pMe4/rS9z23dDvxufWa97Jaq8+ZPgzhD7FCdSr2ikheDU/ppT0ysyHvL+MVqSCye3tLZZ5lrVVg4yV5F2WBZfzBZezeAhdtNqLuOebZ4PkNTjPF3zz+IB3lxkJGRNNeH68xfHuCQ43N9jlDJwIealYaMYMxlwL5lKC3AzFGZTgTGmT8roK0IjUGJQUL0GqMTogF48BU1qAKk6y1GRhJf0s6akyRM43I2CTR0UrpuQ84Zgz/sJPf4Jf+dEr3NwckKcs/dG1r4E+Ig+P4R1Ow8xeXYzD8CJfH5U9OzhEMz34d+Mz0UN38JcDgC5XnnktxTBAk51Wxp5Wyqi9a8SE38/L9qJ47vkn7fuAtYXELTKgupKJwf+i54/ofl/rGfJO+7llpJAjPftduhj7ah5zVQ0LzVAtPypLdb/OWhSUEXmXGGZlTKoiM2klTjnIEsOjPGM4KueMvMtIpSBXMUS6F2II240YaZomMDN2ecLhcECapqDqtnvXcxn0FJ1zCZHCcFVXxo23j4al8T3jvI8Y0o1BvN6/nS7JFlxE3XzGa2UMtlxN1lfTKJkBTZ4cjXXWvs2F8w/Wg8sMLAsHTxzFy9FQQhIy5kZwaKJmxQYLF3BKKCQznRJjoZZrK+m4Etrhu3mxWHsuC0yfMfqOwln/JjKnDM2fllqpj2jELMpwk8oIIoNH4olvZ1rkxhe5xMhO4OKgBomAQxbaK9wcFqwaElHVvk2yB0i8fwsSSrIE/yrnq+hUEugGUFKjvqYAyKQHvkTIS0GaMjIRUBlSEVNote0xoevMlsRbvVjVC1m2r2BXhWuq7tnckrfDqK0gAxoPS3qAxW6nUhrJhMrZcee16ztjELKh+h/fQraNAH3rdHXLWmyE3AA7/IURuMb7x8uFCgOsKDuecH7I06E9Kr8YWI+viZZ+A8eR2dk9WydY/fvjSfmaIeodcWS9kAlz048fOB6P+M3f+i28fPkJdrsdmBnn0wkPjw94PJ80wa4ImYsmrTydTnj9+ht8/fVr/PwXv8DXr7/G169f483bdzidzpIk0/P/sDJSkvliK3HL+PST5/jJ5z/BZ599hqdPn6BWRspQUKUhYZqos4WLab4FBdrnywVLWQQMcwUnwgzG2+WCadmhLhlTYixLwXmeUTVZW9Fs/4W5m7vO4KHMD2gKWJtWauXkNW+MeAqpK7Inn2U5SVCFryljjQ7Mqp2IJNkkJ+w1PljCmyb3qOppSqzizOR5MkYaiwI/hiVcM8q4cu3j0HclGmgu0PBAV1t7Lc5vnOeopBtN2p6IOaRiSeZmnJWAAlIgI8atloPDfrY+o5tHq7KhnW5eazqGlNQwRHbaorwB8BxFHNonPT0gSIlQm/P4/h8u0lDXQEub5EKQtVG66/jZda+YKE9GkLl1f/sMaAYoVgHeTtnkNFLbhtCOcd4rA1hf3ORFNLiArE/bNCJqonwnlY7IFedr4+nHRuu/N5Qs+fJqN1btbb018pNOefL1C4c0QV4nZk9C3dpaK2pA63fkh8aTonGQ7b2d8rdFK9dG0z/z4fkmXM5nBwAV8CSu4h004/EkpezP5wvmy+xeRDbfKSXNH/GAh/sHcdUHIWfC9PIOrz77DJ8dDsDlAa/5hFovSJcFy3nG42XBSUOr2UpGI6GmnkKTgk5TE0SmNX6fIJ6u5oFAKutSauuaI88OPBNgVOqr9AEa9pgE3BOJkfy43+GTZ8/x27/5G3j+7Cn2u10zknDsW9jHRLYtnS60e+IdxJZjQt+u932InC0xqJ0MW666ce37ZNNwejDZ8KHDD/OCtZ/XsegP5qB4VXdcTh0f8LW/smXNuNru3/Ymjd+P97jxMSSHje2Pcqvxu4FHGG/hsA9djLVktNgIAzFjw5YsE52V1XPa5JW+kCpSBnImyVVVE4j23q4YJicPpUnJkkaL8r+3pPihH9ZfHj/Td7ZQsX5eVzoTNvDjMP/j39FDcOTF1yrz9fPV98mw3ojJxj6MwtClXkjIuiU/urQZ4R+QcDqdHXu2MK62rm29zfiRkLMeVutbDJda2oP91AzOiUwnYE9an8g8hAhWwCalLDmKCPBTbdIDEzN8+Lhb9AJUx7EQKHCIrABEf6sFDaMlMPfFZarm5GneTKYXkRxIdxs80DUHg5OZeMwQA81VR9AIDDl4mJDaYbyOSkw9rS/O43eaKoIgoQP6PoKEdnX2BLX+OpQyr0PVcwHzvJJLQjHNM7ThSIA8YTQRMFneJW2YWQ6WkoW5MSMWItm6vjMGIQC4iu/D90DcpLboNikfBre9kUQJFOSlQEnBDBuMZrt39ECSDSrELEpcOx/VXm0ICOsxjBBsFAOgb8YmDQkaTDbxuS1lMX4mwLbfHMaA23xGrkcuXlq/eyZm/Z2XGfcPj3j9zRvc3dxqzPGEx8dHvHv/Dm/fvsOXX36Jf/ZHf4Q/+vnP8ebNO9w/PODx8STeOpoMzw4BLVt81Q1ew3pL3kQDnMC02+PuyZ3HOxvSYxV0zTNowTxfMM+XUCVGknSeTic8PJxw//4ej48nTIcDbm5vsTscAdrhXAiP5wWXxwuWy4JlaaFGpUqoGDoBZUC0mzKfNwbAKbknkD2X0P/tn6lyGdcghQ2takzHfFPOuL29xWF/xOFwwDRNGyELPTUlEsZX0dNSNLiMwnSkm47ew72kyeTEOkYAZdS6KN+LwmzbkOp97JJw9t4a9rcBcmZeeQXZz7gP7RmRJa1EvF2jESwafJjae2njezsVnrKUrrRSmsySGyIUywrroRXJhtDICLB+uHqas31FUnMTluyThv0kn2ETJH+Mh25dHRALuQ+IKLzW9qaBtdYnPyEbjBhb7yEiAWjaJogi8Xy072xtd4rwMDeI3eY4hK5vPAD3UQvteYKCsI2plNM+7uZxq//tvf19K6XK+CsaON66TKb3fW6ALc6DiBo7bW1GbgedFvbZtee9gCWaHQ3o7U72xZmmHaY84Xi8AShhKbPKrhn39w94eHjE+XzpkkjbOCRsNWE+P+LxdML5dMLEjJIIuDviN3/9Z/i1ZxNu8glv6RFc3qPeX/DmbcGb+YRlYSxFKphU7VIlgEPSAjYFlM1oE5SGlNTAbTywGYScRxpw9u0RKnVB+OM0SQLbquHngBpSiVDmWcvUVxymCT/98Y/x2aef4LDbqYLRpp+4GT8d8Q0YjHWBWeWeGQEEyUnVloyEguI0Ze3YQUMclxiFhpDRWn2O7LNexvGKRkxm9W1vHwT2ByE/eJH2F/k/mzozhgCRx0jpZlNAKXiWXtMnRmPFh4x09v6tZ8wgEVeOkoWeJs+xaMei2nBQTg1EVN+Tjgo3sNUKwzkPbT9TStjtJpSDlrQmQlkWHNLR9ZCcJkkonTJymtSAIN77aQhJibw87kd5W+NhGPoZZfN6fkWHMSV6y6D6Qb47vGe8N/a5VkYK9OPGjWFs8e/2vqwhXvFzoTNGMSbU8ZTeIFTdqA0Ap9MFrLwNTqP9vLgRp1bknNzLXKoNZxyPRxwPBxwOB+x2E/Y7YD/tcdjt/H7P18Ks6RFEKFQt5mHj4VqUdwsdmoxgz8k6zJV6UHOtaIRgUQU2Vr2f7DVJc4aWxuN03ggtD2ll9tw7gOWWahgjeirZVRSPSbLrhKogiTijcMGOCFksXa64V/0HTpB60JpjCeTzzKWCoDn0fC2t48FTjKJe1nQ8wbTqKcsEzs1zFGAxMOn9ZnSW9ze9RN6ZNA2F2Dgql49kEPoOGYScL5HTn3weQR/1T8S4X5v0yHy3FEz5PEK4ptC3jdyMHvG5+G5TLAK8aPdFQwD56Npn+hhhZCJNiHRtWBObzPHDFxmhOeIVARIFJQ93g6OjYBtXx6QBzPMF/+D//J/i93//9/HTzz/Hp598guP+gHm+4MuvvhIPoK++lmootk76Hzkl1zHrerOVRQ/Ksnxe3YhSIQz6cDg6GJU17Y0BVpnFci3M84xlnrEsM5grllqwgDFXxnkpqEyYdntwSqCUwZxxngnnS8X5XLFcKi5LK/tofbNDBjEMCG0R9/RgwJ9Sgjj8CGMlf84WuFGjf6brbmtXlfGYOCWQA2BAlIPj8QaH/UETUY7eQRFQGljXuS+S68lP4QegOgpR+9zG2eUZMlqrNh9JkuFZ5ijZQJ2w3DIKjfQ+7uvoLWQu31veQTHXhp2GEOnJRyhZb32z57aMYSZ0ocKyBvf+7h0aJmD5niwlB4j8pMP6XUoRL6sKrc4hLr5bc/B9vrbmovExQ0gCuoC2dSKf/zZtjt9/2EBEoWnrA9s3aKBnAK/BqNMSEa/p2mSK/43m/RA62d45AF31sRR35g+Oot/r8rP/rr1Dfucgq6JxJCphm9cKPI9fc7hNTxJrW14LL+94xQdH5y2H3015oeHz5tDeIEFE38HgZP30DrR5GnnkCosAklMBwPF4g1effoqbm5vOq/Xx/oSH+wecT5eOH7F6oogLewYhiSfr+YzlckEFY94d8Vuf/gg/21Xs+QFzSSiPJ7z+5oR/+v6Ed/UM5gxyWhJsUJWGPbwLklOBmJHMnR6ivCb1gqzUG36ICHnKLr7cS0jBuclsSoRSKiYNta0MFOWPtcrp6OUs3sUEwnG/x8unz/DyxVMcdlZB097Zzy3FD6MSYmNSTOH31yaSWDSdbr2uGY59fYmQcgq5faijyQ5DKU6FHVIEpXBULKOH0Zbs7Wn3hwvoaaHnZ40+m84QcDcsdKPn+dfWfmx324CxfgYcFbfqNCkGiB6DhYcHLKL06/CQtFx22w/2vFXi6idprdfYHp7yhCVX7HY7AEByWQRMWbw5pikhTwSrYGQe6eYBO86NzbAOJsz79euaMafJoR7bfkyWb61pfCYeGq7X3BT7bXrYfmHv/RUNhZZbals+9NEfXIHT6aR6hNGHGO0k1YG8g9TILGXPE6asCaR3GYf9hNvjAU/ubnFzPOLm5oDjMeEw7bCfdmI8miT3TfLwKXJ9cFkkPHhZFoAsx1v19AyFuXm2qvHGZZaMSA0TECcMM2go/RQzbhC0erRiHWawOPH0ueqU/lmfFe+YrF5NcmBhKSGE9rMfehOJBxBLRh+kWlE1j50cLmXsrEpY0T5p8ugC81SXhmotKJSQCciJgKphd7rsFoGBsIdA1K29fr3SvUy3I83D23KISURGzHtIDECjZBgNDzMAyoSE6aP86TtjEAJHIW6K0+ZtDXJdYQQfAvDM5lKs+modX7SVYX5sxIwp1lHrmY7DGH3oL3eAsnvCN0sb9Pq947i3BNE4zi1F1vplybu890GwmHCKRBXnQ8Yif8/LBX/8i1/i57/4peTxDZnQzV0QieS0kYVhudGBmkdVHGA1ZcMHrP0xdzgCPv30Ezx58gT7/R67ae+Mo+gJqp2uXi4XqcYyzyhFXO1nDRc7zxc8LgvOtQLThLzfIU0Tlkx4yJJ9/1QKLuZKX4onkIaOD5oh3lZbHM+knK5vVAhQBKn7PKtJThsqMrhGt7axydasvY9YsuDHUwsDkyDxJNjt95imSf6FPEIWyypT2MCw0IMqocFwt7WPRloajTN2uukGH0BOBCxHUKCzRm5rod9+b32LxiAi8neNVzN4cde3JhiAyQx/IamePRuNQWO7LWxMlZucvLSmdTgq44DmcDEBpxb8AgBcwNzC4CQxdVNwppTldOCHHELhuiIY0AAwIcEqP3VPBmAm9/cnqfG+j/HWrg0FqM2+o67TIfmj0zybkaEZF9q4Yj964Er6nYPhYQpM+Y3jaIZg5cbO/weP1T+BoWw8KPH18DGtZfKH5PFoYB75ymqNiKLX/dAXBFkVRDOuKWrsysz4ufHJJt3Vm5UBW+hOpAfla0vRaYpn6IP+end3h9/93d/BZ599hpQSlrPIr9PjGe/fv8fjw0kqlAzrSyQVffI0YVmkCtn9/T1O84xzzXh2u8OPnh5wd3MAkDCfLvj9Lx/x//7mhIwFN2VBXRiPlVEXKStMRFKqN8xXTgmJCRmSv8fng/QQgAgpT0rz7F6NZvQgQA4GvOsyD5JbrTr5lLIg5YwnT2/x7t07vH/3iIeHR1wuF/c+Ph4OeHJ7g+N+j91OZFsOVR99H+maG4CWvrXy3M3pXvcVAE7N8FhZcYjK8a2E1PGn7S8Y4JcvBxposqFS2y0E+Mm60Wk8xNk6iBkrIfk8/3CFq/eiss96nmKfUydaRrmwxb+2+NrK+DFgC+uL8WAi9TAVtVRlxpWQpPDO7t0EuPeDYY4keZBiZdY2pqTYk3yOSD245bAsIyVo2oGCnJN77O2mCdNE7nlOimmJ5DPqqDrKrGFd0PbiOM6t3/t5bFpSmwsgrveH2u3XYi0XXBnv1n6kowBlh1dGo1/UAe27NQZYP+97nc1jTUq826uSJguWtBoix5jZrCZi8NYDYfNU3++lavJhP+G4T7jZZxz3O+ynCcfdXhLWk6TeSLlV5bOf+z2wLEVwMxglMUqxPEGkXqLqRVap6YnaV3EwkvBcMWQkr4RqUTogoNYih1dMkpOOWbyRUg4TqVigMjgTqBTURfQBN3sqNuNh0Vz3N1lgOX0IINbalMRIVDxcXcYiJeOJGUX3C0PLyFNL9J5SAqnxKhG8miZHAlJIyCn2Twxmoof5R75/a6AF84yzAggc2nXa5Ib7ajHZvl3gwq7vjkEIgNlXdA0AIBgF+jRvI1M3ob0W1D0TJdLKSCxWPq5VT6+a0O8Ee5eQuTEiw+QW0iXuzN5VBxNgG8MaCHYXA3GE8X3SHrsRgYZ7xt/jWDct4v4eDv9F93uF++9ssy0GxMMkOdPTJOj6rgbKyRNDcgfmQ7R9eGjjXfqMz05KmjFd5l5qMQLLMourfVkwa+Ln+XLBol5C51KxgLCUgsuy4FwK5nlBXSpuDnu8vLvBp09v8OLZExwPe5R5wZt3C765EL4uC06lYp4LlqViqQAjo1IFJmHcrCFkjvuJhMEkamV1KzAJYSFlHWxqgp2oz13DrG78JMaeCS1uFFzdPdMSIu/yDsdpj2mXvbIJKGl+IfFGYV0sTtAqRCpA1Bs0JkHu6GagqeuWZumf6I5Gi8YQm4cQBUbYBG47rY572U6YbZ6iEab1s6LW4jS41Gq+cDDLvMTAJ/UES+Gd8LxTUSDHvEX+O0kiuUSMeREBPKlBp4T58Z/ykCZzJGUUerrDfSx4AwzqIaJZs364AKgR2Yz2FBCZgUJRus2zylycM0RoVlAyT4EEUXF7EDny0fEz+3wFFm1Z5Qnvrhn8LFkguTEneJmg8Uu5Vx/eBMzVX8SBrse+dePQ59IGHa2g+gCQLbS6dXJ4PgjEpmSEFwNgXDdobs3xmq9EYarcyucude1zBAxdP8nv96Fs8DL5W07sex0iKevys1nl1yrk3ODWv8P5oP+MfZKx/OW//C/hL/2l38Pd3RHlcka5nHA+3ePh/j3evXuPy2WG5IPoldOcM3a7HXLOKMsJp/MF35wveFMZ+5zxfJfw7HZCRcXjZcE//Gdv8M/uL7gjRjo94jxfcC4V91UM0fs8SR4dpTHDQQktn4RB1ZzVcJQIIPEKgJZCtnxypZqRA5oHSDwhi3pxLmVBLVJJLeUJL58/xe/9V34X7x8e8M1Xr/HN19/gfLkg7/fYTeLBezgccdjtcJiyGII0GjnV2tYhqNjg5jHRVg9upJLqOWhJpVeUA4wYysC2KcQy3kU8pjQrda1Vgs2qKkg5o7KcnDugV2Na0XblhL12OHRTxrKNsslKoY1r8vj7eBkvspwj65yAsnfFU70WjTgwRdxki+oAa6qIr6HhA/GoC6hGcS+DKDfeYxjbqoFtNL9lkJLPquomFe1J4ZPiiVFgefQQ8D4hgbgCJPNiZcMVToqSnhkTNNxxkdCj3Y60YlQSI7Riy5jbysKLtowynU7iCXHRq0UbBrY4rc2j/cOH4eM7t+6J2DLeQ/5dCNHpnovy0P6T+udtWAxktjyf7ZA0+TibXJMDyJYQulXCrZof7ozz+UHagfE0xbROtwATMBVWlULoLmsuIQnpEyNFTsq/0XhJZTvMzZBgAeF1LUS54Z2qOTDlH6u+3LAIkVXkkg9qYSCpN1wM60/iBSp8XAw8GYQCAmXLlQSJNa5iAJvUA0qM9jrnST1SGR6SZvwxwcLsmiQQccEgqkjEaoTKfoAwiUKg+IY0BFmMVcU8R1MW1bPKuLLpCNw8ooo+jzDHYNIwMww6SIyyUBKrrFF6jFIXVEjVtFIbZnQvLFMj1RaSKam3VvF8d2ZjuXZ9twxCaPzV9lrMdl47PCpTbpvXjEGr09sNg4gx+t7SvlZ6G3H3gjb+Ffsav3ejwIYsiX9aW1uKSDsBMBazraCM16q/V4HviFD7Tlo/10oCOcMbv3fCwzXC475t/a8LxA8wbt9olSWXwlIcUJYyN8+gyyzlefWfl+fVqiy1SKWpsixYlhlEjLvjAU9v9nh2POAmJ2SuOM9nzPMFp9MJ8/mCy2V2i7y4t5MbgUDiBZS0f540GqSxqTpanTjPwwBg51MvrFnCmZJbzota/Z2UlBRIPVUmZo8NzRB330nL1HpOGt1YfoJj3CR2zfrJmvvDqobpGm/RkFuvg0eNLaHlnPgAMdgqDyA7BXoyI28wnmgFnmi4MUXD+yramtOq7WvxnMoOwq1fVtp5WRa/1/oQgc80SUJFG2tKGibAk7p2VmfInmCUGniv6gxr/Mf6G3/a77WakfEDU/c9u2RJ1l4l63vaZTnJupKpTL4F2nMflx+RLlxOyFtWL2aVvl3/yP/jND98iV62eWMuzCPoEuDay63uAMM/b2Mar16eRT5v/1HOsyF2ujmi+KPJ7bHtq6D/Sttd+4zAS9opZOwzO5Ncy6549f2QMdpwVwpYZGMEzwHWDllaO+3RBpBTgpccb98Cz54+wb/xb/51fPLJS9RS8PD4gIf7e7x7/w7ffPMNHk+PYDCmqU8ubGXI024HgsjDN6d7nOYznu734DLj7iCGk8ey4B/98oz3u4xXy4zHh0dczgUP54K3KDjudtinCRnigWqKakqaC00NPFBjGZF4CqUkvLjWisqL/A5CXcTQs6j8spPsUhacl1nCwRYN4SXC3e0dfvs3fxv/6l/5r+Lx4T1+/w/+sZ/47nY7L7d+yBMO04T9XvIt7aadJO5PjV+XkKzfMIVVMrbP3GsokXiI2mqM2AP9c+GvjjbcWydgPTPsGG5hNQYt6gU6hu/wih63MWF8fTzo+JZb6nt5iQeLzVHjl84begdfxTNhrQf+1u4V3lNrq9SEYKxua2ptZUjlL+OQynNUyetKnMd3YIN3drLD8JExJxtQ0nFb5TSlaZZQn+gp6gnSYYdvZkDLAGeYB0orloFVonPfWwN+GvtvOI7Q+Cm4T9K7lmWNl24ecm/M25Y83JIH475ruh+v77d531CfwKyRFuy8DYCHkI4yun//Gme0+ZI5axWXt8cqlx50qlG/1gpOrEnAM5KFHmiOKgvvKpXBxGJEKAUgaD4hgkRoqIeZVQzzXEKMWhcbPoQOi85dOKhBBVXjyY3mrDow/LOWtqLWBbUUr9BoxYYWrShm5reyNIMVGT5g3efaWybI4Tmah7RhbAm/khBlaMJuCROrANqhe8pZDpmNphIDSJbgFqWIbpksuTVzMPjILIhOoJWduWqhhl4/N4OQ782iMpQrCld11ujTWdRaO4MQAO+r5ZyK/bh2facMQqPMY8BL6o73Ea2ZZJtIdJ97m4FRGXO7dhpjFvzO0GNGi64zmzi5M5jE5wE7XYxu2epCSaZAhOS17MEmAPW+Ah+0qOMDzI+w3emtcVwB02N7PAyWgZbnIXxL5m7/kS5sMc4mSCWcJvl8yiYRg1DFMouh53w5SSWxZVGmJQYhO5m0U8rdbsLNcYfjJFXFEhiXyxn3pxPuL2fMxRJmZoCLxsAWZzi+mQ30J8KeABf+1JS/qJja7Cwk1dNMuWSWXA2JpMRhnsxNX0oV1hA6R5xATGoQEVfLNNC40ZjtqZXii5FWpD8t3nYNTMf9YpclObPTjWZkCuCFAlj3WSBQUkNZIKWk1b6klaRMvOUKsj6VUuAnFVAFjOU826oaSChDdiATcwzFZK39vLWE1g7iCbCzhpQSpgz3/rFnYjhbf4LSDGhOE2E9RpqPc/7Dtb5GoAXAjfGN4gINdiTLjR+yJSjUZ4Y9Mhrt1rQvbtOmeBgQ8QZbLzoZZR2K75V3W+jg+N52n7cwyMHG3sn+v5ZtvA4xGYGJzdHW9/Gefi4MLMsiUD/Yzf5+28v0rRayxbDqbjL/4xO8+pWoKWrefwW6ztM25wGrv+1k1e5f80T9zKErunEzgL/4e7+H3/i1X8c0Zbx//w5v377F6fSId+/u8fD4iKWI50msemgG6t1uB5omMQbdv8frN99gAmPHBWUH3Bzv8PZE+EM+48ntDZ5/+QXevf8G81LxZp5xSsCz3Q2OWuKdAckFlDN2RLjZH/D06VMpyrBIDr5E1TFZXSqWecZcFpQqcrFqSHUtFZyzeAiV4PWSgZvDES9/5QWe3j3Fjz79FL/1m7+JX/vpzzCfH/GL8wmHacKzuzs8efoEcylgECZK2E8ZdzdH3Nzc4OmzZ9jvW9EEM86NEYB2YsulGW2i9AXQQj5r5L29UbWvGMVKb7zCjwSt4BQMU2A51PmQPL2GdUYM1xkyvJ9NLv1wyeWFRtCMEHLJ2nkyVkog6j1bTBmLf9tupzRi7uj5R86bKmpg3yYNxnVfy64VTwy8QpFN0wfY9IZWir3DHD4XrZ+MqoYX1a3QwvGdn6LPzVmLvp2SKrCtX1tGDsM4/VhXYiCulj+3fqZ9dw0XfczAE7/fqhAW7xN9C04Pht9dFTTFRt6EZiiHY8/IJTj+Pchc4yvrJR8MSJDExfOybI6xu7eK0QAhObUnqi4tHUItC5ZF0mBOU0YtCyingGHYPWFEPAqt2aFrqZY7qPoYmBHSLVgeT/g9yQw4Vb1HdZKIQ9Jkw8/c9x8s7aSUcVnEY9Y046gXgINHqHr0EkkIWNW5IRJ5ajpEStXzm7IZVmsBkXg4VdP1ipaOIhLjUSlICShLAVISf7zKEn6pAtX2ra2XGT2rhdeRFSQJhAJ0NOEHGASN3KhSXl71qKT7X1iK8oTwLINdvpsTwbXrO2UQMjDdfQa0zWhg2xlcTCjbJm2LQWwl1r0WYhb7E6XsiJEjAMcHGNeqXQcl5B8YG2+Z0oFWZUyeGY1BW9cWqGgfiOK9OrX9QH+3jEr2OW/NGcKGREfjq78NJFf0ydxW47DntC/i/pgRIJ2409WKMhcsi3p7zBc5uUTLeu/RVjDLK7Db7XDY77DbiRtsqYzH8wXvHx7x8HDCPOtpJsyIIQuYkyWGnnxObWNnU1RIE6FxdWNMdzpIScobUnPfBIkrpBkDoc9NOeNASTyj1JhxmRcUM4gw+wCJpOIYmQakHRPBYbOq8w4pB9zmfK34xYTRY4WVrTWToaWOCalh34WkV6fhZkmPyhU4UCo3QcncTmC7fhqQ09HllKVcsY+jARgx3CVvZ0wiPRq+bA6sX63kcPM8ApFUsatCg35yPHJ7nyvu29XPSyleWWzLQPTDdR08kkpG2ZdWNUn5K4VnGcFEKqFlMefOFh3YuyIIJtvkLhPkp9tsCaEtwIkToUPG4G08sXSojUvbaratQVF0TGr9XPPijVnc/LY3erQ+jN+tL+uEtbPm/3/Sa/0+ZSQMtKP9AOTR5tx+F1qweFgdEwdcr2FDETtsGfwArPhCdaQlgLXRhsxuCKhuI+C273/nt38bx8MB82XG/eWE+/fvcTqd8f7+AafzGZJHoecPFq5Ra0V9eMQffflL/Gf/8P+Ot9+8Ac4LwMC0v8G7AjwuBT8+Zhx/+Ut88+YtHkrF42XGPAE3uz0OpaKynG6CCbvdDvvdDj/9/Cf49V//C8g5Y1lmXM5nLPMMqJx9+/Ydvvrya8zTDoWl4MJSK3KeQHpYQyRgf0oZz549kzFkwk9+8hP86NNP8ezpUzx/+gw3NzciH8uM/X6PJ0/u8Cu/8hkWInzx9WucTmcc9jv8+Mc/wq//hZ/gV3/8Ge6e3oknrCam3uKR3Wc6f1KBxxS95ulsNN7zW3bwPq7d1nuS0lIXduygHa5ob/VvzAlk17pCqHlTs/a/lV/+8F7/fl3MbT8CPU+AGUdUI2Ut8iH39ftcLup+xO8JErbIFWjVyqyNxp8IGrrvQmDgXYGvmOEgGqc7juwyzTw3lL/BlE/F1VxDm/1cxHeN2LujP8pAMi8KC08CKJmi6YJHdTTpcw3ys5eXwxxSCox4Q65d0T1G+f8xvWvLgBL/dnzr/WL3yreyIJ28d7rxPzff40aKQFej8S+qYFsHEAQxtCzz7DiZQlvtGZH44pkvNFlrRaGKeZmRkuQHyhcgJTEcWFLnkjS/jAInj8yx0DCtZlfd60S8YWxexEvH+iS5hlrFr+p6EzOL3gWgcIHle7TDOPMwq+bBxgGv1QrG7OPXFsGsPJqoHeqpgLd9xCTJnRmat2gprohULl7cIUa4eMUzNhzVwuRMdizzLH1LrBiAQaVB/i2jJZv+QHBvLNtX/r3pWgN28MqEHbjSFAlBJ7G1NS7lnC+E/21d3ymDENCYlUx6p8uOd3aMYMvK/iGjyRbj3zqV+RD+9XuwAZqVsMd3jH2+BhZlDmQb+dnCnwBdbzEWc5cb3/ex66pFffMz6r7j4dtOKDiCD/0NG6nNQ0jMxYxp2uHFi+c4Hg6SRT8nMBdcLjMulxnzecZ8aSFk4moom2IpFaWI67b9fnM8IOWEhYFzARaueDjPOJ1nzBdR7llBBBFhN2XTLWRtCJDsCaqMErQqWqs0Zacrk3m8GCAl0nK/mrQUmpSTVNxrJb2irpSJJNn1XGacT2dczrMkukaVBNIpYTftWpUrXyTXWvoVUVosEEik8kC+21j2aAjaFH5Du25QwZqOOkOQrTEaCGZV7gGbH3j1naphY9D+RmMNdJ1BNbjwNtB3zZhpBqHoCh1LybdKHY3PVFZjIyXkKSOTnIokWEJTPT0J726eTbIucV7GcIJxXn+4+svCIZsR0b8BzBDE7WMiOy2xeY/u4R3b3lT+thUGeV9vLOiBd+uTyQajb9t1RduFAOQIkjtDy8f59WjkH/diu9gaXY0v3mHj/bAxaH199GBkQ3ZvAfst45+DNJ9aWrXpz4O8YlT3zjgcr4bA3ZQ0GdRO8txYzXCebYcENmNtDXolKO7l3W6HT19+AgJwf3+Ph4f3OJ1OeHw84f7+BGH5oqhYkYT379+jFKkm9s033+Dnv/g5fvHFFzjXRSqgEEBTBk8T8uGIT3kGfvENfnE64WEueLwsWMC4oQQ6zzjVCprFcLE/7vHqR5/gX/7L/zJ+46d/AYdpJ/1X5TMnQllmvL+/x9dfv8bDrz6qQZ1xulxQWOlJZRSXAmLGJy9eijcTgOevXuDVq1c4Ho7CZ3V2CwO7nHF7c4NPXrzUMOmEKWXcPz7iN3/91/Hbv/4zPHtyh+PNDXb7Pfa7CXn0jhlIblN5dIzSvDaM5CJ9jXvmQ8Yg+xkrXHJHnmsl9xrtx0MINzyq7DEltHJF0lC+Jqf/BADxe3JtGQvWPLBXyrcvMwJs8P1K7Xe2NoXXy6sIUuTAhELDIvKMeH5c817p6Vf7Ubl5mmuOIwnrIrgsGviYGTokpMh0j+bR3Q5K1EBSCUhm5FY5ZQq6mB7gHpobfJc59r3fJ/098O+u6WXX129jjMM14tStfqydA+IzRhuEWlWGR3BsfG/jndd+2u9mHGgeNU0+1Fpd7zHMGwTyao2tn4UFbdbKKEvFwgvOgOs85/MFDw9n5EzYTRN2Wg1S8sE1DG64yOeEi1YWk0VzncX73XipFdphVeAZDK5FC6zoM7rennpDnhaZBzEoeeoMn2dpj+KAOXnUTUWgY83Twzo2aaN9ZkqcYQF2L9DeaUIMUyYHWsJnJ8MK1ERiWHL50ryC29rbc8Yn1AsKxqNMlwSKeoNZb40m2ULSBjoDi1HJTD+Vi9pQNLm8eVwBYWTr6ztlEDLm4LhCLe8dHnaDQcsZFI0Mo+Dthbo8fI3x2r3+PQfWfgUL0/AzvNzBJbkOyWj4JbiKBn4yAlqhg/6k97pS8hGmeGUM1wxr/6Iu23xRSZLOypeWjNQ3LYJg8D7KFkgAXr18gc9//GM8efIUN8cj9rs9ylK0tPyCRfMJgdTSLf7kkjxyKVhKwbyId43RTqmMcymgeUaiBfenE86XWeJCzQUSLInZNH62KrMTupTBJZAnF0sgV/BzSsjEyO4IY266VUrtVnGNt77Nc8X5suB0ekThipyAH336qRt8iAllrrgvJ8zLgpwJabfDbjdJws/cDAtRj9wyTvo+svWw+zQhZh3oYgTY3UkFG8tRsK1M24CSvz6AXScHsph39ufsVAEsRrHmGRSBTPJ9CwhjT2xCHl7uvTJjqRVTSl5S2U7ft5TO+HsD/CrtfErJaVr2qnquTQSqRfIdMXfteFuKK4qCfaN4EQpV8dcPIN8u4+D2V+Xq5+Ou5EX+aaeZZKfqrRUBQCpcgjIQ+dMWEO0KD3SX0H0Ekz0gtr+5B5NuSGhj9F/MoOAA9Doo5tB3AyUGLuz+doAR5GX33vUkeEGEKBPCrxQ6vDps0J8eDuvNmMBrJ99Rlo9XhNs+bpWpZqCRpI+02rtmjLYGxLOiUQIa3OxkbPd+439NGslqe6J8mYgU6cOhl7/Ynzd5+Pz5c9ze3uLNN9/g9euvXMZdLiLHHh9PePv2LR4eHnA6nfDNmzd4/fobPJ5O+Prr1/jqq6/x5v4dXrx8gdsnd+LdmgnH4xGZMg7Le5xeEy5lRllmSRTKwJQzUhH5tacJuycHPH/+DL/1W7+Jf+kv/UX8+Fc+w3F/wG7aYZezGF6ylOd9eP8e37x9g2dPnuLh8ST5+WaVk7ogl3mRymCoePLkKXbThPlywd2TJ3j58iX2h0M3t1wlYec0Tbh7cieKhp5YP3/yBD/+lR/j5fPnyJkwZcmRMeXcyi8b/uOBBhmd95DRWA04JNI/heegxsY+jOy60teUu+p5jKxNqTYTKngOdN7zGHlPO9Ahp/FeWen3KG8opT9cQFzZxmPid4CCUAx2gNYC9XTl9NStRZx7Drx/+MeAMS9TXEUWWU4W75HSdcT6DEZxfubKpHQS5h1khkPSNljHIF/27X1ozozumtxQLOhh/W1eDGMSxVxpDc/bvYmaUZMDTxzn1uYdgKce4OG+jx1QrGWJyTfvEtzJx5V005WCzDN+MDTlzxi2BTwHW8yLY+1fq1wbf498xMaecsK8VMx1kXAwLeQjhUraIWbru/KtKoakixrt05JwuRRPKm29kwNQnRItN98otuqhLSMr4bkxJ2BWea15VFHT5XXsILQDVW6SUfA5a0iaaQ3i4WLPWf4iDu/0Pah0UFQPaGXZ236qVeSJWMkwQi7fRzKlpKoHBzFAaphKgJQKUMxRXb5U7sdgxahaKhBGzOVlROQyBAiBXvqsRlY0zi4GIdi8BLwheyS5l5flKJJ1kOIppZago21f3xmDkPXT+yoz1APWbhzxBMfa6Dfgh5S8tYLbrPncMQB9hyO/9bvWlvHGeEwZMQbug6PwHmrviW1HMGsC/9tYx6+dYm3d++E52b4iEOruG+isg8TB8BB6Ald4gJYQzJ4fmk4EHHYTfuc3fw2ffvIJnj57iuPtDShlnB/POJ3OuMwXXJYLQMCUJ2FwyyJW3KVIufEsluTLMktSyaSulaXislxQl4LT6YxlKVjMA0QZ3pQzppyRKSFp1SBbpylnCdNCsyMbY7lcTjhdFiy1Ytbk1PLOBUtlLLWglOo5gmoVSz8lwpO7W/zo1Sv89Fc/x2E3gZhwejzj5198gXfv3julCoi0CjDqGpmawiOT3JfnjUYhB50OeFSZQwMVcQ0jsPXniSS+NbSdQG6hJmWwJjHGk9BmDLKuyEkBF7GaN2PQGpC7UCRC4qb0Vl0DrhWZCFQ1mRskrMxCMKz0OzN7DqCYC8JyZzT3az0588pXpFVjs3h2UZIqdKVo1Y9e6DPkpNeS9xlNUDZwJ1UJam31+L7Xl/Nh6BxljQmLwC3wLrVwJmJUz9Fm68YgD8s0ZW2d1DMC8o+B0Mi3V/zVDBEuyFTejBVsuHlkGN8X4OSDWwn1prC0vsXSq6t+dh8HyO5KDIdv9BkDWAFTy88g9zbmw4fo97Z+mvfLx3TZra9Mpnb3MK/uNSBlX0Qwad4lDZQNnkUb6wi0mH6/x8jNeKkbkOxzA8nB5RxSbv7Lr77Ew8M9pp14JS5Lwel0wv39A7744gt8+eVXePvuLd68e4vX37zB+/sHLKUq2TN2+z0WTni4zMilSB6IyuBlxv3ljJOuZ0oZN8cbPNntsN/tPTTscDzikxev8PlPf4LPPvsRntzd4pAnHA9H3ByPuDkccHM4AIlwuZxBVbxrhX0nPD4+YgHAE7BoqGwCYT/tcHNzwN3tLeZ5wd2TJ5r3Z9+tERGhqO8yZcLx5kb5osi+n/30J7g5HMIJsjyTiYCUwFlOkBMPtewCLUS+buvMLGHdtpTmos/B4BuTwdqz0XvV5EPMZSfKnIwomVewhtAV5iAHBwU0jM1kUXtXv41jjgg/vFyFln2/r6oKUixQYdfqwFWegCGekeM4789YXxabg80vA5uWnd/kifVD7utwb+Qfkf8QAG4KaTNMpQa2wV0FRMdT3l17/1rWuVxC85zLyYxoMYmtykulSyJTzJOOuR2MGJ37IZgOo1YGpZa7aVOu2udXZG5MXbCl32006Evb+t/yL/nnNtVWyh3N+cAOcQ1LEILcqOb10tprRsi1l3fUByOW7n9Kn8/ngnnhUAmx8a71WEmpgL2wS1XcX0rLQ5QUdybl5/IZmb1B9Adu3q9JPctIsSqoIKcmh9thiB3OUjcXQg8jLQGMBVaxWvZCGAkRJM+O0g/3ibXFSCQ/U9igtTilydwWw1FZm2I/TBQMWDpdSAxrwRClvKTJAdLqz73Xr2FO894rLJ8RFwAVOVOH53uDUH9QUOt2vp8oo2onr0Q2G41KxeXka1pLC+u7dn1rgxCJmen/AuCfMfPfJKJPAPxvAfw6gH8M4L/LzK/13r8D4N+G+MH/j5j5//Dt3rH+rBF9+7sTjkFgbxllbNKiwmvKGKmF1QwtjUEb4LS/I4UKFVyb1L4f24zJTgYQ7ru+RP1Ytt8T+uYtBfDN7etYGeXaez50fZt7EHtxDexzvGutTI2nMqTuYp+8eIkf//hX8PzFM9zcHLDfTyhlxun8iNPp5FXFQFqRxQBfEQ+h3W6H/bTDLk9q1DEru+SRSQvAS9XqKeaWqeFDZNZzyRkjrpZS9rMU9VB6fMCyLICCewJhXhacLxcUJiwFDgoBYZ6WL4iIQDkhTQmHlHB3c4OXL1/gZz/5CX7l01d49fIlAMbjwyN+/vNf4OtvMqZMWCCJp6cpY7+XfuVkuWlawsDOgKNeMjEXT0qtMDURNQYV1nCrEsY1uoj7bbyPTVmkPoeO3AMF1uZGy1iWtVGkM5z6/m57I+esykvjEZ6QmiomTXpqBqFpmiQpn47RjEJT1fL1RABbKVfbvqTAQoVRKgom7Cuhu0zZq45ZX8Ux1rCc/k/72Ly7moL+5+H605YTlgzQnGOrVj0yser0HhVISPU9RODHAvhgRjw18DVjPrVcI3+CK/JqA3QCGKV/9t3Va1juKLdGQ9DG2yG6YUJ/Ptn3rZVAHjz0MIQtsIGoVtY29n90s088GlU8IEfWyJV0VTzC++vWuMSSos9Rkwnc9kx8fxzjOLZR6Y6fR5kzGoTsnmvP29+e+HGcawd84W9935dffon/5B/8A/zkJ5/jcDjgcrng7du3+Pr1a3zxxZd4881bnM5nLFWUwFL9gFMNGAAK43RWYxCRVCMTqQK6CJifcsarV8/w2Y8+w+F4xN3dHaZpws3NDe7unuDZ0+e4ubkReag0kEgPP7S6mR0K1Cr5KC6XMy6XC87ns1QVg4TzzppLYr/f4/buCQBCIsbNzRPs90d0XqBtAjsDx+FwwN3dHQ67ndOB5XhgtKTacuiR/PNuna3NQUa4PIN5cbTnSi2ODY0+x3Xeoo9NGtHnU06OQXvMRp2SaJ+bLLQccq34QHsPabGJWAH0z9P1Z6NLNEY6zs+WgUg+B4wu1t+RK3tCOOy8CAAo8DR2+trm9+v+tH5ZmMtKxY+4OGAEoVd9d5KwEzB3e6xXMvv8j035Db5O6nnneko3BtWL7L2+cWm116qNhbb1pbg/x/kZv2NgNZ9bPL/DuMP3whPanJjMN2ki4UQcxiHrWnkreqKXB6yyKvKxOP+tOFKjGXkl+3ij6O/mi4F5rhr1LN4617e8vIvsvazeK1S9fHmYUcmjWRoOr8xAlfyo1fKReli+k76JZu+7fQfInCVP9CyJmWX+mg5CGsokhgvStQmhsQTX3do7ej2ira8MxRI2GxaPB9+mbxf1KmdmcPCSEqwXDfBNrthakodmsqyDVXFjo3nzzmHVCczbCfp5BVVLIt57/8VDd/+MKyhUNLZrxCsRa7bv4Z+xKiMpTR89XP6TeAj9jwH85wCe6d//HoC/z8x/l4j+Pf373yWivwjgvwfgLwH4HMB/RES/y1KL7ltdUVCP13UsPTA4vVb5N3RTCsOsWrK0+mc98zYWGYQF+gUZGUX3fFCIN405tqvsVddGRuEmAyzUQCZFTtL1vX+eWa2itD7l/DbXCIrb5jaJ5qkaZC4D8MJwf7Rwj+2rr4UOV5kqMXIifPrqE/zo01c4HPcCirjidDrj/vEejyc1Cs1neU8iZJYy4QsWXJbi5cnNAGIlDZdSMC0LEkn1lLJUT95sAHyuEkObSKqeHA57HG9ukKcJhQhnrrgUAJikjaJWZGRwPgBcMWUG0Er5TnmSUug5yYns8Yjj4YhPXrzAq09e4uWL53jx7BnujkdMecK8XPD1V1/j4cktXj67wxe3N6iPjP3hiKd3t3j+9Alub4447PceBzyCVV0qAH01rNUaGxUFwNK1MQhmBxpRAIcwLhPq5Irhh2nPBMpYYn58LwKEMkOQXSlnpPCsjTdpMlJKhFQJu5SBVFH1NLmEk9+cEnb7vb+KfO+Zy3DrR7I9j+Y9xCSOprGqYRhk+1X/mRJg//6cXX/qcsKFoMbYxxNzE9qg3ij0gcZ0CahbCxPo/7yX7CN173XZ0OSJ3XPtHb2BIoAa0GoPyJ5aPwvAnZKUBcNCycb3eolcR30eXQBz1TVwb3qCJEodeIL/zzqsQDnISD8NjDIB1qfqCrt9T9347T2mpCl/C2MalfZrCvOWwrT1/bXLZVkIaYhPRGVo7AcDePP2Lf7zf/T/wj/+L/4pjscD3r9/j4cH8QBiiJdo1bFVBaHM8LESMy7zgtffvEHWWOSckpSEz8KLTGa++vQz/OjTz3B3d4vb2zvs9jvkaRJvITU+CBcVmptycoOL8K0CquzVPOd5kcOXy0UrPJriU5HyhMPxiJQS5suM3X6H/WEPM5ylkWaoHQ6IQkDY7SYkltxJLjeU9qaccdjvxSNXZYzDqWvKZ8AoYA40at+tZeSI8T5GC95HiLF/UsOa8XzhVZZrorYE+NQqg1IIFevfr+OzxK/QU+qYs+gj9Poduv5MdIleWVp/Z3zfvS+NV5lcX91vSqPs9MqLnL4DAFdIZcg1To6fXTNmjHj9mk7RePk2ZrO/VzxQvnB+3RlPmJDSrv2tDhkpBS2/td408Ob66frRt+G3vt+u9H9rp7nZ5gN7+6P0H8Cs+K3b7/BxctiT19qPBoroNdJkWcuTw2wVsrK+ww41GMTFsXCpdcNZuP1hhW3MeLDF7yzPkBleZF2k/coVGZZaQZSzRObF0x/OgGLBHKXHZOnrqcllMn2UV6G5FhrYDgBsHuO8qlEorIXPZbjT5IPodBvpXpT2bH19PFjvx6j32gG/YL8MSklytYZ3xSTTIKisl0OSrJhe3p9g2Y6YsyaxVn4hhIuUMnKKnoStOE1l0W99PGy2i62y9KKbSFqQNR8gArLn1mVvQ+Trh3WKb2UQIqKfAvhvAvj3AfxP9OO/DeBv6O//SwD/MYB/Vz//3zDzGcAfENH/B8C/CuA/+TbvaoP7k9xrG7L9PQLm8WqguBG3MTX7nrvs9wCgm6kj6jUIbQ91t677ElB8s0JeAZCDkFmBFGqsLj4T1IlvxTi33vNtLu8PWRtySmk9qmFt2qaPAQf6PmojEG/ElgfnsJvw8sULCbEBo5QF5/MJ94+PeDydsJQFS5E4W1vKTJJrIKWs1mppr1QpQcil4lzPcuKplcYySaztsixYipR7rFJGAtM04endE3zy8iU+//GP8erVC3z6yUs/dV1mKcE7zwWX8xmPDw9e0vx0PqNodn4jjmmasJ8mgBn73Q6kjOPm5kbyI+13uLk5SlJOIuR8wI9efSJzS5KH5t37exwOBzx7cocff/YpXr18iZvbGz9ljGvfXeod03n9BAX2QyvfwHtyI4sB20YDYhgB0Mf+DlVbYhJlK8doILeU3iXf3i2CLXUWesM79p0Y3LKsdWkY0vrLkO8J5nlSMOXsichtXrK5/U9TEz6Dodh/tz7qu7LFAXNvzGp4qqnOopRUJD0VYGZXHv48XH/qcoJ7UJaUX/TZgQ3UDTyaOSjszZVdPvy4sveBMW8qjmRoCs3r1BPfbLTte4D9P4FfayADGZ9Vqhn4v59KDQqEAaqtqwGiRp/Sl8a7/T2EBloJCIW7uveK3culTjdX1hyPnzNg7t3xXmvDZFnQPrx5jlMR+JfMXX9ivN0+rn42Phfb7T435hOULjOQuPI19KkCeLzMeDhfwKaFwTwzTe0kD3ml8Lz5q1cWz5bLvHg3bF5AwLMnT3Bz+wyH4x0ON7fYH26Qpx2maY9pmuDViQaDxJQSduqF47uG2T0urTIjq7HegHbOYjwnAh7PZxADT4/HMLfmmdNA/oipmLXiX06gIp+bkSSlhOPNEQfNcdR7l448doMOAv3GteUajarkfYxXrLRp8i/KIvY5aEUJaqkuJ93whXVVMbIxqvdTpK+Or6CVZAZikYUaVOzv7vVnqUtw4KXCKAJvZIACMRheEXbYyw9pKxgDiMBanl30UONNVpoDiLlCruF470gwfvs7jI1s8amNDxr7M97TqltxA0abY6KUNTG27sk6Gh7GPm8dECh2QYJ5NWztHxmxVVHmVZ8iX9jq67Vr1Fuu8XIOexzGssNzjRaGhyJP5xYaxjyUjedmdPC5Z4KVRrfxSWUrwe/MKm1dzEY9jcHIuJwvejAKpxUj7yi3xStLC9Nk8SRMTNhpwZmUyEOI9tOETFKN2IvfJIlSIBCmZPxf51TzsZr3mECO2o01GiW84pfSinnhWDQGhRxpUYzGy7BbpONSSh+6GyqiAe1wqxmENB+nH0qrMajbSazOIWKwr8wgZK8GZitRa3VML202/iJwz4rIwPMaiXGMwCzeu7DQODVimb7jxi6fDwY46VzWMJ/ZJ0rSmTRvPtYcU6aDGZ0QLJzz+t4Avr2H0N8D8D8D8DR89ivM/Me6KH9MRJ/p5z8B8H8M9/2hfvbBa2u/D/gqfE7+81oFni2DSiMuAyKhwtHK8kgRB3fg3IDH2J+RCUaX0tFItbb69e2NTOk6g7sOcKUPcNrr2kNLFuxC7YrAuN4wYIpW/F2YRfO4EoWGVicbYh0fCZRtwE3x0Lb3uwlPn9whUZLS8vOMyu9x/3jC6XLGUhYQCDllN+AYaFtKEYZAJMo+MXaHPXZzq0Z2engAWCznrg5p7ozDNOH2eMTzZ8/x8sVLvHr5Aq8++QTPn93h2e0dbo83OB6O2B/2OBwO2B2OyJRQ64JaCpbLBW/fvcPpdMLp9Ih3797jcrmAWUs26sloLRW7nHEz7XCYJuynHQ67neSG0OnZmWFsmvD0+XOcTycs8wWH/Q7Pnj3H3d0t8jQ5k+/WnZoSBwOoG7TjoJctpLL/3K4xya5hbfWRcebdrbuCkxHw2imnKRyN/hoBrxReCgkaA7iz+3LOmELOoajMEBEWQEoX273ThLxIricJjyiYaMFiQlPLr1q1qki3zBKaNBpeU05Iwb3f+8qsAkT6nDXXRNwHIiC++0Bfr7+HP005QYH3I/D/DdbXKUcGtE2wsxlYzLV2E3d/uB/oAVDkn00Ij6DWes49HQde6qFRYV+YkRVooNoNUHZC5WChhcpQbNu6bry5+7yFTVu5cIMQHMZEMC8HOOAQ7JHaxofsDW+BuVX+gO0J8h0d19Oq8Kzkoevx7SWdEc6GSaShDOsxXzPoxHu2Pm99Xv/uzzWm1xl9bFz2t6mfXc4Zs7Jxwxbu6G4sAka72gbLyaI5nMW2DUxWfShNeyBlMAhzqVgY2OvJLCAHJZSSV5hJGmqcU3YFgtneWTsDhFnijK6JgGnaYcqTAOVEUlK+w0vbG80NUgSYQWjxdRceat60+91eQsaMJxMhGhMtVKUjyo3LAbPRNre8fRWt5G+khy2jUNcOEXa7HWqtfhAUjVms+KKgL//bEkg3BSjKwBHneuizrokdjPw5uP4e/pR1iZH1Gz8zhQiwNWUwF8GpINtdqlhu5QQSeqq+0c1waF4SALPVnLZ/7VrzGO0cre8zrhgNyfbstX4ZjofS81a7rQ12nkUEN3BRklBErk1PWuNz+5u0SA4735Y+x4pT0ftTdI4u21Vo3xT61lYbr/G9qDttGU3XhokrXmJKGGMb0SjnPyl3K8kcD3mCpK/BGARL7O1BajqftXtufFfc80TifcqV8fj4qAJCeF3r87pfCQk5kfJI0vDfSfJlqkFoykmLBSSkJKHBgBSjmVR3yJpfKXqhyHw2LzmAOxrp+RSrPNLQQQvRB2OpCxzT2xx5dVVahbyTJmy2nD1J940YQKitAlfBHxUAJsndSQ1zsVZ1NZ0yXkTQfLJ2eDABWd5rhzQjW+DU6DPp3FeV66XTbyeAqiaebo0YHuJOzwp2DfWQyET6LsELVvW0w0kgVBY5Uphdd9ZeAMz6+XWZ+FGDEBH9TQC/ZOb/lIj+xsfux7YEXnExIvp3APw7/oDyRQGGDQS5noeQJDwITG1LXhI3EvfVxCJjGZVgCsjZ2Tiv7xv6/9HPyNsegadWv9HkbM4jqGdIkZldMxoRkZ/abh10GzBi4v4zhiRFZiUY/dphW5jT5qPTQJ3DeBuzCZeWzbTrq5+msFT56Hq3BbItfwdL34mA/c0ReTehkiRhPs8zzucZjw+PmOcFYJLTyZRQlgUPD494/fpr/PLLL/HHP/85vvz6Neb5gt1hj8PtDZ4cD3h6PEgZ91nK+kpJehZ3P4hl/ebmBs+ePsHTu6d4cneDJ3d3uL054ubmiEPOSFXAZIIYBCZK2BMwTQm1TFhYcsVkFfSJEvaTuMTXWjHbJmUCcsb+cMDheMC022Ha75CmLN/XCqoAp4zdbo8Xz57j9niUfi9SMW2/32Oi5PkgCOTVd0yoRkHSCU9fV1mDCl6VZ/+QddnplQCEjP+jUK6Au8iPJdatnxU9rYuwWnvGWXzy1r6R0DEGc9J5a0nXUCoKz0CeUBLrIU4C5Yy822EaAIeFkeVKGgbXQIsZHZkZhcTAxFGwgzClJAnmUhbjaKkoaQGYkUL4QEJuilatIKQQEPXdvf4s5EROwrMUhigm75U2B7sI/DJ8ZzyyAs4widSodOVU2LumvJxMSAGqYGgmKEqtDYaDD1CVdwyD74uNNeN8OzjwkpRieCESwBNcgLVHgQ0LTybrP3HHk7vk1EDg7faDfb/Fdtrpbru1gX0jWW6Y1duklT3T5S2398nzBIonqRHsexu2vgowTQ6afsPeu2acQZzT7RCg8bNtxau/2EBK6JrJW3Az7BgoA3Polb4jNUVkxCgVUP4rsoFYXP+rgr2qxiNQO2mG/m0ihaYMynpiWAtg/6h5mmWTF8mUBzO0tIEtXDF74QOgsmTPq2aQVwVk2u+QJzOaZ3EGZUmwb3guEa3WIUEVDZL9sqjstyqQOWfsdrtmtM9ZjFl62lq9jDZCaG6TZy572PLBCYCPc+9zyE5hrs6NxsOohMbPzWPWc/MBkqvC96p4J1ufYjWxROSJzu102ZRICn2tpaCWIjmPtBBBjfkyvqPXn5aM0LZdTrx4dofKyj+ZIAp9/1jDC8lhLHOBW1XR84SmW7DLZyBLpUpvy9aUACzSDlvIR8TvDMYCQgJqAjyMpHo/rY7pyAu3J4hUfpiRkfqZC88mLaZg91glogTN16WG5qR4nTqvVpsDk3t2OMFww5KLlyabAHhJ757tVm9Wtl1rwPQaq1wY2+wMQLY23PQFQjvs3tqnJrdiW3F8tkLVdMhY2QlSpEIu8/4mxSMM8d6wRgjiZVJgYe3GpaTPVgmrea/TMFZVGHC+zGHeVEbCjJiqV6nxiCiBmNRbKyFNwlt2U0LOQku7nYQvJTWsW1XHnCUvaUom25tRKKuQJTVIVeOVDPUeEn3BSNCwmK9Vlv1Ya5H8cGzLbcVUktOJhJGl5oGToXpgBde4H1SHZgtFVpxiSnG2WVe+bSvvOJGb/qyGh0RZnicJ+wJYcyppCBxyh/mFDkujXd3FmRPAahhMSY0xkl+pwyi6n4zeGi3A50vyeslYpLqZyNhsZOvvlnHkSENG2URI3Bs3x+vbeAj9dQB/i4j+GwCOAJ4R0f8KwC+I6FfVov+rAH6p9/8hgJ+F538K4I/GRpn5PwDwHwDAlIjbBkUAlT33r/3zH+y0MefxXgONkTEZADaA9KED+Wh0sp9bBg32l3yAiQNtU1PvhTH2ezUGwBnix4xWbETf3eeoR/F7YODebSNBG2szsNkzHbN1haIfadv4xuh7sLYydoX+2BxWAOfzGV9+9TVevXwpOXIg1ZwulwWn8xmPj494+/YdvvjyC/z857/AV1+9xtv39/jmzRucL0tLOpYS8jQh7zSHwr4BzKIhYkup4Frx9OkT3N7e4fnzl3j14gWe3N4ip4QpaRJVZRieJ0BPVb3KV04oJRgVlgXz5aKnmKRlgCetYEGgnHG4OWLa77Db7TRULCnga2ua1K08UfKwJwI0H9Gk3iYhgadJa51PMo0jzL8pnIBa+jdAcFyrXpg2AMUUaGuDNsc2xhOaUUFyItq8+vevDUYZOTFqmrVqggBsqb6gc5JFsUg5uYCcpqmd1rjyHX0U2jvlJ2BJ8kop3T1SkaCdEMc8RpWq56qU8vMVCRnm8i2Vib7bQF+vP3U5cZhSm2xaA0TAPjNDzKDIwdaLGgCwbz46xe0eky2km0jEh4ZQujtwe44Cb4/cf7U3Qh+2vOrkT3XtXu2rXha4wYjqqh1/Pwig/jTZZEq8Nz4b92sDLw2cuxwfnpN56yfZvE/C65VFre9fy4j1mLwdb1T7pj3bMgRtye+rcnelVIS2QhPMW1hFAbQBeMCTe68MQso+C7fnheT19F7pLfLZ+G5jUmKgoKY4aUW+qBBRavdMKSFb7qDUG+sRPF4sDKopq5K3aNpNmKadAu9embZcCeabBLY19M62UHAST1kzBJkxKKniHKtH9WsyzAXaGrlsgBhFm3KmRhZVqOwLMzCSKjgRB8XLvaXQaGk85bc8R6Zw2P7tS8uveUErPtF7ttpPWZba0c53/PpTkRFALyd++vmP2GSAyWvmcDC2whxaXamV1Fi1L8tTh++bHIn8sMMhznO4a0w8AizHXINnhs+uGai7z4MC2hRwwPdUexhK6RoK4x1pXuTKoxrdCupuMLzx6n7+TDlvPh0r/u3ykl3tGMfmY48y3WZtQ79quo1cMe9WXKFqxlTnBbafgDE/i+010n5QeIEZHJq3Y2/g699toWLo5rW1EXvIbe3DfET+WrniMl+irbKfX50T8dpkMAoqsnpjyVg5seYRyhpiJXgi6b9svCjwZEYJmEK8Uojt8EZiPiyROem4YuoTCR3sZQWD1SspaQgUtb4DgFUK5oREGVXz6SWVDVKRrDmEjB6bQH9AO+osslXsfeaRCdVJh6I5pHqWkAqWRdJ5lGUDn2lYWktMLTkAHW4qf2CPDZR/joGIQ87GVhlTF0Dkh+fMFI/eWkrbALYfgh4a6cTXcc3auuujBiFm/jsA/o68k/4GgP8pM//3ieh/DuB/AODv6s//nT7yvwfwvyai/wUkEdzvAPg/few98jIYNmh/UrOCdveh6beNAHtgGAFWc3szhts+M0agYxzHH9pcW+q3AGMDQ2ug2Z5vUoAZrqwaM9LjKx9M7JVBSlaGMxqp4t8N/OnGRTulpKC82DOpvcC/83dHIGlKwUoxWQ3bhuDDSWHT9PdEJhkEhr71/cMD/q//2f8NP//jP8bnP/4xnj17hpvjDc6XC15/8w1+8ctf4uuvXuO9VvoqVZ7VswlxpwOhLhU8n1EfzyA8AHqyzSzpbSiJy71k3Qee3D3FSwWTiVI7zeQ2fz3t9YkhmSU55rIseHx8xOPjo4SpnSVcbZoyct6Jgep4xO5wwG43YadGKw/tI0IiTUCnDFwShyV3o9xN4lafU+72hNOEAxUvHtqWqxOMYb2HNR6TI0cGvF7L7d9N6MVryxBkgkb2OqPlvMCQNHgU0u1dXsaXhP5rlTKXJkxEsMAFWyz7a0zYFJ+tq8XnmthkjRsOSE/bZTByFWNeBSOLLR/Qyh6VxahAgJ9y/HkoO/9nJSdsHxgoM1oWw5nlk8ImD2Ljr2jgVlu1O1YAoqdrAb6RT5kvG6lwx9CuGyjCFuoUdKz3R2dcIVVg7ZaUWvV6G6bSjMuJQV5A6TKFtpt6G2Rnp7N8YP8yEM6xYMpG2phTM2dGQ5W8lnv+wv19KyAHdAoXiLSaSsMH9ntbHpN1pFuMunfEMRkfGNc+TGED+WhAL06yvD+e2lr7QcFhEvlSDYCWjmTEpVz6aVVeDC5UCjqGowC4kuXM3JVKYMqSS8JAcFR+LDQsa66IKWVMOXu4mPeJJay5WpEF49OAnijvJMwgW0Wy1r+IT4TnxY0AN45Y+Jfta6n6uINVFDNl0fhzzNOzwgtBjpjiYH975aOA/WJJelOIIlpMgXbZaKqy5E/SgyNThqx/Auab108sFYxESJqAuDO6Ya3MmLJs/RxD1Drs+jG0///n689Ol3Du6bwgGjSAdbUtSRVCXW6YqB8I29NnOCh6OvfjOnZd6XZ4avKAWHOM+Y361TZ/unaNxiP7zJ5tCj03XoGgF4RsxsbWmBkUzl8k/5J6XAdzt9BgKy4w7sPI92UvbmMZFcvOV8Y91yYnjDPg4taXZnhAZQ3jq2tlmEV2R0kW95LNth3Wt6ILNkbzDlIJ5/HojSbsADp2W+63sFaGR4Xov2gMMjxSa8H5clGaG/XPAZ7b2BVLMoucrCDJcFUVC0DkSUqi83CtkvBYE/V7uGwOjgqVQ1JndaDw8LHrOL/9Lf0SHtnw9Arvu57JlrEDjrNW+ibrfW0draiMGYxi1d6+r6Q22abX55wdl8X/1sIQb5/1+Iy2bFvbeuaUUaCHIZ7awsbceFJb17VOJVhLowW4t1lkat5RAFoY3TCXzXBW8bF8pH+SKmPj9XcB/IdE9G8D+CcA/jva0X9IRP8hgP8HxG/yf8jfoioAB6YYdCj9e2AOtreHjNlbjHEEDDb5wHYJbeZ2qhSZUe/K1RN7/MxHMYYIUCuvPRqw3II3ZkU3YKDeGg6sGldfA+3Q78YctVedMEgrnWlL8ETAPs6TtBTuk5myHnZfeqgCbwPuNg5rLJzohXk5nWf843/yh/gn/+SfAtAqXibFtJtFx1lrEF8K5m1DOOsnMZQBupvVGGR5L9iMZtp9r5LSMeVGI+YhZOsdDRyWq0j+SeIy8UiZkLJVh5GcDkzJcz9EgNBhfjRmRiRWZPNwSRoLPNIZh7nQAYF0XBVjfLcyI5V3I93HsUWaHkHBuMbjd1t5wJghWf4NxKii1O33RLrN7MQnMtwWMhr3nggIYaSxDLwLYmoGoZwzOLVKO/FqbYkRwk+JWU7wF2N5TsM2P4w8ieJY0QSXMbOKqkYheBjZh8Dgn4PrX6iciO7S4AjsLTwAvfIFw1rCJJz0uyk18KV/Gd9czTtrzhzq/w6VNOSXIGtgYMOEuUGdbcOEfFmdl4lxUMbqAIHjM6zKrXIGA17GT7UvyTwqAi8xRaQZidDyqaoA3jaQsCpFzfhC2l6U0czcDjl0LtrnTTi011GLuNuQEd08sYBpxwI2q9w/b7nrXF6G7wJbby1c2WsMan3k5inYgH54idGZ80aXiIJBqzxtuQbYn4cnkDZDgM1NbEMcG837wQbc7iNd/5zIDwZEHvY5ZwB4Is2shwuSJ62fd3+mVA+dBUlJdeGN4l2L0HebIJsRkbtZwsXjUShJKHU8cc0543g8YllCnh0i927oPWs21mqgnfGQId4T97pjEJCEpnLbrQ1HyvZkNI8LO7ChMC4mkuSs3N4x4slrJcA5zKMph1ZBaCtnEQBP/vrn9PoXLCPgtOhe7dx4vK8F4NWRbO6TJmQlkJYKX+9hsk1p2APN8Nivp9K9E6marH1TCP9WE0jofEKrfNznSd3C+TpXV6bBDgDbAUDnVYHGa1KarFvwBGWGudhwcpNfXg/YirgQ+n200Vep0LSxHwFIPicC195w35Ru89ppek18X4dL1dBGjUN2eNNKj0vusR63uhFWn8zU5ivOgWEz9hH0eoGPn+Q9tRaVr0JXxKzJ7IVfmjdMv3bSl8tlbnrcILW68TOjEGNKWUPIRKlh0oq95mXCwUCu2KDWimmawCA1ppmebBXJ2qFJw862x3r5X4rwSvGS6UNkJTl2oKUNfial7paOPo3WIj1JNxhEwaMqeCR19GMth4M4rs2Dn6vhLlnHosY7031KIc1lJPozmNWQzGpYE+xv6TtSljtt/3MleGLoziZRwRUo3IrzyJwDSQ2NXC1Zta6J5sxTribPVaie1PBfDTmW2EOLr19/IoMQM//HkAoAYOavAPzXr9z370OqCPwJLrMYsv9rWGDNWGwTRgbftXaFcQKWpDNG+H+gV1fadmuiCfgo1C1eNG5UIs8rYpnpG3im7v54RcbpJ2jcgNw1QeDv9nb8C9nA1c7CrgNvu7/7OfYrMOf4twkI6DscJDZz2wq4tXa5678JAdZ+MIyhKaVoSQZl7yh1BFf6noadW/4yCHMOw9FS8TB5CCtlLfkbVHF3gdTmm0iSskUDhI3JcwpwnAuo0aPNig2KYOs00HIiZCKUIu6MqbQQkqShcElDnjojBofB23zWxohNzsiYjOmaQaV/dLxGUDLS5WiUATAA3bWHUcpJmC830GZ0EQHz1vvjiYABdSKppoBSwalKHgbVooi587qw5+ykIYPcwwjUgwdRYitIc4HUUoFEXXlL4xV2vxmbisV8e6qY2nhgAD9/3q4/TTnhIFb/Hvm8/NK77iMYZeJ+dXrVtROgtOZLrVJok03ECawnjJaTgaxjnUJgvGFQ2IZl9XdR7BvrXgzuyVfIIdJjU2zX363vb03m+ByJcYY4eIE21Cf3pNRkCEfvvSbXADXKqLLQlGfAEkg6CAqgcDREbQG8BIL514wyJBq5Gl/rlRWraLklQ6/J1muGqihv4uV8wKdQ+QQ342STPaHUvD4To8LKloge2LrRHIM1H1ByBaDU5mFifU4pgbKGink+ieR8znh0WcQg5MA9kVe+lHxxSh5h/NGl34wZmeM+kUFGnhj7ldIihRdsfC6P7ZleEdy6ovHL5QNaP6OBxqc0LszA7w1PuOFOhLWDcqP7lPWwoLaT7UjbEePE97osC32L6zXuCwCa0w7AFn18R68/XV1CkKAbWUgUo9TNucnXDdxiPDuZF6I+QXbK3miGOSDagG2ow5QjvrX8XAzYfoDxTyVy3x+9R3ZPQ/LOrYPt2B9mgKviH8PigV6p8zSwzSn99MpsHQ/O0CNTmPcqodHmh/ajLwjCgTWLoaBan5MZIXqviTjCLXwZ/265JbHaMyYbmGM75HMZ54+CnmJzZQq7TRWRGcvW3jKGVyxvmHeTAUZv3BV6klw0YveUcc1Lwfl8cZbEtqhbc6Ff2aGDwAcpNw5UpJpQiVHsPXVCrYumnSBcLhfkbHm1yA2kiSoyhXkmS+4c6dbGrYajRLpfbEwNiynHBAF+YF+UjpOCEhEPVUOURQ+gxNoW9Pk255WrGlyr91HmNfv7ZR6S0mzz4o/pIeyS3GzNMGZ6BzlGg+tQlpMvUVJvIgbV4jLO1sT2ejRe6Seyx0LUQyXSwkSlyZ1F+sSkOQS1zzlJviXDUBzaHOnkQ9vzv4yH0L/QS+bJHNW2exyZtTMBjgw7LFxgbj2z5EBsxn57oGwAOCqVYG7Vq7SHHJiHv83e7cyxrtsmi5PkldfQyEw/zOh7pro2rDRwDzbDiG1om8u2NRtTun6i1vfVRr4G7W1WAHNiDAOAGT14a63ZTnV1nOEeB3WBmbP/be034NaMUtYT+I0GnFvbTRQ28AkfZ8WCygWgSb5OMhaJ1CX9QGJfuzWqYihgycbZFH2uwjygJ6wgEcDMnYFxNAgpVQMsHkEpV2SCg+o8ZcnAawASDWC2k2qCuf4aA/GJsr63t3rSuGtV/WJfmfs8Cr1ADQBbacDy+oSu+S8m2M3l0a4EatWLNui+6xNLNZ2cGTkVLOF7C79jrpgGY8A0TTBSSCn7fG69x55B7vfPKPDjHCUi0DR5TiF5l64Ws4bbMOgDc/59u9p+RAf2iKiV+MYWYJTfPWzIPH3sO6Ke9rmnQ9geafqExtOzKwaqHXQSl8ihknbGH9+kJVb5pGdLYe8bXSZDhE2GOe2Qf2fCbeQfCG1a39puD3wm9LGBQHJ5YaEPSftDxJpQsu0f8ejgVqoehOzjpcafTK7bmCM/Mhk/jMHWIubGu7o3dU1kvKxTo4DZl6w3Rkk79p9m0IrdsudXeIWtDHubWbYqKSynzJJEUvpR7FTPjETkzgf9GLrBG+jr90Qbr9CDrY/NeVHgDQSP1pyQptzKDythmMF8KQVLrVhqgeoZSJo3SMCpjbP6u2301ecCrjS2PRC9k6TSTaT3UosmGmWngWY8GnKGRFrqliIcetjfuoD9/rI51oM730PyzzzYoyyNSnrEiilJqWcGvDBD3F2GncSzKsqugDV83tahjNp9gCUBeKWWo+mHSy9nWToviZt8qAQJfzJiVaOI4vWYK9PogEiNFJbLJCTx7nH3lbXS1owZmuxqm7wZaoKlqh/SCufYnuiHbnvdHidXgDPACwIKhBmDRF+xMBXVisiiCIIMYKsaaZ4SbZCjoTL2ZzRaxdB/wHJWxvf561wW9XO6PjBYf9dkercEMENTMIgNGLXTIbiluTBPKUv03vQgky1hPdEOpE3GVWuXq9ybCCiGXxB4tRiHxGggBXScXrgdilkf4ly3+QKWykCpYmznhHmRKpFTSshLwpw1RYGWopdcQlnbbnnkEhESRc9r2xfZF4oBMSYB4GLhXjYnzbjH3Ggq6pFtCWX85mbQ8AIDVDRxdkarGNjCoYhaLjjBSgxg9nQNXGX9OmgHhBytyfvi61a0D11KAHKcZqtN3utASzYcDPuDgsOC0ciGHpP9QKXYW10GNVkrOiZMbjGad1cpMMNbtw+uXN8Zg5DnU8gUCCN8b4BAF4LCZ/Y90ICBfN6YXLMMK0gduWhow04xWxyfEobEIIWqET7VHXg2F8SeyNcbdysMLf7cYnhRAbp2MrAxMFGs0ei5AXs41+3A2lUmu+7rtfFJmyq47N3ege3183fVaCAbCaKf18p6EmvD0VwiLqRs02tVNRsygK6ssgEyazoldcX2LxozFgapDDklpDwB6j7fuW8z9HSUG7NmER7upj/t1JAz+Snp1pySz6cy3mqGDimdasmQSXNAjOEX4zi7hpUaEpHms4ErW6YY+NpsbdChv1t0PN7HxMhKx1DXVYu7tpw64xw0Jit1CKz/th/avjKxKEze1jKReBZEw6flkBiBfdxrlFuYAtCMxWPYmfWFghICoDOQ2Ths/9qa2/fuJWLvuj7d38NLT+nQ+BfpHrX49kSEShy86+SUZ0Lc982onfykqAH6yJ+acZ08e0Lvuqz8PBiYOn7mhpqPXwLCW8LD5llUfSx+asuD/EHb36QKbBxHvzdZwxLhwEu+k59RUbX2ocoHUTNYmGJD5m4TrhQb5PZ1VWTsvN9ewC1wQnIcUHieG3oLQAhhXDa2VaJJbgZBH4vey9DTVAYm5Z+SPLkq/rO8AbautubmzdefYouRwEBeO9io1GQUsx4QwECnTVGTVRH4dTjZ5XP73W0BQbZ28sA85gAsmhA6XnLymtyT0rCTJVqeS8FcFhQ2wwM5r64MV7RtrwRTlZ9kOoaK7yX13kzk4Wot/0OBE1uskJqSVxmLBqK1jOv/7mjE/kW5IssEXS64gUDnx2jATmSjx+94SZ5BTUaY1GuZKzKljvaifIn9ZmZULsHL1GS2yUMNAVXFRooj/HBo0F/9DiKgM1g3sKjf1drRmXEJO0zg+AwaHHSaD+s4YtqR/izUSm/u3hes5+Fd1w6L1+9oPyEGoPjWWvvcb8rPWh8qWPNskuY2HN/BXMS4FubB5tM8Ak0O2Vys56HNWYPKTdb1Y4HjvLGtOD+rJLohzEvs1M2IY/02fg40w1pnTALA1fJBAmA5+LU5q7W0g0p3ZujXzSwzKSk+heZxIc1b5bxGMAWzeZOI7KlV/i6RbgkxH/lAEyrvNOyJWULRwISSGJQkLUShKni4RFwQaAN94mQiPcxB8/YHLBTddGb4eDvsovPQwvQa/4O1afONxptXcopIvbkBrgXRI9ny7YHQUgYkeTeDkahoV8QCQAQ/5GkGnIApdTCmazAD4uhkDiHU7QFS3VIMQuYVirZADnLa59UMOLYnhtVsOo0eDXOo+J3Mm6h5FdUQTZs0AqjWlvGLwlpdu74zBiEADl67jwJBikGnZwBOPDHZp0647A37I1rlt5j0QKSuBLRlqtBqBOYmOSiqCIyrdaQXGuN74jX26ZogGOcmvuPa3/57kDvmFdQx6aH9LUEXenz1fe29jfEKU926Zy08uj4Pj7kgBlA0pCIpDbQOtZ8doF7/6q58QkdNoXLQBnXjr6GvZjQJ+Qxi/gWbW+tTrRWlVolL1Tl1UJuk3DmIwehPqPornpxIJ+WdUsgwTzukPLl1eJOek5TR7GjRGLINXN9jec1tj41Ae1yjLbreWs/uM30Ovp8bo42u0k1469oNe2k0Vl7rm5+KV8YS9lc07ETFZOvZlhB2TK7Y3jcanKxfZnxahbW5kL0+v9/3i9DAYUXbsxHUet4ooFVhcuIhVwpM3I+z2yUuxnr+/cDZJINtmQDwP7ZmKwXV+Kt8qVuw8eROeQyzIYarvp+jvOyrfugc6byYodEMbAj3WB+alLW27SRX+Y8l0wyAOo6RIfHu8qH8R6Fky6PST44ao7XqhutH4ZDAbvV5MyktD5ApOwroKuB5AOI8FAVSOWd8/vnn+I3f+A2UMuPx4QHfvHmDN2/e4t3bd5jnGbMC0Oq0Fk882cE/+//gxh77aUDMysazkmfIR9qmwVFc+0Knz3+C0aceGZQdytHbxw4mqq+zGWRytiqbpgCoUlEZXEqrbFUtjEHpLXR4PJySIYacN2BYqLzTUiI5vMiT89zIZzMlTJSwkIBaZvZ+Whsj7x9lXsRQcR+M91bv4zb+NFUlVs25hufivpOcGYu2wD73W/Iq9rnvRs9TUkotNxeAH4xB60sqJKWOLqMxyEK/UjLvnwKje6bmEWzhlk2f4BXdATHkUAwptS49VkN7Xn6nBre0T7aBP4Zl2nek/KAPiRQ5Ycacfl7qVgll/6inxVa6XV1XKBrH1v3zfRbb2Mh/FOejrc/60FvGwRra25T+GKJk928VBLDfW+GbxrNHnWaU94TGpysbPrbJapNwTV9Zj9X+7u+NeiOcvjSHlBovTucFl2WRG/Se8NRqLaxdowPRX7R6bQUKmdG5qvd8QsoiX1lD9bZynC3+nqYzxggXE0pbc0tEnjMp5n9jwOW6tc0MdWBYz+0YwUJOkOS06rOztNAx65fno/V/6omv/B9Ejg3Nwyh6nltfxECXWk5ZUo9/zadVQ8iftqYyMUHySdVuH23JKf8OzUOI3UFB57Y7lGAnCpH3zTFC7l309+v49DtjEGp7ViYlUbBuMzyPiOWUEzCujC8BOewHUQYAqb5iCq4smjtNGSAYO2EblSSxYP81bf40SzYp4QGG01u1IbI3B4DBbf2UhAO3ZUZG8+oZBVBUKCMBfYwpieGkwc9uM5syEucojD8yoZGkNpUg/cgt4SBf34+BolVTtjTKJOFMIek7DGkCZgR04TSAag6DaIzZ+QpsOggJCKerdkkeIc21gEZfUrUl+amnxL6Kiz7D3MABUHI3+ZSz5OJQd9lSK7IKwS0Q0GWZnybZKzVLEsuUBGQP4DTOaQOc7Z8tbMpZaI6asmsjH8H1tdPREXSPhpJVyJlbusPkp/aOWmPp02SL5mAijnGkozgHtj5EchpdwCEpdA8GxnnrDH6DkIvzOPYnKuNRiRiNQk43ihC7/Vx5PWff14uAyRQt443OdxUgw9i4f9EAFBEsGW+k3J4OGnPYAuQU3mFCfkTdI42shnEFLEZhXWtVT8MGklZNUdu7RKnL9aNcEoBVyWvvMk91H4+BsdTG3hi/Sy7/2/vMrKGkoa1h3KrKy7ex+dSAJekUuoGrA3vNuEI2Nm/H2g28ytto78s2r1HmE7lR/1//1/86/vpf/2u4zGecHh/x8P493r17h69fv8br16/x5u1bvHn7Bu/eP+Dh8YRlqUGumDGo8TFzZWeGGzKMTOxft5Qd+ZCPl7n93SYu4IC0NmjaEiWw5A9KSdlqS1jaAWoEI3kA/8afJHeQ5h7qTiSb95Wvlb1eB8u+tkangxKtoQqtGEOzbolBiLCQ0Z8qBESdUWgrxH0E2PFz+2n83MYaseBaiWteF+P8RXkXL5cLYc6totBW++MYbCHHe63SkxlLo8zZln7fw4uda66AqmBxqC4AwE7zk+wR+VCUOYEa/aHPlvwHlOY0lEW2qRktw+71EBf5flT+PnatDFHGKjced30C5omzxrGhYQ2jo+55wLCuSUzd90PxGwrtANHII4a3ZvDp8ZH8bnt+O+JB2Pr2nrla2W3j2uIP2vTm1XCnznm1kTZ9qeW2XMv0MbGxHThKG8npgpmx1OrJ563ojssUJpTKmmBfW/A1D4pNHKPdF2k1yO3oEWM/a1FZTj2WBbCBe01eozvsbHtCUlhwoD/HL9zoceSFW/QX10Nkj7TTqgHqZFgIIOBFMXydwl4kQxL6LJPop0X1jmQzVRkUD7KYYYbXquHeTM3LPyWShN1yh+aoq45F3Z5hi0fmwdPrH2udxvKNxTUmjHZdIuvmoJfAcGrL33iF5AF8hwxCztiicsYIsX9mnbaJEuu+hH8Q3BNIiTChKQS+cSiCWz0l7hhsBCsBvWLIJzR03N5lGy0rwY2cun+29/ag4R5nJsPrRmV/tCZeu8bEiuOz/UualOGeGgfsyk7wW8Ydb98f2n7nh4Si73ed3canuPvJhrJDX0x8QWnJTmKNHAykr4avU5DsJIJIM7Q3hmiAMqkxx6zsRM07yEF1LZ4TIJEkfgZD8s1kOVFiQDhTYk+OFg0LABw8k4JiF6BEKMuCNDU3egcPaGs+zGz7nPR039YvKpYR1KMHr9sM7DotRgDUganUyvIih9+9n40WtgyJa9C8PjW2907TJK6+3Aw1H2orKiuxnViqeDwxtt/jc3afGR/Mem8GbrJ1Hpj/h9w7v28XoSU5tPMVO9l3Ac+2dlEZNGAifzUF/ToNyL1rnmZXrxy0LWN7LjqQE9ageXtPNq4mrveR17fGZK+KNmBGjTHnGJEdQqicYcAORLK6/hFRS0gLaPnhfh9JWMogk6DeRco3rJtmy+mBaAiBjB4+7rGbQMVAWwMtNhu2tkEktUndmB8vlxtE56i0G4/b54y//d/+2/ibf/O/hcfTIx4eHnB+fMTD/T3u7+/x7v17vL+/x7t37/DVN1/j4f4Rb9+9x9u373CZZ1zOF5wvZyzLgt1+j1IqLvMMaDhVUcNRsUMBBaiy/80LYQCFih0svCx5CBVr4ufkXm61Mi7Lokkn29Tsph2e3B7x6pOXeHr3BPvdTuAP2hzEBM7O8sMcmTv7pSxYzCCkMmPRSmPVch/FefYtF9oJ8iIqqARgp15AYziuyTgqBdDT0YTkuTxGGbK1n7aNLNv7WSpMrj72d8RqkhFLje2vMNnG+0ZjQmxjlCPjWNs/eMLqHyTEeDVjnOQakcSypsAKaxe/xRxkgvA7aLl1DdUY+PyWIuuGCQLEM8mYIge9xC4zLK4V+VEH2LqiocGMFtdMgdHDwz1oVE6m8A4x8ArWXSn3IW+SGMqC1yoavRt7jnRqONl+71bI568ZqrYMq3KvzU2v+8R2+jYHg7Drjmv9ZByz/Wye4GZAaMYIabe/P/Zr5Anbsp78/X4gBdVR/BBQjG9lXlrVNG4hws2o1L8rpRZ9AAg2iOHAmcRbx/CBq8psuqy0FXmyXEZ7abWecr/OJRMmGx8FTEviiRf1E8v30zluAGD0xkGK3xOQ02BA1DVxG5nTUuuvJwI3M4lHUsjEy/zLnORMIfRMwgJJ9wg0wbWFzVMiTHnSuWFwLWKw13CvlKijX+LmKILUZFrt5lbnRygFVGpLbl3ZcVu3tzmkr9Dk2UnlekoJqLXDpVvXd8YgZJ4PlM2NvCcGX1wmPxU2sNtvuGY59Dac4ZJPdvtq+yRJ2mh/O4gxzoJmfXNmo28Zsau1sfX3NWPIxz4bmec1BcPujQatLcDRC76ozHD7bzdPPMz9enxj+53xZtVeYLD+gX0ev18L1PY80NxnIUwiKAhuBIKsG6MJMlMQqz6bqae71p9e8UqaDDOesNomlSz11TO/WwJP56ZJwL21633h3gOnAWjSZJ7KQFLye7dOV6KS6Forh76HEw5QU5QMUHWUrLzUxmL9GulpyyAUDUHjWjvthVCfmBPC5rKtPXtfvu3Vn3a0sY8Cb9wDtm9ijp84ltEdessoZHMWDUpNSQIsBIGgIamU/eTJ1nVZYhrs7/dlPFZT/yn0Fp7giXwD0Gv8JTVAGMAssOadbbt8xNDtn/d044oltb0THu7VAwc07Xv7W8bXlIt2m/6eYh/MqNsUfEIDH2608QMOQvjQgZa/Q2Ugte6EstoRUGl7DkK6W5BgHiqS18mVW7AfPKeU/NlRxlguoU3ptgHEiUwyw3kdyAxj5PN2PBzxb/1b/xb+9t/6W3j58gXO5zvc39/jdDrh/OQJTqcTHk8nnE6PePf+PT59/yO8efMGyyLGkcfHEx4eHgSoJ/H0nJcZ8zyj1oJ5WeRk18qFc9vLomQ1Q0+pLQmmKD9yGim/2/xJUYtpN2kSalFu7x8fcDqdUIqEGu92E168eIHD/ohnT5/ixbNnuDkekIhwOOxxOBzw9MkT3Nze4ng8YrffechYVHQKV6BYla4CS1pc3FvI3NHbcpCuia2f5dsxuWtyzvkqJUyacy/uJ/cWMu8m7VdSxaHJrw97CIz7+hq/Z9U4rxmV4u/RIBRpj3QPse+vpFWqwrOMULFw3XYnVwir8XUYyt60oZT+cLXLFF5gUJyNZwc8BM/zmHU9BiNyOESLa9NjL4Z5KPq72Iwq/Xp2MkM3iJVk39QPuH/OUlfI732aAZMJ3YMwn41hjkx+oKej3jgPSKLj2vSpQQeJ7bEzh23ct/6bfA9291cZW7vf3rHePyMGM8bD4K4Nk5X+Xu83JHdcSuE9NvcELwe7Ycyz9465jLZ+9kaz0SBlayuDFXooXpHWjWuR7zoN9LoJJc1RSqRGIdE9piT4KeoH1u2IC8hwUmqJ1C0lRiuk0Qp1IIw/OaUFYzYYKe29n8ZLs1Y440ArMR9o/CzqqlGvdE++lFWGtTWQ/mZJDcIVUnXNAIoeqHEVXYzEoSODwKU4drccjkSEeS6gNEmVryyyY6JJZZWsF7QgguWVbNEAWasn94cJDHFAMMznNEEAc/HQVp1mt22I7qT4hm2OEii39TV5lRIB4YBv6/rOGIScaIqVbDetj32jEJEnNmnnp8aoQ6yww+ZgDLBbac0S5d3m3mVW/cYou6SFrCDd9m5MwBumejSyxM+kmS1X46iA6MJz8x6yWFoj3G9niR7mN9wzej1sG4VkoL7p+zc6iLzWhw/1aeyPva2aEYqp3zTcVpygnmO+ynbqD2eY3fklN+XGhK/sQtcf5dJiV1W0KWEggbnU2mJDU0qYEmGXE6YsLu6eWFZLjy/qISQMMQF50hOoCFD0PSBUJqelKECIyJMiT4oqC1dwnsQLqZTOmyWl5EyfOXhEoKmWzJZPos19g5wG4lndslobY7iY0Uw0Om7Fjtschs3TXkYEoq0wtAp4XiV9XoV8FMAG6mH3RIYZwZr2k6rQdCbCUkSpi0nq4rzHy5WdK6fEnfGrCtFlPQ1nIrB6djXjku5BWHhJRdJcVctSsJQFp3nGD5dcVs43kQh1gRKqiBGsGK5JBaVaM+S3tdniPXI1/rsFdj0fDZuHaeNZwpu1FaMBbq1aH9bt6p4g8hAsVjkjXINU7AX+DOODJotMRlooMSHZnkDzhjWgSDrIShYfXz3sWuGi5Bcg8VZsRiMCK++QmHl9hisqt9BXQL19VFIXUv6hxk4yQEaEmgCQJdyUuRW7foYZ/XoQbrTQ5C0zNxll/dIv2+fyL00J/8pf/Sv41/7aX0WapMLW3e4WOQP7/YTH3Q67/R63d3eY5xnPnj3Hy/MJp9NZ+N+8SCn2soQ+Meai3qClYKkC4kttiZdb9SpGLYylWEy/eOwkIixLaTyazRguY0opo7KGm2o+nlILyE6zmXFzc4NECcuy4O7uFnd3T5FyBgHIU8bxcMTxeMBhf8B+t8N+NyEnALVI2Agay2eu4MJSmQWEwsBlmbGURRSUoJkws5dy90o6YGQWECoGWeGxKcmulUTSooyYPDWaNnxHij0qmiHoGqaKazHKqD4fXY/DXKkAuxdbaA1A8wg1g5id4Cu5+bgTE4jYk8BaJcx4GLB1OBfpu+FNmYOi+DZ6rDhOCqLtOtL6/l26q1S+tsTw8mUNno8tr5WnQ0NT2LZCEkdc3z6zfJRReRMvpU6D92daWJLrOerF0OizwFRU8VRpiWPNCNRXqmv0RLFdw1ZKi9HzWLqw2GOuIxGzF2zgof1I0x+bm75fa0wWjTV24LiaXzRcaXx/1KWa91TQn1znk5EahrS5T3qosfYSBoCk6xmSgINc6RbVoEA8p4zvWBv9gfn4c5yXqF+Ck8g/Evq7fzijFEtAHJ/VHrneyi6jkURfmJIUVEnUDqxzVg+iRH3YLiUtI6+7J4lBgxy/Bg/h1IxjQet13DTqBx1fJSu8QGK86NYu0hT7977OPOAyAiovsITcsi7iWVMgJthm5DLNB34Ik5LoXDPL/TklSZ5dq8hE1ZFqrZiy7MGaWHQwk8PEyDRpPluAOGsuoeqH7lHfp9JkgxREsvQAgm3d2APVujgjTTvI4XEzCiYtVuEHh3awpuXnKWXVk5onqRsUr1zfGYPQFjjfYrqS8Ko/4dW74bsluGlG0GhtrNuNeUqah8faOCLvMTBNBM/gDWoGh7HvsQ8mzK3HxujaBohttAwM/cWaRb7vVQ1jGBlw7NOWUrQFrExYOePZ7It98893bStHW4yzf525TTZzkP6jdn8NUxTsBR14inis2uemSJg3ifbR41g5KFfKgOPJpd0rwDpWIwlaCozuGj0YA2j5GtocefLorD+JQJUAqpjRjHsxH4TNo/eLuWMKyRW8OI+99bqdRLZ74vqMtDX2uRk+ojeRroTvRevbuq0oEByuXU0MqEa1yojl6kOv3OMn1wrODM4VzKWpnVcNBes9Hedi8xn7vFYXqqIIZb+/Mw6hGfBM4YyhaT9cEINJ7fdaSKUjf8OEJHzDN7pfe/10hpaPzLXxRFJ+3/FZrNt3KBJpZOiHtbs2spqcW8stM8QLqE3eRpsTaWvkS52XBBESLHRITiObFJXfc5ynML9EZsxt4DclBlBaMvqghMlbUlNkw5syAE6Eysnfyykw45XMHuepTWKTs32/iQislVVuDnv85Fd/jEkN+YmA/X4HynegaULRV5dlUQCdsT8eUZ+xlHEt7bQwpWYsWPREkYvwJzsIMOXLFBHxHDXDZsvzQ4BWH1MPoFrlb5bwMk7wMCEftobLy3ib8kZcsd/vsdvtQSRyQ/7eNUOiCsJSZgHPKamhqaJUGWupxWXSfLngcrmIUUR5LYVcj3HrdHIH5nnB+mZ5e0pJKruF8AZSI2GOBxuckFkPAU0Wbiij8d1RwRurONrnPUZaNdMpJkBLyt2XHA97Tv/m2gywMTkrb4TYYfi70VXIMQPDLzqXG+0wc2zqe3+5d88gp+UXURyNBzWsM+DzQCOj7NiWIWnFq0d5EI1M8m7jn7orHQ7ZMy1tAYK8iYfUHPhsj0uMThuAX2P8AJhVp2E0usOwZ+ynGZWMzjuDRDdu401rOWv804xoI/mO7Y5FPGI7q/FAZJrfS+xDGQ20sb2tubFy5tKHOOetL80IaO+xebD9Kd9t8S3jKa4zcNUDJuNlHNpqOsy6n3DdOGkeUysnn7JFGOj3pBWK1ZMxkYXpkhtRPHyJQwqVIGNzzsoAbUKaJkNI/XoTBANTo1fZo2IszaGqo8kh53tOoxWJ2vwybB0BdRlHZTXiIRwqkBw6dInHFcCJfJEOJgupZ4CmSQ9CxCDUxkKYwJgoq6yVqrCkWMq6QlwV7TRDsdEGZdL+Se6ixCKfWSOjIj9qtSUIxJJ7ShxD2A+97J1AUnwsh1DQvEZEqeUyXGGp/vrOGISADwNz33TmwhFKFMoVDBcK2kfguGX8GOdmVDL9cyOu2E/dKHZiHJ8zpXswR8F6tv7diNTGK5/bCXAEHbL3uFVACH00Zh7nZpzTLeV9VJ63FCfycbaTcNW0TJpi64orGQXI9cuEpf0M33hcgnoIGZP0zSHrLlnW+yZraN1UkmZY6r9zoxCRx3tWzcJvfbNS8SlrUmdSZ38F/ux5FkI4i4+jX6P2eRwnt39kTD65i2ACgZiQU8ZCveFABJQB5+oK8ThQE2LwE9/WP29PkW5LmroG4ls01RnNujEa7VuZUxHeHL5v/2L7zRgU+9Dn95IT2i0PJan4wsh5QioFKZvxrFqh776/zOI2Oozn2tqNY2yGqfCcegok6itjiPJDrmgxoCEm5YeQMbuUr8f1rFViqxND6ZfVUKPzakCTndi7dfw2wNL+NsBiP00BjNfYpvzSP29KXTPMXHun5jGrvH6Rv9/GCWRqhgX7rvvX7ZP2Tt01ED8MBX8mjsgkX+NeLtMoISYcNe+tJi8YEpsvn2dK6jGRNImr8l+CA1U7y6kVbhgxQ8AWoOkND/1a+VhdRqu8LgXffPUV5odH1MtFDD+HA3a7HRjAsixYipw6Tjz5WLlWcMrgSfqx202uqPS5ZaTvcFqQQUbjb8vv0YekVjavIkYpiytLApLZXex3u50ohdQSllpIWqKE/W6HaZLqXVam3f62++bLjMvlgst8wW6awLtJaJMZ4CrvV1lWyoxlmdsYagVrNZyt0KaIOTiaAZWmcs7q8ZokrBDwEsbCAsl5IlUND2Os1trW2PoVPXg8YX/OKx4a96nlR9qiqXZP8CTiHkv5PzRZazmgfG+FfWHvXnt2jAcnOl+a15cgyUzhc/rtQP738yIJN8q9MmdhT80rRWi46qFNvLYMHPHnNV3FPuuNNiP2pobFyLD7xigoAfHwV+WYGGyE2XswBYTvWFumqPLQstPXVR0LCJr75nw0bBjobtgz7bn2fLe3YLnVmpYU59iMUq7Ao8kruzoP8W5+0X0e3y3rogf6wTMlPi/Dtz0fZGC3h23MCVWN/xYKLNtZ6cnD7MwAKEzOdETz/pP9H38KXd7f33uI7qBG+DLFOc8prov0s4K1uEKQ+ZVRUZGQUK0MvZbrMGOdeAg14yqRRYtICLPpSgSWIkw6p1Nqh57CD6NnpHjDlkUHY7pFh73tq+CcwRWERbdAanOZ2p6sTFiqFBijlLXUfWlYRtuX/R7opFSkNAFsXueQinxp0vuLHMoIMMeUJxA0hBqElJPrkmBGYkXxeug/7eRlpVheIdvXHlMMy3dGSU1J/jX5mhlGoAT3JoTyAoIktWYSXMCkOQgJq5yp167vjEHoQ0KtZ8Lt/q3vP9T+eC8r2DEX+5ExxMRbXduBKSQir3hDyc/dGnge0oG3cVwvLc4wTyFjQ6ZAQ0GmLLp/ppdVEEvB2tqeXgPlrfnaUooiYzTPC6XDfk4GYdApz6ZDhGe2mXgESa33jbmYQCxui7K7anf/un92omGXZIoP9xlm0D8SJTeyefJavVbhWWaoie6vETwPLpGjUuPr5YJQbM8EhiXvttKGmQRIV1YXx0Lu7eNr1k9lvw6kkCHkALGhl2snJgpwxyShW+A8/j6O0+ZOhDyUybf714BYvQao9wyKynAEJzz03xhgLGlsSlULsyO1HlZ0cf4BiHRzGN+Jfp/EywC/7Bnru1Q9KrW6gmqx3Q5CIEx/KQXLMmOeL/jhkosAzV3TA3MCafw2EDmwRH+rAWdYpwg2rhmHRnqMl8WXj991BieEWG7AeUhM6jmC4W60uk8M0LRvyD8jSJJFZRGhD3DvExA8VNWYcQoyJJG1aXuWXVGJ4/I1cMnU+ufhj2zKrhmRKzKpwlNZcsMIYkaihmsc3OoaF0CAVW2AHBT2WZj2LT4U/0neQQGiiYF/9k//EH/8R3+EZ8+e4e7pU0kKmeTw4XA4YJ5ncCngKsC31sVf515W1LxVjLcAkvOo1opaFIiqnElsp4oM0tNAMUpn5/uJGYktt8K6kpYpmnmaBJAzo4bENHUn/Hkiwm6akKcJ0zRht98BZpSCeD9dLmecz2eUWsUgxGasKp2SsiwLyjI7bzUPJ5jaad44uijOxyujgJFJvHUpk1eyyTl72AIgxsIEJYKcgKpzEzxEzUt2NKrZd8uy9HOkRjAzQFnfI72Yd1en5BOcX/RGIVPK1hiKGX4o2NGgKgYEOxSCGqv6gy67f61MN5nZKhXBccka6PxwsRp+PC8hGYoHgKSR3M3DkrX0dtDnAo/p53aMHNgyTgNrHLSWH01GxeciRhUluAOl6vUgBEpkO7DRq/BPDm9pUQcGuRrEXeP/LVwzfr8aj/H2je/b71vYVL3mOplFq+et89b3UY5vyV97p80zq2BhxJySpoe1fRXbMjogUi9PO6zr+maeKlY5TD1fzD+EY2EQ/b5NG8yw5HSTCKxpKYQREWqx36/t89Y+68Eu6bvN0FJrlfylYWzm5Gv80dOwUAshm0LxAaZ277hOicQjhohAeer3Ba3zUWUQ9pPhOAu1NDxCne7SvGvYdRw7mCdKAhIsxx0k3C5phehs66vyzPocDUJEhJQrChIyWY6fAqapzV2afE7zXnPfUcK8iBEKkxSPSCmDyyxeP2rYcyNkBbgump7CwtAmDfdGS0OgmK0AIG65Lwmi35RaAGLf24mgRizRKSpVxb0EQ50WlUAbOlu8vjMGoU6w0nVQnnK7b+v5dq03zxo0AkZ5W4aQAEO77zpFxAAJ2d2shoQGlkcAMSq+K+EReu+bwIZEdqLrTygwkL/S2GfqTwg+ZHS7ds8o6EblacXst9owQw31TH28hG8LIxw9PZjZn2e918Cb51diU6pd79G8QIzCqmAQ+lC8MKEunEIGemuGK4cM/7HKmCkGlhAdYOhJb6gwhmEdnC58PA3cxTmW9lsizpyynuJzcwkFuZcSOhpq+RSqGhpaHwA7+Ta6834p2pATWi+4GNZ8+9qi55i/IQJ5MXzZxCMS9Uqo90pmWJMwT6jmXtvvsbEyjKxvM+RN04RlmcHhOafvqi6jgwCM4+37oUZrXq/11b2H5kUBtDDDWouGjpXN576PF2livKgoAZC9QJpsWul302gHuz2eFjY6GWVOZ9zh/qy10TC6sDUH5iQCvNoGR9vPlXnFq6Nyaxdr2/FG86axZ8xsHfkqKXjjFOnOfheXbvF+tD6jATLlIbb3NmUjmVKSQFwVLNpeMFknJ4/MLWE85YQaTq6JBAiBEqia8Y6cdxdiSTkAmwM7VYUbsDj2y/Q46ueRYAZ+WccvvvgCv/8H/1+8+tGnePHqFZ5zxX53BMAodYfDZY8yz6iLrF+iNJSZbdXuktGRlpkllTfkxqJGeJUlDCwrKJw0DLiU6iVwU5W5y7kZm9ppOrunD5FRkBIIQfPJVTkRhNBGTglkigcDdVlQFwl9M4FmvCsa/AHxuJlnCROLskl+bnkHwQ0VZvSXvWR4KxqDUjCG2z5rdCYh0hmpFperQPCECvLXPm8JNJOXpzeZE/e0J8eOcrYReUfzzTvIR9nxcztQ9PFzMDBxvy/DKzrZQcM7zagVeZO1bxIjKVaqiv+uw/zv10UQrEY5zkg8xGpJg5vSH54nU1TXhoZxnfpnwtsGg0Y06PYGD+mDrWFcRMNHbU9s4GZ9pip2bHuohc2PcG2ku7H/Y4ESw6ZbegCG79gmdbN9qyjWiqDYXMf7TVaMbY9j6LDf8HkMy9PZc5kBiv1bj7nnQ95wN3foPu7X2KRx937q97GzbW/HDCO6pJa7iYGH+8eeXmxEGxveIhFYeeECIGXCxKRRAK16GqgZmo3fLrVimsR4UMyzBhR4nBqZwHqgbB9bCDH5z0Yf637aJWOQUDXLyyRftPxasgcISIwCM0aJ8StJfBsoAbUU15HZoiNszUjlsWETBT42haWKTE7IIKriWUjwdSSEPHSV3YA2TRNKYRRUPcAgAFkOdiBeP27wCTqj0ShywK+aijvnjAqNFmC4jJYQwAxUldOJvRqa5JkMtgmG4ori85ioevjhtes7YxBqQlH+vmYsUf3syvPwid+6qWMPOknx21YerjHztUlIHmt42RSRAM367MWdYLeX+68wqyh7GAEpMRiwtp5yEBrGeD0JqZUMRrsfw9xdt6TDn7X3sP6slQ19w4UkNeKLrtzGADt35mCOcrBo8+T3t8sYogFSGwxzG4/32TZs+IyZmkfAuGzDBx1P5v6ngLjk/2AbFAwLxaIkCUqTxtLaaEsV8FxLqwzQDE4bQszmQ+mizb8ttxCcJB41pqNrnwiUE6iQ9iE2PCKM9o8Bd2+1ExA3pEVp2IFlO2nZ9hAaQRAQwnpgAKf1izTZSB2e6daodQGAxD0zVTlFCftDQL+58dqJDvxhUwq8XxDFOmdxIbfTE1Ji8/hcY8jEHlI3Ghp6o2UT2paKsIENXTdKCuPr6uSEdb/VUn08JbT/fb9MObaLmSWfmm5mmVnqyJ4iEa2Q3rZCZp/bzy0QHe/zfWrvxP+vvX+LtXXb0sOgr/X+j7nW2rvqVE6V63KqbOyKcUzKEVYiKwpYQoARBIEwL0FGCrKQpbwYEhASsXlEiuQHFJkHQJQCyBIJxjKJYvGQm0newAkkkcBxLCzbclWqzv2y916XOcffe+Ohta+11v8x5t6HxOfsffb629bac8wx/0u/tN7uF0CYFqY0fKbnLow6PIv1mY5DNPIc50IeQeMOUqY2Qwjf2dldTMFAoRZ/B5poRAbhoGxI+UBFZOUXM4zRnBupDXmxtWpVeAJ/eXaGpfvDDc+tdDBEgKFGf7MwNh9O+s61EY/AUdCJUAl7rL//TmfN47tHfOvb38LHH3+MN6/fYA61ejvdwsLni4Gnd494ald/dVXskyZGJy3updPXLi2jomDCGXRi9yBECqZWSJmFky20ewDezaUt604esW0bUvhGRNG03s2wrdPqGYgXaZ0z0qXHMIPUDAMPZQozUo450Z1OK4Cn6xW7jmOgghW3hkBmibCOPSoiA7g8RkPDiNPTGMR9CoOr1+Dp0rCJYLSG4c+/7gMiTxi6lRpEa4Q35ZJjQWCupZcvd4fNjPPINU1RQON4gXyPYcXEZE+beJ5/yfKPvGLMGefmufuozBsKr3KDFvx2X/Td57y3IPTOu7n8IJuk3OASr9aorXJtwSnKpFx7poMn/V9loHsGFD7Dfp9OFgXwxhnc6xhfImDOzcdI43nkhzh95EVpkCDvSloPpbzPdZg3a4Myn2Xt/GFH/SF4pP9OPhRIDFk6DwISMlVdnyrTHccDIAwYpB210DSvpxLOEdEQuKQogOeoMpj6kw4Af1WRpysfJJ3I83p0RpW0v5AriUt5HY16pvBrsM2nfQRt5dWBEmQ9h30Yc6K5sixqtWp0TGyOKl4RG7NZBOyOHZM1fubE9JTep8Hi291kh9aN1/qisPuVybsT4mUSpjdGCR4EYGsXqJoMMlBapCtloyzwbsXTuZ6uYzbB1IHpeKUTaDqtlqrTcxVrEuPcyZdn5r6HHEC5zDFk2v+mWAS/eBrjgHXcbNKwjxFy2hgDEDbnsPXQMbGLG4IKA7TC0e5c79lIR32vpImVsiiylJUakdhsBSNLM0XSZMgWzQVUpzcCaRiO7w1mwGIKoshzHMfgC2MQOgqclbGvnttFlndIS2+hE/Xh8UwEwXErYyCIP6eMp57AJJZ2XdU5JF9xwwT4gtVbmf/PGdhD0kIuIYjzuVyLNNe4YNySwGLF+xsxoTKqGyYJZK66UxtzyJOpmOD6watX+OWvfQ2//LVfxld/9qv4qQ8+wNP1Ed/61rfwW1//Jr71zW/hBz/4AR69O1IYhpxZDY5RFZ4RFLp7EDb+kGSKWidDwlr2UINJ5uou8ttMJZ0TrtfGIijx0fIvJ4Dh95K4qSOaGWUQRD7q9Qz7HJ5I3997QCObCXd1zxzPGovBFYOlMyiRjBiI7kHLnKogkYrRGg1gXnuIRGobgKi/QiNQvHN5ZNaeeo6RG96q5/NyAMk8Y5R3FO/qSare+Qm4oaZ6Tovw7Md36kTD7boLrPYSujH9TbbihXZk89RLKURnYeBlPOFlkbp7tm4ZKWDMT0j4RdY0AHHmylpVaorDfkYIAbA1s05LM9JXmK5bFVDwd9I6CmL+lIhg4DcHAe6eIgnAxe9j9EAxdJQOYfYmvlcOykWOhwaGoxIgjifhhKNSCQQVCF5XyH8D28xnKrORKI8qAItG2puqEyZrmlQetp5tdmUh/vK8qGqm/PAp09ZEAW8d78+lUYTCoJpyJBBP8+AuuXcwCjtOqmoQF/JEelxpdNnW78hv8x+NchPf+8538fqTT6xVvCradsGDPEBUMJ8GHh7e4e27J0gbJqDGGWb4uXkcGXUZfKgqGaqRtmRCvoWAN2XacRFcoE6HYSHq3HOnfd0/987WumlUM4O2ieW9CwCmjSc9tegh61y4l8jDCet4tg0PX6dgvQ/s/pn/zKBSZBDv7hJrHTIP5R5JPHU5rbni0YKvrTxDYMYgxcxON7CumnNcoTrQ58R26faeSFUkHrc1yu5wjuf06F1o6mnOZ0EajEJTlAIKjBcUnsdWASbDrAqevS73sNaKYipHPWv3jM3kZ3X89xTlo5PpfQY7fq5csnjYgcbW1MGlgykYAbHCui90iK1yO+7sy/2aHXXfTQK9/cz3xoxAg0Q41gB3BFMArdKeINPU7e+Mjlyd3G6YcoMYn2+vK1E/Pi9GTOd4sMhmN/ob0ugTqVMqcXvMo+gkn+Z8mYzYPrz/eI/RRYScUA35Sad5jmtZgjWiqp451QErlsy/ap55GjWCDjk9L+lp9rzu53+Gg1k108qk/B+wxgRvH59864ucUhSXXCPDQUY0sgkOYAaa3tZ1mDohswPdOLrJsIohDVsfLkfYdjdGq3ohC3Fncg/9g/Te1qq7DGI6mX/XZhhUGJlsPMpwl3WGbIojxrnQOdGyB/Zza95xWey+xzExW0dTRvIq9mm8rvneNKate30n2yXr+rn1Zs48FVxFcZ0jil63JmjTRjdEPPtjYkqzDBJfr81llaHTs1EamhpvbY7HAwpM8nNzFplBzZ43RTwrxbXxJpj7IUvDLG/W1XIObGjQ1gGeeYUHmhSDNp6HL5RB6GjlrB6VWy+ulgOty3OOn/P8ZgSOwPhE9za5gnl7PxDCgRCBAW8jXSNkUiDtfRVEFVIOrj2A1cfrwVdVzDttr4/Mv0cItK9PahYLQ6jrlApE/mzlnhyvM09FKO8iDPG3yJSf+cpX8A/82h/Af/r3/l78yq/8Cn72Z7+Kbeu4Pj3i9evX+P7Hn+Db3/oOfvM3fxP/0W/9Fr7z3e/j+x//AJ+8fo3d80SnJiHQwWUoUR3BhJxQlNWM9fLvaKtgjR+BmdV55QTCeRIE9cjc+Xg+WBDtGFUA6faPYxzDPYtDoWxJ489hKohFChnRZyj78NB37jeQNXkWZXEzQ1TdN7aebmZGjrNQU9Yqnt+Lbqj1TprXn6jPyW5oBScc8aNTTuAKlnU8Mm5+d8vUNfZV2i1+17U50oN1/M3XnEw8a0H4dqQyVMZT09eWNfQ2tNHxQlOAjM51Reip+7eOu64fFQwBpKVCNacLK3lfClWxut7NR88IIQcB96AqnrmP3JcmknUcDxBGCSAuOF5W95e/x4WCmzNSr7s9BeszjvfmGazzpBJ5j6+R76ToyH80MvB55FkuqqZh6MBHq+HBfk8DJnkbo4FCaSljtQ8Uqso8GBikVnCS4eyJ44zosXXbxAxEYzIdxhUg8q0wl6tHgSVjVZAe4KY4rNCTR7ojxkdff/IJxvWKh8vmqegK6R1ts3/b5QHbw8VqjY2BMbNGTe3+d4/21dplNICoikc8VdqNOPdjZ1RwQ+9b7EV4npEh5zX0m7hgNXTcaDp9r8SUCraiH3Nin9MEVX/unAP73rBvIz3rOrFfbb50EhFfKHtx34+KduC6yx7N0+Ky3p5YZ7HDaTkqdoZDhsStNYzd1vw6OfYJ7ROzb9FNj6liR+PJsjdAeq7VjFTEmSYCNI9kmIxF82gTYDkrcW6d4UzQE5vzuYcfsZ/CDnJZf6rSsromR/n4ubmdYFCpVN0TAAtuJM+et7h3B4cWhw9lDf9cozyr/HAPDyiGhrGmnJ96Tx1T1HxznOP7iZcrz1qf46PHkdulPEVFx1ZPKn31wd7ryKV4Hg9Np3G9m2t9GNNdefOZ9T+ejRguz+Lh3Ue54J7h9bmxUxZfzyLAKAtm88B1juqGZrfbe5CyJ3wPAVqlj8Yo1le6XneENsnlqfJC4eX2p+Z0fQLoLi8oMAcUA0MAGer1gQbGqHqEGUjHtIhWAcIwhGblKix8dXC2YRCSKpeUNFpGsDTsZkAvexzjF4QOZE/1FF+kvqOuH+be2HnYW8PQEXrirrBUeeplYQyx+qux7pRnSI+brVlvWatr96ghqnmtCfos59KPDf8u7sgYqtiNaUNhTpQmArFCQnaPGzeNb6esxiYiSiOTel0olXBar4Fu5E8zUk+1dei+Q+eItOVb/eQWvjAGIeAeUTtE24C8NyOCtHzm70vlef8jBQYTcOfS9YF5f1yskDNJLJPrl1pBpZbDQpDogYYdAhH3klp4mj27LUSDAnJkaRpm2dwYQUOi5PMk88mR1efX86Yojl/wpkCooliAyCTKKDhAvOq6CH7uZ7+Kf+g/+wfx+3//34ev/dLX8NWv/j1g2912uaD/1E/hgw8+wC/+jp/D7/3V3403b9/gu9/7Pr71nW/jt77xDXzzG9/Gd7/7Azw+PuHtu3fYd/XCrBbKPrzy/pwprNKcNVse6roW6kq8Z7BaOLgrPk2Bh0Yhusc6zUnPpmJ4F7AGweadWXprePVwwasXFycOihdbx8uHCx4u3T2wYfu+If3hgZyW9jPG8MKc4yY/m8ADGwqdE07WDWoi6EhFrRqDWA+HcSSR/nXwdKWAsHqetRitjmBEuQhK9UzeXL3et7y3UUnPM/Zpglcdb71uKeIrCml6f00PQhOQysq6hh0iHr7aPH/YFSKl9ggsxarrOKsh7d74zVBHpgZL8RtO+g90y34i90Ot09BpEEoww0LS4GDqENTlb96FwdVXADRY2Oc0bqTikEa5VQn7YZSxOFtLTZZ65m7PRPI3Kogrn2PkhQDQ6cqneHSM1ogel9ckIy7EZ0xa0oCgI3XuNEpwTUgfgraoR6DG9d2EMi0OGaWh3yNSXN6b0NiH6UI0xEKjrYe60V/AvJdahC5AodPD0GOvbS5878RMejRdGPNUkTDyFlpFoxjrw80x8fjuHaDD6urMgS4b0BvatuHhxQu8eHqBse+YO4XyckZ9TA0HZU9s7ltjUePEAxFGaJXOlVo8xFLr4vg43QtoDQWI+xo0h7Q01mVmmL+I4DoGMK3LVvAGZTStQvdhHslpguwVCvX6ZTeC++EMTJ3evSbHu+C54+UmWf+OPLaVNSGNnC4ZT8d1iBfdxm6KykijnHXytLXbpJd1O4yxOADm9PpKY9o/PzPckziXSkWBEQBGN8IREVNez2AqYlyHymsHast6KpwoOH1cP86T/PloyF2U3U9jyO8Z2HK4tubnpa5vrrFHaRzkuIpH4cTBrb5hJH+CRYTb4b6j8SPlDxqtVz6T77g9SxzlKn/p4dk2p6jnBjmMuSdfkcRBndRpGjISszhf7qyJv9gV4aPxyV7AvwUf9XuOsMh5N3/F3bWJ54Q8mOO8x2uP8uY9fbN+vmcsSqWaVDgjgjwGK3S9ens17IUM7i3LiQOiDVN37jKgVjrg6enR9iqXNZ/tP6NcApgmDIvq5HuZNuw8kgbQhoYhjOQU57GIaEajj8PwpAla21zf9ShMzfEzyCDwMo6fyRw9xQgAiRuQDucAgW8ht2vqD/7IjMz3FOR97LjO3XGwYwC4Xr2+EACrRZvBDca3Vjpqeq/pQp3rMYFdzaDUVLyWoKV3sfAzxzmoRTbKBjMCHFRMR7VAEosOS7KUOq1LXphzGP9r1mhhqvOb6WljjnsrXrtTae42j+YjUotIYhkTRnA9B18Yg9CnWZkBR5wiQFNo9avyhrJIS9i4sDUxEEy6vCdIbBGWcbzmSOw1P7d4iEaKVXNBxzy+/oljkLYQMrs1leVlDVxYZ7ikW6EQqowyQqkSwZxZ0M9lnfLpCyHn8hbCKz6XX/y5n8Ov/p7fja/90i/h53/+5/CVr/wU5px48+ZtCryeZ9leWZeTDz/8KXzta7+EP/Brfz/GUFyvOx4fH7GPHQ2bha7PievVWuBeveXv4+MV+3Xg6fqEd09PXsHdim+yUJZZsq1dKFvxTp1AFw/5U3RY1NbDiwdrN94bHt+9w+PjI96+fYsffPIWT09XvHjxgK9+9av42a/+LF6+fAErC6Rm0Z0Dr168wM/89E/jgw8/xKtXH6B397iXsP/h3tXmhNzSxUYoFEevcgq2bhiLpXdiKmlUYBHSBQdhhFkcnydb7obQYQoEBduK46vQcV/BjXHWKv/BBiuDuh/pszzP8TCJvSw4dmTYNwal8l099zUkOAQPVIqwet+O87PPrMlPRs95IgSYVRBBjP04thtQJIN3aN2Zyj2hj4pOKG2A3l/S9w+EaYweCVgFnkX4AoijibcrPIfvwG1RzVAGDtcvOHEc6rOKwO2em8BUniVJhive0BTgchuAtR5QjeyRlkpAXn97plhbiOmmee7tOraqjW5PfI6YINyE43feBp5v785Fx8cE2ubpY7D/zaFhoFE3svj0AZ0RVh7Co18jjgPp5LELRQRDKGAhn0UjILIWAiAYY+L73/8+Xn/8Cd6+eY0Pn34G/cUDmvOLOQf28crCnMY03rSXKJA5Ib3fdgbiArbCe480xL5ccMRuM7dQLYZcCyo3F8Rr/RvycHYSqXusqiWd1daFheqDxniNCn35AkMnrnNAr9eyH5VWrrxrzmGqjXuW7xnMiVdb7+i9Rbv5TsT09GGXn3NNqKCIpLGzzMneZQKzeKM183avUZs3St9u+ynTjJ0dZjyM/XN+2OApvUvkrKYMRlrEMz1LrYqyXutRZyrPahAWeuHvwG3k7q0RwZ9+/wHvIdAIQvM4z9INr45aQ8/T8/q9yPEsa6ADXI6rstNR9rg1EgFHunx8Zx0HlVLqGXJAS6vtltcDWVz6FpLLcI0spb2Vv60OkeP47o2Tv4VSX+ejerdBx3JORW4w+d45vrc+9bn35vxp47+VzR1/ZH0e9yzlYRbLTrzLQ3/rXLJnTFj3AQWzMkQyhYw0cx8D17FjpYzJn3OKVQCyC5bsGbdAUP+FR+KyulxT6jHGofcxzIBR9YBdIW2Cxkx7fukS7DXhmpjxm4aciMrXGd2QOXaBAC1654VczW7IYRUyBo/mxiN+LwIou1n2BujAUPHonBVH4iwOOuDSsU76AChGc36mlvLFtWB9xqaKNphO57X3oNCxo/XujSaqgc7Xfk6ITuxelwliuoC6w8fYgqWjKMwpI6VkjuGFrU06iUmLjADI9Pp+zXgRS2tQppp3zkSFL4xBqILIracWtDiWQ7VWhs/7FUeFT/IZgD2nWAbrdXZ/+ZsiO06Bn2sOot1nBqFKnW1ME/leoSIZIhb/L0s4fdCZMi4auHjHwC0Bu6eYBm0icywCap3zouySxvmBNcOI4qMf/ACvP/kEIsDl4YKXr15A3IP3ySdv/Pm1LgAgzE3WrIng/CeVeZiVd3p4nFm46df3HZlWCHPf95hb81oKfC7TszBYL2F3Jj1Bz8plu+DycMHlcrGoodax77sZo65XtNZwuTzg4cUDXry44OGyAdPaAXPsE0hDz7SctzbMKKWggceFOK8oxnD3e5BkmKxFoqW1hb8jCOtCoNVydTOqCFb3gYahMXDZNlx6v32nlO5bzzDQMLyIpXIAiEgfIupxPMtzDmerKiV2rtZ3BsrrKqrUZxxBw0OxXiMhId1f86lr5IE60aaPh5F5VcCrSkF6MPRmDlqunTrRJNef90gTyCytqmdGx42x43q9Ynel5zmjw/sILTxcxw48Sf9MABmJa6spB0ecMBkpvcA1Cu2owB+xaYnWQOJrCL/1dzxjGMCtgBtGxFBqbIwiB6VCMwpVXMrglO3aLFbKgsomBEneB16bdMSE8hJx5O+GIgsb8T4XQDnfoAMARF1waohceFXzuvXNDQiTAlqzCDCmTcCjjJQ8zFPDXKnQlblFIccovB+Lb9TV/txDCIQIvvnNb+Ljjz/GuzdvcX33hMurl5CtoW8dl8uGFy8eoMNo/dN1x74Pj/S4r3zYmraSKubKRUkFWQ05JVUIafwgXtJAbAK+RdeoWnrYMcX0qLgZPVnxeN+tfhAjhYZOXHWiawveqddhRiIKoCgOht4tbQAm9D9fq4edMXukirG7mDVHkFC2MorhKL8Uutoa4HUguDqszbfwCQH6LOuuq3NQXXgfqmawY2OGQ90hvxhNMmqJsp4e2v45BUAIjPyrIbXtZ2+Ad9ujcHSPr9SnQe87MY7rRLnk5BIV0jkE4Gat0zB3pOgZwZE1eBYpBFnOWVJWL2xFg/be6iD36P9do8phj4nDipK+7w7iQi0McxQwescGJEUHEXi0RF0Xp10NyPQ6PRiW7n8O+YXnTNIAcE8ZN1y9pVP33nHPOHajr6Du5a3hqhri+KxKs+/JVsl/7kQ0KeCMx+Y5+Cz4WW9L85kQhW/mWHSb+r2NFlOtALQZ76th/laeVeqh/lxphV/fuUfVDfXcM2+KkzXubOZjzjCUs4umpWLM4GPCM8TnwZ9ji+777e+xvy4OTuNtgHj2g0X6msBQ9XF7XKaqkb4S3yMaWk3nHiIYOhYnQmvNnTcClHk1n/v01Orh8k0TK8Y9xwC6YJ8DCsVFzGjaAC90bYbauQ90RjWLpTY3NAyPTurNZJQx1WslDiuB6nVOnb2Zc0M8AWw4gWHKMhRTjAKFtqJmEFIFmtp3c9pzaHNoEOgcESH1HHyhDELrQSVR7SEUsUAhqTCvOT5DAHcapjHJiFXmRSZhYaXwJKsumgWTZXQD2MEEsnxvgvM6jnh+eB8QBhNyKRozgAyns2KD8IOYHbOmrEyiQyzH0AWM1Qt48NJxyZAKLuvcROpcIVyxEkXKEhG8e/cW3/3ed/H69Wvs1x3QjhcvX0JghplP3JpKwVFhEUNG/VKoNOKiUKTi9bBdMvUGGkUXg5wpvYgpAtaUiSkSXkP+FBjT1Dnd22jXPlwuaF7DQAFsl45Le8C+UXDdcHl4wKuXD3jx8IDuOcJjDoyrGY/2p0c8XZ+8uJobg+aEdsGYA/scuLq3lVE7FcdvGNxMPLEtbejwVA9GITVAvV20utXX5VnPTzXD3RgTV5+3TIVcTKAWz8toB3pAolJxtxqf1D348funSJ4rc8sudKtAbAra9DQPI3gk1FSUDsqBKrQVASFScwreVkGDRxUHhkDDi3EUMyKS5Qi8RrWvrwCiA5jm1VZoFBUHgOZ1Orqvz9SM5Gu+kQpAw5Drtbk8IqmJQIvxgXRu6sR17jG2s+28gUAgrXsYLUP4q7CltEuYsTeYKBk8De9Zu8XAFPbo9NTas2supEsUtnyPW4345LUFHx2t0PTO2UcR2ULB4KhnEaxMDNAwGyNSV2hMCEEfzYoqYmaqmJ+rZvKfR+Co1xWyGldMSwLSIEx+KeWdrOvT6GGEAl0sFNvpE2u5TTpUZveaa4ohJd2rNRcsb40Kds5L7a7C9EUPSpNYwUcRQVPxWqu2Wk2bS8pGl6RNdChef/wDvPnkY1wfH73zlktS24bt8oCXD9ai/eHhBR4envB4fQJ0OD/y/XeBSwCPOHEJoir0jpiVB1rwCVUAGzMNcE3dMObRSeKGFADY9yswhmGBJv3HmFDnvwdMhCq8hfzVZSDjZ+rRR3S4zH23YpZimJF46bUznOFYJ5Nm67ogL5VNhcgWuMK0sS2cE5K1/fwBx9Rbnunm6yHqco8rfgPmwcVg1IR5VMdgt5rEpWpEDeNdS2dKNd7FNSLQtkG7yxFS8DJmwb21UyAw77AdB1sbU5w00tiBZh5lUKl240UUQDZcqYbD2Emh8YyfXQbNkh0nQAC9ODamPFFBMWyttccZtmWfLnXxRN+LKnY6G4J1GiSoE9C5U+89Gic+cxYHGSgN7dPGLRf3QROv+WxXCCWdFHyl6ghDT9Q155IBS13HfO5thMtRz6gzOtZVvFl75wtptE5HDJ91NG7fg9WQGiQ2/nbUg/7/Bq9tt4ih/h+NCil3GO9TTedpHcd9g986N6MBzVODrphd8HTdcb3uQc8iNj72y+mb00d2ybpIFuOH10OFAFupVQbvQCViDVYEWc8unRepi0N76lU0RMR/XpgdZlhRp4nUiwCmVeWCChD6p6V/t9AZWBN0cTjQZa5aHD7cD4RDaIo77ZnW7UBHXxZn8fn5OBTALrkmA4nLQ5iePHFtQBOPdrq6c9nxdden4BNmqNuzrqzrP+qpymgCHaaLbM3qBUkDMLK0yCRecMQlApUGrqHskDix+3lq0tAGW4lMXMWNZ3Pi047EF8ogtBwaCtwuYBChcThcx8MWgisRHo4IMw9uCM0uEEPDFpzP4IZGFxCP0FFYjR0fTitE9a5FnEEWroRAK9HNsUzWsqnCHBGJBAiG7GR0ITsAOHrqgoDD38nrykxTrKmC+I1eYwqHCN68eYvf+I3fwC/8wi/gK1/5Cj788EM8PDzgcrng1atXEYr+9FS6QbmiNQ7F8nrrQMOieNWCv9qSmEeqXBB+m2svkS9NAXFjDA0mjcUh4077lJE3GWVwuVwypcu/3/eBrY0guvbdHvWAxj7RL2vev7ohgNE3/KflmuP1UhUF/uzdckhbepqJu2k557od6yeoC8VGAMac2C4bOjav/o9lHPTa1I0/elQW5nwHSZ7zIi3fiXlioVXot/FSKTkK7XffoRqTtxpWHPPNLct8FoOpG+mWuknBoCUYEopBiZIVQzyFY5r1zM1lzcSv18ZC9DMY3T7WukQUjq5Xw7HHx3d45+mNJxiIuMFiGh3WmSHoKXCHGBxnC8jQXeAWv4I2aRrguH9HYdj+WO61i58dM02I7diNKX7WiNQMNUZ0j6wDreNNfK3IX3H9GPZtHjHW1PNaa6Q5LUPBuRYQU2xJm8Cj58qQoHn9FaFYZsdTPIpnTq9t5gpXs+dKpfVTId2EGwwz+k0XXGxsFHwQAvEsc+VeLb/7QClAWXRtW5ZKRPD69Wt84xtfx3/qV38v9usVLg6Y4dHTkF+8mHh6vOLFixe47leb0zDDbYRu+0Oz6DPrlZUIIL9m27YSGbgv9UnU93/Oa/Cgfd/x4MLsu3fvboyVfBY7WjL6KfAv6MrV6hOUaET+a74PYwyLQgIWpU1Iu/OpMV4Wx7yRw3zvGBW0bRu2vmWRUjfsUG09GoSeb3LgZ6bJ0q2mjumo2NTvSX/jPNyp3UOjcMhKjAg/AClN5WdUlJ6NkihyH9/Lc0wFrK7F8bXV4MeIDHbbPAG4JZp3DBOain2Vm6yWKLda4vwymogyAZrE3oRoSnm8yt/P0Kf6+Z6haDWKHs5hsf7ROGjXPC+/HZ9vv99ZuWfkujqnG0X9MM/nDFnxe5nPvXGt74w7kOsPUPEh7agiaZUFjs+/Z1y6S2M+BdazWp5NXe0w/+PvHH4YiyuOSOqtUODp6RoRQhR7Y653hikw55TpN3S4SOkSFmIsRHrop4weZiQQne2tFacuXJ/rPfC8CQtq20ND1mltwZMFj9240pAp70J+MGERm1jxKte5udwhkOZyh8JTl+HGUucN2m7w0taAkVtlAcWisnIsyTeJTxUvLbAnIxBTlplAz9TpeIbLNHOawal5+3nSk30McwiMkJYOWVLwbJt0IE9/l8kDfdE99rnj0i9gcW46wFfN8Ra+MAahI3GQI7aHO+k+ESG0Zw58QwrRBB4OpnolwgDiAgeQ0T+NCqI9NJ/pRKkKGpTvb4jdM+OnMgkK3kCE3qnaG6zYs1MSkTAsmU5KcrQqG4ZMDJdHGpIO6xt5yTAftLqnl0ITx/3d734P3/3ud/Cd734bX/3qV/Hhhx/i5cuXuFwuePnypaW6eDh7Jd739qsKydynyiSlvJ8KQg3jjbGR6THiRGytGGJbI1qYVxsKUBHGeqxnSJnR8ruJQMcsghrAhy/C25yYw4pJ1xbuUIVOK86GZh6oOu8gNkjFzdreN0j5R6u/21Hc05g4xUJvprR4xJQqHqC4AEDfnOCKp2oUnClKTcWho1C9jPeOkPxZ+5zCjKWz8Hm9GOiOoL6GPFj1ulqgdcWlfNeRKbcYgwZjJr6k0MXrubdukFUjrLPsLd9BXL9ZFyKMlv1WDSXOFDX/3f/t+479el2NVie4QJB7TCM6jSsAWCvU9lJzHw2eF/gEBVc+RTA8CtzPKQD2TAkFpN6b11WhXpL3ebRoHQdtXYwmoEPC6ErSbHuWpuGnJb1sDVHgMKOH4HqO0T4RF6p8NLyfuG/swZ5B0lHrOk1PK1XPxTeXtYawNyBo3QX35mkMEKvJM1nU1EOrAegELr2kVmtwqtzVOwpP7bAhPYVCXrDvO771zW/i3bu35unzCJipsOLSbsi4PFj62PX6AmMfeJxPGIIo3B/RkAB2jwix9cKytzWVrNYCmk6vKz9TVVyvZhhqfcN4+xbX69UNSrbOl8sDINaUIdKpfY2rQEljUDUEHfGQjhclXpe1NKE7GyRc9yvG3IEp6NvFDN6F/vEnawZZinbDLS/gs4swu+/rdbraYmodBFvHHu/k381I2QNvq/Gr8rR7Mkh8Rgr0fNd63hE/eW9dt1BhivGz927R3Mu7XOL0ea5GoKRpS0qbHhRdVGPdCYS6wisfJeUYgTupZJN+km1rKMAEURrAwzR9l+8/J8/wb1WW4nf3rrudEQJf2FLaRCNdeRhHJ/Xe+zL3c5/rWOuz1qGmcUwpnD73NzGd5siH4/nL5x7XCZJGMfIhx3g71nq27xnYKs9+bt2fpQ1e2kIidb0d1khu3hnvwrrvYTjwc28qQgMb9hzlP0YbV7pDbFTA6ps2v4hpsUgnkABR/1Rn6kK0JyokoxYX3LVUagCRrt1aj+eHlFXl7EMarnoki3W/QhT0V8DrGArm5LMY1a+ho8MNgWEIh5+DabMfmin0w/VBGreoQ0prpUscDJ8UEXFsc7aUy4ojUZOJhraZZ4065RgzdQS/p/ceqVsALFOj6leA13OqOrtfIlkI2opUu6avkzmeRYZcHaNqRRfDzjEnldbn4QtjEAJuBeX1d5jC39YDXu+7Z2ShgM2DAKBsIq/Lw9UdYbMbiwcJaYksKvczbDuID18ked2RCAHAkRglwq1Ei4MjPXcHK+Zh/AzuZltmGhxETJgWIql/uQgkquH9E9MGImKJyE4v8rt3b/Hu3Vs8Pr7D27dv8fT0hJcvX6K1hm3b8PDwgMfHR1yLUagabtZ1Pxh0yt5XbzVXPYw1dX9R2FxZw4oPPAa1wFnzwmE9BDp1I4EpAwrziIpYdNOEhIFn8HD62hHGGEDrMR8aG4g0ImJGoemKke99o6AZOEIDkBPqgyC9Mpr0worjbJOG6SkZGfXk77goRrMi1RF+qslMjkLykVE+J9wcgXtYGXNYt6l0TO4OYg2OzwCNkaoeynlfaIpwY8mw1zrmY0HJ6tmnArpTaG+mmLYmGPsee2zhsMnU4/nAAYdTITIa7gytJfHO+gX22RSP9A7sXoR8zBHfnwBksmnSbfH0MC04Kx7FqTNx1owIPDO3+LbgvT3oU8dSBU/ev/z98OwjjVuFWcVCzEI5yY/s/EiDEVvIN2leRDo9gE0sDdkERb++FS+hWAqPFUk0pSLqCXlKEPPrSbsoANr4V++V0U8zxk+2xAjc9+/5naYCJhCPyPG9nGZ8ggh0ihuWEHQ6cu5bs7+5Uah6zmIvnaYTV8TXw+5KYerN27c21+4eXnpEm0C6hdtfHi64XDc8XC542jY87TswByqdDGOLr5elCWUdidZWg9D1esWE4mm/eutZuzANN2kc2b3rV2sNr5rFZYnY2g1VvHt6xBgDDw8PTltXA8ucIyKTaPymsMr1evXBB1ZMW9NoRDwdY+Dtu+T51+sVYx8WxdovBf8zqoLGmu1yiSghl8ZAfk4Mr+t3Yyg5nDlx4aq1hilZt4TGp15SwereHOWP25p8cOOx14WYJSJkUeLSGJSRXljex7N8jP4QcblCFShNJqqhKnkVlnsX3JajkwYn3IEasVFIKsy5Zt2A0pbgFCP2Ea6V0VF60BsA0wuwyko3fMC/vxstUT7fM9TWVMYc1wzaZfftRj+LsEm8SGcZS0qsKer3DBf3ZL8cUzov6jNSprnHCyWU2tBDBMj4isM7YlwulYfxiBGXpgwex/Fp8Jxh6N463LtOl/VeDYuV3tVr772XnThZ95C6yWDUpia/V1W8e/suyhQoECniCmBdPuFNBZ1XvZK3kMbpIcLpuFZH+sjvVDWLUztfzUFVWXy9V1W97IMAjQ1vZjpnXecyeaR5lod33VKr1VqbXzSv0SQKDJchLq5/SesY4xla6VLRoGIMhUxAZDMcFoVqKXGxrI2tqy9v0aPVdcoW9X1VNRo9iOuCz6WNti6RMdB7hzS7XtwoaM9x+tAEUPIdjWwXIKNf+Y7QeznOz+ATXxiD0JEZHoVlCqRAHuBKKOvyJuFlyphE3ZTVhEADSy3YfPCaOuNXhp6XsYlIGoTCCiQe1bYqCp928OpcOL/4u0jUvqDS7Pa/5RnLugDhSaXgwjnOOQOJbxQZNcXbUjDqYcr5jTHw/e9/D9enp4gEomDJcPMoGnnYx7q/xxC841xu104X3Ig9E7hgteLRst7qhLR4ySmsSijo9tOKAJMJi1mNxdp/65i47gP72F1Rn8AY2DSF5+nROUbENJUp0HM+09LsGBcth4mTraH1hraZ9Z1G0LpWdW4o62eGJM2/+fOHd39TVVwul2VPBF5uQ24J4BGOa3u8vhpejow27jVpwP9mUUJTJ5quxNueP0Obs4LWc8HddVwtQkgpgGghwovRpmXNqUllvCypCIw5bRtEhyk/RwEqjIjrWhyFsfovNsX555HpZsQQi6vPM0LoCI7zdqqaFe6XtUaUJtmBeZ1mKGmFlQCoEWa3uHUUFPndvc+fOuTDGbgrdGM9X+H1c4EQUtRpF6bIF3mOjSeJtU51o1hrrBHAM+JKtDB9TMOrZilmZoRuXoyaU6zdRVTJYzOqpTerJdcAzOk0nsqvH7E5ZmTwK4C+dXc+KPbBXHjFho4pZtibkAibp3JmvL0V3nRvzX1/uwuPzjktfbvFvMwoookjIrCSQ264dkG0946+eSv5g8EBUyNWIGqdwQT9iL5V4z0PDw8AgKenp5LKVdKLXYGbc2Lfs4C1iLjzxbp18TsajzmWfR+g4lQF0+7RVyKWIs3xk2fTGHTddzztV0DN8THHxPVpx7tHq5tn46IBq2U6ggha26CqRRZwI40bwrjoca6I2z72mg7HM+mon+fHgmADF2kcovPE6gPyLCX9r5E6t+fQ/6dmkBtqUb7H6KBbHKsyjBvSgKgJWK8LGuAvXP9OmWw1EPG59/jdjQJ7GoUCjnScihHoJQ9ezGhQV7r5fWjcbgDRfO6nwVH5vCcr3fv7UbYFki/xnpxJ5V9GWGvk/O09a+rlPZ3hOVntdr4S70r58WgkyWvtGix6SP2rxpjv3036kOPyMR8LYZa9PPLW587OZ+3l8f51nWbwHsqZ9+AoD0PqmmPZ6yXNeMJp8ViOtSqNEkhRUgR0wMR7iQ+qxqP9fVPX6PgwODJ6RjLw4Qgxj/VLc4DEWt1P01pon8vqvQlEWxpVxK06AKANsnHdEdkDIJ+By3W8bbZSR83/6vM4Bh3QICTSQ9YHI5Ql6Tg8QmihxZIyvAAZVeX4YOxIbuc+U5bjWq5npsF9baaPedSftoxMMvlBDnMCeA5RIoNqTWGmP9fgiufgC2MQIkG+EZSlhNO3Bnomj4cUEnZ6t4bbovr2mDGAOvjh8DIPksStgaHyQpoWSxjIGFZhH3NKLP6R2MjDkMi9knb7YNZaDeFTlW3r6Z1YBf9GAUbyWfWf4fgataAxgFQeKkMyZallpXxVQGaugz/33Zs3aALrwvWw4dWrF5Gzuu87Hh4ecH26ejG0o0LMp9wXrupBIjKrWi6rzdNnJz4fTcIT+MDomxLOb4KkJ0CIH37KBeDBnQCLoqrdZ2toxbLndY/imzoVY9/NV7EPzDYw+/DiYYwgorXeSJDCFFXrnEOB0dfZ9z0MVq7mNPfW97aYHnyfJ5gbE8xG3FAhgtkQHYAqMaKgbUSkoC5SCTruCf9VInYUIrj+9e/1uyCQfj4aPFJHboXnYL6gJwMhxLnOFrggTTBHPsMI4IpzlZkpkOlyd4SG6slrrUGHeb4khKG8dnKPhSPzsF/HT+n5rBSkfBBYv5tzYsyB635NY9CYZow6ASKCrTfMMfNEqTNP0ke/bmKa7C8KZhI20jFHgjDi4z7+HgXke/he4XgOjnTJrwKZe16M0EFC0HQ6xj8nd+N5LR02u6U1N5uu0RARiAx08gtxWtK8xgCNQUBEVLBpg9Eg8WggdoksNfSgViQePMUcpxlUprqAC+tExQSw1gVTOq57NnZQNRlwV9Z8852a6kxuZuMDcHyAesrG9MLh0aaWo1HzyomPPTtDUYnR+Dy8y6RONQFVKFwKpDdsW8ccHX3bwiD0sG2Y+wCmYugIug7n1bH3EkcdzVOntm0Lr19zPjT3Hdd9eKh7dorUMX1BBR988AE+/PBDXC6XUFxr3aA0KhgeVWNQE6tTsM+JFy9fovVMFyDfmXPi6ekJj9fk3YB3JtuHzU2BcbWoyQaLeNr6htY39G7iJI06rBt08QihJdJVFdIFc1jUbDW+3JwvYZoEnQLEJaf3YhGvvaUjb5FrClSjUAVlPajC51TVZQT1+cI9+KmYVMFeOYdQBNw4elC6mxtJ2yQHz+iVOvUj7eH4jwruCfdhNQ64ARlFqSYkAzcZPApEA9BpNLkpmB4ErHtSZdb8nRuZ15i6tRoVAJTI51W2qPzmaFyyiMpRalut+pA6PQW89MQhrfKenAYclef1HJK2xHO8g2Qaz+rPel/9mbpErJCPP2u4JC8nVYXUMR8dN3q7p8/APUNqNbxq0QmiaDTX2JFHqHtAy8mt+gtnp2HfsNBWckKJ94iwPo/CIlIGVKd3pOp4fHqCaqaJLesY7wKGWjkDo31enwbqTQNSXzLZloXTEXwSMDmAGxPzO9DijFjzS73jqwiKcSTPyEKryA+dL0+PDmKHMS18Os4SdXc+QuNbWIa60ehcRtNZIwoZpmMUySD2R5j1E1uYRlUrvWHrUWvV2hTKuvAMexAJab4FVTCKZ0LFHDu99ZA9pbUI9JiAN6Ipy+V6oBJ3FBDZyliKMZKCFAAVa0IB9X6Iutb8unNEA74wBiGKaPUboBBWKq1BdO8TgPpdKwQDgJchuo0gCVGRgrSmYG1IJ9EiWwToBYE5plUgtdx525CsO8JONDTqLO93w9E8cCzxgYs/X/0Ad/F6Cprt9GoakxmuJHyi4srnzdyLoKGOqBSALHWgKkj2rHdv3uL6+IS5P0HnDhFF74KHhw0vXrzAy5cv8fT4iO1qUUM0TE2P/xehADvLu1dlKhWA7AjE62gz1zhAst7nxG+U56Pgggl5M9fzjhK4EvfKNHUJFYyaQcNb9XoBVPjYyEAX1ZPGAZWojM93EAebGA4xck1IcMCxsSPbDLbkpCo3S9MDUH8GcQh88Xf3FpEV1QB0jOZajXu3cIzIORpwbVHNzUvlDbmNoNBUv4quX2UNLJ0sz6qSsfI9vLeOXTJs9ziPo+HK3jvDsAgRiGah8nh+DhuqiXcT3mkGK10KjzUE+0zvEuuAsDg7jbQ6bhWY9xU6maR3fBjQEB4F6mV0PLZmFsHe6Wotqt/8rN4z+vB834NV8L/1NgbuOd2vxD5PaKU7EsISvVQiWMYSz5WDmC4AW2SYcJQh7IDJsuxSKGKGoa01LyZt6ZFpDFo9UM3DuzvDvOHpXB4VQtBoeeI8O3SJpC8WQWNKytbTeBFCNgStqdXpcobMWnchAANo0p09ciVbGGUnFAgexzXOvffuADakOaBiETMff/yRpYbSmONeTmnWgrahYWsdmxs4eu+4bBvGtkeB+UHL+kEuYDMF8lFG6lBIu2xbFNZsXiByTsXO9JFpBrFXL1/hp3/6p/HixQtfcxMQrfYQ+SpybQ7K5dXbzW8PF6/LpGgbW8LbeK7eMEFHKkbk2ZfLBTon9ifrxiaKiFJSANt2gQjw+GjpZJfLlm3m/R3iWoPhoXiDDA3+8xxfse33aC2x6C0ljogAnelivUTf5pk5KoD8vp7j6d0dadTJLp4SClII3sBi3EoDknf2dHnD5JbkPYvTIXBb/UzzDBc+WVagGrjqNT8MP37fodJpRn9D2YmirpvmiWH3YZcVqGDXZx7fAXDf7jmbKM+0OLvZccaiFylf1+fdc6qpy6/2eZTv3TACj4ZU1stkxMRtxPIRlypOLw6smKfReyN15GR8TsXd+/iortuEw7TqaCFia5x3Sa9tPD/0Oa3vXXk4oZ7x+nve7zNQ/jTCYmvoz1UJ3cikOnFl0ksIpAaZYwOZoMb3teh3pDuHnG38KSJUdELQcb0Op3vL1EPv4XQmSjkRrRFLGrUvxQiSGWOmR/Z6uQTWsxNkkwmV3CPylhs9AGacFxVv8MHrs/aPkIb68pE38f6a8yIABmbU61Wd9nzup6ODikaTjpDPY8/9ac7v1aN/qJBVPSzklLAzHGnrWgeJciZga9rq8yirqVGSRfdpGaBAh7+q8XbQQYDkJeJ6GmsdMcpHQ75b9aqIZOUIuXe6RnTx3c/BF8YgRCKTxMW/A8D/UaETHIgsFW5ZzUoUjoD8WZkuwZTlInwHbSOKrgIEF/SYq3c7Fv+sM58nNFSlVToJq4/fT5/NsKQAlfHOOcNyuRA7XSOtWhAxHzkPe7mPz0hDAQC9te6SSbx7fMRHP/gBPvrBR/joKx/h5atX+MpXvuJFLS0l6cXLlyGEjqdMg+EYuLIsnFb3aLX8H4Q7rtKBYVaoEU33/p4GDhvFYiQ5XjNmRnlJEsKo76K2D9IFTTsatvD4tWatC8Mgg5K6OIHw8ospWdwbpuDVehOcCw0Ztbj1nEYlRRJP67Pq56OBCKqRhmURFLcV8iuOxD48I4De25fjeaPimcpLWrGN4OW5u72/emiSIPNMzLnO/zgeznXJ5eW8bBeweZvOqYorNSO/V5pEQ5fn1qDWTlJlBFF6k/mTfIhKXRZOt/HtY+A69jAwve9Auto8okSxsrYIu2b4fRHVcBdnV3zmnjFd74i3N+Mp99Xv7MnqUWIH2g3g+NQQYA50a00nzOcXvSH4pZZ7KfjYp6KEiq1RBzxqBN6po3kkopTfTYHvbFmLQluAEF7CR9oEaB2M2jLhcEK0o8+GMWVxDhj/81otw4xTKlSW1OmmjTmNYGVeOiFijdFN0LJ5Jd+md9aVpKjZ5sJ62VvW2DFPnnpr+wbpG6TvQB+QkdEw27a5YWhDax6hI2155rFeyD3FjtEzDw8PlqJ0vUKBjA7SNEo8PDzg4eEBvXcfr6Uxs5ukiIQ8wBpqawraRNvy78Zbkr/QCM2xUQAVkUgxfnp6vGt8aE2wbc0bSjwBUDPQdE9t83p9TSROrIC8dO14VnnBzfmjTM/T4giytR41r3iO7imACw4XQbryVVUNwf3I70KGWaJ1q0yQaY0AQunl4KlozWmdelRHKiqaz7pHdxYZoNCpE344ENCIwXVbFXignM0gOIw8WY2MR6h7ljhzeD+V4qJThKEh8HGGEeae0a++a8XNCXFDOTxyUqTDYxWMNiFTz+sZA24dsvzOamjNw/xDObq5Z8Xdqt/Ip1y3vjPmyvnmat3ns58hkz73LpRrlUaB1NiWd9SoMeok9r4OwWp4zzGRYSc+jOEGEE3aV+eQ9Gd6Wqzi8e1j0DyOUp19hUqrdCDZdawBZ7X4bqc9hvHGEbIpnSnq58QjjKZaap7nZVkTrLHytqmYOkLOkCYYyjWj0cLXQ209Yk+8WdJUNj0SjGk6vnrWgALQMb1OnNX9ie2C8R7yEql47Gs0yu+lVxAlv1i7hacc9nKp60X5glFLkzp9z33MCwOPIiK8qtStmcOnvJfvCv7HzCbYmra24no15HqDRLR2cVwaaEWXW+dwH34og5CI/G0AHwMYAHZV/UMi8rMA/s8Afg+Avw3gv6Oq3/Pr/zSAP+HX/5Oq+q/+EG9BKHvLZMWVXYmNAyjUEAFozPHClnxWjN+QuxUiksKtKaC5WHmyQoBpq8FEpRh7SMyVRgA3EpHQcx6uvlCcjinXFZgSphuUZ1pSUOzFouyuRaoEihldd9SfY+H1vrZTsyZNWY+qxOba57o3OAKLtUJ88+YN9us1FGx6Ti2kTaLOQLRpH0k43T5szFn1GSWphCUuQiit1XaqK7LXw3w0MsVnJ8QpTN3ONwWu4THigrnv0bnLUsWs+NiEpQx01UWojne2toQcxnwwodOVLSfutApXw01VMO3euQqvGtTCGcc633vGoPpvOnexOj6Is3Z8/j3l9zgn/rxXOI1rWvGsEvCpFvklIhkl11CoN5msPdPqqqUXby1GmvPnGcBRqHJjzCLmKM+G7XmD1VRZ63uIn6nnBcQ6d1VTMGf5DFVTfmk04Php7HPj0D7mGvn3BYcfD58AQMM2boVSCUmJAp7RcnWjAJW9POd2n5bv6rPWWh4JR0HzaHy8d4/EuFZYrtN6hUWdbB5RQoO02X4yCsbex7TnFBab1x9rzfL1m1htoS4WV8NaZb23pRtZ89Sb1rqlnEkJFZc8O0ETbBQxP1VYHruv92wIbx6YlgNP8wSw9YZ9zBDeaq28Vs7j1NopwwZhchCjWlE8z8h6f5rnkREfcPojkjXW2AJeRDDRIG2DbBdgG5C9o7US9eLRQtfrNXCRyHSke6rqBgDNVLFmtYQ+/PADSxHTiad9xxgaBhvW6Out48WLF5FqVvkqeXc14HBfrtfdx0ASaCnd27YteMdx3aPXvXdcLpdVKC7zsjVdjTfm0NiwbZnqLFweIf/LSM9Z0tvqeYuzGQoEOYApJxbl1rFx/Z9RPisceVsoyX7c6vHkWkb6MUypaMVAuvI9T5Vz5WA97Za62oOnUx7La45y2HG9741f7uDcFx1+HHxC+P+iTJOeB30+7FAZoMuWSLqqAnqC6rof+cV9A8S6j4vDCAAdG3MmztfnHaG+I4oTq6cBSdEvUPETYLTGPV62Tp/X8FnEseIwjg/y7DOfG/9z76YsV3eFn49NR47rbH9rYXRYTl45K/YZEFhNPabN5rPV1y35qMn67CrmMqWaXiVSol1j7er62M/4O2x8TTxV1Iqb+r57lFhEkHhNtbImGg95Zj3LJ5Nzi/GafACKqI9DnVTvr1fKGQCNGpYVS2JOnQSeWsdrasOF5D8mn3mjBWX5DMdRPs+WN+S7qH80mQJFXLHIpIiuWXDBu5UJgJlytr3C5CIdKZNR/sv7AYA1SRXkWBCJ5q++4THHVZfMZ0/vLp3vYGo8zPEGRsytGTwaodIsldPc5rE6AkyvKuOId5shGMASPPJ3K0Lov6Sq3y6//ykAf1lV/4yI/Cn//Z8WkV8D8McA/AEAvwzg3xCRv08Z2/gMqFcRr5PMn8fPGhEGeb+nn5SK70RkJ7fLs+P5LT9ntAFzCLnfshT2RR0phRS2zC5jX98l8Swrz8M5zFBYercIEoabGeKMQMQ63xjzkvPLuZJwuf9WJH4PhdeVilvCmlE8yzqqWSdtHBPf+9738Pj4mIqyAG3bcJnAmA/Yx8CrfcfY92zD7kJVCIX+bkutOUQk+bur1xNw4Z3hss3TC4pHj4ShEvmabgZN40FrgtqqfH03lvcOT+VhwWjVUQRZTxm741msqQKMOmGxVQsTJsGWmC8jhOLgCv0WblEvnlTOaUGOA44QT6pRqH5v6GC4MgouHRkwfx6F1XrNPUH1KEAtxqjDWCPuw3GE5+soELN4XZLzdZxhCPPr411TgWFRJLa/6fGQxWDmhktfs8lQW8Xdta7zr/O0V1bjdKaRGAuApxgAwzsJjTGxX6272O5Rdj9B8KPjE8L9X3O9qzGQe06mzfaoIprp3oJy7jVTQP1+iKDdKKer8ndUBAiL4Cm4vQ921iIV1x9z5C92VsvUQ+leGXorNb/sPKjXu9Bo6dqbWJqYAFvv6C0jT/h9ppbZe3rrVtgertSLIFPTCv9j4WXW8vHRWJF4E/zGPjFmA7YNsu/RhUPQ0KalWF56t+YAXkS6tQZMMxKZDKmQYYZgyklx7n08UWBSojKBrZW1Lcnfk6gAEMwxsO9XK+48BjYVoHVLaWod0u0fPHKKxqBtG1HPZz8IaUdaSDyg4YUdv0QEj9cnvHn3zoReVa8tYHy1Afjgww/w8PCAfd/x1lvPV8fDvchPGo46O4A1FlYvigbIOuaBvma3EnavtIiyFmeE/2wtao2FTEHsvQPC1DIuu7hQ7Y0XPN2a6bJ1PijvojDPZ4i44Yn/+m1EUT17R5lsMQyoZv2fA6zfufHNi67fGGcCr3k16c+tstGbpavKLOO6I6iLUKG6HylSn/kTBj9SfaKu5WoMuF2/5T5n/LmmQTGeVaPu7oO2Qispu69ddav8ouqyfNSU/Oz3HI0QKSdlxAjPt31XMhoOzwhZvDjz1vVJfpVrYVR2DgByxMfVoRvLotRlnjfeLvwUyZs/bey82owbxqueM1IZLWqxJ3wDU/nohAiaU98Vxp1W5qhYVkVyv2297N4wBAKYMiMlWsCI8RkLrDDH4Nu374oemltx7BCm5Rote1ArrgQt8S6egJSRS/w2nb4GDgmd9/UdNGj6Tz4b5ZrDfsZPuAxHvSNwgcnfiUfUXymvZRUmAbwRDQMMihpgvJQTZzkWndApkYo1humFS93Uoko1KQ5B6tIFp6lvHvGV+hqlveERu9GkInQRhB5AxXg1ujK6qoFBHZwScDg/0gBp0GmGyum1qCr/qHvwHPwnSRn7owD+i/75zwH4twD80/79n1fVRwB/S0T+BoB/GMD//dMe1rqkcCxHolkkUKkkmoTLLPhV6ap/DysEzCKXi3mLsIJUDHujAOOCULPnNNNWMw1I+Ozbwk1BWKuCHJukoEWV3c4shwSBGBMjBHB1AkTSdFTs56CRo0a/eAgeAHerBcIfGUwKX4h15/GM6BKf2He/+1185zvfwe/4hZ/HT/3MV/D27Vu8ePkSgNUT2jbzao5Xr7DvA1fPf7zOsbxPXQBeGFD8ZM4jQqmfc+K6X+13GqOGM1EnSLMnw9m2LXBARDI9qnnhUF2jS1jfgeOj4DxJUJxo1zo0c0xoc6PQGKCHhgedYx1zYh+7RUXpNGWCOOeCdFUUspMMCeDK5OyM+Dtu8mgPhs7ynuU6iKOge0A9TFjj+bfCR927Ix7dMyIdx1XHxxa84yigL89JQYftlkOoRz3398dCgV/VI7xUEeG6/nfDh1RESNjJaW1/2PrxEEZ6WNf67ucMCcmgZqQejjkCpyicjDnvKio/QfB3jU9QyWeB2aPgTAGCnrxqwOAtPJQiSA8Sz3ERmu36+8wzcMxe6rQ+v6sC7PE8kB3xXhZ9T0VSyhlIJwLvZyQPsV4k634JssYSo8UbO4PBavd055etWTpYbw1b95QepGFh6x29G+1s3aM8iNMwHmnCo81fWYCTCz6TXjVpkH3YfR1oMtyor5iiwGhQV5Anpnv9fIZ+xm1yijnMqSEKTBeSWrP3N1F7gaZiIAqgtxSm5MCnAbx79w4fffRx6ZwlAHxdWwc8vYr0itGw29bDIKRjj+cdDfbVgKJqRZ4vD5c0NEulOU6DAVwuF3zw8AKvXn0AVcVHH32ETz75JOhV8/o8EWbeOxqjGTW7kqJlGiTrFNlYBCLpHKGhiL9HKqEXoJ5zVVbJX4m/rHuW0cKZJlVlLqPHjIK0iNt9n7EWSTvXIy7+paI6OGTp+HZPYcyzJzffp3Fo3vyNv1uqo9cGQqUnrmh4ZDBTG/xGaBPQuXeMgp4FH2uk6i3//PR58W9fAvi7p08oCg6te+7k9q7xjdcJki4bOC2L31bZ52jcMDJo9JHFbe+/i10ibWSUORgPovM2Ku/4zlD8/TmUTzPqpI561Xnu4dM9+ateO5URSXTGqEWMtLoGRnsZsfqcXLcuRl3qXOuIqHZ6RlpXx8Qx1kI7y2t8L8vRBEqNtefkWK7p1EzzrzoSOXmlV1VUK8d3Ha/Ld1wbVQRt1akYM1Ohdc5lbVIkdbwRGqbyxVYPzSJnzCFS1kKALMLm6xIPpzRtz5s8J1Mj2hiIKkq+P4javMgn5ZDLvDM1kevLxhQ8mxwTPNMHGHEu+M/H66KGpWvXBbdrTC7RdAwiAwViTKEvSBTkbq5jm+Mp8bAJaTk/H+iIMoLUNijqODUFJbtmCkqhHwfaICaDhWx4YA503qtO0KZHZ7Pxpu6NhMQd3nScSMgMn6VL/LAGIQXwr4mZq/63qvrrAH5RVX/bxq6/LSK/4Nf+CoD/R7n3N/27Z8EGDZCQxBZWRdaD26CuBIZw4UKvIMLCRGjlznA55pdXobZROFdFRwq62TKdgqS4AU4BDLS5Iav23yq5NnZiIhG/GKLaMYSRv4O0PBSNrqwY7/8cCcLkUxiGeYuzzsn0sTdNuyqZDrtnHAmrOhJ1f6GKeZm5Jt0R+vHdI54enzCuO8bTFbgOPLwUXJsXDt2s8ObDixd4uF5x2Xdc54A8ZRvF5b2t5ZwUETI4BbhIx8VD4ocr9fSSqitV0w03JryNcpB7FJx88eJh8TzqrNZlww16Nmu+NeuSWCFbs6CrCmSat7CxkeOYmPsIIZtdW968eYu3b9/h+vQE9TSJtm1Q9W5YbvTaaovebsL0BlvzNktUgyrU04kghbho7hPxmoamDovC6rHGGtprnImpXoTMGIKEwupF647RaAf8PQoYVfFilBYAV+oF6B3wcEpAImqHzxASYWKvJtOggADiswjYXTAUU18ruPLJFCzrbOa3WlIupkgUJKYBV9VwxAqZGhNtYp0g6txbUcrq2PNcru2Ol/PuNEmHGj4qsE/FrmLjLe2sfwLgR8onSFeb950eJdUE8LUVsfzzqbDEH0PgQUYuwIwuJXaWp9Nq0bWLDIVAwkIrxfEyvgvJwwpdF0HQ574IzBTqKFeKHAQfm609T+3s2q88nx4lx9RGEYs2cMG3o3snMY2IhibkbZsZgtqGrURYZLexrP+imG5wSe+qQKJYukW4qisAu41PgD6ty5hOYF4npAswr0AXN+hsZgD1jmM6ZxSvnhPefcn2YGfnNQDSTdCddsEqiHKtfR1tLCYzmPDn9NBYsN9mLe3fvnsLhu8bzbEOYCoN0hum18TZese1m1Fo7AN7H+jbhs1xYZ/T+QgNL1nnIPCgCfrFI7CeGi5uXOot8ePDVx/g0jdcLtbd7OOPP8a3v/1tM+psHdt2QVcjocTVzRUVCsmzCToGdCSfnTpLNBFpcosUb8NlV/ocz0UU+7yCBfC4ztMjuKYqQKNIof32ZA/QIh13gZbGIPtnjhKdwNbd6RX0ERCdaIr0xsoa8VobXzyrcB6Aa2Y1mNa/rYqmy5M+poYGGYBsApkK3c0QpEx5lOjf45krqeSYjqKAR4Cp1wkRdZ3N8fHWwJMe8qqsHg2OP0Hwo+UTcqDVfCnlfcCV5VjylYdgePaRuSDSwddpTUB2P74fabQoeqiyNpA1earhIjQV/967m4G6SnfDRI41ohcmCyDz2fnO+mzTERkttBpVbgxnBxkvv8t5q+tiba2IkOtzmD+ewdMbg1o8w2k+6Q3HMZOGLfeWlL4E378iDt6uzzqOezTkdj3ciUw9Dx1p/HP6KQPMTNEUCax8CVz3EAXahM7dukmJAGqRso/zCW+e3mGK+1dyWcqHpF9OWqAWRuC6iRmWGi0IXsCcQiWjLDnH6TJWztPokzlUR+yPkgaLeDmWdKTvRRZO50PSqqmVR8N4rNc8shp+CmUhdDVdNvDT9d9Lb66jpgzuu4LpcqBIixo68N9DnlMPeJCMcoJ6U6cmGLLyINIC4V6KcTQas0agr+OJIYvpZK27Wi8ltU3zvY4lpoM4/ziUNkhdilkPVzPOuo7UsNbPa9KgsjkdSd34s+CHNQj9YVX9LSfS/7qI/Iefcu096nhzwkTknwDwTwBujeMCgNZOE3jXw5nEyJ8BLqzLY0Hcj3SH3zH3nBY4EhzDg/q7PaAWQjQU7RCpxX5dMI+8VfVzl89SpOAaBMwFBK+mCYVZhsU5lLozrjmiUihIdEvlvPkJHc1c3nbosgja4g1RhJAHV7CDuNpCoezEYf0knvn09Ii3b95kGtUYTqP8IEqL4psPDw94uDzhul9N6PTaCMCqLHO9W0pHNtPS0aZ7LZ/r9WrtuH28jLawLilzsaxv24bLwwVzDjw80CjkxECS0Ygq4GPj2jKFy8IM3ft6ebD1ADJ0fJqh4e3bt9j3HU/7NQxCT09XPD09Yb9eITDPb98uEJHwpLp4EDU/GMoYeOKLwUgjGvsmaBDNQomtNegYwYDrP99MoH7OxYeYlGq7z2LVjglZ5f7WEHRUzOv7jgz2eMbi+3Jo08hqQg67+Szem8M9FVf5b+1w5987kyT+Se+mtGWPUKv7M8vC+2Bs7A2tZYrB9NpSi7FxIeLrOOtaxfX2lygSa2PWUI5+QuBHyideXnoYJZpHfehU9ObnvzzCyJwzyaHRnQLgz6T/+V28866wWH/iDm4fBVvS+/x7OXZ3Z7sKnjffq4ShmCOPdyos+qb5aRXN1unNaCp5Z6Q99WIM6mZA2th5SuAFne3vqURw3W6jYSuuzmYRPEPVihZJA7BBVDAGIn3POhdTsJpQbV6M2kP3p2D3iCCZzi4HaF4oStbqgSZvvre2jJ4hXNl2XskrLfza5tWA1pMud9+D3tC3jr53tH1H75u3TU48odEujRfE36T75I+X7eLpfA0vX77EBx98AExFb4LXrz/B17/+dbx9+xbb5YLt4YIxFJdLpn5t27YapSWjKY91sJiGndGw02lYtpqfY0DmhErD0N20SY+kIR+gEWnsO7T1W4HT5RzuE9Qjg3jvtdYYNPlhCGAFcSs+rfyEn+8Wnn4G7hlms9EF/B2poOd5d/6jO/Y5rf6WR/EON2hVT7Lilg7wfMJp0BL5sfDJxON7vJN/P36fL/qhluKLAD9SPvEzX/mpm31kF980MGg85ZaGw5R7rxe4/C2GU40p94a3PpM/ubc8e+FMAMAiu8wzrLTMUkA0lmPBe0GMq+JHTqvgIooCjDQqkU6sDlON6JjUdZKuVqPSUS48FtUP+lPw+znji0FGsXAMOYn7/Pkof8a44ppP59f3DGQA0EKxPtSppGyqWrabxnTN68X5Fd8vHv0TRkGjwWvHO8G+D+wzaWqogmU+LHsR5MTH3jxtOmTxUmB6mTPPBNZ5xzoAhReW+4WRsLEQPh7PbDk40oDiUPa1ML/exOYygA5kF2DxgAym+bsoR3l+qEUSp/7v+o8gnNhHXISvl42/LcudXR+ZuFbWDnCjWOFjvo9JDfJcke/zu+brQ/2Y1x1xr7USqMEBz1y7Wu9uerdCjnOxn7gNgbYAZslEJsyn8IkfyiCkqr/lP78pIv8SLGTzGyLyNTVr/tcAfNMv/00Av6vc/jsB/NadZ/46gF8HgK15NuVBqIMbK1yuLTps/l2RUT8W5i3e1csXHrLc63q0CxMUbiW8c+E904y2gN2CphKda1nxG2peOvhV+a4DwgRBjCsz1L+5vMXK6grP2/THeL0kBg615tXY/R0k/s0toAq7x/8cBDQspTHayro0eCTxiUYsVnjPvbN12i6X6JRyuVgIvLhXo7Yv3rpfc91wdcH1HkFPgwXXjx230oAzxjDPtwLXscfcWBh0uHFKYALvg4/t4cUL88L27gTHI6i0WE5VsbtF+1iAHCJo2wWbGw7IyKfXarjuuxmpPAVo0Gjl4eY0vJkBYotUA26EUP5oVkuqtxY1LxQWJcIwRAW81rWW/VuBa1k7lR2NNPeEiuYIuQ9G26x7FArDIfQwjRiZklfHshC0O0JBffYquEnUapKobwVntmuRanbF4DOo4BA/phvtwuTp4+JnIeLHGPhuomMlvB5eyqeJFcll3RiO65iesgqHHp+mOVfVTNvgvzHu7fAXD37UfOJnPnhwgpoCKMmSdaRUp9OI0F04ybUUIxThrRaglKCFFACo2KH8PIwr8IhQjRN2zZ1zVq61i+DCyx3FQjXSVHzWcf5VF8YDhnszFN1q4yHoCA3tFr0pltbrKWRb1C1r2LzeCw1FZsSAR8em9zBCOJHnx2wGmfYzZ8bbjAZI61YWFuZtbNIgm+XYj91qCNo6dAzYWZUGbNowpsJjr8LTv8oLyeCPxqBgx6WZgpbagQCyfk3fYF1W7IRr2zDbjrZ1Tyl1w9DW0HZfs60DQ/Dk0U7kRYy0aq2bACpMBe7YWgMa8PDighcvXuCybbhcHvDqFfDi5Uts2wZVxbu3b/CNb34TH330kdFQ512t9cXQw+LWFP5UJ7x2tHlp2ypAikjMOaSpoOFW2wcAmuwQj4YaO2uc0XDUMJ3XEdeDdi87gJBFyCOu1yuuT09mDPJnQF2R2doynnpmKi+raWPPK5a3cOQ3qwKfvIHGgTmcJgNAd7lhWrTyhBc6PSjJ9TNN1X5w46BXPsELbnhQ+X11nlUF/T6N+qLCj5pP/Mov/XwIVhKKIZW5+AuW4nHLs6i/ueSlfJakEunGIilK4ErrWRM1I1m4v8rokoMRkvqC1g5NSB4SSv+BUVTH2orXS3IPL470z3zmqqAKWCjZo5pb8pX6nop/1ZhieLp2LKTc1CQbbCBk6zrWqp3Y5hzPd8qGZQ0O47jRL5657x5/rnyfEZRcK3XHIqTMeXkVm4MUgwhaZP6kUYk0wZ0hvh6A8XyBBQjsu3tBgr7EbWU1ikGoCXq7uIMHHh3s8y8G9JB71ZwONG7Vd7RaF9cjcPjKiYPMXFIjk3auBrZqFIxz6fQTNJIrTGvvbrAfFjlD4w9g58P0Zb9fZtRis0glTzOPQstVjvN/Ws+GrQMCF4/6qGKJdwuBAqGqUn+qcl3godWDsfmTBihu14fyoiatb76+lHfsWo/8CutXDKro7e4ww0o37smiFT7TICQiHwJoqvqxf/6vAvifA/hLAP44gD/jP/9lv+UvAfgXROSfhRWB+30A/u1PfwcXyIKfqqWNC3oUDAxIYFPYMOG1Z/68C4eqJYWlmeDRjdoC6lFDLYm+eBoPw+yBJKDSTLBqoVBmi7/ctKJvwEP5SkhhzIAIwVxDkagFBHXhl8TYEcuIpEfBiEdXiUK0R6tdaQ0Y5ulbivdW6lWEnsBb1LUOP7RboSWohXnXUnEFhTUFFFlgmZbP3iQ8oNwHFr5k3Zy6X713S4saA/pwwaV1qDTMbYR3ZXi0DNdxDrfiC9C3DS9evsTLly/x8sULXPoWeBBE2edJ4XsxeNS98c+9kW0ZMWDXGxbEvF6vQLP0jM3n+fT0FEaS4RFevTJwP7Yaa9VCmeO77bqsYzTGMNXILcAK+74UlXecW4VnChj55OpFKvfBnPoqYjm8mp1g7nWbqT+555UBHAVkLXu2fK9VEHLhq+C8o2zcm8Ke/909L9Xzy3S/pfMZjQk00AVOW/2rmreuoJFLwOQtYdX/WEcXXATYNTuS1XWvwL8T/9m5jq2vuUbRCvsnQNj/cfAJAGA0CQURETdCUKj1bpIKS7UCkq5Cie/iirunElFWXiXeBT8/aw/qNcpqhgd+sGgfIQ+6qEG3VgH3pSHigRzNG4WP8u7ExRLJA3WhkLyVNYZYQNqNQV2wdSswbUYgMx5dLhu4dFV54LofoXVTHCzA1wS95mNpQzEavaYC6c26Ck53smwABqDaMYaGrSvC63WW+VJ2WwXPqjhZnr3E6UShSSHPFaNQnlVXACJNpEFks7TerUFadhkTr6tgKcYZQauw6wSlo1Cz1LMoeM21hkbr+cvlAoVEEe+npyf84KMfRCTuGJaedkHiFWkJadkIQ36mlwydgKcDN2nY933B1+n7G5GxUzH2PdKXaaS+Xq/Bz+ydGnx0qvFAATy9OlOOm4in+dksZrgfAAA4QElEQVTe03nC6KA5J/Y50FuKozSekX4DKz/Lf7fn7955rXzoVkFYoQrsw/k7FOibpQzN6e3iyxnm8xn5VWmJn0qkslheVPYyx1pp/vo3m5tjZuuHOXy6sP9FgB8Xnwjl8Q7Zpq5QxnQfX+A8P3jNVh8NqEBlRsTXil8WJYD6LvFEWEXIEgCWhgLBD1DwIrZYFoWVP70M/6rEisKt7+tc0cs4s3bWGFeI9DAGAVbDssr4C0775xoZnWtZjUeUGYtjbOmmRuXcObX0+J464XEP41euAYqcfODb5ZgazT/QgCPdOGYs1PNll2VKH8JYWCuESY4rZFnjKTonmjTXWTTUdiuw3P09E5ai2nC9jihvQF6X62zvMjpp72L0C51ITdxYLpW/VT6o1muNv3tamSTCgRxURFJrpR4sDBQQ10VW52eFZd2J75PnZKBhCz0LItZ0R1fHPNdW4Bk5LvtxXKqw7qnSUXWb7Dhd9zPTCEXYiEQhVjjYmlnA7QJzWoq8CKYXfef6U297bs7isqjJpyn7iRRZEHCDlDnsdFLHt7qIU+2MCJ1KNAy0oq+Thzs/ThuKO+gmz+Ri2rqBHyZC6BcB/Es+6Q3Av6Cq/4qI/DsA/oKI/AkAfwfAP+Yb91dF5C8A+A8A7AD+pH5mh7G6iPldINFM4SaUTD+DQaiaBPJOF3yOGxW0sqrFclCYPWzLcvkkBFpxhDDkmVGsU1yAs80plnaZHuHhwnsQHgHQYyzR7QKW0w/A6i0ohVzAOrZLTgBAlwb2dYFEkBsEKF1cbGy1K08QP9UbZBZNUmBheDbD6q0A1HNOBW/fWMeTsmHWnaaxdsJak4IpZE9+DwUorkOGFPL3LIbJcW99i6ifp+s1/iZmnXEiYwRmEyMz3XM/xzThuBqSsl5UEnQTgLPjiaqGEsD5cMzD8TM9s+qEI0Pq49o5yvNLvQUn4lwPFtIOhqaIYtjTC3cyZYzXWY6xGTMUiALJz1mFKfTe4EXBryFz+Rvhud+r0HBMn0plzYWaA04uY4zotzQe5btMqBZlHQzOQ6A6oOmPzXGtD4h31XeLpCIGkTAArSqD1Q9q0jFFMMU84xMKaZvXsaLSa89lm+mjUcyUqmKA1GRgZoDjmhot+AmAHzmfAIw+N3g0Fpm2iBUYjjwkFPlMPJJOIN1q30T7cjEBjM8mqLpR6VOUTDLh9Ts+h0KSgtaHPGv13nW4x3MQtNhpCo2ZOp0u+dxjbTx1uaY/Gl9x3G52fd+snXxv1nae7cEv22bpYxu7N5nQQcU7x6ZFSM3vp1pB/TEGRBtmU++GAgiGOSh8XVvrRq/ZRcO5WZAHX3OnhLjZqUrAYqsPirVvyvG8t9YWRaG3Fm3draZYCviCDmkd2lsUl956x/CUu701sJx0MT/Z/Byy+DEnZ0Jtlw2yTVwunlp9ebCCoq7ov318xOPjk0WijAG0hs0NUDTU7G5I3rYLUvmy5SGfYMH+BqC3bD/LtdCWyt2c6gY9E3wpTD8+PuLdO+P3dAzYntPYLsGjmEZejUH8flfFdd+xX3eMMe3fjNKhC+0O3HL8o8BMea21+7zts/hVnf8RqrLMXeXeRqFOwDNaahQAgn/Uf7ZGlYsUXMSqhNa6hXWcC024Q4+cPPykwI+BT1gEIsp5hMuzIcVS9rqnw6rFNcqBxqxxAvcXnI4qOXS5orIW8k8d16LsEz+o5HeT/1RcobxfUfAGl9UfEoohny7ZcRBHmqkmoyp1pxl02dZ0NcACtd11vp/RQRm9bWeFadsx0zKuOnfyzU/D6dWoa3NNln90MOaSHHnGvWceP5N/1+dCGRnOaNLjHhYaoMfxcs9LDUSBRzHn2pnRfMS1OTaujSzP5OvNKJD6Y6WpwQvLusSa+aJHMWoklorrFrGOSNwxnG43Z2v5O4ou4LKD1zpBNP9ArvGU5lEUiTOU9WxNrfu2RT23mLddY4b7ceD99tPXyc+HlDlJ0T8Ra6eRHE8eZgEgt7rVSpN1lVFa4pCGccjlNEWsgwhc5vLnOF6wyQZLvYhnOKn/HvqDKmgktDQ7T2lSOgk/nVF8pkFIVf8mgD945/vvAPgjz9zzzwD4Zz7r2bf3VWTixNLqRXmqKu/CwwoSWp8/GB7N7yRoZGUTQXh4nXqYHehZTQ8BwmrXo/hTGF2EQrsL6ZJxIEGQPOytHhyzwpsCvLmVeAxXGMQKcHUw37hELwDuCVdPIXMvOWDtfqGRUlTftzAApZUaLIscIWo0QhpbmOjibdDVlS8Irten8FxSuNmaYG4dY9ss7agpWk8htm89InIAph4pqnWZHZbmNIV67gO4bNbtpgk++OBVCJFvvGbPUF1ynukBp/DPtC6mcHFT1AkhD6qCgvF0oZotdLNtfUS4zLlEpFQDT5OGcWAiIoK+behMPxAJ7xBrVCSRkSBKgBdD1oF9lkKeyPpPzY0PUHa/gxFpcYVE8ixUsLOioM3xOSWLa0Q8CmVCM7LqnvGIz+Df5sx2m4y6CyUKuQd8D9sEWMtjequAbCtan21P4RwibUuo3Fv4LQtqN/CsW1E2cYR3Md6ESs1aVP5U87izmK6Z4UAjNQvgrfiNMArdKy5NGB7dBs5HNX5+0eHHwSeMV24AGEo7Il2DETBACgbMj0/jmuOzlrRB1m2wO+07MbSj18j4bO5V0lH1vXLbhn+ugmlt1UqhGu6FHf434n2IPf6RxYjNCVeiZZ2/meSg0S0xn2G/Z1ckN3iyVhAatmZpSw/dDD99a9g2eDqZRw9t3mpB7gl3VJAk6MZQM9SJ13wTp4sdpOlqRaWlYewC9AaRiesYxutdaRDMEFitHhoj+iSEPNEBKzDuJKLQ2DpOZ1krL6ZskbuC1ja0tgFLCg+8Ds8GtA3an2L8vXmR7qDZoB8YSxQuMm2XZqYppE/Wyv3ycMHl4YLtYcPmRfbnmNCdEYKAOj/r3sFr9/St6U6G1rKAqT3blbopluIFQNwYupO/OW90VuNRi2YI6q3DvNQ7rtcdr1+/wbt3jzfRl3NYe1uoYt+vmGPgcrlEUXCFnSF2Gd2n+tjZddNbPVMShsRYYtfIx2Nu94Xau0bbAsczfFQqyS/SOeXpIY4lkbbgymdTiUYTRC4aeAhZxJSRivCo7xwbeeB95wvAJgbArfXiqLh+0eHHpk9IRs64hlWeV5+dhr/gD0bVnFaXeyR/In4IooW5VHziXno9RgVSY4DzIKaM33OOuVNqEjf4LpM46iTKkFIOq+OLq9wBTd63rEniuXVn2hGxDUr5vKyRsi4LpUfE8xOXAToI7Mw25yXNa5zmGMmztfKvA02vslM9K2nk8FQ3P6Yqt2cqOpDCC9ag6h3rmVwNLbkW65GT8ve66tUotbuBMVPnwhgUO4OoQSc+Fuu8mPiE2DcsP6sM3rs5WhQmX6iasxktgw+6wJukJMfgOssUd884zwXcyTwxtayVSARqSFPj2dJvjCI3Thqt64mYL8UeSDGg64DEf9R5uxtFDE8bnyQsdyEmjOG5GnMSUTi9mR5qxi64w96fJYKucaRjXk3cWCV5ulYcK3vERiEmQIZcH2fZdt3WHXl72jR8DZkyWOskufxJPJtsYCHmABVYJsoocuHynmfgP0nb+b/r4LaOVM5ndsEAxkLUzWODRbADlV8uAK+M+8TDpjMMnxbzxSrkoYAsQN28SLItOMXgGl3CQo1utCpCM2mEFESnQhysyGsICQuEWVsOXMeOsNqKzTcLGEoQbA7b0liYtpXfE7EqVEIk8Y2tSgdKB0cXgFpllJkyhvocX8MmVstgmzvGbGhXj4BpLQxDtQAlu0OJ2AFMbwq8WLUWBQUAXuLd4yMu22ZRWJoHp2nD5bJFTSOFGYOenh6X2ixRKJqr6DgXSAjvZuSH01J7piv2XBrF8MKYx+fSu7R5IVF7l4+xW4eZwMtQAPNeG4sxSDMKeFeWYnw61qchtFBMqahIEJCFsfm7AzNYtJyMFqaMmuppnbg478CjwpSPRqGjAakyCHVCFczDC1gb3ZuxJ5E+HYzExQZ/Vi2KKDgWgk5Bm+c0O794aKYkoVQ1o6JKElGNemSIuho6NcKp0f05Cu/EcBuRcBRkWOeLK08DpKUDzvAk1ntPAAyjGQ4N66XhwgrgRxeIyEK2qeXfxPec9I4UbV+8b75/gWvl7QcBNczpXtQmFQr7a8g1KKzr4E20Tpb+NCVXshvyN/dWiQS9UpRzRbpVhBGR24gF1nPrntJ62SzKZdua11drVr+sGPBFmMKaOO1b4fw5x9iGYjYE3kobEAuaw5xep6/7HJqEcC6TKVQeNq/qdQFp/HXaqGb01Zndd1ycuzGaBo2SXMU5p6e1IWgqYM9++eIlXj684JUmzCnvtKghpo213iFXq6/U+4bePV3Yd6bWvFhodJFtaORQmei9eR2+DWNMPF13M7RMS7/r2wV92yMi5nq9Ys7rYmxmtCGVS0beLjSkmUJy3a3eUNu2KLbLf+RlVltqw5yW1vru3dslxYvzG2PEWMduHm0ajSYs9H6fEyMiizSMWewSaEol6wbdKma1CUQs5DNQ+cuCr+W7e06L/N69tnDjrVrXVhb3tLeTdng0iKcZGO+2OVQcMPnfx5XCQ6HtcjPue2O8p2DFiKpA976Dy00uPfErAEmLg86GkY9bROVp7TgZz6zLLy4cFWU9BP6gTmlAiBSyGFD929GYKZGFsEJb99llmioPhiHjDkLcfieB9/n+seAZHfMpqwlQu0yieTBHOunqQoVhBBmdGQ7GuB4he1IeE2Ch6zk/lHcU+Yj8U9W31fftyN+jDEG8tSjqec7SEKbu8Cn74+/TMv5bEKiOsseOMlPrJb5TxcEJ04nevX0KXcTkxlxPw8+UOWLvaGAB5QOxFD0gghamGJ8wg081XCmX0cc5k1cLMA+oY3upxWji3PigE1TDzLq2riO5uDV0QJpg6PSgi1q3yK61VC6XEZg2JoknnNMcE9o62HG8FpaGRwmpWsaF1fgzfBo6oANR3gTkRzSmSHMbAMKxzCYVacglPSmmrJLad0Pv/Twcz3tthGPkwlMvD3hqjT88rT54jkSh7J3y0rP8I+ELYxCyxSpEBDzMflB5mgri2n0UUDWIga+wP4cf3eoHVvP2jWFkhm9Si1oLEjl8W5M0/rREjiYof7MxBjGTHB+FA3UrqosSiyCm3eZqG2tEYmpPpULVCmF6NBHt/CEANiuoPehNRQZ7Ap8mTBz+tiA/sp6NH6QJ1sDRdY0puPWGDkWf2aGLLYxZk+By2TD3Hbuqh74VQe4eG3MiXlNvtu0Cdm05Ghzo6TPh9NFrtVzD88drKGgyD7Yyi4ZktKGQNQr87eY5VQHgv+kHEWV8XG+mkm1e+ZPdaCpY0WsTmtmit6aaUZjm53WPM5wycTGjZxbDDff95hncXz8LZNbFWFGNHCbYp3c6CBmLPd/ICilI0av1aSCOlKsHYv2Ov3MOrIvVhSdC45zWdSuTtbHM0rGHa+0jboJoLa1zRmrRrPviUPEESC9NraPEf3NkbaFMyTil/AqttUj3JP6wdsrU9ZzNYnAMciUN5nlKuZo1h+7ifhFeViWNhoVbAyhQcaCqIse/5eeGlWcYPsG6cimi6QGFk9D/FNAxLbLFnRUUEsnbaBhizbuL0+Otlw5jvXuUkLdA75vXyalRi/RW2YtVW0TTqiqkT8808iLuQzAggHqky1QIup0ZeowxoB59ufUG1Yy4gfOy3mQ5N7HK5I0HHKm0kHw3aIKm8sw6gXBh7OnxEWN/QqcyyU4hIkDb0PoGbR2zWepYuynYTzkix5HGanjEKuUD99yKoLUNLy4PePXiJa5PA9Brpko7fl8uDwDcYDyvUbOo1uOjk4bpy3S6UCjfr1dcvX5Q7x0yBlQlun6ZoWl6rQvB3EwxZO2g63VPJxDP2LTIIJ2Kd+/e+Xc7RJz2Oq+bXuhTpyk7UaSZeyZAmsk1ojdJj+8pXUcD7afBImvdoalHReXeGQ2e0tJRBHjau9TGG6uSuBoH5WYcq/J9y5dyXHHVMu8fdg3eG9C6JkEpi7JalGAXSATc9xoV5o8jLhyWuMoEGvzF3klDSZGwki77uQgOsfCN8nq5xT2+IuiaKqz+zPP7fzQ2ftZ1ABaZdjUYWPR9Rrr4uMsz7hthS3reHfn1xqjhF1dZkvcIGqDd6quUAtl+HLlw9sP/tnRgVG/LXcW+csaOdGA9e349TK60a3Jayxmda+MTRnvW9ZnFWMWxmUGmuXE+ZWPKtkCP7ltQyU5criK7S7/wJXI5uAnN1raLxMbV+U5olDSMTrc9jY2LfCv5YNXVycv3VofosQZpHBw+09OcI70SxeYKc0x3MUObyX4CZVolbN1EBGOfcPYKkRxDAzyNXawT6pyQafJT5T+Maq1OxcAlgdsaTefGlKypLcUItDC4nMPxHIbeefxOaCewKENL9/b9QOJlNSphmtGoAcA02wVgjpmkEc/Tii+MQUinT/ygPBGJothSEZqBohQqDSSwtBAWnoIhvYWX09KWjJ1t3SPFyOswUACPCrsuNEpTF3asCKcpiOmBDWHPXuTUG2adjfBEKUoIoojUmLsREFdiSVTm9Pavw5DcPFeeNKBSoob83TCjUnOlggrwkbCi3ONfBkNbDAu8RgCBh+nPiafrFft+XZ4nzT2o4t3AmrXq7VvDdmnoo6G3jsu2uXCuFoKHoiwrl97XQCsz5VqvSE1jEWsVmRCbrd8BRJcxEg3WIYh1E4lq9ZwT/4WVu3dI1witH9Pa9aaHlus7898YpvroxJw7xmgRJWVGm+2GMSrMIs+UtH14zYXdilqmYtEczSQU4zof1hhZmHRgIZVKdUaxzptXqROhMIRFhAsiik+kGaEkZZ5GxPgept/4YShrXMLqsTIm+5etUKsgnPUWAJFS8L3MtzXvykOGBGunbfugy94vAnYZS3P6MWHMr/tCzWk1wua0wnwQE5SskPGaQphGv6RZS7FoyYjI8K5z/vhsQe79AYVikETZN7GEEp084ncItHevL0ZPi/1H+ltp5/FdCOGGPrxUTqtgt+LjHWWCbMifdU95m45rCmunyvED6VkKnkDa79JOGiKYO96CPnQXiJqYUbSJCeYWBVQMQJu1UbdIFdZL8+5YjWdrGbEJHtIiMq6V7jljDAzJeCbVDkzFgBksIIqm8BIMA3PaXFtrRr/HQOuADipXjNxIHqGw8OgamXesjVF/0kgWgjPrDqrik08+xts3n2BcH9HHFbK98JF79CBsLdDEU5eN5hlN9LXC7o6AsRjGU1kx3t67GZPQzCi0eVHph+3i9fmMRgGIunvW7h0Y3jhhzhk8j8Xpk3bCjTfVcDowRjpFrLbZFnu6R2F7S+Xaeos05Hfv3oWxCFhTqx7UCkJbZNMTBJm6PMeOKxS7IBVkXR0JC2/1k4bg9wikqxEb9+DWYLt+d/dcAiFbAGzfLIlfqh5t2ILHpAOIiqV53I/4ds/wZL9W7it+Np5PI67NCcqT4qeLr2ck6RG0Oq8mMFtZtbJ+SLzKb5EyQyV6kzwAIdvQQF+N5i69LcNJw4Ezg6DvVfbI79bvUT6zdXRGgvgbbt8XS7HynCOe3ftbVdxvDTwz2oCbkxtxHnj9rRFKY05cL5TPlEPre4wH5veF7SeNiDQ8XcywSU9W+g9bujjznwU2/lHfHDyOKa7821HGVk+RMx2P021gulh1WHFs1UAT9VnjHQJ4kEDuzeqwictbSx3WZeMGhIOH6XRywFMau3NOblDBGoWzyMyqsQOUV29k6gNdq8a/yV3ia4uMpa4uBG2Glc5osAghK7diadOm6zaIsAMna6BO9M3PuWci2BqYc12aRf8mrQV098yUwneYkjbU3qi9hey/GN5i7umMj11Uc4y1nhFLTQT72JdnxBqxRpJatBeNbtyfo5FxPTNmMzE5sUV31orLR/jCGISAlZkeP4cu2e7nkFcFOBalHCQpSCdSQshCMFRPD3MDD/LAmCJodUZMoHbPpSuBFMwBFwIpSvomGLBtijo/8DoLKtE+T5rGIbA0yAn0hgHPfe325DEs/7jDrJzWYMoPOQDVVGKNztwKLEfEq2u+rJ9xP2NURFivZ/H69Rs8Pj6ZwOjdRxpoQLHUKAq/lvK1YdsGZh/A5RLKr7M5MP2PHZz81R7WmPtMZaX3joeHh9x7j0Cac+Ldu3d4enrC4+MjHh8f7doXL6ygau9RgT9D/XyX+loMNLwPlamGsQIhnNciwSTONbyeYfXx058z9mFtdosFnvPkvjBd7eo/2a3FaoY5spQzkfuIwMPYazJiXovKZJNcmLIMRB6smMf2sm2WClAilezPGudgEbCaGzWdkAkEMoe1oPaxttYw9h05DL2hAfVnXZ8qMB8FmxA0zAqUDMuNy/TQK/FPQ0SP+ymERRHsEET8XIjNz4ymDdoUJRsSqlaIjnWz6r7OYfU5nq7m8R9DsyaV0ij0k9Fl7McCAhhVs/WwToSZBhqqlohHJDjdZEG+8pgG66An5TzcVyr9bc43DA2KYOMKLPA83trnWyG/QuBgzBM5/jBgCWhmpVBnhn+e60rXJX6YfCihyDAyyAxDHdtlc2PQZkb7vlnIdO/e4rxh4Q0hfNaoXATOjjFhpfwpBPlQlM/a0Ro80mtCtWNuCgyLio3CyJ7OMYd7ggfr63gEktJ50JD1n275nBmCMgq4t2b8vJzxb3/rm3j9+iO8e/0xHn7mq4hmN2J7x04tFK77ZUPfu/07dJYST2+rOBE7UtdPBNI7uht9Lg8P2B4ukHe5d+zASSVxMST78/dCO0XEClGPvUTBYrmPNHOMJ7BWDhsgWPq2QFvzVLF3ePfu3aIg1hpCrCH49HTF49OTFW3375+uV7RptY1EabA8CLzlM3nq9FpqipqWn84OzvPeWbqndDxnDHrub9UJpArveJc0x6+MI8ZagNGR6llynUpxPaf3CvOSt9Ux8XOmpq37eULCEqXsimQ1/gCFLlHpU9Zlex6n2L24uhEWHYUyc+FTlrbCc1+ivYRGgtRvCCJJwxajijeyKJJOnJMb3lOmce+sVfg0Q+bq7LC1TJxTd65lpPzt+VplbFReza8OBs0azc/rwugpJndz3GksvT14q3xLflSNHXfW7bBmWvYyH1olCtzck2JBjq3qMNQdRJKmUz81A4hFbK7LJuWNSUvIG2jcMEeN7RMN1r31cOy31lPGbc1SyqhD8VliBpfmRyLLp8nNmhGvOf97NL7Ok3BMp16hyOVIxzbg0S7iK8uD446pCSvnwHeTjvI8CBVspNNlqnpXM+r1XioGZgqsMru0hgHBEIuA3qjHF/7PeWWnTJNR+9ZtRlMgg4ElaWirDZaI1zom2EBaaExwnb5eq6qliZVNcbDbn7rxMYTL53nFF8YgFBbhRaFkHZeceMd6cANPghjHLwAY8WMpVE0pFPsGsmOFWHAnjXZWh4iFiU14FACbe1inTDMG9Y5obRvdL9wzjXwP+JOEUBgS16LFvVXhNwHEjER2//AICdEJKKOlAGiLKAWVRG4jvg3NDQXRbo7CXBwgGo/KARbJBZ31ukLQfWJNsqh0TQsTIvVQCK4hRDev07T1jrF1zJHt41NpUFfWDKJwp2Raw7Zt0Dnx4uFhqRUU3l4gDEFv3rzB49NTKIt6fcKmGzb1nM/WsJEQenQXu3RVYlJxkl2juBYWbp/twaMdubDOUgrNYwz3qGeEDZRFqVehT+P7ubQmH8OFi0qAUdJeuN6uuNS81GKmSfD7MzWJln7xqDaEIad6d2h4q5E6frszw8KwJJXGKqDFuUD+rc7/KORWppIeUZ60uArsJMB3q2bvsfDKiERb7OnG4CD8/i4W1Gtcl7IvaOLdxfy8a46R/yqjp4ADn1cTwa6WbvH4+IjHp6es0RFpgtXLfwJAMcEMHGN4yLDXoGmlwCvZwEK7XEoTP7fEjXq+7ylWUq6tkMa6ZLJHo9LK1w61Req1QmE7JupRQ/ydHTAU02sl0CiSRW35KJ+XH0ZzdsDpqKWQbZ0GdDPytpIutvVutYY8ZQxSUmELfXQKRBUBqlbLZjTrHDVgkUHq7zZ2wmKaLC4PmJDkdHK39ub7tHpp+z6xD8Xw0HV4bY0xR6x9FcZiuQrfJb228cMNZC3oWmuC733vu/j+97+Hp8e3Ht3ouMNGDmjROn66ca0zdYxRTddrGljK/nMcJnukgSNSxrpFZtEw1Ghg8r8zqnXO612jwWKcF4EOox0vXjwUZ0XpaAOmr9G4MTONS7NZwL7veHx8jOgj0q9WBNd93yGt4fHxndX169vK9+ZuOKItHDnHI8a6bWbIHVBkNMdxL+/BPUPu8V6O92gQuHdeSaN9Od1gk46iMvKQ6wCPwmuC8ORWWkSlH2t06GJIrDKW5v62oqzcroEpFrN0ajshIZS0wqOfv5aGVyxrWWV39fW2rUxDUCicdkdRmv1pymILVX/Rw5jSaJTX5BhMtqSMFG9K2ezOPfyOYtjxb8+t1xGqTMasOmL36m5hTdBMqxRJ+qeq0bDh3ljNUL2mpR4/xwFBVfz5nlUGsLbt1ZCSBpkKa0pZNeDB3qPVCChAdIdaaUjse5OsrQM3Fsc8BFZ7R9Yzy3UCimzNMTHCKddxxa0qB2cMSQ0GqA6C0AsEaFs6S1jD1QIUYGl5DIooBpwqU4W+M2YYJwGmw9ln8pZFv3da670xQsZqLlvTqcco/Vh9L/9g9/u+Qz2zZt2TxWBIHZNz16TfLHlhdYOK00YV2nz88C7PrjNMEUhfTSiU7aknhT7F/fSIZjam2HXkepWMKMCcQZPFYaai034hua/K9ZgTmxuzxeszEg8D90zBfZZXAl8gg1AlXiYMAW1KHPTW4OlaRbg3a4ojcxHLo+gTzFsHhOGmqW/Y1Ghh3NAgbPkucAOQG3e6WJi4CBps81pv2HxDawh66yTSFEDhgrwbZZxwiwo2brzzIPu4QYdVlu8+N8DmPT1NjIIq5oDIhjnUozAUQ3e/ZWLuTJMBtqbYJzAckS3MQaAjmV0cIF9dKstcE467NrpgbYHpBo4p1mWs6YbeNQon2wHsaJjoMq2leYnmAeDzLsTcBWJLKZgh2G+exvDixQNevniB69MVj7ADMqbi8fEdXr/+BK9fv8ZHH32Etm3YLpuF5xPH9oEBI5BXyQ5iecBWolUNHwCwX69FyVut0K01IxguLPPfoCFC7XBP7xwGuMFhy4gZIAkoDUkM2R/ObCdg9SzE00LUjVy9x37eKElIw00Y4gCIewgg7tfSrOfAayu03qPFMKOoVFKI0gyjCZxfjD1L+DuAqWGNj7GWsd9T2kk4wwgreZ9dZkxSoBB1hWeOrA1U1oe1xZxeljkLdA5TAIcbdiTb07OWDbscQS0NxiI5sIwfnkbBa8ZMJVfVWjG/e3rC49Mj3tFANIYxhHYK+gDC8NlQWopSMBbxlCvHE23omBAd3mY+jZT0lkSNFmWeesExmACeihwHYdF5Gt+nYHiEWyWuCm0Vr1cBhn9jl8hGz7YI2KUMkwK+j9E9eSEJTkDnALSHQG4GDOMnZsSwqKDmqWOXhx5ptawttPUtnSrdq8eVc5hh7zPS8mY32nfVFJCuc8dsDbu6cXtM7Ptwo8OOq3d/tDVHzrUJWgfQOnQOo3MT2HSD6Egv2MH7T+G2SXOnCRfFBUTn/12ATRTf/fa38I2vfwO/+votxn6FYEBl8yL0FPI2zLYB2462j6wdyPcJ0HrDnLC02rL/zflgbx0dnmLWG2YX6wzbrKX85mNiYwBLxGugq6S1bl3DDnxnqgY94nsfr1cvTD0jLX1qOnBUzQjNYtVUxGiAeHIjdeVtl9Yx4TXOnOaNYYajN6/f4MMPfxoq3carZuADgN4vd5VgGuZ6ywjq9OKuxhwJ2pxrfjxvFSp/jkfeUbbjvIXSa2d1jBm4f2M4shegKQV8i4mzrtEZ2VlrEVKl5No1YUe/UgONyo8rKDnH+0ZPM6ANQG5r37zPcLO/bsjhEh0Ng/y5LrEWozWAVgoEA05vS2cl8S63z43FZSK73lOdSnt6KnqOBWA6VJheRABckLET0/ddQtGr+FLnaAaAUjcnWtjfnsl7a5j471jsZ4SLodN1Bs/gqBFEAFN+yFuzvmZV4AGTez/NAEzDWO5C0VGwr3KmXyPal2gUe8bwequmn9WC3NKcxzvvtDQtjjTp0r31ye+SN9AQwTFxZFafxpyRU3W5bqri47dvgNa8c+36XjFlFkqDTaymdceV2bMZhHhRaK9h11s3SUkQvCCjdx0nfaTMlrHom4aJYjjzEi7TaVfbEGO0mbiBRySk8ZBViuG1RuYTFwUTcCP37jo6XC8R18enCnT3M+ClVNRxrdYjPmZ6LKncfmY2P/yidqzNcYewI0xV7LZI7ihyGRGw7IPAbSsBQqfQoAyngO5VTxrYy5lige7cX0GfI3gxAOxww7Y3YSKCbc0CS3ZKCV4qY0Khu+Njc3y9W6g+4QtjEKpCJgCvCwAEgrTjdQiCY0eFVbZbRBEBbvkTCmyGVNbdw5ULKdZjN+yAB04UbC/P9LDezCrYaVF1OYYRRrTYww8WAEgrBEVg7XVFMN37CgDoG+a06KM2LUwebhY1YU+9jbJJNtK7C4CmxXcR6Ehi2Ro8lDMZnaAoHkhLc5CwVjq2cZHjo8T6cNWPXkcKMErht/eo1s4W8LTY1n9H6/8UuKdN1+eDKXnA1jdctgu2vuE6reAyO3E9PT2ZMDsGehNs2ILwWSFgW0N79ox1iOcXwgGs3oMa6XHE3fo5DEKsvTAyssWeZyH5cKFx01zLGlXEz8wnpvKleqsAAThYp28FI363CLj0alNwldtryxdxhgBLX+SZ4XrGmICb/bvH5I8Go+MYj8W270F4XorwRCPNnYuz2wsQ3pFFGtSkMU1hTFWZ76xgy4WkV15Thesyx/L3WRRE9c411WMDtUgzGhCfPPrOBIXbNXsfIQxCXTB2x7UDrkIzcgWa0V4VR+uzmLp5FKBV0yRavTbru4piAPWCuTwvstCVZR5yEN6lYu4B1Dxtpjh7gwLM8LJSEbDIoelCW4j5KDpwpMhasKa60ce6jF026zy2NTMGPTw8RPQLmwHwQUylATxCUocLYxmtUunYdbdixlevOWfeuBm0pDfBAxp2BdCBOU2g6U2AaU6BybpKc6SxWvmYe4pLXUJ3ZoRBQZcUW1XB9fEJ3/ztr+Pt6zeY1x1dzTvKlTQ3ZqdnKhVDyQgli1LL+jjxLgcW9W6MvHJnE8SdTNtmBiNf823rhWd61xWve1AjJRXwWna1O5BYUwU3+AxvD0/lh0IyvfmUpcx5QzqUncFEDLfRFZiCfd9xuVygU3F9uuLNm7d48/YdXrx4FSmvpGW2Hn0RzI/nwOi8BM7yzOY1n7K/RXY88uJVhkgBnKftyHdWhdPP0LG9znFfmSrDPV8U+HUsw9MaNpePSFtIu+hoWd/jEldRZmJOtWvhXQLyfgLXjcWDVQUsdbDiH++Q8nOAUcZwA11cdWTFTrirt94GcL+mHHUSqQaV+AuV7NQL0mBErZk8T53FJf1Jg6agWrLu8aBgDMXQwGsr3lY6dqRp1TGXc3EXe4PzX573uTwzNLSDvBdybNEL7hp6uVaHs1bPU+gXBx4RuNGOEcKFZ5dInHtjXBzAd6K41Z2kudZOF0Sy5t0z55Xzu16vy1rT6EhDhIs05oCg01BSlq37uDQ/AKNlzcl+8RqXl8tmLKl7a3eol9YwYyI8JRxi0UJjpM4yGIkaegyCjqrrFbVeY+5Jz46i/jemgre+Fce00TlGfJlsoFBp1qCCkWHUU/0e6mHL3vh1AhogW/A3cSOYRVxKpDJO8ajfRvnRaMe+ZNLYcdqn1xL0Oe1zYnM6Mti1EgfdwD7ZWjof7979jHo79RkhP/T7h9soMPzZvtcRJQTYOWzmULpLDxy+MAah1ZtzJNoukCklcIeKK6CxQMplGTmUOYhugafxw08Wu11Z0UfxqCKgi7XnbbAi0uxI1f16NDcY+fXmbfOws2bjpmJcZgsIvOizDVbVQ5NVvJ7MNIF0qnUWcwXTLDwZyaEyzeOrQJusmZXRTrFM/j960VHkh7rWHOuqtBjSx154bN4ajk6XtTFhbJsVkO4berti27q1bd9XY9BSCLmbi1tUM2yeofVlnEwdu1wu2C4X9LFjH0t8iRGSQ8HoEKAHvTg2p1qboNYQqgavej9xqQrmVAj4c46Z3VmerEbMHBOzudI0R3h0t9aDoJIY1LNALy1Q8QTOtExBuWdoidW4EXxWT0YIPmChO8T8CAv+iv/PrI5J5J2Qi6AwyqNi5GfiMwT7um/HuXAtjl4fCll2jY/HnyvluYCfVxhhb/WgVLlwclwm8Kgoau46NM8Kozgqjgwg8aXinwv+HFMq9KMwVPf4a2WV7zuIR3wofTPLGhKIztM7201a99xoYdzfZQeT4gG4oFWUR5GaSunPjtoBZDL1XLDluJ1L64TB+zRwd8FpAcSNOTeGolVWBzyqsHmE0pxq0WtTMNoMHBxzWnFz2eIBkZbMSQvMg9gQUQo0Dj28eLAooWYpTDSkAzzXGimuOgbmbl5JFjeuRY55T98a9r1FgfWxG925uPd2jIneJtp1AGho3ZoWXPdp0ZW71elqWLv5rQJ9EdqR9MCIUgP0mD7rfvY5McfEN77+dTy+fYMxd3Sxc5f8z+ls3zBFFppbeVnUDyrGD3ZGadLQaQjoLsj63rDe3sb0MS/qLALvANcx9oanfeKT168jMjel31UxjPoFw9bNwveH40ArvJsRQ1sR4JPnHHFyuNd833dMANvjIyYUr1+/xvV6dUfGjuv+FDLLtnWPbrXnk8fqYR/pXBievrZdbsPx634/y5/u/L4qvfx9xZnguRTIUPnm+tz6/lh30MeN4DuA05CpXvsRSxTq4qBiNBcymuAIRyNTRlXLySUKtNaN3seZPzi2wP1Z5RoTk80DTwWM9dko2yzPmAzN9EdQ4XLlfaHnIYcdI4mIa8538is/kzMNAMGncDgH61kQUK+octdRwFEgDOUH+lme/ZxsuZ5BDb2H8U1mUCiGtZA7GZFzbz9yXpSFVzmwRoof5if3xm81WGo6YH0Hx83PqhaV0sr9dk2/oTtH2rjwoSJHAzzzawTyKoffOp7Hvtv4FWVNgSgoHsYdCTlCRCKlNxbJ77RoRQsSoE5s6qya495xvsVPygXd77fv6NA28SLXdAT9dGOXHxg2Hci1gWW0zOFnNGVsZkFM13EtdYw6BLBhQ2TcUJZp9s4t5P2c8ZCkiyZjE4vswnCEwPktqnNNADV6PL27N2UIy+7plukxZ0QtMSq5a8eEYsCi2WHDtJM8V51UIZi6oxpNzYA2Pcgj5SjT4S37RjkHtX2VOTHdyti2zVSYyUwh4my76+AgfGEMQkAyu7tGoalFgid4pAvvdeVJ1DGe56eRHBrRmKLYHOmtTo0fJtBrjyw6TA8psmhx790KOstE21zYAyCiljam3PDnFfWj0j+nWSDFm95CGnQf2KAYmNDNlG+v9GsT6l7fQWFdWaqCPM2LPBVmOQxGozjmESq8BSFW4SiLxNnc6PWY0yy0IoKHhwcvFu21fNBcYLZ/rQkuW8e+dez7WCIjWjkUkQVbGACjjEg0qtGl1hTqvaONFkIsLbPVmk9FxQMgIciCnbeCpRMJZ8isCUCCvXntIxZ+qwc2cHhXXId7xUcq+iGIw6NIVHGFYHu4BBMk0FhWcaTL5tZ1ElI3NoggRR9YlFbxVlcmmkYaLEIDFSl1ArauST11vA+A76N1Ums3UWPHzysTvw9VADgKwPwuP5c21fE+fs65Ho2erfy0qySOVexnwUUNYcpMqspzWJ8NYILF4Cwf+brv0UKzzoWGSd/EUADoxQ+lF0C2WX+/gSSddKArMJB0yS6ioFta0ZK5Cvz8W/Hv7HpXpQQK1Nwa4xniBhh258DUOEtxnR6jHVfgs9bzprjnpY26VWCkqZ8jcXOYqhVHB3GT9cwmWrcxzWnneGrOUcBQcU9xcieH1Q+64PLghva+wQr3b4sCb7R0gO1+ATMoZcetFnXlSB9ja151TK8RNK4DWx/YL55etk+03WjtVOsaMtrwxAinY8qQaDP4cg2PdIHrnETM9qW7EKlei49RTyaQmcG+9YaHD1457tCT7fUwQqAwfniPt1v9QRg9dHqadMRSyrbL5unQnuMnJcKIDRh6j3+Xy4YxrnirA9//wQ/w9a9/PTybxBvyQo6BRrygjaoeam5Uauka1jvasKgtM1avhThVKYAKuirUDULSBEMnHh8f8fbtOzw9PuF6veK6P+Ht27fhtNEBtD5t/1xwrbwyzgZ0MeRDD2el8PObc3XnM39P/nP/e/+m0GANfOOpgbpjjphwh55PYDHsAnn2mAKGwqtMrs2U+Ujrm8MbgrQwTBzTHAhGi5IGnGBga0lHon+nesC5CchakB1IXUDjZq7vLZ2G6x2gjBB743wI9XdezuuojPpnl3n5PqVBxRQbo+lKma7ymiMuz0qtQu66Bac/qksmye3ZWP92/D2N5iHOGN7GrDWi56ga1K6Dd2l4rD3ie8ua8N/dMX+v++CqQMP4RxhoqvNglrVrjg8a8p79nBR0i1xp+3p893IuUZ5xGF8YjwsPzXWw9ZpTyzOPuMQXrvhd5Rc6LCgvCcUMx4vgSS33JOcxURvRRJ1YL0fS4/qaDeOaq+vqvUkY+C+wrqExFqF8Ynxe0bzGzh6O8uE64VC482tGWp1ODfZuqYfJD6JukVhK2fTnUL8c1ImATMsFou6im+NtOV3GAhBNIsJB6HrsmDOifFOctE5oEBq01OVFx5eWJUFExApaz4EmK1+Z0wtQx+aYXBvz8FInzRbTHGbbhqETY78GuogA4t3NxAuKPwfyWcrZjwNE5GMAf/3zHscXDH4HgG9/3oP4AsG5HrdwrskKX+b1+N2q+vOf9yA+Tzj5xF34MuP8fxw41+MWzjVZ4cu6Hu89jwBOPvEMfFlx/j8unOuxwrket/BlXZNn+cQXJULor6vqH/q8B/FFAhH5f55rknCuxy2ca7LCuR5fejj5xAFOnF/hXI9bONdkhXM9vvRw8okDnDi/wrkeK5zrcQvv45p8drXWE0444YQTTjjhhBNOOOGEE0444YQTvlRwGoROOOGEE0444YQTTjjhhBNOOOGEE94z+KIYhH798x7AFxDONVnhXI9bONdkhXM9vtxw7u8tnGuywrket3CuyQrneny54dzfWzjXZIVzPVY41+MW3rs1+UIUlT7hhBNOOOGEE0444YQTTjjhhBNOOOHHB1+UCKETTjjhhBNOOOGEE0444YQTTjjhhBN+TPC5G4RE5B8Vkb8uIn9DRP7U5z2eHweIyO8SkX9TRP6aiPxVEfmn/PufFZF/XUT+v/7zq+WeP+1r9NdF5L/2+Y3+Rwci0kXk3xOR/6v//r6vx98jIn9RRP5Dx5X/3Pu8JiLyP/bz8v8Rkf+TiLx8n9fjfYKTT5x8gnDyiRVOPrHCySfeXzj5xMknCCefWOHkEyucfOIWPleDkIh0AP8rAP91AL8G4L8rIr/2eY7pxwQ7gP+Jqv79AP4RAH/S5/2nAPxlVf19AP6y/w7/2x8D8AcA/KMA/te+dl82+KcA/LXy+/u+Hv9LAP+Kqv5nAPxB2Nq8l2siIr8C4J8E8IdU9R8A0GHzfS/X432Ck0+cfOIAJ59Y4eQTDiefeH/h5BMnnzjAySdWOPmEw8kn7sPnHSH0DwP4G6r6N1X1CcCfB/BHP+cx/chBVX9bVf9d//wx7GD+Cmzuf84v+3MA/tv++Y8C+POq+qiqfwvA34Ct3ZcGROR3AvhvAPjnytfv83p8BcB/AcD/DgBU9UlVv4/3eE0AbABeicgG4AMAv4X3ez3eFzj5xMknAJx84ggnn7gLJ594P+HkEyefAHDyiSOcfOIunHziAJ+3QehXAPxG+f03/bv3BkTk9wD4BwH8FQC/qKq/DRiRB/ALftn7sE5/FsD/FMAs373P6/H3AvgWgP+Dh73+cyLyId7TNVHV/wjA/wLA3wHw2wB+oKr/Gt7T9XjP4L3fy5NPBPxZnHyiwsknCpx84r2G934vTz4R8Gdx8okKJ58ocPKJ+/B5G4TkznfvTdszEfkpAP8XAP8jVf3o0y69892XZp1E5L8J4Juq+v/6YW+5892XZj0cNgD/EID/jar+gwBew8MXn4Ev9Zp4Lu8fBfCrAH4ZwIci8o9/2i13vvvSrMd7Bu/1Xp58wuDkE3fh5BMFTj7xXsN7vZcnnzA4+cRdOPlEgZNP3IfP2yD0mwB+V/n9d8LCtr70ICIXGPH+51X1X/SvvyEiX/O/fw3AN/37L/s6/WEA/y0R+duwMN//soj8H/H+rgdgc/xNVf0r/vtfhBH093VN/isA/paqfktVrwD+RQD/eby/6/E+wXu7lyefWODkE7dw8okVTj7x/sJ7u5cnn1jg5BO3cPKJFU4+cQc+b4PQvwPg94nIr4rIA6xo01/6nMf0IwcREVgu519T1X+2/OkvAfjj/vmPA/iXy/d/TEReiMivAvh9AP7tH9d4f9Sgqn9aVX+nqv4eGA7831T1H8d7uh4AoKpfB/AbIvL7/as/AuA/wPu7Jn8HwD8iIh/4+fkjsFz593U93ic4+cTJJ04+cQdOPnEDJ594f+HkEyefOPnEHTj5xA2cfOIObJ/ny1V1F5H/AYB/FVbl+3+vqn/18xzTjwn+MID/HoD/t4j8+/7d/wzAnwHwF0TkT8AQ9h8DAFX9qyLyF2AHeAfwJ1V1/NhH/eOH9309/ocA/nkXbv4mgP8+zIj73q2Jqv4VEfmLAP5d2Pz+PQC/DuCn8B6ux/sEJ584+cRnwPu+HiefcDj5xPsLJ584+cRnwPu+HiefcDj5xH0Q1S9dGtwJJ5xwwgknnHDCCSeccMIJJ5xwwgmfAp93ytgJJ5xwwgknnHDCCSeccMIJJ5xwwgk/ZjgNQieccMIJJ5xwwgknnHDCCSeccMIJ7xmcBqETTjjhhBNOOOGEE0444YQTTjjhhPcMToPQCSeccMIJJ5xwwgknnHDCCSeccMJ7BqdB6IQTTjjhhBNOOOGEE0444YQTTjjhPYPTIHTCCSeccMIJJ5xwwgknnHDCCSec8J7BaRA64YQTTjjhhBNOOOGEE0444YQTTnjP4DQInXDCCSeccMIJJ5xwwgknnHDCCSe8Z/D/A5/6FmaBrEBqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "p1 = Image.open('./000/3RScan/q1.jpg')\n",
    "p2 = Image.open('./000/3RScan/q2.jpg')\n",
    "p3 = Image.open('./000/3RScan/q3.jpg')\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('p1')\n",
    "plt.imshow(p1)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('p2')\n",
    "plt.imshow(p2)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('p3')\n",
    "plt.imshow(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3728c1b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 540, 960])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/igor/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0072,  0.0050,  ...,  0.0034,  0.0063,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 540, 960])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0076,  0.0020,  ...,  0.0002,  0.0062,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 540, 960])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068, -0.0019,  0.0014,  ...,  0.0054, -0.0031, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "tensor([[ 0.0026, -0.0072,  0.0050,  ...,  0.0034,  0.0063,  0.0022]])\n",
      "tensor([[ 0.0006, -0.0076,  0.0020,  ...,  0.0002,  0.0062,  0.0003]])\n",
      "tensor([[-0.0068, -0.0019,  0.0014,  ...,  0.0054, -0.0031, -0.0041]])\n"
     ]
    }
   ],
   "source": [
    "p1_vlad = VLAD_for_single_image(p1)\n",
    "p2_vlad = VLAD_for_single_image(p2)\n",
    "p3_vlad = VLAD_for_single_image(p3)\n",
    "\n",
    "dummy_p = np.zeros(p1_vlad.shape)\n",
    "p_vlad_concat_matr = np.concatenate((dummy_p, p1_vlad), axis=0)\n",
    "print((p1_vlad))\n",
    "print((p2_vlad))\n",
    "print((p3_vlad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8693f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3003\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "count = 0 \n",
    "directory = './images_for_pca_3000/'\n",
    "for image in os.listdir(directory):\n",
    "    f = os.path.join(directory, image)\n",
    "    if os.path.isfile(f):\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184ac9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0091, -0.0048,  0.0084,  ...,  0.0097,  0.0028, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0167, -0.0038,  ...,  0.0133,  0.0057, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0056, -0.0008,  ...,  0.0008,  0.0009,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0065, -0.0060,  0.0019,  ..., -0.0099,  0.0033,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0203, -0.0035,  ...,  0.0061,  0.0050,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0058, -0.0079,  ..., -0.0002,  0.0022,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0072,  0.0003,  ..., -0.0072, -0.0038,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.9138e-03,  6.8743e-04,  3.1720e-03,  ...,  8.1362e-03,\n",
      "         -4.7998e-05, -2.0179e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0073, -0.0019,  ...,  0.0081,  0.0048,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0044, -0.0047,  ..., -0.0035,  0.0072,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.1651e-03,  7.9573e-03, -3.0077e-03,  ..., -2.1980e-03,\n",
      "          1.1200e-02, -5.2169e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0033, -0.0074,  ...,  0.0043,  0.0083, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0040, -0.0075,  ..., -0.0017,  0.0028,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0072, -0.0063,  ...,  0.0097,  0.0057,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0016, -0.0019,  ...,  0.0106,  0.0141, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0019, -0.0013,  ..., -0.0006,  0.0024,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0023, -0.0059,  ...,  0.0058,  0.0069, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0016,  0.0006, -0.0073,  ...,  0.0005,  0.0042, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0085, -0.0100,  ...,  0.0163,  0.0059,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062,  0.0014, -0.0032,  ...,  0.0021, -0.0022,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[2.1537e-03, 1.3482e-03, 8.1702e-03,  ..., 7.8698e-03, 8.9473e-03,\n",
      "         6.2282e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058, -0.0035, -0.0018,  ...,  0.0071, -0.0020, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0042,  0.0063,  ..., -0.0008,  0.0008, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0097, -0.0002,  ..., -0.0009,  0.0046,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0074,  0.0033,  ...,  0.0087,  0.0097,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0067,  0.0046,  ...,  0.0110,  0.0017, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0003, -0.0003,  ..., -0.0053,  0.0054,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0057, -0.0017,  ...,  0.0060,  0.0081, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0028,  0.0043,  ...,  0.0153,  0.0087, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0139,  0.0039,  ...,  0.0013,  0.0056, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060,  0.0097,  0.0006,  ...,  0.0026,  0.0056, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0105, -0.0044,  ...,  0.0049,  0.0076,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0020, -0.0043,  ...,  0.0004,  0.0003,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 9.4087e-04, -2.8804e-05,  4.0532e-03,  ...,  4.1473e-03,\n",
      "         -3.3481e-03,  2.1000e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074,  0.0013, -0.0001,  ...,  0.0054,  0.0013,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0035,  0.0031,  ...,  0.0032,  0.0003, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098, -0.0093,  0.0005,  ...,  0.0071,  0.0019, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062,  0.0177,  0.0008,  ..., -0.0066,  0.0125, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.4525e-03,  1.7408e-03,  2.8658e-03,  ..., -1.9759e-05,\n",
      "         -4.3309e-03,  2.4899e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001, -0.0167,  0.0047,  ..., -0.0073,  0.0044,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0056, -0.0160, -0.0004,  ...,  0.0034, -0.0016,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.4832e-03, -9.1362e-03, -3.8654e-04,  ...,  5.9103e-03,\n",
      "          3.2856e-03,  1.2823e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061,  0.0007, -0.0005,  ...,  0.0061,  0.0083, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0036,  0.0017,  ...,  0.0184,  0.0005, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.1255e-03, -5.7565e-03, -2.2812e-03,  ..., -7.3578e-05,\n",
      "          2.6476e-03, -6.0346e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0039,  0.0150,  ...,  0.0041,  0.0060,  0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0052, -0.0052,  ...,  0.0011,  0.0065, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0049,  0.0015,  ...,  0.0082,  0.0047,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0049,  0.0017,  ...,  0.0124,  0.0034, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0099, -0.0039, -0.0069,  ..., -0.0037,  0.0054,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052,  0.0136,  0.0007,  ...,  0.0046,  0.0049, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0049, -0.0054,  ..., -0.0074,  0.0055, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0006, -0.0077, -0.0043,  ...,  0.0022,  0.0076, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0035, -0.0057,  ..., -0.0032,  0.0003, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0093,  0.0007,  ...,  0.0044,  0.0039,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0080, -0.0003,  ...,  0.0025,  0.0031, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0031,  0.0020,  ..., -0.0026,  0.0059,  0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.4236e-03, -3.2223e-05,  1.0749e-03,  ..., -7.5481e-03,\n",
      "          9.4463e-03,  3.5464e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0090, -0.0037, -0.0031,  ...,  0.0115,  0.0077,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0100, -0.0046,  ...,  0.0113,  0.0071, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0072,  0.0030,  ...,  0.0094,  0.0053, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0023, -0.0090,  ..., -0.0007,  0.0031, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.2222e-05, -6.8474e-03, -5.3172e-03,  ..., -2.7649e-03,\n",
      "          4.5169e-03, -5.7225e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0116,  0.0028,  0.0011,  ...,  0.0080, -0.0023, -0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0041, -0.0101,  ..., -0.0028,  0.0018, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0158, -0.0044,  ...,  0.0037,  0.0022, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0065, -0.0018,  ...,  0.0131,  0.0008, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051, -0.0068,  0.0046,  ...,  0.0053,  0.0015,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.0959e-03,  8.2323e-05,  2.7761e-03,  ...,  5.4388e-04,\n",
      "         -1.7100e-03, -2.1456e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0017, -0.0038,  ...,  0.0057,  0.0082,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0156,  0.0033,  ...,  0.0009,  0.0076, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0021, -0.0034,  ...,  0.0126,  0.0071, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0106,  0.0031, -0.0030,  ...,  0.0088,  0.0007, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0152, -0.0073,  ...,  0.0078,  0.0127,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0106, -0.0010,  ...,  0.0093,  0.0040, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0127, -0.0013,  ...,  0.0011,  0.0033,  0.0183]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0008, 0.0185, 0.0034,  ..., 0.0062, 0.0030, 0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0058,  0.0066,  ...,  0.0049,  0.0050,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0072, -0.0017,  ..., -0.0042,  0.0015, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0043,  0.0041,  ...,  0.0074,  0.0059, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0085,  0.0053,  0.0042,  ...,  0.0074,  0.0072, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.3569e-03, -1.0039e-02,  6.0901e-03,  ..., -3.9408e-06,\n",
      "          2.3297e-03,  5.8744e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003,  0.0038, -0.0033,  ...,  0.0129,  0.0010, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0111, -0.0083,  0.0028,  ...,  0.0137, -0.0003, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0003, -0.0004,  ...,  0.0004,  0.0021, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0066,  0.0026,  ...,  0.0029, -0.0003,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0181,  0.0031,  ..., -0.0095,  0.0066,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0073, -0.0046, -0.0009,  ...,  0.0057,  0.0055,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0014,  0.0121,  ...,  0.0028,  0.0036,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0062,  0.0057,  ..., -0.0102,  0.0033,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0058, -0.0026,  ...,  0.0084,  0.0098,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073, -0.0003, -0.0069,  ...,  0.0088,  0.0060,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0121,  0.0088, -0.0007,  ..., -0.0057,  0.0036, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 9.6004e-05, -1.1744e-02,  3.7159e-03,  ...,  2.6991e-03,\n",
      "          3.8555e-03,  3.6051e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0017,  0.0038,  ...,  0.0016,  0.0045,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0063,  0.0012,  ...,  0.0118,  0.0013,  0.0119]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0118,  0.0104,  ...,  0.0088,  0.0054,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0062, -0.0060,  ...,  0.0038,  0.0085, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0126, -0.0024,  ..., -0.0019,  0.0136, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0107,  0.0038,  ...,  0.0016, -0.0028,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0029,  0.0019,  ...,  0.0213, -0.0027, -0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0033,  0.0022,  ...,  0.0050, -0.0009,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0065, -0.0020,  ...,  0.0087,  0.0050,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044,  0.0050, -0.0083,  ...,  0.0138,  0.0050,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0148, -0.0052,  ...,  0.0007,  0.0021,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0039, -0.0024,  ...,  0.0130,  0.0025, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0018,  0.0019,  ..., -0.0107, -0.0026,  0.0113]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.7947e-04, -6.8632e-03,  4.1253e-03,  ...,  4.5534e-05,\n",
      "          1.4830e-02,  1.0552e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0065, -0.0046,  ..., -0.0062,  0.0018,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055, -0.0029,  0.0003,  ...,  0.0013,  0.0050,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0084,  0.0029,  ...,  0.0078,  0.0042,  0.0117]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0037,  0.0068,  ...,  0.0080,  0.0065, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0011,  0.0052,  ...,  0.0002,  0.0005, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0111, -0.0053,  ...,  0.0074,  0.0037, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0117,  0.0106,  ..., -0.0021,  0.0083,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0009,  0.0044,  ...,  0.0030,  0.0099,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062, -0.0074,  0.0040,  ..., -0.0045,  0.0036,  0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0052,  0.0071,  ...,  0.0055,  0.0045,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0098,  0.0061,  ...,  0.0096,  0.0046,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0069,  0.0038,  ...,  0.0086, -0.0002, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0071,  0.0015, -0.0034,  ...,  0.0134,  0.0038,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.6419e-03, -1.0622e-03, -6.0189e-03,  ...,  9.9724e-03,\n",
      "          1.5803e-05,  1.0189e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0038,  0.0185, -0.0040,  ...,  0.0171,  0.0098, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0108,  0.0002,  ...,  0.0070,  0.0106, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0121,  0.0079,  ..., -0.0066, -0.0016,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0038, -0.0038,  ...,  0.0182,  0.0072, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0005, -0.0016,  ...,  0.0180,  0.0047,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0160, -0.0020,  ...,  0.0070,  0.0067, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0160,  0.0010,  ...,  0.0077,  0.0084, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0006, 0.0063, 0.0056,  ..., 0.0095, 0.0043, 0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0049,  0.0026,  ...,  0.0082,  0.0058,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.9298e-03, -6.6385e-03,  4.5251e-03,  ...,  4.7282e-03,\n",
      "          3.5184e-03, -6.4297e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0032,  0.0011,  ...,  0.0093,  0.0046,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0039, -0.0007,  ..., -0.0009,  0.0079,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0118,  0.0053,  ..., -0.0090,  0.0047,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0094, -0.0048, -0.0004,  ...,  0.0012,  0.0027,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0019, -0.0057,  ...,  0.0150,  0.0059,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0235,  0.0014,  ...,  0.0066,  0.0062,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037,  0.0061, -0.0056,  ...,  0.0063,  0.0076,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0103,  0.0077,  ..., -0.0018, -0.0021,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.9442e-03,  6.0083e-03,  7.3152e-05,  ...,  1.4737e-02,\n",
      "          4.8716e-03, -4.3911e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0017,  0.0046,  ...,  0.0009,  0.0051,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0052, -0.0045,  ...,  0.0002,  0.0061, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0002,  0.0028,  ..., -0.0032,  0.0041,  0.0158]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.3156e-03, -8.8087e-03,  6.5810e-03,  ...,  7.0270e-05,\n",
      "          5.5994e-03, -1.1042e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058, -0.0063,  0.0057,  ...,  0.0063,  0.0025,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0097,  0.0031,  ..., -0.0003, -0.0028,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0073,  0.0008,  ...,  0.0143,  0.0074, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0055, -0.0037,  ...,  0.0113,  0.0009, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0063, -0.0069,  ..., -0.0053,  0.0086,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0031, -0.0083,  ...,  0.0068,  0.0048, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0048, -0.0005,  ...,  0.0161,  0.0034, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078,  0.0128,  0.0005,  ...,  0.0157,  0.0042, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0013, 0.0010, 0.0041,  ..., 0.0046, 0.0011, 0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.3546e-03, -7.7566e-05,  3.8805e-05,  ..., -6.4861e-03,\n",
      "          8.6542e-03,  1.0404e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065,  0.0113, -0.0063,  ...,  0.0059, -0.0019, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0076,  0.0013,  ...,  0.0086,  0.0005, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0082, -0.0040,  ...,  0.0063,  0.0018,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.5037e-03, -9.2959e-03, -4.5878e-04,  ...,  1.0126e-02,\n",
      "          2.4132e-05, -1.9075e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.9255e-04,  5.9142e-03, -5.0199e-05,  ...,  2.8755e-03,\n",
      "         -3.0203e-04,  2.2615e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0163, -0.0038,  ...,  0.0155,  0.0097, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0156,  0.0027,  ...,  0.0008,  0.0023,  0.0121]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0071,  0.0156,  ..., -0.0001,  0.0112,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0005, -0.0028,  ...,  0.0121,  0.0033, -0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0072,  0.0005,  ...,  0.0144,  0.0047,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0064, -0.0015,  ...,  0.0013,  0.0020,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001,  0.0097, -0.0023,  ..., -0.0036,  0.0144,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054,  0.0042,  0.0004,  ...,  0.0122,  0.0040, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0085, -0.0032,  ..., -0.0083,  0.0064,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0011,  0.0037,  ...,  0.0050,  0.0073,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0074, -0.0024,  ...,  0.0103,  0.0045, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089, -0.0126,  0.0038,  ...,  0.0017,  0.0074,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.2741e-03, -1.3504e-02,  4.3970e-03,  ...,  7.9726e-03,\n",
      "          5.4047e-03, -7.6367e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0057,  0.0042,  ...,  0.0124,  0.0090, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0118, -0.0024,  ..., -0.0046,  0.0073,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072, -0.0022,  0.0076,  ...,  0.0172,  0.0025,  0.0085]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0088, -0.0070,  ...,  0.0197,  0.0054,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0160, -0.0013,  ...,  0.0134,  0.0071, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0050, -0.0047,  ...,  0.0061,  0.0056,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0064, -0.0021,  ...,  0.0091,  0.0071, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0123,  0.0045,  ...,  0.0174,  0.0037, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0037, -0.0041,  ..., -0.0085,  0.0111,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098,  0.0159, -0.0027,  ...,  0.0134,  0.0021,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0011, 0.0096, 0.0053,  ..., 0.0048, 0.0061, 0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0069, -0.0063,  ...,  0.0090,  0.0084,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0120,  0.0032,  ...,  0.0119,  0.0074, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0123, -0.0010,  ...,  0.0008,  0.0030, -0.0120]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0093, -0.0002,  ...,  0.0155,  0.0008, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0201, -0.0078,  ...,  0.0002,  0.0033, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085, -0.0093, -0.0025,  ..., -0.0042,  0.0050,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0047,  0.0053,  ...,  0.0058,  0.0002,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0125,  0.0084,  0.0022,  ...,  0.0187,  0.0048, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-2.3176e-03, -2.3235e-03,  7.1463e-03,  ..., -2.6585e-05,\n",
      "          3.5828e-05,  4.6689e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0015,  0.0048,  ...,  0.0058,  0.0049,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0039,  0.0059,  ...,  0.0151,  0.0053,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.6128e-03, -1.4991e-02,  7.0436e-03,  ...,  2.5711e-06,\n",
      "          3.1239e-03,  3.9136e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0102, -0.0046,  0.0049,  ...,  0.0091,  0.0073,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0070, -0.0081, -0.0037,  ..., -0.0063,  0.0074,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0036, 0.0175, 0.0010,  ..., 0.0177, 0.0040, 0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0120, -0.0015,  0.0041,  ...,  0.0062,  0.0031,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.2803e-03, -6.4552e-03, -7.6005e-04,  ...,  1.0647e-02,\n",
      "         -5.6933e-06, -1.5564e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0155, -0.0021,  ...,  0.0057,  0.0188,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0125, -0.0004, -0.0032,  ...,  0.0115,  0.0045, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0065, -0.0036,  ...,  0.0028,  0.0066, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082, -0.0019,  0.0036,  ...,  0.0190,  0.0036, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0145,  0.0057,  ..., -0.0013,  0.0017,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0060,  0.0006,  ...,  0.0128,  0.0042, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0119, -0.0064,  ...,  0.0170,  0.0073, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0013, -0.0013,  ...,  0.0140,  0.0129,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0204, -0.0052,  ...,  0.0023,  0.0040, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0101, -0.0075,  ...,  0.0007,  0.0045,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0088, -0.0032,  ...,  0.0022,  0.0017,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0002,  0.0015,  ...,  0.0059, -0.0030, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0147,  0.0020,  ..., -0.0072,  0.0107,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0034, -0.0037,  ...,  0.0030,  0.0067, -0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057, -0.0059, -0.0033,  ...,  0.0067,  0.0106,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078,  0.0082, -0.0041,  ...,  0.0006,  0.0032, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0026, -0.0021,  ...,  0.0184,  0.0025, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0126,  0.0011,  ..., -0.0010, -0.0018,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0045,  0.0188,  ...,  0.0030, -0.0006,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051, -0.0003, -0.0021,  ...,  0.0103,  0.0070,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0062, -0.0044,  ...,  0.0066,  0.0039, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0091,  0.0001,  ...,  0.0107,  0.0067, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041,  0.0063,  0.0113,  ...,  0.0151,  0.0034, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.5772e-04,  1.9361e-02, -5.9617e-05,  ...,  1.1106e-02,\n",
      "          1.1798e-03, -5.9737e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034,  0.0149, -0.0004,  ...,  0.0111,  0.0045, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0080, 0.0061, 0.0149,  ..., 0.0054, 0.0010, 0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0117,  0.0070, -0.0011,  ...,  0.0065,  0.0030, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.4492e-03,  4.4958e-03, -1.7157e-03,  ...,  1.5021e-02,\n",
      "         -1.6898e-05, -3.4548e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0154,  0.0013,  ...,  0.0165,  0.0007, -0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0008, 0.0075, 0.0013,  ..., 0.0085, 0.0024, 0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045, -0.0109,  0.0090,  ...,  0.0064,  0.0030,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0063,  0.0058,  ..., -0.0008,  0.0030,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073, -0.0079,  0.0004,  ..., -0.0081,  0.0011,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0084,  0.0053,  ...,  0.0124,  0.0068,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001,  0.0018, -0.0020,  ...,  0.0042,  0.0030, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.0276e-05, -3.5410e-03, -6.2228e-03,  ...,  5.9150e-03,\n",
      "         -1.1838e-03, -1.8155e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0030,  0.0039,  ...,  0.0046, -0.0056, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0009,  0.0006,  ...,  0.0106,  0.0062,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0137,  0.0028, -0.0014,  ...,  0.0051,  0.0036,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0071, -0.0045,  ...,  0.0074, -0.0033, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0018, -0.0014,  ...,  0.0103,  0.0017,  0.0084]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0082, -0.0004,  ...,  0.0041,  0.0021, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0068, -0.0062,  ...,  0.0127,  0.0046, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0040, -0.0013,  ...,  0.0162,  0.0045, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0129,  0.0060,  ...,  0.0210,  0.0070, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0067, -0.0013,  ..., -0.0116,  0.0028,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0037, -0.0047,  ...,  0.0070,  0.0056, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0051, -0.0018,  ...,  0.0206,  0.0086, -0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0050, -0.0017,  ..., -0.0018,  0.0051, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0098,  0.0039,  ..., -0.0050,  0.0058,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0121,  0.0031,  ...,  0.0037, -0.0003,  0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0030, -0.0007,  ..., -0.0024,  0.0042, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069,  0.0004, -0.0065,  ...,  0.0106,  0.0080, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0010,  0.0096,  ...,  0.0030, -0.0002, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0047, -0.0083,  ..., -0.0035,  0.0035, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030,  0.0016, -0.0050,  ...,  0.0050,  0.0022, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0032,  0.0028,  ...,  0.0061,  0.0080, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074, -0.0079,  0.0017,  ...,  0.0031,  0.0072, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0006, -0.0009,  ...,  0.0022,  0.0041, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0046,  0.0014,  ...,  0.0104,  0.0062,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.3637e-03, -4.8375e-03, -3.7484e-05,  ..., -7.0390e-03,\n",
      "          9.9707e-03,  8.5244e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0026, -0.0040,  0.0013,  ...,  0.0020,  0.0024,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0116, -0.0051,  ..., -0.0003, -0.0013, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0024,  0.0012,  ...,  0.0027,  0.0052, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0073,  0.0002,  ..., -0.0057,  0.0018, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0044,  0.0099,  ...,  0.0072,  0.0052, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054,  0.0007, -0.0006,  ...,  0.0075,  0.0046,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0009, -0.0057,  ...,  0.0032,  0.0181,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.6983e-05, -8.0962e-04,  4.2712e-03,  ...,  7.3778e-03,\n",
      "          4.4124e-03, -3.1428e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0083, 0.0065, 0.0068,  ..., 0.0108, 0.0074, 0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0028,  0.0026,  ..., -0.0050,  0.0049,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0037,  0.0104,  ...,  0.0049,  0.0084,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0068, -0.0045,  ...,  0.0112,  0.0101, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080,  0.0072, -0.0025,  ...,  0.0087,  0.0090,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0075, -0.0034,  ...,  0.0043,  0.0043,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0025, -0.0076,  ...,  0.0097,  0.0048, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0014, -0.0041,  ...,  0.0018,  0.0052, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033, -0.0016, -0.0033,  ...,  0.0070,  0.0088, -0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0064,  0.0018,  ...,  0.0076, -0.0015, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0004,  0.0009,  ..., -0.0006,  0.0026,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0121,  0.0004,  ...,  0.0193,  0.0027, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0097, -0.0034,  ..., -0.0005,  0.0066,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084,  0.0049, -0.0081,  ...,  0.0002,  0.0025, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064,  0.0052,  0.0007,  ...,  0.0167,  0.0080, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023,  0.0145, -0.0030,  ...,  0.0145,  0.0015,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0091,  0.0061, -0.0066,  ...,  0.0099,  0.0005, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0180, -0.0004,  ...,  0.0049,  0.0012,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062,  0.0001, -0.0001,  ...,  0.0049,  0.0021,  0.0203]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.8446e-06, -3.8863e-03, -4.6073e-03,  ..., -2.9099e-03,\n",
      "          7.6878e-03, -4.3785e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0037,  0.0011,  ...,  0.0091,  0.0044,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0065, -0.0078,  ...,  0.0088,  0.0038,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0149,  0.0070,  ...,  0.0049,  0.0102,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023,  0.0111, -0.0039,  ..., -0.0098, -0.0010,  0.0134]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0003, -0.0058,  ...,  0.0089, -0.0009,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0094,  0.0087,  ..., -0.0040,  0.0065,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0108, -0.0003,  ...,  0.0041,  0.0053, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0038, -0.0101, -0.0087,  ...,  0.0134,  0.0054, -0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021,  0.0035, -0.0047,  ...,  0.0021,  0.0003,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0032, -0.0004,  ...,  0.0010,  0.0020,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033,  0.0025,  0.0067,  ...,  0.0099,  0.0090,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0090,  0.0068, -0.0054,  ...,  0.0172,  0.0122,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0024,  0.0063,  ...,  0.0116, -0.0051,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0022, -0.0042,  ..., -0.0049,  0.0059,  0.0189]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0071,  0.0014,  ...,  0.0128,  0.0011, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0044,  0.0043,  ...,  0.0169,  0.0069, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0229, -0.0032,  ...,  0.0135,  0.0055, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082,  0.0146,  0.0087,  ...,  0.0171,  0.0040, -0.0085]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0068,  0.0010,  ...,  0.0137,  0.0069, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080, -0.0052,  0.0100,  ...,  0.0185,  0.0050,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0022,  0.0065,  ...,  0.0144,  0.0118,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0056,  0.0027,  ...,  0.0024,  0.0059, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061,  0.0102, -0.0025,  ...,  0.0085,  0.0103,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0098, -0.0086,  ..., -0.0043,  0.0024, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0024, -0.0052,  ..., -0.0014,  0.0103,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0041, -0.0004,  ...,  0.0108,  0.0077,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.9498e-04, -6.3025e-03, -8.6951e-04,  ...,  1.4868e-03,\n",
      "         -3.8513e-03, -8.6748e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0140, -0.0004,  ...,  0.0026,  0.0050, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0042,  0.0039,  ...,  0.0121,  0.0033, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0075, -0.0062,  ..., -0.0022, -0.0025,  0.0142]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0036,  0.0009,  ...,  0.0081,  0.0062,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0018, -0.0022,  ...,  0.0095,  0.0080,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0076, -0.0018,  ..., -0.0060,  0.0005,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050,  0.0049,  0.0054,  ...,  0.0170,  0.0016, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0079,  0.0196, -0.0054,  ...,  0.0134,  0.0040, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0079,  0.0025,  ...,  0.0143, -0.0020, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0048, -0.0036,  ...,  0.0051,  0.0054, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0032, -0.0004,  ...,  0.0056,  0.0124,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0121,  0.0069,  0.0017,  ..., -0.0053, -0.0021, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0011, -0.0021,  ...,  0.0027,  0.0050, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0048, -0.0067,  ...,  0.0143,  0.0046,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0146,  0.0013,  ...,  0.0058, -0.0020, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0054, -0.0104, -0.0052,  ...,  0.0059,  0.0030,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0112,  0.0022,  ...,  0.0033,  0.0030, -0.0080]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 9.4507e-05, -1.4915e-02,  1.6475e-03,  ...,  7.6499e-03,\n",
      "          2.8387e-03,  7.5620e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0093,  0.0061, -0.0002,  ...,  0.0061, -0.0013, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0094,  0.0088,  ..., -0.0108,  0.0028,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060,  0.0014,  0.0045,  ...,  0.0103, -0.0006, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0019, 0.0020, 0.0006,  ..., 0.0088, 0.0038, 0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0041,  0.0027,  ...,  0.0141,  0.0047, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065,  0.0178, -0.0013,  ...,  0.0138,  0.0056,  0.0153]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0036, -0.0027,  ...,  0.0105,  0.0067, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0015, -0.0031,  ..., -0.0021,  0.0006, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0100, -0.0027,  ...,  0.0091, -0.0035, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0008, -0.0008,  ...,  0.0072,  0.0045,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078,  0.0114, -0.0023,  ...,  0.0143,  0.0122,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0023, 0.0059, 0.0002,  ..., 0.0152, 0.0093, 0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0063, -0.0042,  ..., -0.0005,  0.0044,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0151, -0.0004,  ...,  0.0038,  0.0013,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0011, -0.0021,  ...,  0.0064,  0.0075, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0017, -0.0008,  ..., -0.0016,  0.0058, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069, -0.0015,  0.0071,  ..., -0.0020, -0.0042,  0.0100]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0084,  0.0002, -0.0039,  ...,  0.0130,  0.0092, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0057,  0.0144,  ...,  0.0058,  0.0017, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0054, -0.0014,  ...,  0.0137,  0.0066, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0155, -0.0001,  ...,  0.0089, -0.0002, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0136, -0.0012,  ..., -0.0034,  0.0072,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0029,  0.0034,  ...,  0.0066,  0.0098,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0109,  0.0126,  ...,  0.0110,  0.0012,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0088,  0.0079, -0.0019,  ...,  0.0102,  0.0077, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0065,  0.0038,  ...,  0.0010,  0.0067,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.0256e-05,  2.0362e-03, -4.5356e-03,  ...,  1.5698e-03,\n",
      "          5.3372e-03, -1.7945e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0037,  0.0034,  ...,  0.0107,  0.0032, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0007, 0.0075, 0.0088,  ..., 0.0072, 0.0076, 0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043, -0.0018,  0.0023,  ...,  0.0108,  0.0054, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0073, -0.0010,  ...,  0.0021,  0.0012, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0014, -0.0047,  ...,  0.0111,  0.0081, -0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0020,  0.0185, -0.0001,  ...,  0.0112,  0.0071, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0117, -0.0090,  0.0107,  ...,  0.0093, -0.0007, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.2551e-04,  3.6897e-03, -2.8674e-04,  ...,  1.3159e-02,\n",
      "          9.6415e-05,  1.1865e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0005, -0.0024,  ..., -0.0066,  0.0032,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0064, -0.0033,  ...,  0.0020,  0.0003, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0073,  0.0034,  ...,  0.0097,  0.0055, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0141, -0.0048,  ...,  0.0228,  0.0107, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0110,  0.0011,  ..., -0.0085,  0.0029,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0114, -0.0060,  ...,  0.0045,  0.0049,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.6555e-03, -2.8665e-03,  1.0295e-03,  ...,  5.9533e-03,\n",
      "          6.4898e-03,  6.5499e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0021,  0.0056,  ...,  0.0113, -0.0043, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0063, -0.0021,  ...,  0.0048,  0.0023, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0031,  0.0051,  ...,  0.0021,  0.0016, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0097, -0.0003,  ..., -0.0047,  0.0035,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0006, -0.0022,  ...,  0.0053,  0.0030,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0013, -0.0027,  ...,  0.0125,  0.0035, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0097,  0.0049, -0.0055,  ...,  0.0018, -0.0029, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076,  0.0082, -0.0097,  ...,  0.0023,  0.0094, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0104,  0.0012,  ...,  0.0153,  0.0054,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0102,  0.0087,  ...,  0.0003,  0.0067,  0.0114]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0003, 0.0119, 0.0013,  ..., 0.0143, 0.0059, 0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.9399e-03, -6.9095e-03, -2.8242e-05,  ...,  3.2063e-03,\n",
      "          3.7933e-03, -7.8734e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0094, -0.0041,  ...,  0.0104,  0.0028,  0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0092,  0.0009,  ...,  0.0026,  0.0037,  0.0100]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0115,  0.0135, -0.0018,  ..., -0.0004,  0.0009,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0039,  0.0030,  ...,  0.0009,  0.0015, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0117, -0.0084,  ..., -0.0021,  0.0024,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0104, -0.0004,  ..., -0.0035,  0.0055,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0020, -0.0077,  ...,  0.0079,  0.0045, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.6261e-03, -2.2805e-03, -4.9705e-05,  ...,  5.4692e-03,\n",
      "          2.1351e-03,  2.5367e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0094,  0.0091, -0.0024,  ...,  0.0205,  0.0012, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0007, 0.0103, 0.0039,  ..., 0.0052, 0.0046, 0.0132]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044,  0.0035,  0.0009,  ..., -0.0131,  0.0049,  0.0150]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0033, -0.0054,  ..., -0.0051, -0.0018,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0033, -0.0012,  ...,  0.0185,  0.0055,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0039,  0.0139, -0.0004,  ...,  0.0099,  0.0052, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0057, -0.0005,  ..., -0.0014,  0.0127,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0031, -0.0028,  ..., -0.0023,  0.0032,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0101, 0.0015, 0.0023,  ..., 0.0049, 0.0071, 0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040, -0.0004,  0.0022,  ...,  0.0012,  0.0133, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058,  0.0115, -0.0040,  ...,  0.0039,  0.0051, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061,  0.0007,  0.0005,  ...,  0.0143,  0.0148, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0059,  0.0064,  ..., -0.0007,  0.0035, -0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087,  0.0016, -0.0029,  ...,  0.0105, -0.0009,  0.0110]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0050, -0.0051,  ...,  0.0079,  0.0048,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0101,  0.0042,  ...,  0.0074, -0.0020, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0041, -0.0012,  ...,  0.0013, -0.0014,  0.0143]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0065,  0.0104, -0.0025,  ...,  0.0210,  0.0051, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.7042e-03, -3.7192e-03,  8.6207e-04,  ..., -1.4985e-03,\n",
      "          8.6463e-03, -1.8618e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0010,  0.0050,  ...,  0.0129,  0.0014, -0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069,  0.0037, -0.0022,  ...,  0.0037,  0.0020,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0038,  0.0076,  ..., -0.0004, -0.0043,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0010, -0.0059,  ...,  0.0076,  0.0100, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0081,  0.0050, -0.0014,  ..., -0.0067,  0.0046,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0068, 0.0078, 0.0010,  ..., 0.0011, 0.0174, 0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0011,  0.0031,  ..., -0.0086,  0.0091,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0023, -0.0020,  ..., -0.0045,  0.0044, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0044,  0.0028,  ...,  0.0116,  0.0023, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100, -0.0005,  0.0031,  ...,  0.0122,  0.0029, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0012, -0.0022,  ..., -0.0022,  0.0117,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075, -0.0051, -0.0025,  ...,  0.0062,  0.0084,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0060, 0.0031, 0.0007,  ..., 0.0098, 0.0061, 0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0019, -0.0005,  ..., -0.0051,  0.0030,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.9054e-03, -7.1050e-06, -4.2006e-03,  ...,  8.4032e-03,\n",
      "         -1.6010e-03, -6.1257e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0046, -0.0061,  ..., -0.0015,  0.0102,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.0614e-05, -2.5114e-03,  1.0950e-02,  ...,  5.9055e-03,\n",
      "          1.3495e-02,  4.9098e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.8906e-03,  1.0102e-02, -4.6014e-03,  ...,  1.7323e-02,\n",
      "         -7.8268e-05, -1.1342e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.9056e-03, -6.0251e-03,  7.2087e-03,  ..., -8.1604e-05,\n",
      "          8.8207e-03, -3.5493e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0058, -0.0049,  ..., -0.0061,  0.0048, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0066,  0.0039,  ...,  0.0147,  0.0059, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0026, -0.0036,  0.0014,  ...,  0.0098, -0.0013, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0072,  0.0080,  ...,  0.0211,  0.0019, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0032, -0.0030,  ...,  0.0028,  0.0053, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062, -0.0014, -0.0005,  ...,  0.0161,  0.0018, -0.0085]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0069,  0.0035,  ...,  0.0081,  0.0089, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0037,  0.0014,  ..., -0.0038, -0.0047,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0019, -0.0034,  ...,  0.0079,  0.0048,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0060,  0.0060,  ...,  0.0062,  0.0060,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064, -0.0051,  0.0064,  ...,  0.0021,  0.0001,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049,  0.0016, -0.0042,  ..., -0.0034, -0.0008, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0003, -0.0041,  ...,  0.0082,  0.0013, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0034,  0.0033,  ...,  0.0096,  0.0072,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0014, -0.0002,  ...,  0.0034, -0.0019,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0006, -0.0018,  ...,  0.0084,  0.0071, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062, -0.0026, -0.0018,  ...,  0.0111,  0.0030, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0171, -0.0020,  ...,  0.0041,  0.0007,  0.0099]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.0238e-03, -1.5508e-03,  8.3138e-07,  ..., -8.6973e-03,\n",
      "          1.2498e-03,  3.8613e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0221, -0.0016,  ...,  0.0121,  0.0046, -0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0138,  0.0020,  ...,  0.0042,  0.0039, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.0790e-03,  2.6043e-05,  4.5016e-03,  ...,  1.4450e-02,\n",
      "         -2.1455e-04, -1.1704e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0041,  0.0038,  ...,  0.0176,  0.0112,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0023,  0.0148,  ...,  0.0051,  0.0065,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0075,  0.0022,  ...,  0.0143,  0.0079,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0091,  0.0015,  ...,  0.0038,  0.0029,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0185,  0.0006,  ...,  0.0019,  0.0104,  0.0128]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0076,  0.0002, -0.0027,  ...,  0.0054,  0.0038, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0105,  0.0030,  ...,  0.0034,  0.0100,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0031,  0.0048,  ...,  0.0087, -0.0015, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0146,  0.0108,  ...,  0.0146,  0.0069,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052,  0.0101, -0.0018,  ...,  0.0070,  0.0061,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0038,  0.0111,  ...,  0.0010,  0.0074, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061, -0.0134,  0.0050,  ...,  0.0060,  0.0041,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0003, -0.0086,  ...,  0.0104,  0.0062, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0126, -0.0020,  ...,  0.0019,  0.0029,  0.0166]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0092, 0.0036, 0.0019,  ..., 0.0140, 0.0122, 0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0009, -0.0068,  0.0058,  ...,  0.0009, -0.0060, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0092,  0.0049,  ...,  0.0048,  0.0040,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0063,  0.0044,  ...,  0.0075,  0.0055, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0032,  0.0004,  ...,  0.0190,  0.0058, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0135, -0.0031,  ...,  0.0063,  0.0046, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0044, -0.0077,  ...,  0.0086,  0.0037,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0044, -0.0041,  ...,  0.0013,  0.0033,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0070, -0.0044,  ...,  0.0122,  0.0059, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061, -0.0040,  0.0047,  ...,  0.0083,  0.0004, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0012, -0.0068,  ...,  0.0061,  0.0040, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0055,  0.0055,  ...,  0.0043,  0.0031, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.6858e-03,  1.8900e-03, -5.9871e-05,  ...,  4.3007e-03,\n",
      "          3.0195e-03,  1.5691e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0081, -0.0028,  ...,  0.0166, -0.0027, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0119,  0.0007,  ...,  0.0090,  0.0020, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0073, -0.0012,  ...,  0.0005,  0.0057,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081,  0.0045,  0.0021,  ...,  0.0086,  0.0013, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0003,  0.0061,  ...,  0.0060,  0.0043,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0045,  0.0081,  ...,  0.0086,  0.0043, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074,  0.0101,  0.0026,  ..., -0.0034, -0.0047,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0036,  0.0072,  ...,  0.0061,  0.0092, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0109, -0.0019,  0.0080,  ..., -0.0078,  0.0034,  0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0093, -0.0014,  ...,  0.0039,  0.0063, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0005, 0.0071, 0.0016,  ..., 0.0088, 0.0055, 0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027,  0.0012,  0.0021,  ...,  0.0090,  0.0089, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065, -0.0048, -0.0039,  ...,  0.0185,  0.0038,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0100, -0.0008,  ...,  0.0131, -0.0023,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049, -0.0140,  0.0074,  ...,  0.0069, -0.0009,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050,  0.0012, -0.0054,  ...,  0.0153,  0.0047, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0089, -0.0023,  ...,  0.0178,  0.0090, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0037,  0.0021,  ...,  0.0119,  0.0026, -0.0115]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0015,  0.0043,  ...,  0.0118,  0.0075,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051, -0.0121,  0.0010,  ...,  0.0095,  0.0044,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0050, -0.0028,  ...,  0.0123,  0.0011,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0025,  0.0017,  ...,  0.0134, -0.0052, -0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0110, -0.0053,  ...,  0.0127,  0.0002,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0015,  0.0093, -0.0056,  ..., -0.0009,  0.0025,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.0127e-03, -4.2502e-03, -2.5681e-05,  ...,  9.9105e-03,\n",
      "          3.2972e-03, -4.1624e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0083,  0.0025,  ..., -0.0007,  0.0044, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0168,  0.0070,  ...,  0.0024,  0.0008,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0065,  0.0026,  ...,  0.0010,  0.0051,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0023, -0.0058,  ...,  0.0019,  0.0004, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0175, -0.0035,  ...,  0.0054,  0.0017, -0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060,  0.0014,  0.0004,  ...,  0.0080, -0.0017,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.5801e-03, -5.3669e-04,  9.5327e-04,  ...,  8.2456e-03,\n",
      "          4.5554e-03, -8.0586e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0003, -0.0014,  ..., -0.0096, -0.0007,  0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053, -0.0047,  0.0008,  ..., -0.0028,  0.0070,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0081,  0.0028,  ...,  0.0053,  0.0060,  0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0006, -0.0007,  ...,  0.0182,  0.0080, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0094,  0.0009,  ...,  0.0119,  0.0039, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067,  0.0166, -0.0043,  ...,  0.0076,  0.0063,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0144, -0.0003, -0.0019,  ...,  0.0055,  0.0181,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0090,  0.0020, -0.0023,  ...,  0.0006,  0.0096, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0025,  0.0064,  ..., -0.0057,  0.0089,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.0114e-05, -7.4239e-03,  1.3027e-02,  ...,  3.9588e-04,\n",
      "          3.5764e-03,  3.6480e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0012,  0.0005,  ..., -0.0043,  0.0093, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100,  0.0023,  0.0030,  ...,  0.0170,  0.0075, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064, -0.0060, -0.0026,  ...,  0.0083, -0.0014, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.8064e-03, -6.4297e-03,  2.8414e-03,  ...,  1.4667e-02,\n",
      "          1.2311e-02, -1.9189e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0189, -0.0007,  ...,  0.0053,  0.0002, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021,  0.0104, -0.0004,  ..., -0.0012,  0.0039,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0017e-02,  3.2645e-03, -2.7672e-03,  ...,  1.2620e-02,\n",
      "          1.9714e-05,  2.1219e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0019, -0.0013,  ..., -0.0041, -0.0016,  0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0053, -0.0012,  ...,  0.0012,  0.0021,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0083, -0.0035, -0.0073,  ...,  0.0063,  0.0100, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067, -0.0011, -0.0074,  ...,  0.0043,  0.0036,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0114, -0.0046,  ...,  0.0080,  0.0052,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0012, -0.0068,  ..., -0.0044,  0.0081,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0030, -0.0016,  ...,  0.0094,  0.0033,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.0174e-03,  4.1311e-03,  2.0442e-03,  ...,  5.2578e-03,\n",
      "          6.7374e-05, -3.2220e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0068,  0.0046,  ..., -0.0119,  0.0053,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0055, -0.0006, -0.0044,  ...,  0.0104,  0.0018,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.6338e-05,  1.1475e-02, -3.4228e-04,  ...,  1.0476e-02,\n",
      "          5.3654e-03, -8.0567e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0149, -0.0028,  ...,  0.0140,  0.0065, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[1.0852e-02, 2.3114e-03, 5.3139e-05,  ..., 1.6136e-02, 2.1494e-03,\n",
      "         3.8162e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072, -0.0005,  0.0032,  ...,  0.0087,  0.0056,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0060,  0.0003,  ...,  0.0100,  0.0045, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0023, -0.0013,  ..., -0.0005,  0.0105,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087,  0.0039,  0.0041,  ...,  0.0030, -0.0001,  0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0064, -0.0022,  ...,  0.0015,  0.0027,  0.0123]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0090,  0.0028,  ...,  0.0085,  0.0014,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.6560e-03, -5.4113e-05, -1.3396e-03,  ...,  2.4867e-03,\n",
      "          1.1880e-02,  1.5984e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0037, 0.0066, 0.0003,  ..., 0.0091, 0.0040, 0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075, -0.0057, -0.0036,  ...,  0.0026,  0.0101,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0091,  0.0025, -0.0017,  ...,  0.0120, -0.0013, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0056,  0.0201,  0.0044,  ...,  0.0079,  0.0021, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0033, -0.0034,  ..., -0.0070,  0.0028,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0009,  0.0014,  ..., -0.0092,  0.0024, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0016,  0.0018,  ...,  0.0128,  0.0019, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0095, -0.0060, -0.0054,  ...,  0.0017,  0.0001,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0033,  0.0031,  ..., -0.0100,  0.0010,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0067, -0.0057,  ...,  0.0110,  0.0055,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0087,  0.0026,  ...,  0.0058, -0.0028, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0018, 0.0062, 0.0028,  ..., 0.0026, 0.0028, 0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.3463e-03, -5.2167e-03,  5.1603e-04,  ..., -1.8642e-03,\n",
      "          8.6878e-05, -1.7509e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0094,  0.0087,  ...,  0.0148,  0.0059, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0154, -0.0079,  ..., -0.0056,  0.0074,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0056,  0.0061,  ...,  0.0048, -0.0010, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0076, -0.0014,  ...,  0.0045,  0.0061, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.2560e-03, -4.3936e-03,  9.4147e-05,  ..., -4.3957e-03,\n",
      "          2.1778e-03,  5.8553e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087, -0.0112,  0.0033,  ...,  0.0046,  0.0071,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0034, -0.0047,  ...,  0.0081,  0.0146,  0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0025, -0.0027,  ...,  0.0083,  0.0075, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0112,  0.0005,  ...,  0.0090,  0.0043, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0031, -0.0108,  ...,  0.0149,  0.0012, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0052,  0.0042,  ..., -0.0003,  0.0005,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0016, -0.0079,  0.0055,  ...,  0.0025,  0.0048,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0014,  0.0011,  ...,  0.0075,  0.0069,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0090,  0.0018,  ...,  0.0116,  0.0104, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.5779e-05,  2.4467e-03,  1.3993e-04,  ...,  9.0207e-03,\n",
      "          5.7458e-03,  5.4302e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029,  0.0052,  0.0067,  ..., -0.0096,  0.0041, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0023, -0.0023,  ..., -0.0076,  0.0064,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.5431e-04,  1.5282e-02, -3.4855e-03,  ...,  1.3408e-02,\n",
      "          4.1510e-03, -4.7501e-06]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0187,  0.0007,  ...,  0.0087,  0.0033, -0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0042, -0.0007,  ...,  0.0208,  0.0116,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0019,  0.0024,  ...,  0.0060,  0.0098,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0073,  0.0028,  ...,  0.0051,  0.0112,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0018,  0.0068,  ...,  0.0038, -0.0010,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0115,  0.0095,  0.0005,  ...,  0.0100, -0.0018, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0010, -0.0016,  ...,  0.0088,  0.0057, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0163, -0.0040,  ...,  0.0014,  0.0090, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069, -0.0107,  0.0088,  ...,  0.0022,  0.0016,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0102,  0.0014,  ...,  0.0096,  0.0043, -0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0032,  0.0040,  ...,  0.0121,  0.0050, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0060, -0.0061,  ...,  0.0019,  0.0038, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051, -0.0123,  0.0026,  ...,  0.0205,  0.0063, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0034, -0.0065,  ...,  0.0095,  0.0034,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0096, -0.0011,  0.0049,  ..., -0.0046,  0.0069,  0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0051, -0.0007,  ...,  0.0040,  0.0047,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0146,  0.0072,  ..., -0.0041,  0.0038, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0156,  0.0005,  ..., -0.0082,  0.0126, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0025, -0.0003,  ..., -0.0018,  0.0057, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0041, -0.0030,  ...,  0.0155,  0.0081,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0050, -0.0023,  ...,  0.0180,  0.0085, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0101, -0.0046,  ...,  0.0080,  0.0023, -0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0096, -0.0118,  0.0013,  ..., -0.0005,  0.0031,  0.0114]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0027,  0.0018,  ...,  0.0067,  0.0051,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0010,  0.0061,  ...,  0.0169,  0.0020,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0055, -0.0008,  ...,  0.0051,  0.0034,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0024,  0.0010,  ...,  0.0097,  0.0027, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0004,  0.0041,  ...,  0.0097,  0.0005,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[0.0054, 0.0005, 0.0079,  ..., 0.0005, 0.0028, 0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028,  0.0012,  0.0033,  ..., -0.0030,  0.0075,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0081,  0.0016,  ..., -0.0023,  0.0006,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.6563e-05, -5.7233e-03, -8.6594e-03,  ..., -2.9116e-03,\n",
      "          1.1069e-02,  3.0500e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054, -0.0029,  0.0003,  ...,  0.0097,  0.0021,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085,  0.0003, -0.0065,  ...,  0.0033,  0.0085,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075,  0.0047, -0.0030,  ...,  0.0177,  0.0081, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045, -0.0007, -0.0035,  ...,  0.0071,  0.0084, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0086,  0.0087,  ..., -0.0002,  0.0024,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0088, -0.0011,  ...,  0.0036,  0.0029, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0002, -0.0018,  ..., -0.0021,  0.0035, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0125,  0.0027,  ..., -0.0040,  0.0015, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0002, -0.0081,  ..., -0.0107,  0.0068,  0.0110]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0041,  0.0013,  ..., -0.0091, -0.0014,  0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0077,  0.0021,  ...,  0.0005, -0.0001, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0069, -0.0021,  ...,  0.0074,  0.0075, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049, -0.0046, -0.0040,  ...,  0.0168,  0.0037,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0045, -0.0022,  ..., -0.0033,  0.0036, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0065, -0.0059,  ..., -0.0016,  0.0054,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0014, -0.0004,  ...,  0.0094,  0.0043,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0107, -0.0024,  ...,  0.0073,  0.0018,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001, -0.0068,  0.0055,  ..., -0.0029,  0.0029,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0061,  0.0101,  ...,  0.0029, -0.0027, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0016,  0.0033,  ...,  0.0082,  0.0075, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0023, -0.0020,  ...,  0.0003,  0.0036, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0071, -0.0056,  ..., -0.0019,  0.0038,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0069,  0.0027,  ...,  0.0102,  0.0038, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0138,  0.0063,  ...,  0.0115,  0.0017, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0005, -0.0005,  ...,  0.0117,  0.0062, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074,  0.0140,  0.0022,  ...,  0.0074,  0.0038,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0117,  0.0022,  ...,  0.0016,  0.0085,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023,  0.0112, -0.0045,  ...,  0.0015,  0.0035, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0002, -0.0007,  ..., -0.0007,  0.0103, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0034, -0.0058,  ..., -0.0098,  0.0016,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0072,  0.0044,  ...,  0.0146,  0.0076, -0.0092]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0003,  0.0254, -0.0036,  ...,  0.0127,  0.0077, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0011, -0.0009,  ...,  0.0095, -0.0006,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080, -0.0052, -0.0021,  ...,  0.0106,  0.0053, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0121, -0.0021,  ..., -0.0004,  0.0051, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0001,  0.0062,  ...,  0.0052,  0.0017,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0015,  0.0038,  ..., -0.0091,  0.0003,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0031, -0.0065,  ..., -0.0056, -0.0052,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0034, -0.0045,  ..., -0.0107,  0.0034, -0.0085]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0139,  0.0053,  0.0074,  ...,  0.0006,  0.0006, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0019, -0.0048,  ..., -0.0046,  0.0075,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0066,  0.0039, -0.0002,  ...,  0.0054, -0.0013,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0117,  0.0083,  ...,  0.0007, -0.0006, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0055,  0.0038,  ..., -0.0003,  0.0057, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067, -0.0076,  0.0068,  ...,  0.0077,  0.0018,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.5292e-03,  3.8561e-03, -8.2458e-05,  ...,  1.1881e-02,\n",
      "          4.8090e-04, -3.7901e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0097,  0.0093,  0.0030,  ..., -0.0011,  0.0076,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0052,  0.0052,  ..., -0.0018,  0.0027,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0078,  0.0017,  ..., -0.0049,  0.0141, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0052,  0.0096,  ..., -0.0040,  0.0017, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0005, -0.0051,  ...,  0.0030,  0.0036,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074,  0.0112,  0.0010,  ..., -0.0058,  0.0078,  0.0111]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025, -0.0107,  0.0019,  ...,  0.0003,  0.0018, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0055,  0.0032,  ...,  0.0049, -0.0002, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0027, -0.0063,  ...,  0.0089,  0.0077, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0041, -0.0048,  ..., -0.0058,  0.0060,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0068, -0.0001,  ...,  0.0036,  0.0025,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0102,  0.0062,  ...,  0.0085,  0.0048,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0052,  0.0113,  ..., -0.0040,  0.0095,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0081,  0.0042,  ..., -0.0060,  0.0051,  0.0117]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0037, -0.0015,  ..., -0.0017,  0.0034,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0022,  0.0047,  ..., -0.0085, -0.0027,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.1391e-03, -3.5986e-03,  4.2391e-05,  ..., -6.9083e-03,\n",
      "          3.6145e-04,  3.2713e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048,  0.0085,  0.0088,  ...,  0.0073,  0.0024, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063,  0.0020, -0.0035,  ...,  0.0055,  0.0014, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0025, -0.0084,  ...,  0.0063,  0.0109, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0056,  0.0010,  0.0073,  ...,  0.0017, -0.0048, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0066, -0.0046,  ...,  0.0149,  0.0042, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0090,  0.0098,  ...,  0.0026,  0.0071,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0105,  0.0044,  ..., -0.0111, -0.0008,  0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0143, -0.0007,  ...,  0.0185,  0.0048, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0094, -0.0034,  ...,  0.0087, -0.0003, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0105,  0.0035,  ...,  0.0024,  0.0047,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0007, -0.0030,  ...,  0.0080,  0.0061,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0093,  0.0015,  ...,  0.0067,  0.0032,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0035,  0.0025,  ...,  0.0113,  0.0054,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0066,  0.0009,  ..., -0.0018,  0.0042, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0015,  0.0005,  ..., -0.0057,  0.0028, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0066,  0.0119,  0.0008,  ...,  0.0255,  0.0134, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0018,  0.0032,  ...,  0.0114, -0.0006, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0015,  0.0030,  ...,  0.0024, -0.0050,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0026, 0.0184, 0.0011,  ..., 0.0067, 0.0059, 0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048,  0.0092, -0.0030,  ..., -0.0020,  0.0016,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069, -0.0014, -0.0059,  ...,  0.0038,  0.0029, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0034,  0.0043,  ...,  0.0136,  0.0048,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0094, -0.0045,  ...,  0.0161,  0.0107, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0086, -0.0036,  ...,  0.0160,  0.0094,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0121,  0.0033,  0.0027,  ...,  0.0084,  0.0035, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0117,  0.0045,  ...,  0.0073,  0.0027,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0043,  0.0001,  ...,  0.0042,  0.0075, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0072,  0.0046,  ...,  0.0019,  0.0023,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0089,  0.0063,  ...,  0.0039,  0.0122,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0040,  0.0018,  ...,  0.0205, -0.0021, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0019,  0.0024,  ...,  0.0022,  0.0040, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0006,  0.0002,  ...,  0.0042,  0.0038,  0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0106,  0.0049, -0.0032,  ..., -0.0010,  0.0061,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0029, -0.0015,  ...,  0.0017, -0.0028,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0170, -0.0039,  ...,  0.0149,  0.0063, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0027, -0.0008,  ..., -0.0030,  0.0047, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0130,  0.0033,  ..., -0.0012,  0.0034,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089,  0.0019,  0.0045,  ...,  0.0065,  0.0097, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0046,  0.0066, -0.0003,  ..., -0.0035,  0.0016,  0.0152]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060,  0.0057,  0.0052,  ...,  0.0134,  0.0023, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0060, -0.0050,  ...,  0.0104,  0.0035, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0143, -0.0011,  ...,  0.0024,  0.0052,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0012,  0.0024,  ..., -0.0064,  0.0032,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0013,  0.0101,  ..., -0.0102,  0.0031,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0027, -0.0064,  ...,  0.0102,  0.0057, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0095,  0.0069,  ...,  0.0061,  0.0011,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0025,  0.0038,  ...,  0.0023,  0.0132,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0006, 0.0149, 0.0010,  ..., 0.0008, 0.0008, 0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0027, -0.0064,  ..., -0.0006,  0.0022,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0065, -0.0025,  ...,  0.0079,  0.0064, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0112, -0.0014,  ..., -0.0032,  0.0077,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0101, -0.0079,  ...,  0.0081,  0.0092, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0120,  0.0074, -0.0009,  ...,  0.0141,  0.0050, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0029,  0.0016,  ...,  0.0160,  0.0019,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0061, -0.0004,  ...,  0.0081,  0.0075,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0048,  0.0021,  ...,  0.0092,  0.0104, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0086,  0.0020,  0.0030,  ...,  0.0026,  0.0064, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0064, -0.0020,  ...,  0.0141,  0.0063, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0044,  0.0002,  ...,  0.0085, -0.0049, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0029, -0.0066,  ...,  0.0063,  0.0008, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0090, -0.0083,  ..., -0.0015,  0.0063,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0102,  0.0166,  ...,  0.0021,  0.0070,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.3119e-03, -8.1381e-05, -6.2129e-03,  ...,  1.1606e-02,\n",
      "          1.2464e-03, -4.3149e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0074,  0.0013,  ...,  0.0017,  0.0009, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0116, -0.0063, -0.0012,  ...,  0.0114,  0.0053, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0096,  0.0020,  ..., -0.0004, -0.0004, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0148,  0.0053,  ..., -0.0028,  0.0057,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0872e-03,  2.4686e-03, -2.5672e-03,  ...,  3.8505e-03,\n",
      "         -3.6945e-05,  1.4758e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0090, -0.0009,  ...,  0.0139,  0.0017, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0075, -0.0077,  ...,  0.0105,  0.0060, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0158,  0.0006,  ..., -0.0053, -0.0002, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0211,  0.0024,  ...,  0.0092,  0.0047,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0134,  0.0134,  ...,  0.0060,  0.0045,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0033,  0.0003, -0.0011,  ...,  0.0062,  0.0065,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.5618e-05,  8.6727e-03, -3.6016e-03,  ..., -5.7924e-03,\n",
      "          9.5452e-03,  1.4521e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0066, -0.0038, -0.0017,  ...,  0.0077,  0.0058, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0071, -0.0001,  ...,  0.0019,  0.0048,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0006, 0.0027, 0.0046,  ..., 0.0060, 0.0025, 0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0155, -0.0027,  ...,  0.0029, -0.0039,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0034,  0.0006,  ..., -0.0025,  0.0059,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0026, -0.0074,  ...,  0.0067,  0.0099, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0001,  0.0005,  ..., -0.0020, -0.0026, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0061, -0.0062,  ...,  0.0054, -0.0007, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.7129e-03,  4.5561e-04,  6.4880e-05,  ...,  1.0044e-02,\n",
      "          9.7454e-03,  1.1050e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039, -0.0104,  0.0033,  ..., -0.0124,  0.0023,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0090, -0.0026,  ..., -0.0012, -0.0015,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074, -0.0038, -0.0002,  ...,  0.0079,  0.0086, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037,  0.0041, -0.0046,  ...,  0.0065,  0.0040, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0104,  0.0008, -0.0037,  ..., -0.0008,  0.0052,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0104, -0.0045,  0.0155,  ..., -0.0051, -0.0041,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0023, -0.0031,  ..., -0.0009,  0.0033,  0.0080]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0023, -0.0135,  ...,  0.0054,  0.0028,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0037, -0.0042,  ..., -0.0091,  0.0093, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0045,  0.0026,  ..., -0.0072,  0.0054,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0106, -0.0022,  ...,  0.0113,  0.0054,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0087,  0.0103,  0.0065,  ...,  0.0109,  0.0117, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0104,  0.0045,  ..., -0.0056,  0.0003,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0110,  0.0073,  ...,  0.0004,  0.0044,  0.0142]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0109, -0.0040,  ...,  0.0100,  0.0028, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0048,  0.0067,  ...,  0.0143,  0.0118, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089, -0.0092, -0.0053,  ..., -0.0041,  0.0040,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0123,  0.0015,  ...,  0.0066,  0.0040,  0.0119]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0129, 0.0007, 0.0007,  ..., 0.0036, 0.0042, 0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0015, -0.0001,  ..., -0.0031, -0.0024, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0142,  0.0155, -0.0117,  ..., -0.0042,  0.0039,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0087,  0.0064,  ...,  0.0091,  0.0076,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0097,  0.0035,  ...,  0.0044,  0.0028, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0173,  0.0068,  ...,  0.0062,  0.0064,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0020,  0.0017,  0.0039,  ..., -0.0012,  0.0018,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075, -0.0025, -0.0047,  ..., -0.0033,  0.0025,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061,  0.0152, -0.0071,  ...,  0.0132,  0.0076,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0103,  0.0031,  ...,  0.0018,  0.0057,  0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0097,  0.0038, -0.0048,  ...,  0.0046,  0.0019, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.7048e-03,  4.9618e-03,  1.6738e-03,  ...,  5.2377e-03,\n",
      "         -4.3748e-05, -6.6943e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.2600e-03, -1.0571e-02, -2.5296e-03,  ..., -1.8623e-03,\n",
      "         -5.8696e-05,  4.5272e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0107,  0.0065,  ..., -0.0056,  0.0002,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.4093e-04, -1.5088e-03,  3.9800e-05,  ..., -9.3081e-03,\n",
      "          6.5731e-04,  1.3388e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074,  0.0176,  0.0029,  ...,  0.0120,  0.0086,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0027, -0.0066,  ...,  0.0064,  0.0087, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0059, -0.0015,  ...,  0.0027,  0.0066,  0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0162,  0.0020,  ...,  0.0117,  0.0008, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040,  0.0003,  0.0074,  ...,  0.0014,  0.0008, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.2672e-03,  1.4206e-02,  3.2686e-03,  ...,  2.6845e-03,\n",
      "         -8.5982e-05,  7.9250e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058, -0.0043, -0.0006,  ...,  0.0088,  0.0067, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0054,  0.0052,  ..., -0.0039,  0.0161,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0100,  0.0056,  ...,  0.0005,  0.0019, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0002,  0.0024,  ...,  0.0038,  0.0117, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0033, -0.0051,  ...,  0.0022,  0.0060, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.4467e-03, -5.3350e-05,  6.9197e-03,  ...,  4.5063e-03,\n",
      "          4.4202e-03,  3.4289e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054, -0.0095, -0.0021,  ...,  0.0152,  0.0024, -0.0100]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0146, -0.0064,  ...,  0.0110,  0.0052, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0050,  0.0016,  ..., -0.0027,  0.0079,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0007,  0.0036,  ...,  0.0049,  0.0045,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0064, -0.0066,  ...,  0.0101,  0.0028, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0076,  0.0016, -0.0020,  ...,  0.0036,  0.0075, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0083,  0.0052,  0.0020,  ...,  0.0103,  0.0061, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.0142e-03, -5.7896e-03,  1.0550e-02,  ..., -1.3619e-03,\n",
      "         -2.4809e-03, -5.3632e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0056, -0.0018,  ...,  0.0082,  0.0061, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0040,  0.0141,  ...,  0.0063,  0.0040, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0108, -0.0039,  ...,  0.0089,  0.0026, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0033, -0.0042,  ...,  0.0041,  0.0058, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0048,  0.0070,  ...,  0.0112,  0.0064,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0007, -0.0052,  ...,  0.0047,  0.0085,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0017, -0.0134, -0.0019,  ..., -0.0053,  0.0070,  0.0092]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0052, 0.0078, 0.0028,  ..., 0.0079, 0.0021, 0.0084]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0038,  0.0002,  ...,  0.0092,  0.0067,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0027,  0.0003,  ...,  0.0093,  0.0039,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0045, -0.0032,  ...,  0.0101,  0.0009, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0044, 0.0046, 0.0007,  ..., 0.0100, 0.0066, 0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.6193e-05,  2.8974e-03,  1.8988e-03,  ...,  1.1224e-02,\n",
      "          3.6717e-03, -4.4488e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0114,  0.0015,  ...,  0.0019, -0.0029, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0092, -0.0041,  ...,  0.0052,  0.0005,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0067, -0.0029,  ...,  0.0069,  0.0040, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0003, -0.0046,  ...,  0.0039,  0.0064, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0034,  0.0034,  ...,  0.0051,  0.0016, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0108, -0.0064,  ..., -0.0032,  0.0029, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0104,  0.0061,  ...,  0.0098,  0.0073, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0128,  0.0030,  ...,  0.0057,  0.0009, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0037,  0.0003,  ..., -0.0088,  0.0089,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0072,  0.0060,  ...,  0.0032,  0.0040,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075, -0.0068, -0.0006,  ...,  0.0061,  0.0063,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0080,  0.0040,  ..., -0.0006, -0.0039,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.0519e-03,  1.8123e-03,  2.9371e-05,  ..., -3.6789e-03,\n",
      "          8.0142e-03,  8.8845e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0025, -0.0031,  ..., -0.0063,  0.0011, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0062,  0.0008,  ...,  0.0079, -0.0036, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0003,  0.0048,  ...,  0.0202,  0.0095,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0019,  0.0025,  ..., -0.0027,  0.0080, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0068, -0.0010,  ...,  0.0100,  0.0047, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.6361e-04, -9.9137e-03, -2.7811e-04,  ...,  4.9400e-05,\n",
      "          1.3643e-03,  7.2359e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0030,  0.0008,  ...,  0.0073, -0.0011,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0121,  0.0001,  ...,  0.0125,  0.0055, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030,  0.0151, -0.0048,  ...,  0.0099,  0.0071, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.7490e-05, -4.4100e-03, -1.5127e-03,  ..., -1.4992e-02,\n",
      "          6.6288e-04,  4.1873e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0053,  0.0067,  ...,  0.0012,  0.0098, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0205, -0.0011,  ...,  0.0085,  0.0068, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0025,  0.0033,  ...,  0.0042,  0.0027,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0027,  0.0035,  ...,  0.0149,  0.0009, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0095, -0.0069,  0.0008,  ..., -0.0047,  0.0084,  0.0234]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0025,  0.0202,  0.0025,  ...,  0.0028,  0.0080, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0008, -0.0039,  ...,  0.0072,  0.0070, -0.0102]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0128, -0.0018,  ..., -0.0046,  0.0048,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0036, -0.0033,  ...,  0.0023, -0.0028,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0043, -0.0066,  ...,  0.0015,  0.0081, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0068,  0.0021,  ..., -0.0015,  0.0093, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.6517e-05,  1.3272e-02,  4.2241e-03,  ...,  4.0591e-03,\n",
      "          1.8052e-03,  8.1837e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0076, -0.0079,  ...,  0.0070,  0.0043, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0188, -0.0003,  ...,  0.0004,  0.0133, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0020, -0.0014,  ..., -0.0054,  0.0086, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0092, -0.0004,  0.0111,  ...,  0.0123,  0.0052, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0079,  0.0002, -0.0070,  ...,  0.0040,  0.0054,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0022, -0.0056,  ...,  0.0087,  0.0056, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0088, -0.0079,  ...,  0.0014,  0.0114, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0085, -0.0006,  ...,  0.0080,  0.0022, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0125,  0.0066,  ..., -0.0021, -0.0024,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074, -0.0132, -0.0025,  ..., -0.0010, -0.0007,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0008, -0.0041,  ...,  0.0097,  0.0048,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0041, -0.0014,  ...,  0.0108,  0.0027, -0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0006, -0.0002,  ...,  0.0103,  0.0081,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045,  0.0182, -0.0016,  ...,  0.0087,  0.0024,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0086,  0.0035, -0.0008,  ...,  0.0181,  0.0067,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.7334e-03, -8.9705e-04,  5.2121e-05,  ...,  1.8669e-02,\n",
      "          9.3673e-03, -7.9702e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069,  0.0027, -0.0031,  ...,  0.0137,  0.0035, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0152,  0.0055, -0.0022,  ...,  0.0004,  0.0056, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0041,  0.0003,  ...,  0.0123,  0.0079,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0098,  0.0059, -0.0021,  ...,  0.0099,  0.0052,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0079, -0.0019,  ...,  0.0085,  0.0083,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0085, -0.0078,  ...,  0.0044,  0.0011, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029,  0.0022, -0.0036,  ...,  0.0054,  0.0158, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0033, -0.0056,  ...,  0.0196,  0.0086, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0103,  0.0015,  ..., -0.0064,  0.0015,  0.0120]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045,  0.0063, -0.0080,  ...,  0.0043,  0.0026,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0082, -0.0110,  0.0031,  ...,  0.0024,  0.0050, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049,  0.0053,  0.0031,  ...,  0.0075, -0.0019, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0022,  0.0022, -0.0040,  ...,  0.0162,  0.0040, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0007,  0.0043,  ...,  0.0021, -0.0031, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0105, -0.0026,  ...,  0.0133,  0.0056, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065, -0.0134,  0.0076,  ...,  0.0022,  0.0058,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0089, -0.0002,  ...,  0.0178,  0.0013, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0058, -0.0020,  ..., -0.0013,  0.0096, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0045, -0.0005,  ...,  0.0029,  0.0052,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0082, -0.0010,  ...,  0.0106,  0.0083,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.4215e-03, -7.2030e-05,  2.6637e-03,  ...,  9.9474e-03,\n",
      "          1.6468e-02, -2.0942e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0091,  0.0009,  ...,  0.0092,  0.0045,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0063, -0.0037,  ...,  0.0055,  0.0080,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0153, -0.0052,  ...,  0.0067,  0.0023, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0040, -0.0056,  ...,  0.0123,  0.0067,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0036,  0.0014,  ...,  0.0009,  0.0103,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0095,  0.0006,  ...,  0.0050,  0.0015,  0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0065, -0.0026,  ...,  0.0055,  0.0031,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.9415e-03,  1.2741e-05,  6.3690e-04,  ..., -1.1200e-02,\n",
      "          6.9061e-03,  2.5795e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0056, -0.0022,  ...,  0.0036,  0.0063,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058, -0.0070,  0.0032,  ...,  0.0082,  0.0099,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069, -0.0004, -0.0006,  ...,  0.0076,  0.0047,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0055, -0.0009,  ...,  0.0080,  0.0007, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0092, -0.0113,  0.0023,  ...,  0.0018,  0.0045, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0038,  0.0052,  ...,  0.0192,  0.0026, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0103, -0.0006,  ...,  0.0106,  0.0053,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067,  0.0029, -0.0012,  ..., -0.0005,  0.0038,  0.0120]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.5766e-03,  4.3354e-05,  9.0493e-04,  ...,  7.1307e-03,\n",
      "          1.0463e-02, -2.6233e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0130,  0.0126,  ..., -0.0041,  0.0058, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0108,  0.0055,  ...,  0.0011, -0.0029, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045,  0.0118, -0.0044,  ..., -0.0027, -0.0019,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0086, -0.0059,  ..., -0.0096,  0.0026,  0.0126]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0081,  0.0064,  ...,  0.0191,  0.0028, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061, -0.0048,  0.0015,  ..., -0.0057,  0.0055,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0040, -0.0029,  ...,  0.0057,  0.0035, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054, -0.0020, -0.0025,  ...,  0.0130,  0.0043, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045, -0.0048, -0.0042,  ...,  0.0017,  0.0037,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0011, -0.0071,  0.0040,  ..., -0.0019,  0.0087, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0095, -0.0040,  ...,  0.0162,  0.0067, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0102,  0.0018,  ..., -0.0077,  0.0120,  0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0072, -0.0021,  ...,  0.0003, -0.0065,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0029, -0.0033,  ..., -0.0020, -0.0052,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0058, -0.0022,  ..., -0.0027,  0.0119,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.7689e-03, -1.6465e-03, -2.8250e-03,  ...,  5.6259e-05,\n",
      "          3.2924e-03,  7.2942e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0122, 0.0045, 0.0054,  ..., 0.0084, 0.0111, 0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0069,  0.0041,  ...,  0.0099,  0.0005, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088,  0.0042, -0.0084,  ...,  0.0178,  0.0100,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0081,  0.0048,  ..., -0.0003,  0.0064, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0042, -0.0054,  ...,  0.0064,  0.0034,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0061, -0.0018,  ..., -0.0106,  0.0010,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073,  0.0058,  0.0001,  ...,  0.0079,  0.0018, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0115,  0.0082,  ..., -0.0091,  0.0007,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0028, -0.0018,  ...,  0.0097,  0.0054,  0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0017, -0.0014,  ...,  0.0106,  0.0071, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001,  0.0043, -0.0033,  ...,  0.0075,  0.0064,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0198, -0.0031,  ...,  0.0085,  0.0045, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061, -0.0013, -0.0032,  ..., -0.0025,  0.0028,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0102, -0.0007,  0.0004,  ...,  0.0161,  0.0025,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0013, -0.0024,  ...,  0.0038, -0.0020, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0030, -0.0042,  ...,  0.0120, -0.0009, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0182, -0.0055,  ..., -0.0042,  0.0087, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0116, -0.0022,  ...,  0.0055,  0.0034, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0046, -0.0021,  ...,  0.0138,  0.0051, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0038, -0.0035,  ...,  0.0072,  0.0062,  0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0128, -0.0091,  ...,  0.0069,  0.0051, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063,  0.0093, -0.0023,  ...,  0.0100, -0.0011, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0004, -0.0022,  ..., -0.0034,  0.0061,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0067, -0.0027,  ...,  0.0101,  0.0054,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0004, -0.0003,  ...,  0.0107,  0.0043,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0083, 0.0048, 0.0169,  ..., 0.0065, 0.0003, 0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0051,  0.0028,  ...,  0.0072, -0.0029, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0134, -0.0035,  ...,  0.0054,  0.0093,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0048,  0.0094, -0.0012,  ...,  0.0143,  0.0030, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061,  0.0112, -0.0034,  ..., -0.0023,  0.0059,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0054,  0.0020,  ...,  0.0012,  0.0035,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0196, -0.0011,  ...,  0.0140,  0.0079, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0036,  0.0032,  ...,  0.0080,  0.0038,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028,  0.0051,  0.0088,  ...,  0.0082,  0.0037, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0088,  0.0036,  ..., -0.0032,  0.0018,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0087,  0.0068,  ...,  0.0093, -0.0023, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053, -0.0015,  0.0044,  ...,  0.0007,  0.0056,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0080,  0.0046,  ..., -0.0057,  0.0002,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0028, -0.0024,  ...,  0.0049,  0.0029, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0004, -0.0021,  ...,  0.0053,  0.0039, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0096,  0.0103, -0.0040,  ...,  0.0091,  0.0069,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0214, -0.0019,  ...,  0.0129,  0.0036,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0101,  0.0009,  ...,  0.0072,  0.0034, -0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0054, -0.0008,  ...,  0.0041,  0.0064, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0042, -0.0012,  ...,  0.0071,  0.0084,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0045,  0.0007,  ...,  0.0133,  0.0020, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0002,  0.0032,  ..., -0.0143,  0.0023,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0066, -0.0043,  ...,  0.0131,  0.0076, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0128, -0.0007,  ..., -0.0039, -0.0020,  0.0115]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0125,  0.0010,  ...,  0.0141,  0.0041, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0095, -0.0035,  ...,  0.0017,  0.0015, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0040,  0.0015,  ...,  0.0123, -0.0002, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0108, -0.0017,  ...,  0.0054,  0.0010, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0060,  0.0012,  ...,  0.0086,  0.0030,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0098, -0.0010,  ...,  0.0074,  0.0040,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0077,  0.0036, -0.0059,  ...,  0.0005,  0.0035,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0009,  0.0003,  ...,  0.0128,  0.0054, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0017, -0.0026,  ...,  0.0108,  0.0056,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0030, -0.0031,  ...,  0.0170,  0.0075, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[6.0450e-03, 1.6446e-03, 8.6119e-05,  ..., 6.7460e-03, 3.6224e-03,\n",
      "         2.0520e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0024,  0.0019,  ...,  0.0118,  0.0054,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0037,  0.0092,  ..., -0.0030, -0.0015,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0184, -0.0043,  ...,  0.0094,  0.0022, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0086, -0.0005, -0.0038,  ..., -0.0008,  0.0091,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0013,  0.0004,  ...,  0.0078,  0.0043,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0168,  0.0032,  ..., -0.0049,  0.0007,  0.0097]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0025,  0.0046,  ..., -0.0050, -0.0011,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0069,  0.0032,  ...,  0.0085,  0.0015, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0052, -0.0016,  ...,  0.0030,  0.0003,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0017,  0.0013,  ..., -0.0053,  0.0039,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0019,  0.0010,  ...,  0.0025, -0.0025,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0002,  0.0034,  ...,  0.0018,  0.0060,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085,  0.0149, -0.0033,  ..., -0.0007,  0.0036,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0100,  0.0083,  ...,  0.0045,  0.0011, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0087, -0.0011,  ..., -0.0028, -0.0008,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.9399e-03, -8.2000e-03, -3.7742e-05,  ..., -1.3382e-02,\n",
      "         -2.5141e-03,  2.4333e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0017, -0.0024,  ...,  0.0026,  0.0063,  0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0003,  0.0026,  ...,  0.0126,  0.0077, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0011, -0.0016,  ...,  0.0069,  0.0071,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0012, -0.0058,  ...,  0.0058, -0.0007,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0006,  0.0027,  ...,  0.0168,  0.0092, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080,  0.0100, -0.0037,  ...,  0.0025, -0.0005,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.5171e-04, -4.4820e-03,  3.8088e-03,  ...,  1.2546e-02,\n",
      "          1.7380e-02, -9.5481e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0039,  0.0068,  ...,  0.0160,  0.0068,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0061, -0.0029,  ...,  0.0049,  0.0045,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0104,  0.0038,  ...,  0.0064,  0.0100, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0098,  0.0060,  ...,  0.0003,  0.0021,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0022, -0.0028,  ...,  0.0040,  0.0023,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0068,  0.0027,  ...,  0.0059,  0.0096,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069, -0.0171, -0.0012,  ...,  0.0048,  0.0179, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0125, 0.0008, 0.0015,  ..., 0.0029, 0.0034, 0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0084,  0.0052,  0.0034,  ..., -0.0034,  0.0058,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.9567e-03,  5.3942e-03, -6.9983e-05,  ...,  1.0779e-03,\n",
      "          4.4027e-03, -2.3570e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0020, -0.0031,  ...,  0.0078,  0.0057, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0023, -0.0023,  ...,  0.0083,  0.0076, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0003, -0.0023,  ...,  0.0080,  0.0112,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0035, -0.0040,  ...,  0.0122,  0.0047, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0015,  0.0025,  ...,  0.0151, -0.0004, -0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0103,  0.0058, -0.0036,  ...,  0.0074, -0.0039,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0018, -0.0036,  ..., -0.0015,  0.0033, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0030,  0.0030,  ..., -0.0056, -0.0062,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0034,  0.0048,  ...,  0.0122,  0.0004, -0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0051,  0.0042,  ...,  0.0107,  0.0044, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050, -0.0050, -0.0044,  ...,  0.0206,  0.0018,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0097, -0.0037,  ...,  0.0140,  0.0073, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053, -0.0013,  0.0078,  ...,  0.0125,  0.0088,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0128,  0.0052,  ...,  0.0177,  0.0017, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0105,  0.0002,  ...,  0.0100,  0.0024, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0152, -0.0020,  ...,  0.0198,  0.0062,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0068, -0.0055,  ...,  0.0005,  0.0030, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0021,  0.0008,  ..., -0.0012,  0.0014, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.0404e-03,  1.9041e-03, -5.8952e-05,  ..., -5.7848e-03,\n",
      "          1.1223e-02,  1.1857e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0001,  0.0017,  ..., -0.0021,  0.0024,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100,  0.0017,  0.0051,  ...,  0.0060,  0.0024, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0006,  0.0031,  ..., -0.0007, -0.0008, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0178, -0.0004,  ...,  0.0114,  0.0096, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0066, -0.0014,  ...,  0.0121,  0.0038,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0033,  0.0022,  ...,  0.0065,  0.0050,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0113,  0.0088,  ...,  0.0063,  0.0096, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0193, -0.0011,  ..., -0.0021,  0.0018,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0010, -0.0017,  ...,  0.0054, -0.0001, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0039,  0.0033,  ..., -0.0010,  0.0032,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0170, -0.0039,  ...,  0.0045,  0.0075,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0107, -0.0014,  ...,  0.0016,  0.0067, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.4644e-05,  4.1263e-03,  6.1581e-03,  ...,  1.4872e-02,\n",
      "          5.2934e-03,  1.7422e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0040, -0.0028,  ...,  0.0110,  0.0067, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.4204e-05,  1.5694e-02, -5.2861e-03,  ...,  1.0096e-02,\n",
      "          3.8358e-03, -4.0556e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0107,  0.0004,  0.0055,  ...,  0.0122,  0.0077, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0094,  0.0138,  ..., -0.0013,  0.0101, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0105, -0.0043,  ...,  0.0036, -0.0004, -0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053,  0.0108, -0.0020,  ...,  0.0109,  0.0036, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098,  0.0054,  0.0050,  ...,  0.0128,  0.0067, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0043, -0.0027,  ...,  0.0157,  0.0052, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0090, -0.0073,  0.0027,  ..., -0.0042,  0.0016,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0016, -0.0076,  ...,  0.0140,  0.0008, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0074, -0.0028,  ...,  0.0001,  0.0010,  0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0064,  0.0025,  ...,  0.0039,  0.0055,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0044,  0.0031,  ...,  0.0134,  0.0036,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0005, -0.0044,  ...,  0.0073,  0.0076,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.8038e-04, -7.2553e-03, -2.3710e-03,  ..., -3.7794e-03,\n",
      "          6.1105e-03,  7.3829e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.4429e-04,  9.1612e-03,  7.2794e-05,  ..., -5.6650e-03,\n",
      "          9.8138e-03,  1.1906e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0032, 0.0129, 0.0036,  ..., 0.0081, 0.0109, 0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0035, -0.0090,  ...,  0.0188,  0.0058,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0015,  0.0039,  ...,  0.0082,  0.0071, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0109,  0.0003,  ...,  0.0080,  0.0045,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0041, 0.0050, 0.0002,  ..., 0.0058, 0.0071, 0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0075, -0.0099,  ..., -0.0037, -0.0003,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0048, -0.0067,  ...,  0.0015, -0.0013, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077, -0.0044,  0.0027,  ...,  0.0044,  0.0038, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0116,  0.0009,  ..., -0.0084,  0.0055,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0119,  0.0021,  ...,  0.0029,  0.0029,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0011, -0.0046,  ...,  0.0056,  0.0066,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0122, -0.0034,  ...,  0.0144,  0.0159,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045,  0.0097, -0.0043,  ...,  0.0114,  0.0031, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0091, -0.0095,  0.0013,  ...,  0.0017,  0.0066, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0010, -0.0057,  ...,  0.0022,  0.0054,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0013, 0.0086, 0.0005,  ..., 0.0058, 0.0058, 0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0013, -0.0018,  ..., -0.0022,  0.0087, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0102,  0.0020,  ..., -0.0002,  0.0053,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0072,  0.0022,  ...,  0.0092, -0.0006,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0016, -0.0003,  ...,  0.0050,  0.0046,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061, -0.0035, -0.0045,  ...,  0.0162,  0.0027, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073, -0.0097,  0.0046,  ..., -0.0046,  0.0050,  0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0076, -0.0020,  ...,  0.0176,  0.0063, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0076, -0.0095,  ...,  0.0086,  0.0077,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0129,  0.0044,  ..., -0.0032,  0.0050, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0013, -0.0002,  ...,  0.0067, -0.0011,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0038,  0.0064,  ...,  0.0121, -0.0002, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0101, -0.0046,  0.0072,  ..., -0.0082,  0.0067,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0082, -0.0033,  ...,  0.0138,  0.0043, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0079,  0.0030,  ...,  0.0031,  0.0051, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0087,  0.0011,  ..., -0.0010,  0.0026,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0070, -0.0033, -0.0019,  ...,  0.0081, -0.0015, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0020, -0.0051,  ...,  0.0056,  0.0047,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0035,  0.0043,  ...,  0.0024,  0.0064,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0070,  0.0085,  0.0030,  ...,  0.0155,  0.0036, -0.0100]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0067, -0.0017,  ..., -0.0010, -0.0008, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100, -0.0008, -0.0056,  ..., -0.0003, -0.0001,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0028, -0.0076,  ...,  0.0124, -0.0005, -0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0069,  0.0040,  ...,  0.0089,  0.0070, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.8841e-05, -8.9763e-03, -6.9695e-03,  ..., -8.2082e-03,\n",
      "          1.1996e-03,  4.2451e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0113, -0.0003,  ...,  0.0157,  0.0045, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0106, -0.0002,  ...,  0.0012,  0.0043,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0024,  0.0017,  ..., -0.0018,  0.0018,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0187, -0.0050,  ...,  0.0176,  0.0078, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0081, -0.0011,  ...,  0.0112,  0.0048,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0079,  0.0031,  0.0005,  ...,  0.0079, -0.0041, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0061, -0.0011,  ...,  0.0138,  0.0021, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0077,  0.0093, -0.0021,  ...,  0.0016,  0.0036, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075,  0.0062, -0.0032,  ...,  0.0048,  0.0090, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.7821e-03, -9.9295e-03,  3.8511e-05,  ...,  3.3906e-03,\n",
      "          2.3558e-03,  6.8496e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0026, -0.0032,  ...,  0.0102,  0.0047, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0052,  0.0074,  ...,  0.0052, -0.0018, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044,  0.0021,  0.0028,  ...,  0.0059,  0.0076, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0016,  0.0006,  ...,  0.0008, -0.0037,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0002, -0.0014,  ...,  0.0018,  0.0011, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100, -0.0063,  0.0053,  ...,  0.0065,  0.0034,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0033, -0.0040,  ..., -0.0022, -0.0026, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075, -0.0074,  0.0052,  ...,  0.0033,  0.0046,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0074, -0.0047,  ...,  0.0124,  0.0040, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060,  0.0017,  0.0054,  ...,  0.0028,  0.0091,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064, -0.0045,  0.0070,  ..., -0.0003,  0.0026,  0.0128]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0004, -0.0061,  ...,  0.0134,  0.0126,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0037, -0.0074,  0.0070,  ...,  0.0055,  0.0009, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0112,  0.0066,  ..., -0.0024,  0.0101,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0045,  0.0020,  ...,  0.0103,  0.0038,  0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0130,  0.0032,  ...,  0.0195,  0.0074,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0166,  0.0024,  ..., -0.0043,  0.0036,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0032, -0.0057,  ...,  0.0049,  0.0036, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0013, -0.0008,  ...,  0.0005,  0.0121, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0088,  0.0017,  ...,  0.0097,  0.0009, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0057, -0.0081,  ...,  0.0095, -0.0003,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0055, -0.0047,  ...,  0.0084,  0.0104, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0010,  0.0010,  ...,  0.0108,  0.0025, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0042,  0.0069,  ...,  0.0121,  0.0063,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0029, -0.0045,  ...,  0.0141,  0.0084,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0039,  0.0044,  ..., -0.0009, -0.0032,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0057,  0.0054,  ...,  0.0086,  0.0052,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0148, -0.0034,  ...,  0.0041,  0.0132,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0083,  0.0005, -0.0038,  ..., -0.0038,  0.0088, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0156,  0.0014,  ...,  0.0007,  0.0063,  0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0062,  0.0006,  ...,  0.0016,  0.0072,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0132,  0.0025,  ...,  0.0040,  0.0057,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0006, 0.0109, 0.0015,  ..., 0.0055, 0.0074, 0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0003, -0.0036,  ...,  0.0078,  0.0021,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0020, -0.0074,  ..., -0.0087,  0.0049,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0029, 0.0136, 0.0088,  ..., 0.0081, 0.0061, 0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0010, -0.0010,  ...,  0.0018, -0.0005, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0046, 0.0049, 0.0036,  ..., 0.0050, 0.0091, 0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073,  0.0066, -0.0081,  ...,  0.0112,  0.0021,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0031, -0.0035,  ...,  0.0156,  0.0002, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0165,  0.0012,  ...,  0.0067,  0.0079,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0062, -0.0006,  ...,  0.0045,  0.0088, -0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0082,  0.0020,  ...,  0.0025,  0.0011, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0198, -0.0050,  ...,  0.0003, -0.0021,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0058,  0.0008,  ..., -0.0030, -0.0003, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0036, -0.0060,  ...,  0.0059, -0.0008, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075, -0.0096,  0.0076,  ...,  0.0083,  0.0063,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0010,  0.0107, -0.0023,  ...,  0.0122,  0.0088,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0074,  0.0099,  ..., -0.0004, -0.0016, -0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064,  0.0091, -0.0063,  ...,  0.0173,  0.0013, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0121, -0.0018,  ..., -0.0038,  0.0020,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.4114e-03,  1.5547e-02, -5.7600e-05,  ..., -3.4990e-03,\n",
      "          1.4517e-02,  7.9123e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0058,  0.0033,  ..., -0.0036, -0.0006,  0.0111]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0174, -0.0078,  ...,  0.0062,  0.0085, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087,  0.0222, -0.0072,  ..., -0.0027, -0.0052,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0052,  0.0025,  ...,  0.0146,  0.0052, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0247,  0.0024,  ..., -0.0033, -0.0051, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069,  0.0107, -0.0021,  ...,  0.0131,  0.0117,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.8902e-03,  9.5983e-03, -5.7884e-03,  ...,  1.1742e-02,\n",
      "          7.7910e-03, -5.1178e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.5035e-05, -8.3679e-03, -6.3767e-04,  ..., -3.4982e-04,\n",
      "          3.2843e-03, -2.2711e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0130,  0.0029,  0.0012,  ...,  0.0163,  0.0073, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0127,  0.0063,  ..., -0.0026,  0.0080, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049,  0.0089, -0.0043,  ..., -0.0008,  0.0068, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0008, -0.0043,  ..., -0.0043,  0.0107, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0063,  0.0007,  ...,  0.0070, -0.0027, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0020,  0.0020,  ...,  0.0029,  0.0018, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0043,  0.0016,  ...,  0.0074,  0.0050,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0105, -0.0015,  ..., -0.0015,  0.0025,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0121, -0.0015,  ...,  0.0092,  0.0066,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0095,  0.0042,  ...,  0.0150, -0.0012,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063,  0.0040,  0.0013,  ...,  0.0061, -0.0006,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0091,  0.0031, -0.0028,  ...,  0.0044,  0.0066, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0107,  0.0042, -0.0006,  ..., -0.0101,  0.0085, -0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0044, 0.0147, 0.0051,  ..., 0.0031, 0.0009, 0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075,  0.0001,  0.0014,  ...,  0.0099,  0.0051, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0093,  0.0018,  ...,  0.0006,  0.0090, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0069, -0.0064,  ...,  0.0078,  0.0155,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0068,  0.0005,  ..., -0.0032,  0.0031,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0064, -0.0100,  ...,  0.0091,  0.0008,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.6584e-03,  1.5234e-05, -6.4669e-03,  ...,  1.0725e-02,\n",
      "          4.6536e-03, -4.9881e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0053,  0.0089,  ...,  0.0083,  0.0075,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0042,  0.0003,  ...,  0.0092, -0.0015,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0080, -0.0060, -0.0006,  ..., -0.0038,  0.0015,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0098, -0.0026,  ..., -0.0027,  0.0012, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0039, -0.0005,  ...,  0.0043, -0.0032, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0053, -0.0012,  ...,  0.0132,  0.0079, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0011, -0.0002,  ...,  0.0087,  0.0017, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0071,  0.0020,  ..., -0.0131,  0.0007, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0068, -0.0098,  0.0031,  ...,  0.0034,  0.0103, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0104,  0.0138, -0.0007,  ...,  0.0078,  0.0055, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0074,  0.0021,  ...,  0.0056, -0.0003,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0035, -0.0030,  ..., -0.0001,  0.0004,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0040, 0.0095, 0.0072,  ..., 0.0041, 0.0064, 0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0029, 0.0046, 0.0047,  ..., 0.0076, 0.0030, 0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0032, -0.0035,  ...,  0.0091,  0.0114, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080, -0.0047,  0.0028,  ...,  0.0070,  0.0034,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0096,  0.0197, -0.0044,  ...,  0.0090,  0.0087,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.9494e-03,  7.9253e-03, -8.9294e-05,  ...,  1.1030e-02,\n",
      "          6.3919e-03, -6.5415e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0004,  0.0042,  ...,  0.0012,  0.0064, -0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0091, -0.0021,  ...,  0.0065,  0.0046, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0113, -0.0006,  ...,  0.0023, -0.0054, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0027, -0.0008,  ...,  0.0082,  0.0020, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0049, -0.0019,  ...,  0.0021,  0.0038, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0084, -0.0053,  ...,  0.0222,  0.0051, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0019,  0.0040,  ...,  0.0047, -0.0002,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0047, -0.0042,  ...,  0.0050,  0.0054, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0024,  0.0016,  ...,  0.0129,  0.0005, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0102,  0.0037,  ...,  0.0077,  0.0051,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0142, -0.0022,  ...,  0.0095,  0.0088, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0063, -0.0032,  ...,  0.0003,  0.0128,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001, -0.0056, -0.0036,  ...,  0.0006,  0.0068, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0083,  0.0014,  ..., -0.0024,  0.0072,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075, -0.0056,  0.0024,  ...,  0.0194,  0.0041, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0103,  0.0031,  ...,  0.0074,  0.0032,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0029,  0.0001,  ...,  0.0144,  0.0017, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0006, -0.0047,  ..., -0.0100, -0.0030,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0097, -0.0038,  ..., -0.0031,  0.0025,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0103,  0.0018,  0.0003,  ..., -0.0033,  0.0027, -0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0065, -0.0049,  ...,  0.0093,  0.0011,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0009, -0.0030,  ...,  0.0015,  0.0012,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.2576e-02,  1.2915e-02, -1.7741e-03,  ..., -7.8408e-03,\n",
      "         -5.7361e-03,  3.8200e-06]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0136,  0.0121,  ..., -0.0064,  0.0004,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0012, -0.0043,  ...,  0.0086,  0.0087,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0204, -0.0069,  ...,  0.0130,  0.0073,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0052, 0.0237, 0.0021,  ..., 0.0167, 0.0086, 0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0031, -0.0066,  ...,  0.0144,  0.0102, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.4180e-03,  3.3031e-03, -1.9717e-03,  ...,  1.0310e-03,\n",
      "          6.5450e-05,  2.2181e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0106,  0.0053,  ..., -0.0103,  0.0105,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0112, -0.0017, -0.0010,  ..., -0.0085,  0.0014, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0021, -0.0081,  ...,  0.0144,  0.0043, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0135,  0.0026,  ...,  0.0028,  0.0001, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0062, -0.0047,  ...,  0.0106,  0.0071,  0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0026,  0.0027,  ...,  0.0095,  0.0060, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069, -0.0122,  0.0051,  ..., -0.0020,  0.0096, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0030, -0.0005,  ...,  0.0133,  0.0023,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0169, -0.0012,  ..., -0.0011,  0.0023, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0101, -0.0018,  ...,  0.0042,  0.0073,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0077,  0.0032, -0.0025,  ..., -0.0020, -0.0048,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0056,  0.0004,  ...,  0.0104, -0.0008, -0.0110]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074, -0.0030,  0.0040,  ...,  0.0124,  0.0054, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0086,  0.0052,  0.0026,  ..., -0.0017,  0.0051,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0085,  0.0117, -0.0018,  ...,  0.0091,  0.0104, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.4894e-03,  8.2179e-03,  6.0815e-03,  ...,  9.7397e-03,\n",
      "          4.7746e-03, -1.9784e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0004, 0.0218, 0.0003,  ..., 0.0113, 0.0088, 0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0064, -0.0048,  ...,  0.0054,  0.0060, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0042,  0.0016,  ...,  0.0026,  0.0052, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0019, -0.0034,  ...,  0.0058,  0.0027, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023,  0.0078, -0.0025,  ...,  0.0207,  0.0024, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0013,  0.0015,  ...,  0.0088,  0.0048, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.0402e-04, -3.2056e-03,  2.9292e-05,  ...,  4.7925e-03,\n",
      "          4.7742e-03,  1.6817e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.3531e-03, -8.9570e-03,  8.9685e-03,  ..., -3.5815e-03,\n",
      "          1.7758e-03, -3.1641e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0017, -0.0012,  ...,  0.0077,  0.0008,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0039, -0.0065, -0.0020,  ...,  0.0028,  0.0054,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049, -0.0080,  0.0006,  ...,  0.0092,  0.0023, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0038,  0.0099,  ...,  0.0072, -0.0023,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0071, -0.0012,  0.0016,  ...,  0.0062, -0.0046,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0124,  0.0015,  ...,  0.0159,  0.0023, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0050, -0.0008,  ...,  0.0071,  0.0057,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0066, -0.0016,  ...,  0.0109,  0.0104, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0120,  0.0085,  ..., -0.0018,  0.0041,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0078,  0.0006,  ..., -0.0107, -0.0038,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.2019e-03,  9.3463e-03, -3.0137e-03,  ..., -1.8034e-03,\n",
      "         -2.0664e-03,  9.1993e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069, -0.0004,  0.0026,  ..., -0.0031, -0.0045, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0082, -0.0059,  ..., -0.0016,  0.0095,  0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073,  0.0009,  0.0009,  ...,  0.0031, -0.0037,  0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0059,  0.0035,  ..., -0.0024,  0.0076,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078,  0.0152, -0.0071,  ...,  0.0096,  0.0065, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0031, -0.0013,  ...,  0.0085, -0.0028, -0.0120]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0076, 0.0057, 0.0027,  ..., 0.0028, 0.0089, 0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061,  0.0042, -0.0016,  ...,  0.0034,  0.0096,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061, -0.0053, -0.0111,  ...,  0.0087,  0.0162,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0030,  0.0028,  ...,  0.0150,  0.0064, -0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.4216e-03, -1.6067e-03,  3.7166e-04,  ..., -9.6195e-05,\n",
      "          6.3506e-03,  3.4731e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0094, -0.0016,  ...,  0.0004,  0.0061,  0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084, -0.0073,  0.0051,  ..., -0.0021,  0.0027,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0116, -0.0016,  ..., -0.0012,  0.0063,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0016, -0.0045,  ...,  0.0084,  0.0046, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.0386e-03, -2.2709e-03, -4.9557e-04,  ..., -9.5124e-05,\n",
      "         -7.6369e-04,  1.0721e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050, -0.0064,  0.0045,  ..., -0.0018,  0.0049,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0173, -0.0037,  ..., -0.0071,  0.0097,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0091,  0.0047,  0.0024,  ...,  0.0106,  0.0042, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0141, -0.0005,  ...,  0.0125,  0.0084,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0126, -0.0038,  ...,  0.0059,  0.0101,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0978e-03,  4.7164e-05,  3.6120e-03,  ...,  5.8165e-03,\n",
      "          1.0958e-02, -2.0423e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0098,  0.0025,  ...,  0.0077,  0.0044, -0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0122, -0.0159, -0.0024,  ..., -0.0077, -0.0005,  0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.6685e-03, -6.1544e-03,  9.1941e-03,  ..., -8.8061e-05,\n",
      "          2.9791e-03,  5.3087e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0091, -0.0054, -0.0005,  ...,  0.0040,  0.0060, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0085,  0.0094,  ...,  0.0081, -0.0029, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0019, -0.0012,  ...,  0.0065,  0.0049,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0039,  0.0024,  ...,  0.0033,  0.0017,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0056,  0.0031,  0.0046,  ...,  0.0137,  0.0055, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0226, -0.0051,  ...,  0.0020,  0.0070,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0052,  0.0010,  ...,  0.0106,  0.0044, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0019, 0.0044, 0.0002,  ..., 0.0054, 0.0070, 0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094,  0.0182,  0.0037,  ...,  0.0139,  0.0078, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0026,  0.0026,  ...,  0.0126,  0.0041, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0031, -0.0024,  ...,  0.0108,  0.0066, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0120,  0.0118,  0.0052,  ...,  0.0132,  0.0030, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052,  0.0004, -0.0006,  ...,  0.0080,  0.0054, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076,  0.0038,  0.0007,  ...,  0.0158,  0.0075, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064,  0.0220, -0.0090,  ...,  0.0049, -0.0009, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084,  0.0063, -0.0026,  ...,  0.0028, -0.0039, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0008,  0.0039,  ...,  0.0049,  0.0070,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0069, -0.0015,  ...,  0.0121,  0.0010, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0031, -0.0026,  ...,  0.0076,  0.0042, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0027,  0.0013,  ...,  0.0100,  0.0053, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0086, -0.0009, -0.0020,  ...,  0.0024,  0.0043, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.4712e-03,  4.5297e-03, -3.9895e-03,  ..., -6.5948e-03,\n",
      "          9.4678e-03,  8.7439e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0079, -0.0019,  ...,  0.0215,  0.0077, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.8653e-04,  6.5620e-03,  1.6291e-03,  ..., -9.2301e-04,\n",
      "          7.8399e-06, -1.9262e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0108,  0.0043,  ..., -0.0013,  0.0105,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0117,  0.0124,  ...,  0.0034,  0.0003,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0005, -0.0047,  ..., -0.0067,  0.0041, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065,  0.0007, -0.0054,  ...,  0.0060,  0.0082, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0081,  0.0062,  ...,  0.0087,  0.0035, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0016, -0.0003,  ..., -0.0050,  0.0006,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0060,  0.0050,  ...,  0.0091,  0.0014,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0043, -0.0011,  ...,  0.0051,  0.0061,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0125,  0.0078,  ...,  0.0063,  0.0036,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0150, 0.0037, 0.0043,  ..., 0.0016, 0.0048, 0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0091, -0.0027,  ...,  0.0005,  0.0063,  0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0039, -0.0071, -0.0021,  ..., -0.0126,  0.0032,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0090, -0.0043, -0.0025,  ...,  0.0073,  0.0067,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0030, -0.0063,  ...,  0.0036, -0.0013,  0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0126,  0.0092,  ...,  0.0014,  0.0038, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0098,  0.0045,  ...,  0.0128,  0.0024, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059,  0.0049, -0.0035,  ...,  0.0106,  0.0035, -0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041,  0.0069,  0.0014,  ...,  0.0113,  0.0067, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0137, -0.0009,  ...,  0.0069,  0.0061,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0068, -0.0003,  ..., -0.0070, -0.0071,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0026,  0.0015,  ...,  0.0057,  0.0049, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0030, -0.0041,  ..., -0.0025, -0.0010, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085,  0.0049,  0.0021,  ...,  0.0088, -0.0008, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0053, -0.0062,  ...,  0.0068,  0.0074,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0035,  0.0032,  ...,  0.0096,  0.0010, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0163,  0.0037,  ..., -0.0003,  0.0058, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0029,  0.0075,  ..., -0.0099,  0.0042,  0.0143]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064,  0.0110, -0.0073,  ...,  0.0006,  0.0068,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080, -0.0046,  0.0136,  ...,  0.0052, -0.0017,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0057, -0.0057,  ...,  0.0073,  0.0015,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0080, -0.0022,  ...,  0.0063,  0.0030, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0070, -0.0010, -0.0012,  ...,  0.0063,  0.0046,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0007,  0.0034,  ...,  0.0018,  0.0056,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.6348e-05, -2.4393e-03,  3.7198e-04,  ...,  1.0442e-02,\n",
      "          1.5706e-02,  1.9380e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0043, -0.0025,  ...,  0.0114,  0.0009,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080,  0.0207, -0.0062,  ...,  0.0128,  0.0067, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0091, -0.0002,  ...,  0.0156, -0.0029, -0.0085]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088, -0.0043,  0.0061,  ...,  0.0056,  0.0008,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.1097e-03, -5.8734e-03, -9.1177e-04,  ...,  1.0611e-02,\n",
      "         -8.6262e-05,  2.6304e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0102, -0.0006,  ..., -0.0032,  0.0020,  0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0026,  0.0003,  ...,  0.0104,  0.0064, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044,  0.0226, -0.0012,  ...,  0.0072,  0.0038,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0073,  0.0081,  ...,  0.0028,  0.0058,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0082, -0.0069,  ...,  0.0004,  0.0022, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0038, -0.0057,  ...,  0.0095,  0.0063,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0039,  0.0068,  ...,  0.0134,  0.0018, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0027, -0.0125,  0.0081,  ...,  0.0021,  0.0019,  0.0097]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0093,  0.0009, -0.0050,  ...,  0.0080,  0.0027, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0142, -0.0047,  ...,  0.0031,  0.0062,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0042,  0.0016,  ...,  0.0020,  0.0061, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0088, -0.0026, -0.0024,  ...,  0.0079,  0.0039,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0074,  0.0034,  ...,  0.0111, -0.0002, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0023, 0.0039, 0.0007,  ..., 0.0034, 0.0003, 0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0074,  0.0060,  ...,  0.0187,  0.0072, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049, -0.0029, -0.0042,  ...,  0.0090,  0.0099, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0125,  0.0047,  ..., -0.0016,  0.0043,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050, -0.0073, -0.0033,  ...,  0.0096,  0.0011, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049, -0.0100, -0.0071,  ...,  0.0029,  0.0031,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0038,  0.0030,  ...,  0.0078,  0.0071,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0045, -0.0011,  ...,  0.0081,  0.0020, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0105,  0.0004,  ...,  0.0139,  0.0083, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0033,  0.0045,  ...,  0.0001,  0.0008,  0.0139]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0257e-02, -4.1064e-03,  1.3961e-03,  ...,  1.6672e-03,\n",
      "          7.7002e-03, -6.7366e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0016, -0.0039,  ...,  0.0047,  0.0061, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0025,  0.0021,  ...,  0.0091,  0.0046, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0009, -0.0031,  ..., -0.0109,  0.0013,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0030,  0.0020,  ...,  0.0150,  0.0013, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0025,  0.0023,  ...,  0.0008,  0.0020, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0055,  0.0017,  ...,  0.0141,  0.0069, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087,  0.0029, -0.0033,  ...,  0.0100, -0.0038, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033, -0.0096,  0.0031,  ...,  0.0126,  0.0036, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0069,  0.0003,  ...,  0.0105,  0.0059, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084, -0.0057, -0.0019,  ...,  0.0093,  0.0024, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0104,  0.0156, -0.0013,  ...,  0.0019,  0.0009,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0074,  0.0047,  ..., -0.0066,  0.0051,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0065, -0.0013,  ...,  0.0054,  0.0074,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0113, -0.0008,  ...,  0.0115,  0.0016, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0109,  0.0126,  ..., -0.0007,  0.0019,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073,  0.0101, -0.0068,  ...,  0.0018,  0.0057,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0010, -0.0008,  ...,  0.0159,  0.0043, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0074, -0.0019,  ...,  0.0089,  0.0019,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0007,  0.0054,  0.0008,  ...,  0.0127,  0.0099,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0037, -0.0025,  ...,  0.0097,  0.0042,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0050, -0.0017,  ...,  0.0003,  0.0125, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0087,  0.0045,  ...,  0.0199,  0.0084, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0052, 0.0006, 0.0003,  ..., 0.0025, 0.0138, 0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0103, -0.0051,  ...,  0.0021,  0.0014,  0.0201]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0121, -0.0021,  ...,  0.0100, -0.0024, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0092,  0.0101,  ...,  0.0041,  0.0057,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0030, -0.0038,  ...,  0.0108,  0.0064, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0012,  0.0027,  ...,  0.0059, -0.0014, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0131,  0.0023,  ...,  0.0111,  0.0029, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0107, -0.0067,  ...,  0.0104,  0.0052,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054,  0.0080, -0.0039,  ...,  0.0046,  0.0112, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.4404e-03,  1.9705e-03, -1.4327e-06,  ...,  1.2456e-02,\n",
      "          8.6714e-03, -3.4992e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0090, -0.0101,  0.0068,  ..., -0.0008, -0.0019, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054, -0.0035, -0.0023,  ..., -0.0011,  0.0021,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062,  0.0101,  0.0018,  ...,  0.0156,  0.0026, -0.0108]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0063, -0.0006,  ...,  0.0070,  0.0067,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0067, -0.0013,  ..., -0.0002, -0.0031, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0095, -0.0021, -0.0004,  ...,  0.0145,  0.0042, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0199, -0.0030,  ..., -0.0107, -0.0010,  0.0114]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0072,  0.0087,  0.0030,  ...,  0.0183,  0.0015, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0111,  0.0031,  ...,  0.0011,  0.0034, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0055,  0.0027,  ...,  0.0181,  0.0017, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0086,  0.0021,  ...,  0.0166,  0.0066, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.1308e-03, -6.3617e-03, -7.8542e-03,  ...,  1.3451e-02,\n",
      "          8.8058e-05, -6.3442e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0030, -0.0038,  ..., -0.0047,  0.0120, -0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0098,  0.0018,  ..., -0.0070,  0.0037, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0102,  0.0093, -0.0011,  ...,  0.0029,  0.0012,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0075,  0.0032,  ..., -0.0032,  0.0027, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.5602e-03, -6.5005e-05,  7.0059e-03,  ...,  8.8080e-03,\n",
      "         -3.0316e-03, -5.3187e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0032, -0.0086,  ...,  0.0150,  0.0084, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0223, -0.0039,  ...,  0.0187,  0.0042, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0147, -0.0018,  ...,  0.0059,  0.0032,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0083,  0.0030,  ...,  0.0063,  0.0066,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0125, -0.0059, -0.0027,  ...,  0.0027,  0.0024,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0039, -0.0026,  ...,  0.0021,  0.0133,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.7269e-05,  5.2371e-04, -5.6329e-03,  ...,  9.3490e-03,\n",
      "          4.4240e-03, -5.8452e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0023,  0.0010,  ...,  0.0218,  0.0052,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0095,  0.0046,  ...,  0.0018,  0.0044,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045,  0.0044,  0.0137,  ...,  0.0120,  0.0010, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0044, -0.0016,  ..., -0.0077,  0.0043,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0009,  0.0016,  ...,  0.0097,  0.0028,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[8.4489e-03, 5.0930e-03, 3.7267e-05,  ..., 1.2290e-02, 6.8489e-04,\n",
      "         2.4555e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0166, -0.0026,  ...,  0.0184,  0.0083, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0068, -0.0037,  ...,  0.0151,  0.0063,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0054, -0.0055,  ..., -0.0135, -0.0012,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053,  0.0007,  0.0056,  ..., -0.0021, -0.0028, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0080,  0.0062,  ...,  0.0123,  0.0073, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0166, -0.0014,  ...,  0.0020,  0.0074,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0221, -0.0056,  ...,  0.0005,  0.0016,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0086, -0.0056, -0.0011,  ..., -0.0015,  0.0097,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0031,  0.0023,  ...,  0.0071,  0.0051,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0135, -0.0036,  ..., -0.0016,  0.0085, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0125, -0.0008,  ...,  0.0168,  0.0154, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0152, -0.0073,  ...,  0.0100,  0.0034,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0011, -0.0030,  ..., -0.0047,  0.0130,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0071, -0.0025,  ..., -0.0006,  0.0088, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0032,  0.0068,  ...,  0.0001,  0.0063,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044,  0.0019, -0.0010,  ...,  0.0137,  0.0067, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0017, 0.0026, 0.0039,  ..., 0.0059, 0.0005, 0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0127, -0.0028,  0.0011,  ...,  0.0118,  0.0057, -0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0020, -0.0036,  ...,  0.0041,  0.0110,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0007, -0.0041,  ...,  0.0054, -0.0009,  0.0084]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0042,  0.0005,  ..., -0.0045,  0.0026,  0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0057, 0.0026, 0.0010,  ..., 0.0030, 0.0086, 0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0073, -0.0008,  ...,  0.0104,  0.0001, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0101,  0.0024,  ..., -0.0113,  0.0032,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0024,  0.0002,  ...,  0.0084,  0.0035, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0068, -0.0066,  0.0062,  ...,  0.0059,  0.0115, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-5.2855e-03, -8.9953e-03,  9.8848e-03,  ...,  8.9628e-05,\n",
      "          6.4994e-03, -1.3996e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0154,  0.0007,  ..., -0.0070,  0.0032,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0015,  0.0029,  ...,  0.0125,  0.0081, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0072, -0.0087,  ...,  0.0061,  0.0069,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0061, -0.0022,  ...,  0.0056,  0.0133, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0150,  0.0053,  ..., -0.0087, -0.0014, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0105, -0.0071,  0.0066,  ...,  0.0027,  0.0053,  0.0114]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0095,  0.0002,  ...,  0.0063,  0.0089,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0012, -0.0014,  ...,  0.0082,  0.0147,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0037, -0.0019,  ...,  0.0110,  0.0044, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027,  0.0043, -0.0028,  ...,  0.0077,  0.0047, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0078, -0.0040,  ...,  0.0128,  0.0063, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0102,  0.0002,  ...,  0.0154,  0.0083, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0035, 0.0148, 0.0027,  ..., 0.0015, 0.0050, 0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0170,  0.0040,  ...,  0.0086,  0.0083, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0074,  0.0033,  ...,  0.0058,  0.0083,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.6415e-05,  9.7284e-04, -8.5371e-03,  ...,  1.3923e-02,\n",
      "          8.8494e-03, -5.4492e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0095, -0.0051,  ...,  0.0116,  0.0065, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0030, -0.0031,  ...,  0.0092,  0.0049, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0069,  0.0035, -0.0015,  ...,  0.0061,  0.0063, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0055, -0.0002,  ...,  0.0072,  0.0033, -0.0080]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0059,  0.0079,  ...,  0.0018, -0.0002, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0012, -0.0088,  ...,  0.0075,  0.0074,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0007, -0.0023,  ...,  0.0053,  0.0053,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0075, -0.0038,  ...,  0.0152,  0.0040, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048,  0.0011, -0.0008,  ...,  0.0149,  0.0048, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0017, -0.0025,  ...,  0.0135,  0.0043,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0114, -0.0095,  ...,  0.0055, -0.0017, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0169, -0.0004,  ..., -0.0056,  0.0028, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0079,  0.0005,  ...,  0.0069,  0.0040, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0067, -0.0064,  ..., -0.0007,  0.0070,  0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0023,  0.0053,  ..., -0.0065,  0.0014,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0086, -0.0047,  ..., -0.0055,  0.0009,  0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0117,  0.0006,  ...,  0.0037,  0.0033,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0011, -0.0047,  ...,  0.0019,  0.0028,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0051, -0.0077,  0.0051,  ...,  0.0086,  0.0051, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0009, -0.0007,  ...,  0.0084,  0.0006, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0110,  0.0022,  ...,  0.0028,  0.0102,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0093, -0.0044,  ..., -0.0016,  0.0070, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0056, -0.0010,  ...,  0.0036,  0.0120,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0155, -0.0038,  ...,  0.0031,  0.0064,  0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0062, -0.0030,  ..., -0.0033,  0.0088, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074,  0.0044,  0.0044,  ...,  0.0021,  0.0025, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0010, -0.0081,  ...,  0.0087,  0.0154,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0086,  0.0206,  0.0020,  ..., -0.0081,  0.0018,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0071,  0.0003,  ..., -0.0026,  0.0039,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0011,  0.0006,  ..., -0.0015,  0.0076,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0203, -0.0072,  ...,  0.0082,  0.0061, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040, -0.0087,  0.0052,  ...,  0.0065,  0.0032, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0123, -0.0047,  0.0006,  ...,  0.0054,  0.0016, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0047,  0.0062,  ...,  0.0103,  0.0029, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0048, -0.0093,  ..., -0.0098,  0.0068, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0057,  0.0028,  ...,  0.0133, -0.0022, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0109, -0.0050,  0.0052,  ...,  0.0038,  0.0032, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0101, -0.0023,  0.0025,  ...,  0.0078,  0.0060,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0060, 0.0094, 0.0015,  ..., 0.0154, 0.0021, 0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0075,  0.0063,  ...,  0.0100, -0.0006, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0012,  0.0100,  ...,  0.0216,  0.0058, -0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0136,  0.0009,  ..., -0.0073,  0.0066,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0020, -0.0116,  ...,  0.0050,  0.0050, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0011, -0.0025,  ...,  0.0004, -0.0009,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033, -0.0034,  0.0009,  ...,  0.0080,  0.0015, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0026, -0.0026,  ...,  0.0064,  0.0060, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059,  0.0098,  0.0010,  ...,  0.0088,  0.0028, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.0319e-03,  5.1891e-03, -1.1094e-03,  ..., -8.0383e-06,\n",
      "          8.0159e-03,  5.4627e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0023, -0.0036,  ...,  0.0087,  0.0074, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0075,  0.0020,  ...,  0.0062,  0.0044, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0010, -0.0006,  ...,  0.0118,  0.0071, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0039, -0.0014,  ...,  0.0077,  0.0069,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0009,  0.0044,  ...,  0.0164,  0.0007,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0004, -0.0051,  0.0030,  ..., -0.0111, -0.0013,  0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0036, -0.0033,  ...,  0.0028,  0.0020,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044,  0.0110,  0.0029,  ...,  0.0014,  0.0107, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0108,  0.0067, -0.0030,  ...,  0.0048,  0.0025,  0.0116]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0106,  0.0039,  ..., -0.0006,  0.0037,  0.0198]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098,  0.0175, -0.0005,  ..., -0.0036,  0.0016, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0132, -0.0004,  ..., -0.0008,  0.0072, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0127,  0.0035, -0.0031,  ..., -0.0080,  0.0063,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037,  0.0079,  0.0034,  ...,  0.0146,  0.0087, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0014,  0.0022,  ...,  0.0045,  0.0034, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0102, -0.0057,  ...,  0.0113,  0.0006, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0008,  0.0013,  ...,  0.0136,  0.0078, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035, -0.0132,  0.0073,  ..., -0.0028,  0.0086,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.0849e-03, -4.7668e-03,  2.7471e-04,  ...,  3.5478e-06,\n",
      "          4.2719e-03,  1.8057e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080, -0.0051, -0.0021,  ...,  0.0029,  0.0061,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0126,  0.0076,  ...,  0.0044,  0.0031,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0044, -0.0006,  ...,  0.0081, -0.0028, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0133,  0.0012,  0.0007,  ...,  0.0120,  0.0068, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024,  0.0183, -0.0038,  ..., -0.0020,  0.0029, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0123,  0.0005,  0.0022,  ...,  0.0018,  0.0059, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0027,  0.0060,  ..., -0.0015,  0.0053, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0082, -0.0019,  ..., -0.0050,  0.0023, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0114, -0.0024,  ...,  0.0100,  0.0058,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0046, -0.0025,  ..., -0.0147,  0.0013, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0047, -0.0069,  ..., -0.0025,  0.0085,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0158,  0.0041,  ..., -0.0021,  0.0056,  0.0117]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0106,  0.0023,  ..., -0.0002,  0.0002, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0099,  0.0058,  ..., -0.0032, -0.0068, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0023,  0.0045,  ...,  0.0108,  0.0018,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0068, -0.0040,  ..., -0.0007,  0.0031,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0184, -0.0059,  ...,  0.0052,  0.0081, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.2567e-03, -5.4270e-03,  7.2646e-04,  ..., -3.5911e-05,\n",
      "          3.0804e-03,  1.0747e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0074,  0.0034,  ..., -0.0008,  0.0082, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0098,  0.0041,  ..., -0.0026,  0.0022, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0059, -0.0074,  ...,  0.0010,  0.0007,  0.0152]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0046, -0.0093, -0.0023,  ..., -0.0040,  0.0011,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0114, -0.0064,  0.0041,  ...,  0.0098,  0.0088, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0010,  0.0078,  ...,  0.0029,  0.0038, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0122,  0.0019,  ..., -0.0052,  0.0138, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073, -0.0087,  0.0048,  ...,  0.0030,  0.0083,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0087,  0.0018,  0.0039,  ...,  0.0068,  0.0052,  0.0126]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0025, -0.0025,  ...,  0.0162,  0.0020,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0022, -0.0008,  ...,  0.0116,  0.0047,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0083,  0.0019,  ...,  0.0106,  0.0074,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0021, -0.0015,  ..., -0.0083,  0.0029,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.3157e-04, -1.3066e-05, -4.2285e-03,  ...,  1.1881e-02,\n",
      "          3.5907e-03, -1.0379e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0024, -0.0051,  ...,  0.0048,  0.0035, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0005,  0.0039,  ...,  0.0058, -0.0062, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0096, -0.0043,  ...,  0.0036,  0.0057,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0050,  0.0021,  ...,  0.0142,  0.0058, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0102, -0.0044,  ..., -0.0047,  0.0090, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0027, -0.0003,  ...,  0.0115,  0.0015, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049, -0.0055,  0.0037,  ..., -0.0003, -0.0036,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.0385e-05, -1.5128e-03,  2.5723e-04,  ..., -5.1283e-03,\n",
      "         -1.5008e-03, -6.6128e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0131,  0.0085,  ..., -0.0101,  0.0008, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0031, -0.0028,  ...,  0.0013, -0.0003,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-9.2371e-04, -1.0845e-03, -3.0610e-03,  ...,  6.1795e-03,\n",
      "          9.9125e-05,  4.1977e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061, -0.0044, -0.0038,  ...,  0.0011, -0.0022,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0136, -0.0004,  ...,  0.0059,  0.0055, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0005, -0.0018,  ..., -0.0096, -0.0039,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0033, -0.0080,  ...,  0.0005,  0.0022,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0038, -0.0033,  ..., -0.0025,  0.0093,  0.0149]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0012,  0.0046,  ..., -0.0001,  0.0082,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0083, -0.0002,  ...,  0.0158,  0.0038,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0072,  0.0042,  ...,  0.0056, -0.0018, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0052,  0.0053,  ...,  0.0102,  0.0058, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0052, -0.0002,  ...,  0.0090,  0.0106, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0152, -0.0017,  ...,  0.0036,  0.0050,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0015, -0.0024,  ...,  0.0044,  0.0069, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0066,  0.0103,  ..., -0.0036, -0.0008,  0.0142]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0004,  0.0091,  0.0083,  ...,  0.0133,  0.0034, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0128, -0.0057,  ...,  0.0050,  0.0101, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0005, -0.0089,  ..., -0.0023,  0.0045,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.3965e-03,  1.6276e-03,  3.1339e-05,  ...,  9.9536e-03,\n",
      "         -3.1995e-05,  1.0496e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073, -0.0064,  0.0018,  ..., -0.0012,  0.0084,  0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0027,  0.0023,  ..., -0.0010,  0.0047, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0045, -0.0039,  ...,  0.0107,  0.0035,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0071, -0.0030,  ...,  0.0025,  0.0009, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0008,  0.0024,  ...,  0.0092,  0.0040,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0042, -0.0069,  ..., -0.0090,  0.0009,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0023,  0.0055,  ...,  0.0054,  0.0083, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0028, -0.0007,  ...,  0.0099, -0.0011, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0016,  0.0029,  ...,  0.0079,  0.0054, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0083, -0.0047,  0.0037,  ..., -0.0032, -0.0010,  0.0145]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049, -0.0014,  0.0079,  ...,  0.0082, -0.0003, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0008, -0.0066,  ...,  0.0097,  0.0033, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0124, -0.0026,  ...,  0.0033,  0.0097, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0011,  0.0010,  ...,  0.0021,  0.0101,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0025,  0.0058,  ...,  0.0107,  0.0076, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0050, -0.0032,  ...,  0.0035,  0.0071, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077, -0.0091,  0.0014,  ..., -0.0042,  0.0027,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067, -0.0065,  0.0050,  ...,  0.0060,  0.0131, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0085, -0.0039,  ...,  0.0045,  0.0112, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0047, -0.0068,  ...,  0.0114,  0.0033, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0066, -0.0069,  0.0069,  ...,  0.0063,  0.0007,  0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0110, -0.0008,  ...,  0.0096,  0.0048, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0112, -0.0024, -0.0072,  ...,  0.0099,  0.0085, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0047,  0.0016,  ...,  0.0020,  0.0048, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0043,  0.0006,  ...,  0.0022, -0.0005, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0057, -0.0006,  ..., -0.0006,  0.0021,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040,  0.0026, -0.0077,  ...,  0.0016,  0.0110,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0039,  0.0084,  ...,  0.0067, -0.0040, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0030,  0.0069,  ..., -0.0023,  0.0022,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0109, -0.0028,  ...,  0.0088,  0.0057,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0069,  0.0008,  ..., -0.0027,  0.0055, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0044,  0.0107, -0.0007,  ...,  0.0071,  0.0023,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073,  0.0026,  0.0010,  ..., -0.0016,  0.0030, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0012,  0.0076,  ...,  0.0070,  0.0054,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0106, -0.0003,  ...,  0.0021, -0.0025,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062, -0.0046, -0.0064,  ...,  0.0106,  0.0118,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0067,  0.0082,  ...,  0.0091,  0.0078, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0087, -0.0090, -0.0047,  ...,  0.0118,  0.0016, -0.0099]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0177, -0.0038,  ...,  0.0056,  0.0036, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0128, -0.0006,  0.0031,  ..., -0.0041,  0.0038,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0017, -0.0056,  ...,  0.0090,  0.0025, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0005, -0.0024,  ...,  0.0044,  0.0040,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0147,  0.0054,  ..., -0.0040,  0.0076,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0004, -0.0045,  ...,  0.0100,  0.0051, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0104, -0.0049,  ...,  0.0036,  0.0040,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028,  0.0170, -0.0092,  ...,  0.0082,  0.0088,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0065, -0.0002,  ..., -0.0010,  0.0050,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0015,  0.0023,  ...,  0.0114,  0.0026,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0035, -0.0021,  ...,  0.0093,  0.0036, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0051, -0.0065,  ...,  0.0029,  0.0095, -0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0003,  0.0070,  ...,  0.0007, -0.0021,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0105,  0.0035,  ..., -0.0043, -0.0028,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0044, -0.0005,  ...,  0.0071,  0.0065,  0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0089, -0.0024,  ...,  0.0057,  0.0068,  0.0097]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0118,  0.0024,  ...,  0.0065,  0.0066,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0002,  0.0030,  ..., -0.0124, -0.0038,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0110, -0.0062,  ...,  0.0041,  0.0011,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0077, -0.0013,  ..., -0.0007, -0.0009,  0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0068,  0.0013,  ..., -0.0084,  0.0070,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0072,  0.0064, -0.0018,  ...,  0.0029,  0.0069, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.9511e-03, -2.4269e-03, -7.3446e-05,  ...,  1.1821e-04,\n",
      "         -2.6414e-03,  5.7400e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0106,  0.0108, -0.0009,  ...,  0.0115,  0.0007, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0025, -0.0045,  ...,  0.0039, -0.0050, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0015,  0.0053,  ..., -0.0013,  0.0023,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.6280e-04,  4.4948e-05, -5.1016e-04,  ...,  3.2078e-03,\n",
      "          3.7154e-03, -1.4741e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0089,  0.0010,  ..., -0.0033,  0.0013, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-6.1049e-03, -1.2210e-03,  2.9724e-03,  ...,  3.3520e-03,\n",
      "          4.2168e-03,  9.2442e-06]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0007, -0.0038,  ...,  0.0087,  0.0096, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0030, 0.0096, 0.0032,  ..., 0.0097, 0.0050, 0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073, -0.0061,  0.0010,  ..., -0.0078,  0.0030,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0056, -0.0014,  ...,  0.0119,  0.0088, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0068,  0.0023,  ...,  0.0059,  0.0005,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[1.2115e-03, 1.0567e-05, 1.1259e-03,  ..., 6.5194e-04, 3.7395e-03,\n",
      "         6.1659e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0059, 0.0055, 0.0026,  ..., 0.0056, 0.0030, 0.0135]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0091, -0.0004,  ..., -0.0118,  0.0051, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 9.3428e-03,  8.4609e-03, -8.3169e-04,  ..., -5.7090e-04,\n",
      "          4.4868e-03, -6.1878e-06]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0052,  0.0019,  ...,  0.0091,  0.0006, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0058,  0.0040,  ...,  0.0187,  0.0100, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0018, 0.0170, 0.0010,  ..., 0.0131, 0.0046, 0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0061, -0.0058,  0.0024,  ...,  0.0111,  0.0084, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0095, -0.0077,  ...,  0.0108,  0.0036, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0050, -0.0027,  ..., -0.0074,  0.0131,  0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0023,  0.0069,  ...,  0.0083,  0.0033, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0068,  0.0070,  ..., -0.0005,  0.0055, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0120, -0.0061,  0.0026,  ...,  0.0049,  0.0051,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0045, -0.0011,  ...,  0.0150,  0.0063, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067, -0.0090,  0.0105,  ...,  0.0114,  0.0117, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0052,  0.0028,  ...,  0.0163,  0.0020, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034,  0.0059,  0.0044,  ..., -0.0032,  0.0037,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0044, -0.0046,  ...,  0.0010,  0.0039,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.5840e-03,  9.1781e-03, -1.6434e-03,  ...,  5.5186e-04,\n",
      "          7.0894e-03, -5.9307e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0058, -0.0062,  ...,  0.0105,  0.0057, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0058,  0.0011,  ..., -0.0038, -0.0023,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0028, -0.0025,  ...,  0.0082, -0.0002,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062,  0.0066, -0.0052,  ..., -0.0055,  0.0044, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0047, 0.0075, 0.0003,  ..., 0.0004, 0.0055, 0.0108]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0030, -0.0016,  ...,  0.0059,  0.0030,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0033, -0.0041,  ..., -0.0077,  0.0054,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0037,  0.0004,  ...,  0.0068, -0.0047, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0080,  0.0004,  ...,  0.0088,  0.0066, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0045,  0.0003,  ...,  0.0115,  0.0084, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0084, -0.0068,  0.0038,  ...,  0.0058,  0.0065, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098,  0.0103,  0.0030,  ...,  0.0003,  0.0035, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060,  0.0028, -0.0090,  ...,  0.0133,  0.0009, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0074,  0.0005,  ...,  0.0019,  0.0075, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0057, -0.0023,  ..., -0.0051,  0.0004,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0125,  0.0033,  ..., -0.0038,  0.0142,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0041, -0.0007,  ...,  0.0015,  0.0085,  0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0106,  0.0022,  ...,  0.0059,  0.0014,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0073,  0.0048,  ...,  0.0175, -0.0018,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063, -0.0041,  0.0012,  ..., -0.0019,  0.0035,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0105, -0.0118,  0.0029,  ...,  0.0092,  0.0107,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0061, -0.0024,  ...,  0.0153,  0.0043,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0133, -0.0081,  ...,  0.0050,  0.0067, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0031, -0.0011,  ..., -0.0074,  0.0100,  0.0130]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0112, -0.0016,  ...,  0.0051,  0.0085, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0053, 0.0071, 0.0014,  ..., 0.0052, 0.0100, 0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0103,  0.0065,  0.0055,  ...,  0.0106, -0.0002, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001,  0.0141, -0.0031,  ...,  0.0095,  0.0033, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0072,  0.0068,  ..., -0.0031, -0.0011, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0127,  0.0082,  0.0024,  ...,  0.0155,  0.0073, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0068, -0.0132,  ...,  0.0103,  0.0101,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0027,  0.0037,  ...,  0.0115,  0.0087, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0114, -0.0012,  ...,  0.0128,  0.0032,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.8825e-03, -4.5361e-03,  1.5059e-02,  ...,  7.5458e-03,\n",
      "          6.6383e-03,  2.8883e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0064, -0.0046,  ...,  0.0001,  0.0080,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0061,  0.0071, -0.0013,  ...,  0.0020,  0.0033,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058, -0.0140,  0.0040,  ...,  0.0010,  0.0090,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041,  0.0036,  0.0030,  ..., -0.0090,  0.0023,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0080,  0.0001,  ..., -0.0043,  0.0036,  0.0120]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0020, -0.0013,  ...,  0.0114,  0.0066, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0063, -0.0054,  ...,  0.0021,  0.0059, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0050,  0.0051,  ...,  0.0086,  0.0048, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0099,  0.0102, -0.0023,  ...,  0.0077,  0.0020, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066, -0.0099,  0.0068,  ...,  0.0074,  0.0002,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0075, -0.0043,  ...,  0.0057,  0.0015,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-2.8503e-03, -7.7692e-07,  4.4948e-03,  ..., -2.1375e-03,\n",
      "         -1.0558e-05,  7.5226e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0059,  0.0024,  ..., -0.0036,  0.0018,  0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0004, -0.0010,  ..., -0.0106,  0.0073,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0056,  0.0076,  ...,  0.0005, -0.0012, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0120, 0.0045, 0.0012,  ..., 0.0074, 0.0045, 0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0137,  0.0013,  ..., -0.0109,  0.0056,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0134, -0.0047,  0.0016,  ...,  0.0058,  0.0043,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0057,  0.0047,  ...,  0.0077,  0.0080, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.8098e-03,  3.0404e-05, -1.2930e-04,  ...,  1.7539e-02,\n",
      "          1.2147e-02,  8.1489e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0032,  0.0031,  ..., -0.0022,  0.0071,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0062, -0.0067,  ...,  0.0107,  0.0082, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0011, -0.0024,  ...,  0.0121,  0.0047, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0034, -0.0065,  ...,  0.0036,  0.0054,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0058, -0.0059,  ...,  0.0045,  0.0085,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0082, -0.0026,  0.0045,  ...,  0.0098,  0.0016,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055, -0.0004, -0.0052,  ...,  0.0016,  0.0061, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0072,  0.0015,  0.0079,  ...,  0.0009,  0.0012, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0093,  0.0004, -0.0044,  ...,  0.0062,  0.0054,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.5371e-04,  5.1822e-03, -9.2225e-05,  ...,  9.3053e-03,\n",
      "          7.4291e-03,  7.6467e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0035, -0.0100,  ...,  0.0110,  0.0053, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0063,  0.0040,  ...,  0.0224,  0.0108,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.0874e-03,  5.1510e-03,  5.6302e-03,  ...,  1.5034e-02,\n",
      "          9.8490e-05, -7.8648e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088, -0.0019, -0.0071,  ...,  0.0030,  0.0074, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037,  0.0004,  0.0018,  ...,  0.0015,  0.0030, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0232, -0.0013,  ...,  0.0009,  0.0107,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0029, -0.0034,  ...,  0.0033,  0.0069,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0039,  0.0074,  ...,  0.0056, -0.0017, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0082, -0.0063,  ...,  0.0127,  0.0106,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0100, -0.0034,  ...,  0.0022,  0.0040, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0025,  0.0022,  ..., -0.0009, -0.0020, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0041,  0.0019,  ...,  0.0159,  0.0031, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0137, -0.0015,  ...,  0.0020, -0.0020, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0143, -0.0059,  ...,  0.0107,  0.0046, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049, -0.0074,  0.0036,  ...,  0.0061,  0.0018, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0043, 0.0026, 0.0051,  ..., 0.0143, 0.0042, 0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0055, -0.0077,  0.0048,  ..., -0.0094, -0.0021,  0.0122]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051, -0.0012,  0.0107,  ..., -0.0016,  0.0096,  0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0093,  0.0030,  0.0144,  ...,  0.0090,  0.0118, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041,  0.0027, -0.0022,  ...,  0.0140,  0.0016,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0096,  0.0006,  ...,  0.0123,  0.0023, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0002, 0.0063, 0.0046,  ..., 0.0040, 0.0041, 0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0094, -0.0040,  ...,  0.0092,  0.0056, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0105, -0.0093, -0.0033,  ..., -0.0031, -0.0005,  0.0138]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0099, -0.0004,  ..., -0.0015,  0.0049,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0051, -0.0021,  ...,  0.0098,  0.0064, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0093,  0.0017,  ..., -0.0017,  0.0023,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0007, -0.0069,  ...,  0.0080,  0.0082, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067, -0.0022,  0.0032,  ...,  0.0128,  0.0010, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0034,  0.0077,  ...,  0.0139,  0.0038, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0115, -0.0003,  0.0041,  ..., -0.0003,  0.0014,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0013,  0.0122,  ...,  0.0091, -0.0004, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0062, -0.0004,  ...,  0.0054,  0.0069, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0140,  0.0009,  ..., -0.0016,  0.0115,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.0123e-04,  1.0547e-02, -2.3911e-05,  ...,  2.6443e-03,\n",
      "          9.5017e-03,  2.7064e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0070,  0.0004,  ...,  0.0038, -0.0048, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0068,  0.0008,  ..., -0.0050,  0.0062,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0048, -0.0042,  ...,  0.0120,  0.0061,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0052, -0.0061,  ...,  0.0189,  0.0078, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082,  0.0044,  0.0063,  ..., -0.0006, -0.0009, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0080,  0.0059,  ...,  0.0075,  0.0055, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0010, -0.0028,  ...,  0.0128,  0.0040, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0107, -0.0008,  0.0036,  ...,  0.0028,  0.0025, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0097, -0.0007,  ..., -0.0038,  0.0027,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0003, -0.0005,  ..., -0.0106,  0.0013, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094, -0.0044, -0.0052,  ..., -0.0094,  0.0067, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0125, -0.0046,  ...,  0.0112,  0.0057,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.9595e-04,  1.5011e-02,  2.3811e-03,  ..., -5.7889e-04,\n",
      "          6.7699e-03,  3.7606e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0068,  0.0075,  ...,  0.0095,  0.0051, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069,  0.0034,  0.0038,  ...,  0.0079,  0.0007, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0021,  0.0058,  ...,  0.0130,  0.0015, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0073,  0.0019, -0.0041,  ..., -0.0009,  0.0121,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0092, -0.0015,  ...,  0.0143,  0.0065, -0.0094]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082, -0.0014,  0.0067,  ...,  0.0086,  0.0115,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080, -0.0033,  0.0085,  ..., -0.0041,  0.0040, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0094, -0.0029,  0.0038,  ..., -0.0029,  0.0065,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0059, -0.0042,  ...,  0.0101,  0.0090, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0037, -0.0062,  ..., -0.0012,  0.0047, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0092, -0.0015,  ...,  0.0082,  0.0028,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0078, -0.0017,  ...,  0.0091,  0.0078, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0143, -0.0004,  ..., -0.0087,  0.0028,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0054,  0.0003,  ...,  0.0134,  0.0085, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0017, -0.0033,  ...,  0.0002,  0.0036,  0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0079,  0.0020,  0.0060,  ...,  0.0112,  0.0053, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085, -0.0114,  0.0056,  ...,  0.0044,  0.0046, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0046, 0.0092, 0.0086,  ..., 0.0042, 0.0104, 0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025, -0.0086,  0.0044,  ...,  0.0046, -0.0043, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0086, -0.0016,  ...,  0.0030,  0.0038, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.6947e-03, -3.3911e-05,  2.0549e-03,  ...,  2.2303e-03,\n",
      "          2.2066e-03,  2.0881e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0014,  0.0005,  ...,  0.0059,  0.0133,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063,  0.0090, -0.0029,  ...,  0.0145, -0.0029, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0012, -0.0030,  ...,  0.0109,  0.0053,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0050,  0.0003,  ...,  0.0136,  0.0017, -0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0025, -0.0020,  ..., -0.0059,  0.0024, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0141,  0.0055,  ..., -0.0025,  0.0057,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0107, -0.0063, -0.0015,  ...,  0.0019,  0.0072,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0054, -0.0031,  ...,  0.0034,  0.0035, -0.0102]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0043, -0.0011,  ..., -0.0047, -0.0023,  0.0135]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0003,  0.0006,  ...,  0.0104,  0.0093, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0079, -0.0018,  0.0011,  ...,  0.0056,  0.0023,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0015,  0.0113,  ..., -0.0019, -0.0020, -0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0036, -0.0011,  ..., -0.0037,  0.0014,  0.0121]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0081,  0.0019,  ...,  0.0048,  0.0055,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0062,  0.0049,  ...,  0.0103,  0.0061, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0021,  0.0002,  ...,  0.0115,  0.0017, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0037, -0.0027,  ...,  0.0028,  0.0055, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 1.8700e-03, -1.3567e-02, -2.7953e-04,  ...,  2.1426e-03,\n",
      "          5.4933e-03, -7.0224e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0036,  0.0079,  ...,  0.0048,  0.0054,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0019,  0.0051,  ...,  0.0056,  0.0045, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0031, -0.0016,  ...,  0.0193,  0.0031, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0083,  0.0026,  ...,  0.0077,  0.0036,  0.0108]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057, -0.0068,  0.0007,  ...,  0.0013,  0.0077,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0050,  0.0114,  ...,  0.0216,  0.0056, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0032, -0.0017,  ..., -0.0005,  0.0065,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0155,  0.0005,  ...,  0.0069,  0.0085, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0093, -0.0048,  0.0013,  ...,  0.0080,  0.0031,  0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0013,  0.0036,  ...,  0.0030,  0.0060,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0064,  0.0012,  ..., -0.0053,  0.0110, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0057,  0.0034,  ...,  0.0101,  0.0042, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0123, -0.0072,  ...,  0.0009,  0.0048,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0122,  0.0014,  ...,  0.0006,  0.0008, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0002,  0.0007,  ...,  0.0105,  0.0062, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.6329e-03,  1.3230e-02,  5.6460e-03,  ..., -4.7097e-05,\n",
      "          2.8677e-04,  2.1282e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0023,  0.0140,  ...,  0.0040,  0.0039, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0077,  0.0027,  ...,  0.0032,  0.0012,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0056, -0.0080,  ...,  0.0138,  0.0049,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0044,  0.0007,  ..., -0.0075,  0.0109,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0048, 0.0065, 0.0003,  ..., 0.0110, 0.0101, 0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0063,  0.0009,  ...,  0.0049,  0.0063,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050, -0.0076, -0.0018,  ...,  0.0024,  0.0113,  0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.4418e-04,  2.9278e-03,  4.8806e-03,  ..., -9.2144e-04,\n",
      "          3.5851e-05, -1.4057e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0076, -0.0046,  ...,  0.0107,  0.0055,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0126, -0.0034,  ...,  0.0052,  0.0105,  0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0027, -0.0009,  ...,  0.0139,  0.0045, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0015, -0.0020,  ...,  0.0068,  0.0108,  0.0116]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034,  0.0115, -0.0012,  ..., -0.0015,  0.0069,  0.0123]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0095, -0.0058,  ...,  0.0030, -0.0013,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0101,  0.0002,  ..., -0.0035,  0.0054,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0124, -0.0012,  ...,  0.0056,  0.0027, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.6937e-03,  5.6360e-05, -1.9330e-03,  ..., -2.1223e-03,\n",
      "          8.4468e-03,  4.0239e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0153,  0.0105,  ...,  0.0113,  0.0064, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0020, -0.0123,  0.0019,  ...,  0.0076,  0.0122, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0031, -0.0038,  ...,  0.0077,  0.0026,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0105,  0.0016,  ...,  0.0030,  0.0032, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0061,  0.0040,  ...,  0.0013, -0.0021, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0036, -0.0054,  ...,  0.0070, -0.0007, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0054,  0.0022,  ...,  0.0059, -0.0037, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0050,  0.0010,  ...,  0.0066,  0.0030,  0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.8563e-05,  5.0485e-03, -3.6639e-03,  ...,  1.4994e-02,\n",
      "          1.0736e-03, -9.6454e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.3389e-05,  1.4459e-02, -3.4383e-03,  ..., -3.0477e-03,\n",
      "          3.8167e-03,  6.1905e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0054, -0.0031,  ...,  0.0053,  0.0005, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0135, -0.0047,  ...,  0.0069,  0.0035,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0013,  0.0014,  ...,  0.0031,  0.0094,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0031,  0.0071,  ...,  0.0060,  0.0060,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0022, -0.0013,  ..., -0.0083,  0.0011, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0080, -0.0060,  ...,  0.0021,  0.0077,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0053,  0.0037,  ...,  0.0161,  0.0090, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0016,  0.0035,  ...,  0.0175,  0.0087,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0021,  0.0057,  ...,  0.0097,  0.0050, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0110,  0.0155, -0.0065,  ..., -0.0041, -0.0006,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.7690e-03, -4.6851e-03,  3.1651e-03,  ...,  9.0268e-04,\n",
      "         -8.4331e-05,  7.1133e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0066, -0.0023,  ...,  0.0195,  0.0027, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0074, -0.0031,  ...,  0.0023,  0.0029, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0007, -0.0023,  ...,  0.0119,  0.0031, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0005, -0.0048,  ...,  0.0097,  0.0038, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0015, 0.0015, 0.0029,  ..., 0.0027, 0.0043, 0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0168, -0.0009,  ...,  0.0080,  0.0005, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0029, -0.0054,  ...,  0.0144,  0.0075,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0185,  0.0016,  ..., -0.0036, -0.0004,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0040, -0.0003,  ..., -0.0078,  0.0044,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033,  0.0030, -0.0044,  ...,  0.0138,  0.0051,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053, -0.0026,  0.0018,  ..., -0.0003,  0.0026, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.5333e-03, -3.7305e-03,  3.0035e-04,  ...,  2.1788e-03,\n",
      "         -4.8144e-05, -5.7406e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0110, -0.0019,  ...,  0.0091,  0.0111,  0.0109]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0084,  0.0073,  ...,  0.0007,  0.0124,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0096,  0.0059,  0.0039,  ..., -0.0002,  0.0081,  0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0069, -0.0176,  0.0017,  ...,  0.0033,  0.0024,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058, -0.0001,  0.0042,  ...,  0.0021,  0.0055, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0041, -0.0037,  ..., -0.0112, -0.0021,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.8437e-05, -1.0915e-02,  1.1937e-03,  ...,  6.3802e-03,\n",
      "          7.5820e-03,  4.4020e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0065, 0.0051, 0.0046,  ..., 0.0096, 0.0002, 0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0066, -0.0055,  ...,  0.0086,  0.0053,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0055,  0.0044,  ...,  0.0049,  0.0037,  0.0108]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.6732e-05,  1.1637e-02,  2.9045e-03,  ...,  1.0106e-02,\n",
      "          6.2698e-03, -1.4267e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074, -0.0043,  0.0002,  ...,  0.0095,  0.0081, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0091, -0.0025,  ...,  0.0134,  0.0077, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050, -0.0022,  0.0127,  ..., -0.0017,  0.0021,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021,  0.0036, -0.0059,  ...,  0.0132,  0.0024, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0089,  0.0092,  ..., -0.0028,  0.0031,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0105, -0.0005, -0.0060,  ...,  0.0094,  0.0071, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0073, -0.0050,  ...,  0.0104,  0.0032,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0023,  0.0043,  ...,  0.0012,  0.0103,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0050,  0.0197, -0.0070,  ..., -0.0026, -0.0037,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0066, -0.0048,  ...,  0.0065,  0.0071, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027,  0.0062,  0.0003,  ..., -0.0004,  0.0047,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042,  0.0003,  0.0017,  ...,  0.0063,  0.0047, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0050, -0.0055,  ...,  0.0067,  0.0007,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.1299e-03,  3.3131e-03,  2.0187e-05,  ..., -2.4894e-04,\n",
      "          4.0210e-03, -1.2781e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0137, -0.0046,  ...,  0.0007,  0.0002,  0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0036,  0.0081,  ...,  0.0100,  0.0006,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039, -0.0072, -0.0023,  ...,  0.0001,  0.0011,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0128, -0.0024,  ...,  0.0142,  0.0059, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0017, -0.0032,  ...,  0.0128,  0.0019, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0037, -0.0053,  ...,  0.0098,  0.0043, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0063,  0.0038,  ..., -0.0115, -0.0015,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0005,  0.0046,  ...,  0.0120,  0.0046,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0145,  0.0088,  ...,  0.0113,  0.0101,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0008, -0.0009,  ...,  0.0095,  0.0043, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0075, -0.0026,  ...,  0.0099,  0.0078,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039, -0.0084,  0.0048,  ..., -0.0006,  0.0016,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0070, -0.0030,  ...,  0.0042,  0.0045,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0027,  0.0076, -0.0077,  ...,  0.0087,  0.0070,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0034, -0.0046,  ...,  0.0055,  0.0125,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073, -0.0016, -0.0003,  ...,  0.0165,  0.0016, -0.0098]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0062, -0.0012,  ...,  0.0110,  0.0057,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084,  0.0004, -0.0022,  ...,  0.0150,  0.0065,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0087,  0.0144, -0.0046,  ...,  0.0210,  0.0102, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0194, -0.0072,  ...,  0.0021,  0.0003, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0018,  0.0008,  ..., -0.0027,  0.0047,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0147,  0.0051,  ..., -0.0049,  0.0073,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0037,  0.0059,  ...,  0.0109,  0.0072, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094, -0.0050, -0.0016,  ...,  0.0093,  0.0014, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0141,  0.0002,  ...,  0.0106,  0.0058, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0145,  0.0034,  ..., -0.0112,  0.0073,  0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0143,  0.0019,  ...,  0.0084,  0.0059, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052,  0.0152, -0.0016,  ...,  0.0107,  0.0033, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064,  0.0115, -0.0080,  ...,  0.0186,  0.0068,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0090, -0.0072,  0.0076,  ...,  0.0068,  0.0045,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0025,  0.0023,  ...,  0.0221,  0.0047, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0062,  0.0047, -0.0042,  ...,  0.0164,  0.0039,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063,  0.0200,  0.0014,  ..., -0.0087,  0.0067,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0042,  0.0039,  ...,  0.0099,  0.0081, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0048,  0.0026,  ...,  0.0185,  0.0022, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0088, -0.0081,  ...,  0.0098, -0.0005, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0184, -0.0062,  ...,  0.0132,  0.0058, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0112,  0.0021,  ...,  0.0114, -0.0057,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0088, -0.0009,  ...,  0.0113,  0.0009, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0063,  0.0023,  ...,  0.0128,  0.0100, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0001, -0.0044,  ..., -0.0055,  0.0073,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0023, -0.0026,  ...,  0.0025,  0.0096, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033, -0.0049, -0.0017,  ..., -0.0005,  0.0032,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0107,  0.0013,  ...,  0.0040,  0.0018, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0092,  0.0013,  0.0032,  ..., -0.0002,  0.0104, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0108,  0.0065, -0.0047,  ..., -0.0070,  0.0094, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0048, -0.0015,  ...,  0.0052,  0.0049, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0062, -0.0023,  ..., -0.0032,  0.0061, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0043, -0.0028, -0.0041,  ...,  0.0005,  0.0034,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0049, -0.0025,  ..., -0.0012,  0.0047,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0124,  0.0081,  ...,  0.0031,  0.0031,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0086, -0.0059,  0.0035,  ...,  0.0035,  0.0055,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0153, -0.0012,  ...,  0.0020,  0.0030,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0077, -0.0046,  ..., -0.0008,  0.0051,  0.0131]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0046, -0.0015,  ...,  0.0097,  0.0086, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0094,  0.0088,  ...,  0.0133,  0.0076, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0132, -0.0013,  ..., -0.0018,  0.0046, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047,  0.0017, -0.0031,  ...,  0.0088, -0.0006, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0086,  0.0046, -0.0026,  ...,  0.0041,  0.0027,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0038,  0.0040,  ...,  0.0153,  0.0074,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0095,  0.0023,  ...,  0.0125,  0.0066, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0031, -0.0011,  ..., -0.0039,  0.0032,  0.0115]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0004, 0.0004, 0.0026,  ..., 0.0037, 0.0030, 0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0079,  0.0067,  ...,  0.0030,  0.0081,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.1681e-02,  9.7061e-03, -2.4335e-03,  ...,  2.0428e-02,\n",
      "          8.2882e-03, -1.4262e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.6215e-03, -3.2873e-04, -4.9848e-04,  ...,  7.5671e-03,\n",
      "          7.6945e-05, -2.3685e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0012, -0.0007,  ..., -0.0041, -0.0054,  0.0110]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0004,  0.0061,  ..., -0.0069,  0.0132,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0019, -0.0036,  ...,  0.0142,  0.0035, -0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074,  0.0090, -0.0033,  ..., -0.0021,  0.0092,  0.0098]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0070,  0.0015, -0.0036,  ...,  0.0027,  0.0138, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062,  0.0058,  0.0004,  ..., -0.0017,  0.0019,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0013, -0.0008,  ...,  0.0097,  0.0047,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0040, 0.0123, 0.0009,  ..., 0.0036, 0.0063, 0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0105, -0.0027,  ..., -0.0083,  0.0027,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067, -0.0096,  0.0061,  ..., -0.0099,  0.0046,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0152,  0.0019,  ..., -0.0037, -0.0017,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0122,  0.0031,  ...,  0.0039,  0.0065, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-9.8573e-04,  1.9064e-02,  3.1570e-03,  ..., -9.9206e-05,\n",
      "          1.2211e-02,  9.0422e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0070, -0.0013,  ...,  0.0046,  0.0071, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0003, -0.0022,  ...,  0.0149,  0.0003, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0133, -0.0027,  ...,  0.0130,  0.0045,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044,  0.0049, -0.0069,  ...,  0.0112,  0.0031, -0.0118]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0084,  0.0203,  0.0025,  ...,  0.0069,  0.0140, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0101,  0.0006,  ...,  0.0103,  0.0058, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0120, -0.0134,  0.0054,  ..., -0.0082,  0.0034,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0095, -0.0011,  ..., -0.0012,  0.0074,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0055, -0.0066,  ...,  0.0138,  0.0011, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0063,  0.0025,  ...,  0.0120,  0.0036, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0070,  0.0081, -0.0003,  ...,  0.0032,  0.0025, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0009,  0.0014,  ...,  0.0079,  0.0023,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0009, 0.0049, 0.0043,  ..., 0.0017, 0.0017, 0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0134, -0.0102,  ...,  0.0094,  0.0097, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0047,  0.0072,  ..., -0.0018, -0.0020,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0127, -0.0013,  ...,  0.0071,  0.0053, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0016,  0.0032,  ...,  0.0053,  0.0064, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0061, -0.0062,  ..., -0.0076,  0.0078,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0100, -0.0011, -0.0048,  ...,  0.0077,  0.0038, -0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0076, -0.0043,  ..., -0.0129,  0.0007,  0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0143,  0.0041,  ..., -0.0056, -0.0015,  0.0126]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0040,  0.0039,  ...,  0.0060,  0.0026,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085, -0.0014,  0.0066,  ...,  0.0118,  0.0044,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037,  0.0113, -0.0050,  ...,  0.0089,  0.0093, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082,  0.0035,  0.0033,  ...,  0.0090, -0.0014, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0037,  0.0005,  ..., -0.0062,  0.0012,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0006,  0.0120,  ...,  0.0034, -0.0006, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094, -0.0071,  0.0034,  ..., -0.0055,  0.0071,  0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0118, -0.0005,  ..., -0.0035,  0.0068,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001, -0.0042, -0.0009,  ...,  0.0007,  0.0044, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0017, -0.0003,  ..., -0.0066,  0.0080,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0076,  0.0061,  ..., -0.0104,  0.0010,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0050,  0.0089,  ...,  0.0063,  0.0014,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0115, -0.0050,  ...,  0.0009,  0.0091,  0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060,  0.0005,  0.0032,  ..., -0.0035,  0.0028,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053,  0.0003, -0.0041,  ...,  0.0253,  0.0048, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0112,  0.0097, -0.0048,  ...,  0.0062,  0.0081,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0046,  0.0056,  ...,  0.0189, -0.0006,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040,  0.0098,  0.0039,  ...,  0.0100,  0.0040, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0133, -0.0013,  0.0034,  ...,  0.0062,  0.0059,  0.0099]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0089, -0.0004,  ...,  0.0137,  0.0120,  0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069, -0.0029,  0.0038,  ...,  0.0162,  0.0071,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0056, -0.0059,  ..., -0.0084,  0.0042,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0095, 0.0023, 0.0002,  ..., 0.0058, 0.0041, 0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0077, -0.0016,  ...,  0.0138,  0.0036,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021, -0.0113, -0.0026,  ...,  0.0085,  0.0031, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0093,  0.0029,  ...,  0.0014,  0.0072,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0144, -0.0059,  ...,  0.0082,  0.0052, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0102, -0.0055, -0.0007,  ...,  0.0042,  0.0061,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0008, -0.0042,  ...,  0.0050,  0.0053,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073,  0.0067,  0.0044,  ...,  0.0007,  0.0024, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049, -0.0086,  0.0062,  ..., -0.0017,  0.0108,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0081, -0.0027,  ...,  0.0047,  0.0019,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080,  0.0018, -0.0016,  ...,  0.0126,  0.0039, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0153,  0.0012,  ...,  0.0037,  0.0062,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0014, -0.0012,  ..., -0.0070,  0.0008,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0040,  0.0010,  ...,  0.0066, -0.0022,  0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0059,  0.0019,  ...,  0.0161,  0.0091,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074, -0.0003,  0.0006,  ..., -0.0001,  0.0032,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0023, -0.0033,  ...,  0.0082,  0.0047, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0118, -0.0025,  ..., -0.0012,  0.0098, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0133, -0.0072,  ...,  0.0073,  0.0016,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0074, -0.0035, -0.0098,  ...,  0.0048,  0.0052,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0062,  0.0079,  ...,  0.0249,  0.0010, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0065, -0.0078,  0.0122,  ..., -0.0008, -0.0009,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0049, -0.0049,  0.0044,  ..., -0.0045,  0.0017,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0069, -0.0010,  ...,  0.0079,  0.0039, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0060, -0.0009,  ..., -0.0020,  0.0037, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085, -0.0057,  0.0089,  ..., -0.0059,  0.0013,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0123,  0.0015,  ...,  0.0153,  0.0035,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0192, -0.0051,  ...,  0.0051,  0.0140, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0075,  0.0001,  ...,  0.0067,  0.0075, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0139,  0.0003,  ..., -0.0018,  0.0025, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0092, -0.0045,  0.0073,  ..., -0.0048,  0.0016,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0069, -0.0042, -0.0013,  ...,  0.0045,  0.0081,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0089,  0.0015,  ...,  0.0002, -0.0008, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098, -0.0067,  0.0054,  ..., -0.0084,  0.0023,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0065, -0.0067,  ...,  0.0021,  0.0085,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.4203e-03,  1.1455e-03,  4.5849e-03,  ...,  2.9901e-03,\n",
      "         -9.9723e-05, -2.6369e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021,  0.0149,  0.0023,  ..., -0.0073, -0.0055, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0023,  0.0002,  ..., -0.0091,  0.0033,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0114, -0.0108, -0.0005,  ..., -0.0059,  0.0018, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0081, -0.0020,  0.0017,  ...,  0.0083,  0.0076,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087, -0.0075,  0.0020,  ...,  0.0013,  0.0041,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.6382e-05, -5.4657e-03,  1.1261e-03,  ..., -2.7870e-03,\n",
      "         -4.7468e-04, -6.4894e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0088, -0.0026,  ...,  0.0076,  0.0110, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.6332e-05,  1.8149e-02,  1.6864e-04,  ...,  5.8270e-03,\n",
      "          6.6487e-03,  2.5777e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0020, -0.0020,  ...,  0.0057,  0.0051, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0019, -0.0039,  ...,  0.0081,  0.0024, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0119,  0.0011,  ..., -0.0043, -0.0009,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.2562e-03, -5.0688e-03,  3.0602e-03,  ...,  5.3985e-05,\n",
      "         -2.1990e-04,  7.9126e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0007,  0.0045,  ...,  0.0053,  0.0041, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0044, -0.0097,  ...,  0.0028,  0.0032, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0052, -0.0006,  ..., -0.0061,  0.0043,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0091,  0.0025,  ...,  0.0135,  0.0057,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0015,  0.0006,  ...,  0.0016,  0.0085, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027,  0.0017,  0.0021,  ...,  0.0079,  0.0002, -0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0070,  0.0042,  ...,  0.0057,  0.0050,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0067,  0.0012,  ...,  0.0025,  0.0098, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0005, -0.0007,  ...,  0.0067, -0.0025, -0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0037, -0.0005,  ...,  0.0128,  0.0106,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0031, -0.0020,  ...,  0.0115,  0.0034, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0121,  0.0044,  ...,  0.0059, -0.0018, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0013, -0.0038,  ..., -0.0024,  0.0017,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0074, -0.0088,  ...,  0.0023,  0.0020, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0016, -0.0013,  ..., -0.0068,  0.0003,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0204, -0.0004,  ...,  0.0158,  0.0065, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0158, -0.0070,  ...,  0.0083, -0.0049, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0027,  0.0028,  ...,  0.0154,  0.0149, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0071, -0.0101, -0.0032,  ..., -0.0057,  0.0095,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0082,  0.0015,  ...,  0.0190,  0.0092, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0161,  0.0091, -0.0047,  ...,  0.0032,  0.0042, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0077, -0.0018,  ...,  0.0071,  0.0014, -0.0106]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0054,  0.0069,  ...,  0.0087,  0.0019,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0179, -0.0017,  ...,  0.0124,  0.0032,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0069,  0.0044,  ...,  0.0240,  0.0025, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0050,  0.0024,  ...,  0.0105,  0.0045,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0092, -0.0001,  ..., -0.0031,  0.0030,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0059,  0.0060,  ...,  0.0127,  0.0060, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0088,  0.0023, -0.0028,  ...,  0.0053,  0.0007, -0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0052, -0.0082, -0.0015,  ...,  0.0013,  0.0067,  0.0129]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0017, 0.0124, 0.0053,  ..., 0.0103, 0.0068, 0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.7384e-05,  1.4635e-02,  7.0684e-05,  ...,  8.7227e-03,\n",
      "          5.9216e-03,  1.0504e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064, -0.0091,  0.0104,  ...,  0.0087,  0.0016,  0.0130]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.3633e-04,  8.4945e-03, -1.7629e-04,  ...,  8.0213e-03,\n",
      "         -1.8118e-03,  5.2271e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044,  0.0023, -0.0069,  ...,  0.0023,  0.0001,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0044, -0.0071,  ...,  0.0077,  0.0057, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0026, -0.0043,  ..., -0.0037,  0.0045, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0046,  0.0095,  ...,  0.0128,  0.0021,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0084, -0.0163, -0.0024,  ..., -0.0044,  0.0006, -0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0094, -0.0080,  0.0063,  ..., -0.0009,  0.0011,  0.0153]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0107,  0.0209, -0.0078,  ...,  0.0033, -0.0016,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0119,  0.0126,  ...,  0.0008,  0.0055,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0040, -0.0011,  ..., -0.0080,  0.0081,  0.0149]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0125, -0.0025,  0.0012,  ...,  0.0134,  0.0043,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029,  0.0050, -0.0058,  ...,  0.0130,  0.0058,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.8996e-03, -7.7357e-03,  1.9206e-02,  ..., -2.7830e-05,\n",
      "          1.1425e-03,  5.5159e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0090, -0.0023,  ...,  0.0089,  0.0066,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0105, -0.0019,  ...,  0.0198,  0.0071, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0003, -0.0065,  ..., -0.0078,  0.0036, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0014,  0.0038,  ..., -0.0023,  0.0039,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0040,  0.0020,  ...,  0.0098,  0.0071,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0108, -0.0088,  ..., -0.0011,  0.0006, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066,  0.0125, -0.0059,  ...,  0.0108,  0.0062,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0029, -0.0007,  ..., -0.0021,  0.0065, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045,  0.0068, -0.0062,  ..., -0.0033,  0.0114,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0012, -0.0005,  ..., -0.0027,  0.0032,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0012, -0.0049,  ...,  0.0056,  0.0036, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0019,  0.0008,  ...,  0.0203,  0.0040, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0024,  0.0036,  ...,  0.0208,  0.0039, -0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.3450e-03,  2.3370e-03,  1.2276e-03,  ...,  1.8921e-05,\n",
      "          3.4293e-03, -1.3579e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0025,  0.0001,  ..., -0.0009,  0.0022,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073,  0.0053, -0.0034,  ...,  0.0016,  0.0098,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0081,  0.0106,  ...,  0.0008,  0.0077,  0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0113,  0.0090,  ...,  0.0015, -0.0071, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0102, -0.0104,  ...,  0.0195,  0.0035,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0072,  0.0001,  ...,  0.0082,  0.0046, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0032,  0.0026,  ...,  0.0067,  0.0006, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0033, 0.0006, 0.0073,  ..., 0.0119, 0.0013, 0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009,  0.0012, -0.0108,  ...,  0.0021,  0.0051, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058,  0.0123, -0.0007,  ...,  0.0004,  0.0071, -0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.9546e-03,  8.1240e-03, -2.9117e-03,  ...,  5.5338e-05,\n",
      "         -3.1287e-04, -3.6699e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0008, -0.0085,  0.0087,  ...,  0.0096,  0.0047,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.9836e-05, -6.2300e-03,  5.4221e-03,  ...,  3.1763e-03,\n",
      "          1.7969e-03,  8.7586e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058, -0.0041,  0.0062,  ...,  0.0096,  0.0012, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0157,  0.0016,  ...,  0.0040,  0.0044,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0008,  0.0015,  ...,  0.0086,  0.0060, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0088, -0.0049,  ...,  0.0038,  0.0076,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067,  0.0009, -0.0028,  ...,  0.0040,  0.0034,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0039, -0.0020,  ...,  0.0125,  0.0034, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0067, -0.0027,  ...,  0.0032,  0.0067, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0047, -0.0043,  ...,  0.0014,  0.0023,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0119, -0.0060, -0.0003,  ...,  0.0025, -0.0016,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0024, -0.0012,  ..., -0.0070,  0.0124, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0047,  0.0037,  ...,  0.0109,  0.0055, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0147, -0.0022,  ...,  0.0068,  0.0064,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0040, -0.0007,  ...,  0.0087,  0.0062,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0186, -0.0008,  ...,  0.0181,  0.0096,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0007,  0.0038,  ...,  0.0113,  0.0028,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088,  0.0042, -0.0014,  ...,  0.0101,  0.0127,  0.0123]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0201, -0.0046,  ...,  0.0046,  0.0107,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.5932e-05, -4.2571e-03, -1.8015e-05,  ...,  2.9359e-03,\n",
      "          1.4662e-02,  5.5004e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.9961e-03, -7.5795e-03,  1.1769e-05,  ...,  1.0915e-02,\n",
      "          7.8494e-03,  6.3500e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0077,  0.0007,  ..., -0.0117,  0.0073,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0680e-02, -8.1106e-03,  3.8599e-03,  ...,  2.8108e-04,\n",
      "          6.1829e-03,  4.2014e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094,  0.0056,  0.0067,  ...,  0.0029, -0.0011,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0062, -0.0001,  ...,  0.0044, -0.0044, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0074,  0.0030,  ..., -0.0021,  0.0043,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0031,  0.0076,  ...,  0.0145,  0.0119, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046,  0.0023,  0.0127,  ...,  0.0100,  0.0044, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0057, -0.0002,  ..., -0.0012,  0.0033, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.1534e-03, -1.3395e-02, -5.1388e-05,  ...,  4.5027e-03,\n",
      "          4.3001e-03, -3.0865e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0094,  0.0003, -0.0019,  ...,  0.0071, -0.0013,  0.0113]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0072,  0.0006,  ...,  0.0090,  0.0079, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0048, -0.0020,  ...,  0.0013,  0.0042, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014, -0.0107,  0.0069,  ...,  0.0001,  0.0006, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080, -0.0030, -0.0028,  ...,  0.0049,  0.0070, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0044,  0.0139, -0.0022,  ...,  0.0018,  0.0056,  0.0121]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0024,  0.0016,  ..., -0.0062,  0.0008,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056, -0.0087,  0.0004,  ...,  0.0081, -0.0037, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002, -0.0077,  0.0014,  ...,  0.0089,  0.0086, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0007, -0.0001,  ...,  0.0071, -0.0013, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0202, -0.0075,  ...,  0.0132,  0.0025, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0071,  0.0017,  ..., -0.0033,  0.0038,  0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.3159e-03, -8.0382e-03,  7.4703e-05,  ...,  1.2961e-04,\n",
      "          5.9871e-04, -1.8019e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0089, -0.0046,  ...,  0.0117,  0.0005, -0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0107, -0.0008,  ..., -0.0088,  0.0125, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0048, -0.0014,  ..., -0.0070,  0.0072,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0101,  0.0028, -0.0009,  ..., -0.0041,  0.0047, -0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0121,  0.0081,  ..., -0.0012,  0.0079, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071, -0.0062, -0.0077,  ...,  0.0019,  0.0080,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0016, -0.0010,  ...,  0.0088,  0.0077,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0079, -0.0067,  0.0120,  ..., -0.0120, -0.0024,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0170, -0.0074,  ...,  0.0152,  0.0036, -0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0181,  0.0028,  ...,  0.0078,  0.0027,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0037, -0.0023,  ...,  0.0058,  0.0059,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0028,  0.0036,  ..., -0.0022,  0.0046,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0177,  0.0011,  ...,  0.0079,  0.0085,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0033,  0.0055,  ...,  0.0057,  0.0079, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0036,  0.0021,  ...,  0.0092,  0.0050,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0009, -0.0145,  0.0020,  ..., -0.0046,  0.0077, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0100,  0.0041,  ...,  0.0074,  0.0050, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0036,  0.0020,  ..., -0.0033,  0.0007,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0108, -0.0089,  ...,  0.0046,  0.0096, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.8187e-03,  7.8547e-03, -9.4290e-06,  ..., -8.2051e-03,\n",
      "         -3.4340e-03,  8.9176e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0086,  0.0029,  ...,  0.0095,  0.0051, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001, -0.0170,  0.0029,  ..., -0.0029,  0.0073, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0041, -0.0068,  ...,  0.0043,  0.0044,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0045, -0.0014,  ...,  0.0083,  0.0088, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.7573e-03, -7.6073e-04, -9.6140e-05,  ...,  4.5583e-03,\n",
      "          5.4549e-03, -2.0658e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0076,  0.0026,  0.0006,  ..., -0.0049,  0.0074,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0150,  0.0011,  ...,  0.0043,  0.0066, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0025, -0.0122,  0.0115,  ..., -0.0069,  0.0028,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0065, -0.0079, -0.0040,  ...,  0.0118, -0.0031, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.3547e-05,  6.8669e-03, -1.1798e-03,  ...,  1.3059e-02,\n",
      "          5.8412e-03,  6.1021e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0077, -0.0038,  ...,  0.0029,  0.0064, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0127,  0.0037,  ..., -0.0043,  0.0056,  0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0033,  0.0083,  ...,  0.0043,  0.0023, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0015,  0.0038,  ...,  0.0083,  0.0064, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0023, -0.0031,  ..., -0.0042,  0.0118,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0164, -0.0010,  ...,  0.0009,  0.0092, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045, -0.0059, -0.0035,  ..., -0.0062,  0.0030, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0010,  0.0081,  ...,  0.0083,  0.0062, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037,  0.0083, -0.0008,  ...,  0.0084, -0.0009, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0030, -0.0002,  ...,  0.0049, -0.0010,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0047, -0.0016,  ...,  0.0065,  0.0047,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.8535e-05, -4.2788e-04,  5.6453e-04,  ...,  6.0153e-03,\n",
      "          7.6924e-03, -1.2320e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0004,  0.0030,  ..., -0.0020,  0.0018, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063,  0.0181, -0.0014,  ...,  0.0151,  0.0096, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.4060e-03, -7.1610e-03,  5.3912e-03,  ..., -2.1239e-03,\n",
      "          8.6114e-05,  3.7352e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0136, -0.0057,  ...,  0.0075,  0.0034,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025, -0.0068,  0.0010,  ...,  0.0043,  0.0031,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0073,  0.0079,  ...,  0.0172,  0.0052, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0011, -0.0013,  ...,  0.0058,  0.0022, -0.0080]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0052, -0.0128, -0.0022,  ...,  0.0080,  0.0054, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024, -0.0030, -0.0011,  ..., -0.0048,  0.0029,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 7.4497e-06,  1.7760e-03,  4.8387e-05,  ...,  1.3671e-02,\n",
      "          4.5745e-03, -1.5402e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058,  0.0131,  0.0002,  ...,  0.0098,  0.0080, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0051,  0.0038,  ...,  0.0119,  0.0004,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0035, 0.0008, 0.0064,  ..., 0.0005, 0.0061, 0.0183]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0024,  0.0009,  ..., -0.0012,  0.0038,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0050,  0.0078,  ...,  0.0024, -0.0028, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0109,  0.0062,  ...,  0.0054,  0.0075,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0017, 0.0051, 0.0014,  ..., 0.0063, 0.0011, 0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0006, -0.0014,  ...,  0.0124,  0.0051, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066,  0.0006, -0.0021,  ..., -0.0120,  0.0017,  0.0109]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.5628e-03,  5.9748e-03, -3.2956e-03,  ...,  6.9541e-03,\n",
      "          4.1330e-03,  1.2019e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0001, -0.0066,  0.0025,  ...,  0.0078,  0.0012, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0077,  0.0009,  ...,  0.0113,  0.0050, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0121, -0.0035,  ..., -0.0049,  0.0072,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0030, -0.0041,  ...,  0.0056,  0.0038, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0029, -0.0008,  ..., -0.0011,  0.0033, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0017, -0.0052,  ..., -0.0075, -0.0025,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0064, -0.0056,  ...,  0.0039,  0.0050,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001, -0.0017,  0.0007,  ...,  0.0106,  0.0055, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0087,  0.0099, -0.0006,  ...,  0.0026,  0.0073,  0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037,  0.0017, -0.0009,  ...,  0.0102,  0.0081, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0005, -0.0053,  ..., -0.0045,  0.0030,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088, -0.0053,  0.0027,  ...,  0.0017, -0.0001,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0113, -0.0062,  ...,  0.0176,  0.0031, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0059, -0.0091,  ...,  0.0062,  0.0055, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0189, -0.0105,  ...,  0.0041,  0.0060, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065,  0.0101,  0.0016,  ...,  0.0006,  0.0136, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053,  0.0153, -0.0053,  ...,  0.0053,  0.0018,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0079, -0.0044,  ...,  0.0095,  0.0105,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0040, -0.0069,  ...,  0.0060,  0.0090, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.1112e-05, -8.2070e-03, -4.3095e-03,  ...,  6.4279e-03,\n",
      "          8.7307e-03,  1.9988e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0111,  0.0106,  0.0016,  ...,  0.0183,  0.0057, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0093, -0.0010,  0.0009,  ...,  0.0055,  0.0054, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 2.0177e-03,  2.1686e-02, -1.8521e-05,  ...,  7.7200e-03,\n",
      "          1.4133e-02, -1.1139e-04]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0115, -0.0021, -0.0009,  ..., -0.0022,  0.0108,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0091, -0.0022, -0.0037,  ..., -0.0103, -0.0013, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.8303e-05, -6.6782e-03,  5.9030e-03,  ..., -2.2270e-03,\n",
      "         -4.9376e-04,  2.0706e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0024,  0.0024,  ..., -0.0015,  0.0048,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0011,  0.0081,  ...,  0.0021,  0.0086, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0080, -0.0083,  0.0050,  ...,  0.0090,  0.0052,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0071,  0.0063,  ...,  0.0078,  0.0016,  0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0121, -0.0053,  0.0075,  ...,  0.0034,  0.0048,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0021, -0.0062,  ...,  0.0024,  0.0103,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0094, -0.0005,  ...,  0.0190,  0.0079, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0085,  0.0050,  ...,  0.0082, -0.0010, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0041, -0.0054,  ..., -0.0108,  0.0015,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0081,  0.0126,  0.0041,  ...,  0.0093, -0.0015, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0105,  0.0008, -0.0032,  ..., -0.0006,  0.0013,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0069, -0.0052,  ..., -0.0054,  0.0050, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0106,  0.0003,  ...,  0.0095,  0.0076, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0132, -0.0009,  ...,  0.0167,  0.0033, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0142, -0.0067,  ...,  0.0156,  0.0009, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0177, -0.0002,  ...,  0.0063,  0.0071, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0108, -0.0068,  ..., -0.0002,  0.0094,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0044,  0.0026,  ...,  0.0029, -0.0040, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0111,  0.0046,  ...,  0.0156,  0.0047, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0117, -0.0010,  ...,  0.0013, -0.0028, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0024,  0.0002,  ...,  0.0079,  0.0034, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0043, -0.0019,  ...,  0.0062,  0.0042,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0056,  0.0068,  ...,  0.0038,  0.0022, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0008, -0.0036,  ...,  0.0023,  0.0018,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0054, -0.0014,  ...,  0.0036,  0.0062,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0038,  0.0022,  ...,  0.0160,  0.0060,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-2.6817e-05,  7.3307e-03, -2.2692e-03,  ...,  1.6118e-02,\n",
      "          4.7283e-03, -6.8497e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0034, -0.0014,  ...,  0.0046,  0.0021,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0173, -0.0025,  ...,  0.0102,  0.0113, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0009,  0.0039,  ..., -0.0027,  0.0052,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0156, -0.0034,  ...,  0.0130,  0.0047, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0154, -0.0025,  ...,  0.0010,  0.0076,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0187, -0.0014,  ...,  0.0073,  0.0023,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.7196e-04,  5.5397e-03, -1.3636e-03,  ...,  3.0628e-03,\n",
      "          6.3729e-04, -3.2212e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0018,  0.0002,  ...,  0.0138,  0.0099, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0023, -0.0041,  ...,  0.0073,  0.0073, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[1.6664e-03, 6.6890e-04, 1.1180e-03,  ..., 7.8436e-06, 4.5511e-03,\n",
      "         8.6004e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0109,  0.0024,  ..., -0.0089,  0.0049,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033,  0.0027,  0.0007,  ..., -0.0024, -0.0047,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0016, -0.0074,  ...,  0.0085,  0.0060, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0036, -0.0039,  ...,  0.0054,  0.0057, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0176, -0.0070,  ...,  0.0131,  0.0019,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0161,  0.0011,  ...,  0.0112,  0.0087, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006, -0.0076, -0.0060,  ...,  0.0103,  0.0033, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0057, -0.0096,  0.0010,  ..., -0.0077,  0.0040,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059,  0.0073, -0.0026,  ...,  0.0027,  0.0070, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0107,  0.0156,  0.0027,  ...,  0.0030, -0.0046,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0052,  0.0005,  ...,  0.0096,  0.0031,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0052, -0.0047,  ...,  0.0037,  0.0124, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047,  0.0043,  0.0079,  ...,  0.0080,  0.0025, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0174,  0.0026,  ..., -0.0009,  0.0077, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076,  0.0021, -0.0003,  ..., -0.0012,  0.0034,  0.0115]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028,  0.0167, -0.0059,  ...,  0.0029,  0.0066, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0054, 0.0114, 0.0021,  ..., 0.0099, 0.0064, 0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0009,  0.0004,  ..., -0.0036,  0.0040,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040,  0.0039,  0.0015,  ...,  0.0171,  0.0031, -0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054, -0.0099, -0.0005,  ..., -0.0038,  0.0082,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.4194e-03, -5.0479e-03,  3.7095e-03,  ...,  2.3083e-05,\n",
      "          4.3163e-03,  2.7346e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0105,  0.0103, -0.0005,  ...,  0.0112,  0.0003, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0002,  0.0036,  ...,  0.0086,  0.0009, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0129,  0.0001,  ...,  0.0003, -0.0005, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0063, -0.0007,  ...,  0.0053,  0.0021,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0011, -0.0068,  ...,  0.0143,  0.0102, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029, -0.0103,  0.0037,  ...,  0.0056,  0.0060,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0040, -0.0059,  ..., -0.0049,  0.0057,  0.0127]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 8.8884e-05, -2.1580e-03, -8.3338e-04,  ...,  1.4228e-02,\n",
      "         -7.3427e-04, -1.4354e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0025,  0.0021,  ...,  0.0054,  0.0071, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0077,  0.0018,  ...,  0.0158,  0.0057, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0185,  0.0059,  ..., -0.0091,  0.0017,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0049,  0.0014,  ..., -0.0006,  0.0017,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0049, -0.0058,  ...,  0.0080,  0.0062,  0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030,  0.0056,  0.0020,  ...,  0.0001,  0.0115, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0110,  0.0118,  0.0025,  ...,  0.0146,  0.0045, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0118, -0.0018,  ...,  0.0029,  0.0075, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0047,  0.0009,  ...,  0.0010,  0.0147, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0078, -0.0002,  ..., -0.0066, -0.0007, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0026, -0.0014,  ..., -0.0089,  0.0064, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0006,  0.0061,  ..., -0.0013, -0.0005,  0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0016, -0.0013,  ..., -0.0013,  0.0007,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0026,  0.0002,  ...,  0.0009,  0.0027, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028,  0.0054, -0.0037,  ...,  0.0002,  0.0011, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0052,  0.0113,  ...,  0.0088,  0.0048,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055,  0.0005,  0.0039,  ...,  0.0016,  0.0071, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0097,  0.0045,  ...,  0.0045, -0.0051,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0027, -0.0064,  0.0022,  ...,  0.0032, -0.0031,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0011, 0.0042, 0.0032,  ..., 0.0008, 0.0014, 0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0067, -0.0062,  ..., -0.0025,  0.0055,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034, -0.0102,  0.0055,  ...,  0.0026,  0.0025,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0022, -0.0070,  ...,  0.0062,  0.0062,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0035,  0.0012,  ...,  0.0189,  0.0079, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0032, -0.0002,  ...,  0.0054,  0.0059, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0017, -0.0043,  ...,  0.0046,  0.0021,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0080,  0.0038,  ...,  0.0024,  0.0107,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0090, -0.0004,  ...,  0.0031,  0.0089, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0019, -0.0001,  ...,  0.0077,  0.0026, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039, -0.0109,  0.0025,  ..., -0.0015,  0.0025,  0.0086]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0007,  0.0031,  ...,  0.0074,  0.0026,  0.0145]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0024,  0.0034,  ..., -0.0077, -0.0034,  0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0002, -0.0011,  ...,  0.0110,  0.0050, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0182, -0.0085,  ..., -0.0057,  0.0016,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0152, -0.0034,  ...,  0.0052,  0.0079, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0127,  0.0059,  ...,  0.0172,  0.0048, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0031, -0.0010,  ...,  0.0159,  0.0053, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0034, -0.0012,  ...,  0.0027,  0.0061, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0065, -0.0103,  0.0039,  ...,  0.0072,  0.0080, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.7336e-03,  3.1581e-03, -2.1040e-03,  ...,  5.2935e-03,\n",
      "         -2.0569e-03,  7.0367e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0028, -0.0063,  ...,  0.0110,  0.0049, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0044,  0.0073,  ...,  0.0034, -0.0065,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0072,  0.0045, -0.0048,  ...,  0.0057,  0.0058, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.8915e-03,  1.8141e-02, -7.1390e-03,  ...,  1.6155e-03,\n",
      "         -8.8242e-05, -4.0367e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0091, -0.0021,  ...,  0.0003,  0.0028,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0007, -0.0088,  ...,  0.0051, -0.0017,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0006, -0.0025,  ...,  0.0062,  0.0103,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0063, -0.0059,  0.0012,  ...,  0.0076, -0.0005, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007,  0.0072, -0.0013,  ...,  0.0132,  0.0007, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0088,  0.0070,  ...,  0.0067,  0.0051,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.6836e-03, -9.8683e-05,  4.7543e-04,  ..., -5.3780e-03,\n",
      "          1.9541e-03,  5.3530e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029,  0.0043, -0.0024,  ...,  0.0102,  0.0067,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0032, -0.0027,  ...,  0.0037,  0.0019,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048, -0.0029,  0.0073,  ..., -0.0014, -0.0024,  0.0092]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001,  0.0060, -0.0076,  ...,  0.0052,  0.0101,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0103, -0.0018,  ...,  0.0058,  0.0123,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.6927e-03,  6.1722e-03, -2.7808e-03,  ...,  9.0024e-04,\n",
      "          8.3035e-03, -8.6273e-06]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0114, -0.0053,  0.0081,  ..., -0.0020,  0.0056, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057,  0.0171, -0.0092,  ...,  0.0063,  0.0076, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0018, 0.0152, 0.0010,  ..., 0.0097, 0.0036, 0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0037, -0.0004,  ..., -0.0048,  0.0056,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0048,  0.0050,  ...,  0.0087,  0.0104, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.4979e-03,  5.7738e-03, -7.2846e-05,  ...,  4.5707e-03,\n",
      "         -1.7098e-03, -1.9087e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0019,  0.0031,  ...,  0.0015, -0.0052,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0053, -0.0046,  ...,  0.0008,  0.0028, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.2903e-02, -4.1037e-03, -9.6974e-05,  ...,  6.9608e-03,\n",
      "          6.9551e-03, -1.8473e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005, -0.0113, -0.0027,  ...,  0.0031,  0.0067,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0100, -0.0034,  0.0053,  ...,  0.0038,  0.0044, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0089, -0.0040,  ...,  0.0061,  0.0077, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0038,  0.0060,  ...,  0.0121,  0.0026,  0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068, -0.0009, -0.0031,  ..., -0.0013, -0.0022,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.3020e-04,  1.6763e-03, -5.2282e-05,  ...,  4.5140e-03,\n",
      "          2.0952e-03,  4.1429e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0044, -0.0025,  ...,  0.0011,  0.0023, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0070, 0.0024, 0.0033,  ..., 0.0120, 0.0055, 0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0067,  0.0088, -0.0003,  ...,  0.0090,  0.0063, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0063,  0.0046,  ...,  0.0134,  0.0017, -0.0098]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0004,  0.0013,  ...,  0.0069,  0.0053, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.6480e-03, -8.2687e-03, -1.4774e-03,  ...,  1.1261e-02,\n",
      "          4.8057e-03, -3.4676e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0044, -0.0032,  ...,  0.0192,  0.0047, -0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0048,  0.0023,  ...,  0.0008, -0.0002, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0121,  0.0042, -0.0022,  ...,  0.0076,  0.0052,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0008,  0.0037,  ..., -0.0012,  0.0063,  0.0139]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0009, -0.0008,  ...,  0.0018,  0.0023,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0015, -0.0036,  ...,  0.0081,  0.0009,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0056,  0.0073,  0.0019,  ...,  0.0082,  0.0011, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0102,  0.0040,  0.0012,  ...,  0.0079,  0.0027, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0045,  0.0072,  ...,  0.0031,  0.0128,  0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0063,  0.0024,  ..., -0.0065,  0.0041,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036,  0.0071, -0.0021,  ...,  0.0005,  0.0047,  0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0022,  0.0142,  ...,  0.0056,  0.0042,  0.0097]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0045,  0.0054,  ...,  0.0044,  0.0042,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0012,  0.0044,  ...,  0.0164,  0.0072, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0140, -0.0017,  ...,  0.0083, -0.0002, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0106, -0.0003,  ...,  0.0029,  0.0072,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0095,  0.0077,  ...,  0.0087, -0.0005,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0060, -0.0103,  0.0076,  ...,  0.0054, -0.0021, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0135, -0.0019,  0.0053,  ...,  0.0050,  0.0063,  0.0130]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0127, -0.0025,  ...,  0.0123,  0.0017, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0072, -0.0050,  0.0018,  ..., -0.0045,  0.0071,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0084, -0.0035,  ...,  0.0054,  0.0093,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0036, -0.0065,  0.0100,  ..., -0.0036,  0.0052,  0.0118]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0257, -0.0046,  ..., -0.0078,  0.0051,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0081, -0.0019,  ...,  0.0117,  0.0123, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075, -0.0008, -0.0029,  ...,  0.0003,  0.0011, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025, -0.0136,  0.0042,  ...,  0.0031, -0.0040,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0055, -0.0024,  ..., -0.0040,  0.0038,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0114,  0.0030,  0.0017,  ...,  0.0128,  0.0021, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0007, -0.0077,  ...,  0.0049,  0.0063, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064,  0.0098, -0.0053,  ...,  0.0087,  0.0012,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0003, -0.0028,  ..., -0.0020, -0.0003,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0026, -0.0058,  ...,  0.0052,  0.0027, -0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0030, -0.0051,  ...,  0.0239,  0.0089, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0065, -0.0051,  ...,  0.0017,  0.0074,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0035,  0.0058,  ...,  0.0085,  0.0095,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053, -0.0063, -0.0002,  ...,  0.0061, -0.0041,  0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0098, -0.0095, -0.0039,  ..., -0.0022,  0.0037, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032,  0.0098, -0.0044,  ...,  0.0050,  0.0146,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0038,  0.0096,  ...,  0.0025,  0.0029,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0212, -0.0044,  ...,  0.0072,  0.0068, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0015, -0.0087, -0.0010,  ...,  0.0031,  0.0011, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001,  0.0013, -0.0013,  ...,  0.0031,  0.0029,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013,  0.0191, -0.0090,  ...,  0.0049,  0.0025, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0136, -0.0038,  ..., -0.0107, -0.0030, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0077, 0.0083, 0.0016,  ..., 0.0100, 0.0011, 0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 3.0037e-03,  7.5478e-03,  5.2134e-03,  ...,  1.4667e-02,\n",
      "          8.0826e-03, -6.3001e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043, -0.0089,  0.0013,  ...,  0.0064,  0.0053, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0159, -0.0014,  ...,  0.0052,  0.0026,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0037, 0.0037, 0.0035,  ..., 0.0070, 0.0025, 0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0069,  0.0060,  ...,  0.0078,  0.0050, -0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0026, -0.0030,  ...,  0.0073,  0.0038, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075,  0.0053, -0.0046,  ...,  0.0068,  0.0050, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0040,  0.0035,  ..., -0.0049,  0.0156,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0140, -0.0040,  ...,  0.0037,  0.0029, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021, -0.0045, -0.0052,  ...,  0.0010,  0.0023,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0026, -0.0050,  ..., -0.0038, -0.0003, -0.0092]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0035,  0.0205, -0.0021,  ...,  0.0029,  0.0094,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0050, -0.0049,  ..., -0.0018,  0.0001,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045, -0.0019, -0.0095,  ...,  0.0146,  0.0039, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0068,  0.0035, -0.0030,  ...,  0.0010,  0.0075,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038,  0.0148, -0.0027,  ...,  0.0059,  0.0045,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0001,  0.0026,  ...,  0.0097,  0.0029, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0042, -0.0026,  ..., -0.0019,  0.0001,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007, -0.0091, -0.0012,  ...,  0.0045,  0.0051,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002,  0.0142, -0.0011,  ...,  0.0109,  0.0102,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043,  0.0033, -0.0040,  ...,  0.0051,  0.0032, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0044, -0.0067,  ...,  0.0024,  0.0051,  0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0021, -0.0033,  ...,  0.0083,  0.0066, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037,  0.0062, -0.0036,  ...,  0.0121,  0.0038,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0052, -0.0072,  ...,  0.0007,  0.0107, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084, -0.0054,  0.0015,  ..., -0.0014, -0.0036,  0.0104]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0105,  0.0011,  ...,  0.0019,  0.0063, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0002, -0.0042, -0.0024,  ...,  0.0070,  0.0032,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063,  0.0123, -0.0054,  ...,  0.0100, -0.0007, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.8383e-03,  1.9713e-05, -3.9212e-03,  ...,  2.1895e-02,\n",
      "          7.2420e-03, -7.6102e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0052, -0.0065, -0.0034,  ...,  0.0022,  0.0065,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0112, -0.0046,  ...,  0.0070,  0.0050, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0035,  0.0026,  ...,  0.0063, -0.0029,  0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[2.0945e-04, 6.5405e-03, 3.5164e-04,  ..., 9.4748e-05, 1.8386e-03,\n",
      "         4.9322e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 5.0641e-05,  1.7347e-02, -1.5310e-03,  ...,  6.4362e-03,\n",
      "          4.6674e-03,  1.5515e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011, -0.0039, -0.0013,  ...,  0.0043,  0.0083, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054,  0.0180, -0.0018,  ..., -0.0007,  0.0013,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077, -0.0144,  0.0072,  ..., -0.0017,  0.0014,  0.0099]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0025, -0.0007,  ...,  0.0027,  0.0098,  0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0049,  0.0040,  ...,  0.0097,  0.0088, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0050,  0.0004,  ...,  0.0037,  0.0079,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0045, -0.0068,  0.0042,  ..., -0.0082,  0.0027,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0107,  0.0016,  ...,  0.0088,  0.0058, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0041, -0.0033,  ..., -0.0049,  0.0092, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027, -0.0029,  0.0010,  ...,  0.0036,  0.0055, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0075,  0.0080,  0.0018,  ..., -0.0063, -0.0004,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0117,  0.0026, -0.0037,  ...,  0.0044,  0.0138,  0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0132, -0.0004,  ...,  0.0010,  0.0023,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0027, -0.0051,  ...,  0.0085,  0.0033, -0.0066]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0051,  0.0059,  0.0040,  ..., -0.0092,  0.0027,  0.0119]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0050,  0.0010,  ...,  0.0078,  0.0019,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017, -0.0034, -0.0014,  ...,  0.0112,  0.0075, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0081, -0.0085, -0.0011,  ...,  0.0023,  0.0034, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0025, 0.0044, 0.0013,  ..., 0.0124, 0.0090, 0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0141,  0.0004,  ...,  0.0055, -0.0023, -0.0123]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0084, -0.0021,  ...,  0.0041,  0.0125, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0084, -0.0023,  ...,  0.0053,  0.0062,  0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0115,  0.0019,  ...,  0.0039,  0.0044, -0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0130, -0.0053,  ...,  0.0048,  0.0050,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0122, -0.0036,  ...,  0.0020,  0.0077,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0096,  0.0193, -0.0001,  ...,  0.0165,  0.0087,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0098, -0.0062,  0.0065,  ..., -0.0018,  0.0053,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0079, -0.0064, -0.0006,  ...,  0.0233,  0.0038, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0039, -0.0018,  ..., -0.0017,  0.0064,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0149, -0.0004,  ..., -0.0141,  0.0086,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0029, -0.0014, -0.0014,  ...,  0.0110,  0.0001, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0045,  0.0017,  ...,  0.0026,  0.0152,  0.0099]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0051,  0.0080,  ...,  0.0076,  0.0044, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025, -0.0010,  0.0034,  ...,  0.0025,  0.0036,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020, -0.0090,  0.0010,  ..., -0.0065,  0.0050,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0077, -0.0061,  ...,  0.0003,  0.0034, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0097, -0.0048,  0.0043,  ...,  0.0040,  0.0023, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0147, -0.0010,  ..., -0.0057,  0.0020, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0032, -0.0009,  ..., -0.0077,  0.0040,  0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0079,  0.0046,  ..., -0.0104,  0.0004,  0.0101]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0096,  0.0003,  ...,  0.0101,  0.0074, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0051, -0.0023,  ...,  0.0147,  0.0069, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0007, -0.0131, -0.0079,  ...,  0.0017,  0.0085, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0069, -0.0010,  ...,  0.0111,  0.0044, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0047, -0.0156,  0.0120,  ...,  0.0077, -0.0017, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004,  0.0017, -0.0049,  ...,  0.0058,  0.0175,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0046,  0.0036,  ...,  0.0094,  0.0081, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0016,  0.0008,  ...,  0.0087, -0.0043, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060,  0.0174, -0.0033,  ...,  0.0148,  0.0076, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015,  0.0153,  0.0025,  ...,  0.0149,  0.0057, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0011,  0.0015,  ...,  0.0045,  0.0048,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032, -0.0005,  0.0024,  ..., -0.0046,  0.0013,  0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0121,  0.0021,  ...,  0.0091,  0.0076, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0136,  0.0072,  ...,  0.0007,  0.0103,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0136, -0.0039,  ..., -0.0044,  0.0053, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0040, -0.0041,  ...,  0.0013, -0.0021,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0042,  0.0021,  ...,  0.0057,  0.0114, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0032,  0.0029,  0.0012,  ..., -0.0062,  0.0028,  0.0162]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0046,  0.0048,  ..., -0.0019, -0.0011,  0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0087,  0.0040,  ...,  0.0213,  0.0023, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0038,  0.0026,  ..., -0.0066,  0.0021,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054,  0.0016, -0.0021,  ...,  0.0117,  0.0013, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0024, 0.0027, 0.0026,  ..., 0.0029, 0.0120, 0.0122]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0094, -0.0055, -0.0026,  ...,  0.0015,  0.0099, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009, -0.0143,  0.0005,  ...,  0.0059,  0.0041, -0.0072]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0024, -0.0026,  0.0064,  ..., -0.0006,  0.0019, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0088,  0.0021,  ...,  0.0017,  0.0062, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0031, -0.0024,  ...,  0.0071, -0.0039, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0147, -0.0072,  ...,  0.0091, -0.0003,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0007,  0.0003, -0.0099,  ...,  0.0165,  0.0062, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0133, 0.0093, 0.0013,  ..., 0.0139, 0.0055, 0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0108,  0.0034,  0.0030,  ...,  0.0018, -0.0008,  0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0010, 0.0042, 0.0072,  ..., 0.0027, 0.0040, 0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.8991e-03,  5.7246e-03,  2.7443e-03,  ..., -5.5042e-03,\n",
      "          8.4592e-04,  5.4243e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0120, -0.0017,  ...,  0.0117,  0.0030,  0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0055,  0.0016,  ..., -0.0037,  0.0013, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026, -0.0045, -0.0005,  ...,  0.0042,  0.0039, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0059, -0.0063, -0.0046,  ...,  0.0120,  0.0060, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0080, -0.0028,  ...,  0.0053,  0.0045,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0077, -0.0023,  ..., -0.0020,  0.0038,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0063,  0.0056,  ..., -0.0029,  0.0101,  0.0131]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.1946e-02,  2.5108e-03, -1.1930e-03,  ...,  8.1492e-05,\n",
      "          4.7876e-03,  3.8928e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0028, -0.0056,  ...,  0.0119,  0.0048,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0051,  0.0009,  ...,  0.0070,  0.0041,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0067,  0.0045,  ..., -0.0004,  0.0034,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0093, -0.0100,  0.0063,  ..., -0.0015,  0.0110, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0026,  0.0066,  ...,  0.0012,  0.0036,  0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0021,  0.0056,  ...,  0.0074,  0.0072, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014,  0.0166, -0.0066,  ..., -0.0050,  0.0013,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0114, 0.0078, 0.0023,  ..., 0.0116, 0.0029, 0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033,  0.0034, -0.0112,  ..., -0.0005,  0.0071,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089, -0.0068, -0.0042,  ...,  0.0028,  0.0023,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0106, -0.0017,  ..., -0.0050,  0.0084,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0009,  0.0111,  0.0035,  ...,  0.0068, -0.0019, -0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089,  0.0036, -0.0026,  ..., -0.0054, -0.0015,  0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0041, 0.0111, 0.0022,  ..., 0.0018, 0.0099, 0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0090, -0.0008, -0.0026,  ...,  0.0038,  0.0080,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0080, -0.0033, -0.0016,  ..., -0.0096,  0.0012,  0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0105, -0.0020,  ..., -0.0044, -0.0007, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0165, -0.0002,  ..., -0.0037,  0.0045,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0004, -0.0163, -0.0025,  ...,  0.0038,  0.0050,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028, -0.0093,  0.0043,  ...,  0.0080,  0.0014,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0117,  0.0210, -0.0019,  ...,  0.0174,  0.0040,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003,  0.0014, -0.0013,  ..., -0.0030,  0.0043, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0154,  0.0012,  ...,  0.0105, -0.0012,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0001,  0.0050,  0.0043,  ...,  0.0108,  0.0092, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016,  0.0088,  0.0002,  ..., -0.0005,  0.0033, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048, -0.0055,  0.0015,  ...,  0.0027,  0.0100, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0104, -0.0101,  ...,  0.0154,  0.0075,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0139,  0.0049,  ..., -0.0050,  0.0076, -0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026, -0.0019,  0.0050,  ..., -0.0012, -0.0012,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0066,  0.0018, -0.0025,  ...,  0.0097,  0.0041, -0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0046,  0.0071,  ...,  0.0030,  0.0046, -0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0074, -0.0002,  ...,  0.0117,  0.0026, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0077,  0.0028,  ..., -0.0049,  0.0078,  0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0041, -0.0010,  ...,  0.0023,  0.0054,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0067,  0.0046,  ...,  0.0026,  0.0022, -0.0096]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0073,  0.0085,  ...,  0.0023,  0.0051, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0053,  0.0122,  ...,  0.0096,  0.0022, -0.0083]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0016, -0.0082,  0.0037,  ..., -0.0021,  0.0130, -0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0103, -0.0003,  ...,  0.0099,  0.0039, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0075,  0.0205, -0.0040,  ...,  0.0070,  0.0079, -0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0083, -0.0016,  ...,  0.0086,  0.0046, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0011, 0.0026, 0.0015,  ..., 0.0059, 0.0064, 0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0003, -0.0032,  ...,  0.0082,  0.0055, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0023,  0.0017,  ...,  0.0032,  0.0033,  0.0081]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0019,  0.0058,  ...,  0.0073,  0.0006,  0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0043,  0.0056, -0.0049,  ..., -0.0051,  0.0014,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011, -0.0065, -0.0065,  ..., -0.0078,  0.0147,  0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0107, -0.0102, -0.0010,  ..., -0.0064,  0.0035,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0019, -0.0045,  ..., -0.0005,  0.0066, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023,  0.0175,  0.0070,  ...,  0.0144,  0.0079, -0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.8744e-04, -4.4179e-03,  1.2591e-02,  ...,  4.0000e-05,\n",
      "          6.5069e-03,  3.0688e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0034,  0.0045,  0.0028,  ..., -0.0005,  0.0046,  0.0147]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0035, -0.0028,  ...,  0.0078,  0.0044, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0086, -0.0037,  0.0080,  ...,  0.0059,  0.0017,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0001, -0.0036,  ...,  0.0050,  0.0048, -0.0028]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100, -0.0013, -0.0048,  ...,  0.0139,  0.0038, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0118, -0.0022,  ...,  0.0146,  0.0117,  0.0057]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044,  0.0010,  0.0018,  ..., -0.0006,  0.0077, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0059, -0.0025,  ..., -0.0030,  0.0066, -0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0053, -0.0070,  ...,  0.0092,  0.0045,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0021,  0.0071,  ...,  0.0089,  0.0050, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048,  0.0026, -0.0002,  ...,  0.0078,  0.0145,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0064, -0.0084, -0.0026,  ...,  0.0158,  0.0064, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0050,  0.0013,  ...,  0.0074,  0.0054, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0029,  0.0095, -0.0045,  ...,  0.0078,  0.0048, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0161, -0.0004,  ..., -0.0057, -0.0017, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037, -0.0130, -0.0004,  ..., -0.0035,  0.0062,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0053, -0.0098,  ..., -0.0021,  0.0070,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.8384e-03, -2.3559e-03, -3.5258e-05,  ...,  1.3777e-03,\n",
      "          2.8013e-03, -2.0440e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0021,  0.0006,  0.0035,  ...,  0.0113,  0.0071, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0053, -0.0021,  ..., -0.0013,  0.0047, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0063,  0.0014,  ..., -0.0066,  0.0065,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031, -0.0002, -0.0033,  ...,  0.0047,  0.0009, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0003,  0.0022,  ...,  0.0064,  0.0033, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0009, 0.0092, 0.0008,  ..., 0.0061, 0.0056, 0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042, -0.0065, -0.0019,  ...,  0.0157,  0.0048, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0089,  0.0056,  ..., -0.0056, -0.0020, -0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0104, -0.0030,  ...,  0.0043,  0.0044, -0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0054,  0.0004,  ...,  0.0045,  0.0052,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0184,  0.0007,  ...,  0.0045,  0.0052, -0.0071]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0109, -0.0009, -0.0038,  ...,  0.0115,  0.0088,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0022,  0.0027,  ...,  0.0152,  0.0067, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055,  0.0094, -0.0074,  ...,  0.0009, -0.0014,  0.0116]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0057,  0.0005,  ..., -0.0005,  0.0038, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0040,  0.0032,  ..., -0.0048,  0.0057,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0080, -0.0005,  ...,  0.0106, -0.0003, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0004, -0.0060,  ...,  0.0046,  0.0049, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0080, -0.0010,  ...,  0.0025, -0.0007,  0.0145]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0014,  0.0033,  0.0013,  ...,  0.0040,  0.0066, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0088,  0.0172, -0.0020,  ...,  0.0039,  0.0058,  0.0070]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0026,  0.0126, -0.0018,  ...,  0.0045, -0.0077,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058,  0.0072, -0.0069,  ...,  0.0129,  0.0061, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0080,  0.0057,  ..., -0.0069,  0.0048,  0.0095]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016,  0.0060, -0.0019,  ...,  0.0143,  0.0024, -0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0052,  0.0023,  ...,  0.0051,  0.0039,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0120,  0.0025,  ...,  0.0003,  0.0048, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0004, -0.0136,  0.0020,  ...,  0.0124,  0.0030, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0170,  0.0026,  ..., -0.0041,  0.0038,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0120,  0.0076,  ..., -0.0014,  0.0051,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0017, 0.0128, 0.0016,  ..., 0.0134, 0.0076, 0.0107]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0111,  0.0079,  ...,  0.0021,  0.0046,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0077,  0.0084, -0.0055,  ...,  0.0110,  0.0097, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0073, -0.0008, -0.0057,  ...,  0.0194,  0.0081,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0139, -0.0038,  ...,  0.0002,  0.0043, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0048, -0.0004,  ..., -0.0013,  0.0058,  0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0043, -0.0006,  ...,  0.0035, -0.0032,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0050, -0.0029,  ...,  0.0058,  0.0018, -0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0054,  0.0049,  0.0078,  ...,  0.0121, -0.0037, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0066, -0.0048,  ...,  0.0076,  0.0090,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018, -0.0016,  0.0018,  ...,  0.0095,  0.0067, -0.0017]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018,  0.0235, -0.0035,  ...,  0.0092,  0.0068, -0.0041]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013, -0.0044, -0.0021,  ...,  0.0015,  0.0054,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0034, -0.0037,  ..., -0.0101,  0.0087,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040, -0.0055,  0.0067,  ...,  0.0059,  0.0037,  0.0069]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.0828e-03,  1.7405e-03, -3.3295e-03,  ...,  1.0491e-02,\n",
      "          2.2748e-03, -9.6761e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0062, -0.0023,  ...,  0.0092,  0.0037, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040, -0.0074,  0.0063,  ..., -0.0033,  0.0009, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046,  0.0013, -0.0015,  ...,  0.0063,  0.0058, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-8.5233e-03, -3.9137e-03,  3.5976e-03,  ...,  4.1201e-05,\n",
      "          2.1787e-03,  3.7539e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0162, -0.0061,  ..., -0.0017,  0.0023,  0.0102]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0050, -0.0070,  ...,  0.0037,  0.0094, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015, -0.0007, -0.0066,  ...,  0.0029,  0.0060, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022, -0.0071, -0.0011,  ...,  0.0205,  0.0051, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0097, -0.0059, -0.0022,  ...,  0.0049,  0.0052, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0085,  0.0109,  0.0075,  ..., -0.0032,  0.0021, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0012, -0.0058,  ...,  0.0112,  0.0052, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0023,  0.0054,  ...,  0.0004,  0.0006,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0031,  0.0101,  0.0065,  ...,  0.0112,  0.0072, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0165,  0.0029,  ...,  0.0041,  0.0006, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0046, -0.0059, -0.0002,  ...,  0.0037,  0.0049,  0.0009]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050,  0.0061,  0.0036,  ..., -0.0015, -0.0036,  0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0052,  0.0066,  ...,  0.0159,  0.0084, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0078, -0.0051,  0.0017,  ..., -0.0045,  0.0043,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0188, -0.0043,  ...,  0.0060,  0.0038, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0031, -0.0009,  ...,  0.0108,  0.0086, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078, -0.0022, -0.0027,  ...,  0.0120,  0.0029, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0137, -0.0002,  ...,  0.0100, -0.0024, -0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0097, -0.0023,  ...,  0.0079,  0.0103, -0.0079]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0006,  0.0069,  0.0007,  ...,  0.0050, -0.0006,  0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0032, -0.0033,  ...,  0.0113,  0.0123,  0.0091]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0017,  0.0009, -0.0036,  ...,  0.0009,  0.0046, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0007,  0.0201, -0.0016,  ...,  0.0137,  0.0020, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0012, 0.0010, 0.0005,  ..., 0.0024, 0.0082, 0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0030, -0.0073,  0.0009,  ..., -0.0021,  0.0076,  0.0110]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0014,  0.0020, -0.0039,  ...,  0.0034,  0.0042,  0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055, -0.0007,  0.0026,  ..., -0.0005,  0.0071,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0091, 0.0036, 0.0048,  ..., 0.0051, 0.0062, 0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036,  0.0006,  0.0068,  ...,  0.0141,  0.0048, -0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-1.1470e-03, -1.3122e-02,  2.2040e-03,  ..., -5.6272e-03,\n",
      "          2.6141e-03,  1.1145e-05]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.0186e-03, -2.9914e-03, -4.0431e-03,  ...,  1.0439e-02,\n",
      "          8.0698e-07, -3.1294e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0047, -0.0008, -0.0011,  ...,  0.0186,  0.0041, -0.0082]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0030, -0.0035,  ...,  0.0038,  0.0052,  0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0113, -0.0010,  0.0054,  ...,  0.0068,  0.0048,  0.0065]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040, -0.0047,  0.0036,  ...,  0.0064,  0.0037, -0.0068]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019, -0.0073, -0.0015,  ..., -0.0043,  0.0047,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069, -0.0127,  0.0023,  ...,  0.0036, -0.0011, -0.0053]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-6.2700e-06, -4.9852e-03, -2.2901e-03,  ..., -4.7263e-03,\n",
      "          2.2735e-03, -8.1721e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008,  0.0127,  0.0045,  ...,  0.0149,  0.0059, -0.0074]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0028,  0.0039, -0.0053,  ...,  0.0123,  0.0032, -0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031, -0.0037, -0.0033,  ...,  0.0042,  0.0034, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0037,  0.0012,  ...,  0.0011,  0.0083, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0087, -0.0005,  ...,  0.0055,  0.0034,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034, -0.0125, -0.0030,  ..., -0.0027,  0.0060,  0.0103]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0071,  0.0050, -0.0006,  ...,  0.0108,  0.0049, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022, -0.0012, -0.0031,  ..., -0.0018, -0.0018,  0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0042, -0.0027,  0.0046,  ...,  0.0094,  0.0018, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0063,  0.0039, -0.0034,  ...,  0.0042,  0.0102,  0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0013, -0.0062,  ...,  0.0086,  0.0062,  0.0033]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072, -0.0033, -0.0015,  ..., -0.0005,  0.0021,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0071, -0.0031, -0.0014,  ...,  0.0086,  0.0078, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0065,  0.0040,  ...,  0.0072,  0.0063,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0048, 0.0059, 0.0026,  ..., 0.0006, 0.0022, 0.0124]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035, -0.0129,  0.0034,  ...,  0.0011,  0.0022,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0041, -0.0048,  0.0055,  ..., -0.0002, -0.0008,  0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0011,  0.0132, -0.0026,  ..., -0.0033, -0.0018, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0027,  0.0090, -0.0060,  ..., -0.0037,  0.0012,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0037, -0.0010,  0.0047,  ...,  0.0153, -0.0001, -0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0057,  0.0006,  ...,  0.0104,  0.0042,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012, -0.0031,  0.0030,  ..., -0.0009,  0.0090,  0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0022,  0.0081,  ...,  0.0122,  0.0087, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0005,  0.0134,  0.0027,  ...,  0.0027,  0.0042,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0058, -0.0040,  0.0110,  ...,  0.0063,  0.0081, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010,  0.0058, -0.0013,  ...,  0.0158,  0.0043,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0022,  0.0053, -0.0005,  ...,  0.0107,  0.0187,  0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0078,  0.0156, -0.0024,  ...,  0.0012,  0.0126,  0.0001]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0023, -0.0075, -0.0064,  ...,  0.0051,  0.0035, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0161, -0.0031,  ...,  0.0040,  0.0129,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0047, 0.0178, 0.0037,  ..., 0.0166, 0.0055, 0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037,  0.0009,  0.0025,  ...,  0.0032,  0.0058, -0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019, -0.0045,  0.0006,  ..., -0.0057,  0.0103, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0068,  0.0012,  ..., -0.0070,  0.0071,  0.0092]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0048,  0.0225, -0.0036,  ...,  0.0040,  0.0101,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0074,  0.0120, -0.0011,  ...,  0.0073,  0.0078, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006,  0.0097, -0.0037,  ...,  0.0108,  0.0008, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033,  0.0019,  0.0004,  ...,  0.0013,  0.0027,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089, -0.0063,  0.0047,  ...,  0.0025,  0.0089,  0.0090]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0051,  0.0006,  0.0029,  ..., -0.0005,  0.0016,  0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0020, -0.0028,  ...,  0.0116, -0.0021, -0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0082,  0.0084,  ...,  0.0111,  0.0033, -0.0078]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0026,  0.0077,  0.0005,  ...,  0.0036,  0.0076,  0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0114,  0.0066,  ...,  0.0104, -0.0010, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0035,  0.0038,  0.0011,  ...,  0.0108,  0.0010, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0023, -0.0014, -0.0037,  ...,  0.0003,  0.0086,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0044, -0.0038, -0.0064,  ...,  0.0068,  0.0015,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0032, -0.0036, -0.0038,  ...,  0.0061,  0.0046, -0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0039,  0.0027,  0.0061,  ...,  0.0049,  0.0040, -0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0008, -0.0079,  0.0071,  ...,  0.0007,  0.0026,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003, -0.0027,  0.0013,  ...,  0.0085,  0.0038,  0.0042]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0053,  0.0022,  0.0015,  ..., -0.0078,  0.0011,  0.0093]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0016, -0.0010,  ...,  0.0077,  0.0046, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0040, -0.0046,  ..., -0.0074,  0.0012,  0.0045]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 6.7937e-04, -3.8102e-05, -3.5025e-03,  ...,  6.8458e-03,\n",
      "         -4.8022e-03, -6.5637e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0055, -0.0069,  0.0002,  ...,  0.0076, -0.0005, -0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0011,  0.0037, -0.0025,  ...,  0.0162,  0.0014, -0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0036, -0.0053, -0.0052,  ..., -0.0053,  0.0053,  0.0112]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010, -0.0074,  0.0056,  ...,  0.0021, -0.0001,  0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039, -0.0002,  0.0018,  ...,  0.0131,  0.0057,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0054, -0.0011,  0.0038,  ...,  0.0042,  0.0003, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0012,  0.0091, -0.0008,  ...,  0.0124,  0.0059, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069,  0.0018,  0.0005,  ...,  0.0117, -0.0003,  0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0016, 0.0013, 0.0086,  ..., 0.0017, 0.0039, 0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-5.2544e-03,  8.3666e-03,  8.3758e-05,  ...,  3.6629e-03,\n",
      "          3.5544e-03,  6.3415e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0003,  0.0120, -0.0057,  ..., -0.0118,  0.0007,  0.0063]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0031,  0.0029, -0.0062,  ..., -0.0034,  0.0005,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0076, -0.0115, -0.0061,  ..., -0.0020,  0.0077,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030,  0.0012,  0.0031,  ...,  0.0191,  0.0039, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0077,  0.0126, -0.0005,  ...,  0.0121,  0.0078, -0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0042, 0.0025, 0.0048,  ..., 0.0061, 0.0087, 0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0007, 0.0013, 0.0010,  ..., 0.0035, 0.0017, 0.0121]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0030, -0.0063, -0.0039,  ...,  0.0056,  0.0050,  0.0023]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0002,  0.0048,  0.0011,  ...,  0.0193,  0.0024, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0076, -0.0036,  0.0060,  ...,  0.0019,  0.0022,  0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0021,  0.0134, -0.0059,  ..., -0.0039,  0.0017, -0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0064,  0.0033,  0.0013,  ...,  0.0033,  0.0005, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0082,  0.0030, -0.0017,  ...,  0.0100,  0.0020,  0.0049]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0032,  0.0092,  ...,  0.0078,  0.0064,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0075,  0.0034,  ...,  0.0043,  0.0103, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0163, -0.0023,  ...,  0.0034,  0.0047,  0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0030, 0.0003, 0.0049,  ..., 0.0093, 0.0035, 0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0003,  0.0003,  ...,  0.0066,  0.0042,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012,  0.0124,  0.0001,  ...,  0.0058,  0.0011, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0095,  0.0002,  0.0043,  ...,  0.0064, -0.0007, -0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0040, -0.0101,  0.0060,  ..., -0.0038,  0.0014, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0019,  0.0027,  0.0012,  ...,  0.0117,  0.0072, -0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0067, -0.0071,  ...,  0.0005,  0.0024,  0.0088]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 6.1989e-05,  2.5296e-03, -1.5530e-03,  ..., -3.4087e-04,\n",
      "         -1.6040e-03, -2.5569e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 1.7843e-03, -1.0522e-02, -4.4256e-06,  ..., -2.6977e-03,\n",
      "          1.0853e-02, -1.1118e-02]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0124,  0.0034, -0.0032,  ..., -0.0093,  0.0104,  0.0077]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0037,  0.0020, -0.0040,  ...,  0.0087,  0.0027, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0020,  0.0083, -0.0018,  ...,  0.0066, -0.0003, -0.0064]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0060, -0.0040,  0.0088,  ...,  0.0022, -0.0060,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0056, -0.0040,  ...,  0.0117,  0.0050, -0.0026]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0016, -0.0066,  ...,  0.0046,  0.0052, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0012, -0.0040,  ...,  0.0098,  0.0064,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0057, -0.0076, -0.0104,  ..., -0.0076,  0.0058,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0048,  0.0014,  ...,  0.0121,  0.0047,  0.0089]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0028, -0.0063,  0.0033,  ...,  0.0110,  0.0056, -0.0059]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004,  0.0271, -0.0041,  ...,  0.0022,  0.0175,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0097, -0.0010,  ...,  0.0084,  0.0096,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0018,  0.0227, -0.0078,  ...,  0.0040,  0.0047, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0050, -0.0114,  0.0006,  ...,  0.0019,  0.0031,  0.0035]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0067,  0.0031,  0.0024,  ...,  0.0091,  0.0058, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0065,  0.0217, -0.0044,  ...,  0.0109,  0.0083, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0018, -0.0015, -0.0006,  ...,  0.0036,  0.0056,  0.0004]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003, -0.0031,  0.0052,  ...,  0.0033,  0.0030,  0.0062]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0009,  0.0023,  ...,  0.0122,  0.0028, -0.0037]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0002, -0.0024,  ...,  0.0039,  0.0058, -0.0003]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0056,  0.0004, -0.0024,  ..., -0.0042,  0.0151, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0084, -0.0065, -0.0043,  ..., -0.0096,  0.0030,  0.0073]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0049,  0.0002,  0.0055,  ...,  0.0196,  0.0049, -0.0046]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0001,  0.0035,  0.0045,  ..., -0.0035, -0.0003,  0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0091,  0.0090, -0.0048,  ...,  0.0047,  0.0033, -0.0051]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0037,  0.0022,  ..., -0.0029,  0.0038,  0.0149]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017, -0.0032,  0.0096,  ...,  0.0162,  0.0076, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0141,  0.0030,  ...,  0.0059,  0.0077, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025, -0.0075, -0.0002,  ...,  0.0028,  0.0034,  0.0047]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0046, -0.0050, -0.0002,  ...,  0.0079, -0.0006, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0112,  0.0015,  ...,  0.0069,  0.0069, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0084, -0.0024,  0.0012,  ...,  0.0151,  0.0105,  0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0022,  0.0063, -0.0017,  ...,  0.0088,  0.0055, -0.0039]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0017,  0.0110,  0.0008,  ...,  0.0020,  0.0009,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0023,  0.0024, -0.0068,  ...,  0.0103,  0.0004,  0.0067]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0037, -0.0036, -0.0008,  ...,  0.0040,  0.0068,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-4.7943e-03,  1.1103e-02,  3.5017e-03,  ..., -3.4081e-03,\n",
      "         -7.7471e-05,  4.8157e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0027, -0.0026,  ..., -0.0035,  0.0055,  0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0029, -0.0129,  0.0072,  ...,  0.0082,  0.0117,  0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0010, 0.0061, 0.0095,  ..., 0.0066, 0.0055, 0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0112,  0.0015,  ..., -0.0006,  0.0056,  0.0031]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0044, -0.0135,  0.0072,  ..., -0.0012, -0.0009,  0.0015]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038,  0.0035,  0.0032,  ...,  0.0171,  0.0060, -0.0032]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0048,  0.0033, -0.0015,  ...,  0.0065,  0.0040,  0.0036]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0057,  0.0116, -0.0010,  ...,  0.0144,  0.0063, -0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041,  0.0155, -0.0053,  ..., -0.0020,  0.0021, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0058, -0.0034, -0.0034,  ...,  0.0172,  0.0083, -0.0018]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0077, -0.0002,  0.0062,  ...,  0.0029,  0.0087,  0.0002]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0013, -0.0069,  0.0055,  ...,  0.0031,  0.0046,  0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0015, -0.0057, -0.0048,  ..., -0.0045,  0.0058,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0089,  0.0091, -0.0011,  ..., -0.0058,  0.0037, -0.0010]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0079,  0.0055,  0.0038,  ...,  0.0107,  0.0006, -0.0054]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020, -0.0068, -0.0011,  ...,  0.0135,  0.0043, -0.0027]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0042,  0.0049,  0.0009,  ...,  0.0170,  0.0074, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-3.9355e-03, -4.4357e-03,  1.8066e-04,  ...,  4.4125e-05,\n",
      "          5.7869e-03, -2.2929e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0041, 0.0004, 0.0010,  ..., 0.0194, 0.0055, 0.0005]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0019,  0.0045,  0.0023,  ...,  0.0160,  0.0044, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0098, -0.0024, -0.0009,  ...,  0.0097,  0.0085, -0.0050]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0039,  0.0043, -0.0003,  ...,  0.0057,  0.0084, -0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0015,  0.0015,  0.0041,  ..., -0.0043,  0.0012,  0.0108]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0045,  0.0171, -0.0037,  ...,  0.0078,  0.0063,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 4.8615e-05, -9.9115e-03, -8.2352e-05,  ...,  6.0086e-03,\n",
      "          3.9638e-03, -1.4037e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0025,  0.0054, -0.0012,  ...,  0.0068,  0.0028,  0.0016]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008, -0.0044,  0.0025,  ...,  0.0153,  0.0040, -0.0044]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005,  0.0014,  0.0011,  ...,  0.0008, -0.0033,  0.0061]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0008,  0.0036, -0.0016,  ..., -0.0034, -0.0043, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0095,  0.0010,  0.0033,  ...,  0.0121,  0.0028, -0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0014, -0.0133, -0.0005,  ..., -0.0010,  0.0077, -0.0011]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0158,  0.0064,  ..., -0.0103,  0.0065,  0.0056]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[ 0.0035, -0.0152, -0.0016,  ...,  0.0088,  0.0059,  0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0013,  0.0054,  0.0032,  ...,  0.0137,  0.0036, -0.0030]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0095,  0.0007,  ..., -0.0017,  0.0062,  0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0003,  0.0019,  0.0019,  ..., -0.0004,  0.0088, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0073,  0.0092, -0.0077,  ...,  0.0169,  0.0027, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0091,  0.0091,  0.0086,  ...,  0.0101,  0.0016, -0.0075]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[0.0095, 0.0071, 0.0012,  ..., 0.0045, 0.0150, 0.0102]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068,  0.0082, -0.0046,  ..., -0.0025, -0.0007,  0.0060]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0034,  0.0014, -0.0009,  ...,  0.0152,  0.0081, -0.0080]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.6915e-04,  2.5207e-03, -2.8782e-03,  ...,  6.1770e-03,\n",
      "         -1.7995e-05, -1.4970e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0113,  0.0060, -0.0048,  ...,  0.0031, -0.0009, -0.0048]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0055, -0.0061, -0.0015,  ...,  0.0012,  0.0028,  0.0038]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0038, -0.0054,  0.0061,  ...,  0.0014,  0.0110,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0038, -0.0065,  0.0088,  ...,  0.0093, -0.0019,  0.0058]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0004, -0.0108, -0.0050,  ...,  0.0121, -0.0014, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0040,  0.0175, -0.0033,  ..., -0.0040,  0.0015,  0.0105]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0072,  0.0018, -0.0015,  ...,  0.0130, -0.0023, -0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053, -0.0023, -0.0054,  ...,  0.0063, -0.0009, -0.0034]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0107, -0.0024,  ..., -0.0074,  0.0017, -0.0052]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0020,  0.0192, -0.0097,  ..., -0.0072,  0.0105,  0.0020]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0068, -0.0029, -0.0039,  ...,  0.0005,  0.0113, -0.0021]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0006, -0.0046,  0.0084,  ...,  0.0057,  0.0021,  0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 1.1032e-05, -6.4112e-03, -4.8411e-03,  ...,  7.8005e-03,\n",
      "          5.1942e-03, -3.3803e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0059, -0.0114,  0.0029,  ..., -0.0034,  0.0038,  0.0014]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0033,  0.0027, -0.0039,  ...,  0.0052,  0.0054, -0.0025]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0062, -0.0042, -0.0039,  ...,  0.0102,  0.0046, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0010,  0.0037, -0.0017,  ...,  0.0140,  0.0004, -0.0111]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[6.0037e-04, 6.1984e-04, 1.2068e-05,  ..., 1.8080e-02, 2.7567e-03,\n",
      "         2.6311e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0005, -0.0072,  0.0093,  ...,  0.0065, -0.0006, -0.0006]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0043, -0.0050,  0.0057,  ..., -0.0028,  0.0040,  0.0076]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0024,  0.0027, -0.0035,  ...,  0.0048, -0.0014, -0.0008]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0024, -0.0027,  0.0056,  ...,  0.0060,  0.0057,  0.0043]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0069,  0.0084,  0.0021,  ...,  0.0201,  0.0088, -0.0013]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-7.1389e-04, -2.8427e-03, -9.0033e-05,  ...,  8.0355e-03,\n",
      "         -2.0778e-03, -3.4551e-03]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0041, -0.0067, -0.0030,  ...,  0.0117,  0.0048, -0.0019]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD encoding: tensor([[-0.0026, -0.0021, -0.0034,  ...,  0.0130, -0.0014, -0.0055]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0053,  0.0063,  0.0013,  ...,  0.0050,  0.0054, -0.0029]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0033, -0.0045,  0.0041,  ...,  0.0049,  0.0033,  0.0007]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0012, -0.0099, -0.0007,  ...,  0.0063,  0.0041,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0025,  0.0185,  0.0017,  ..., -0.0043,  0.0045,  0.0087]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0010, -0.0077,  0.0021,  ..., -0.0019, -0.0009, -0.0022]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0100,  0.0170,  0.0030,  ...,  0.0003,  0.0019, -0.0040]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[ 0.0087, -0.0032,  0.0051,  ..., -0.0028,  0.0041, -0.0024]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n",
      "===> Loading data\n",
      "Input image shape: torch.Size([1, 3, 480, 640])\n",
      "===> Building model\n",
      "NetVLAD setting:\n",
      "num_clusters: 64 dim: 512 vladv2: False\n",
      "=> loading checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar' (epoch 25)\n",
      "===> Running evaluation step\n",
      "VLAD encoding: tensor([[-0.0016, -0.0049,  0.0076,  ..., -0.0011, -0.0007, -0.0012]])\n",
      "VLAD encoding shape: torch.Size([1, 32768])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "count = 0 \n",
    "directory = './images_for_pca_3000/'\n",
    "for image in os.listdir(directory):\n",
    "    f = os.path.join(directory, image)\n",
    "    if os.path.isfile(f):\n",
    "        p = Image.open(f)\n",
    "        p_vlad = VLAD_for_single_image(p)\n",
    "        p_vlad_concat_matr = np.concatenate((p_vlad_concat_matr, p_vlad), axis=0)\n",
    "p_vlad_concat_matr = p_vlad_concat_matr[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5bfadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf5004e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003, 32768)\n"
     ]
    }
   ],
   "source": [
    "print(p_vlad_concat_matr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd1905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00908969, -0.00480914,  0.00836766, ...,  0.00965593,\n",
       "         0.0028488 , -0.0046008 ],\n",
       "       [ 0.00459292,  0.01674666, -0.00384372, ...,  0.01326052,\n",
       "         0.00573615, -0.00181029],\n",
       "       [ 0.00046124, -0.00555784, -0.00079398, ...,  0.00075996,\n",
       "         0.00094595,  0.00073626],\n",
       "       [-0.00653614, -0.00595026,  0.00192419, ..., -0.00989878,\n",
       "         0.00325529,  0.0057391 ],\n",
       "       [ 0.00072431,  0.02031021, -0.00348831, ...,  0.00613002,\n",
       "         0.00496428,  0.00232265],\n",
       "       [ 0.00184875, -0.00576885, -0.00787531, ..., -0.00015842,\n",
       "         0.00223452,  0.00436096]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vlad_concat_matr[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1db8d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0923883 ,  0.17384748,  0.06526877, ...,  0.00624005,\n",
       "         0.00528885, -0.02646753],\n",
       "       [-0.18334485, -0.14500367, -0.12144351, ...,  0.0275242 ,\n",
       "         0.04787311, -0.01296853],\n",
       "       [ 0.03865132, -0.01592438,  0.05122822, ..., -0.03008664,\n",
       "         0.02482585, -0.00606288],\n",
       "       ...,\n",
       "       [-0.11864137, -0.22292976, -0.15394824, ..., -0.05625673,\n",
       "         0.03243032,  0.03846575],\n",
       "       [-0.04684437,  0.33223159, -0.04601528, ...,  0.04895419,\n",
       "         0.01530919,  0.02092999],\n",
       "       [ 0.22592491,  0.2571989 , -0.02190198, ...,  0.09683548,\n",
       "        -0.06919446,  0.03532588]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "pca.fit_transform(p_vlad_concat_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53236cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03887184 0.03143355 0.02490106 0.02192177 0.01668084 0.01481847\n",
      " 0.01365423 0.01203439 0.01101913 0.01037511 0.00895468 0.00859439\n",
      " 0.00774864 0.00721475 0.0065299  0.00624905 0.0059281  0.0057664\n",
      " 0.00538049 0.00520024 0.00499451 0.00482375 0.00462494 0.00446909\n",
      " 0.00444831 0.00424228 0.00421258 0.00404644 0.00389726 0.00376001\n",
      " 0.00361062 0.00352659 0.00342041 0.00333288 0.00330265 0.0032356\n",
      " 0.00319168 0.00313102 0.0030983  0.00293484 0.00287769 0.00279734\n",
      " 0.00273093 0.00268651 0.00265358 0.00256411 0.00249849 0.00243905\n",
      " 0.00239176 0.00237085 0.00234388 0.00228093 0.0022463  0.00222454\n",
      " 0.00215271 0.00214293 0.00212281 0.00210618 0.00204229 0.00200311\n",
      " 0.00199714 0.00193354 0.00191881 0.00190569]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606a5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(pca, open(\"pca2.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf7c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying PCA:\n",
      "Cosine Similarity \n",
      "for similar scenes: tensor([0.9138], dtype=torch.float64), \n",
      "for different scenes: tensor([0.7074], dtype=torch.float64)\n",
      "Ratio similar/different after applying PCA: tensor([1.2919], dtype=torch.float64)\n",
      "\n",
      "\n",
      "Before applying PCA:\n",
      "Cosine Similarity \n",
      "for similar scenes: tensor([0.6255]), \n",
      "for different scenes: tensor([0.3866])\n",
      "Ratio similar/different after applying PCA: tensor([1.6179])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1_vlad_64 = torch.from_numpy(pca.transform(p1_vlad))\n",
    "p2_vlad_64 = torch.from_numpy(pca.transform(p2_vlad))\n",
    "p3_vlad_64 = torch.from_numpy(pca.transform(p3_vlad))\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output_similar = cos(p1_vlad_64, p2_vlad_64)\n",
    "output_diff = cos(p1_vlad_64, p3_vlad_64)\n",
    "print(\"After applying PCA:\")\n",
    "print('Cosine Similarity \\nfor similar scenes: {}, \\nfor different scenes: {}'.format(output_similar, output_diff))\n",
    "print(f'Ratio similar/different after applying PCA: {output_similar/output_diff}')\n",
    "print('\\n')\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output_similar = cos(p1_vlad, p2_vlad)\n",
    "output_diff = cos(p1_vlad, p3_vlad)\n",
    "print(\"Before applying PCA:\")\n",
    "print('Cosine Similarity \\nfor similar scenes: {}, \\nfor different scenes: {}'.format(output_similar, output_diff))\n",
    "print(f'Ratio similar/different after applying PCA: {output_similar/output_diff}')\n",
    "print('\\n')\n",
    "#output_similar_evil = cos(p1_vlad_evil, p2_vlad_evil)\n",
    "#output_diff_evil = cos(p1_vlad_evil, p3_vlad_evil)\n",
    "#print('Cosine Similarity (Evil model) \\nfor similar scenes: {}, \\nfor different scenes: {}'.format(output_similar_evil, output_diff_evil))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf2d455",
   "metadata": {},
   "source": [
    "In this week's good NetVLAD, for this example, the cosine similarity of similar scenes is almost twice as the different ones. While in last week's evil NetVLAD, the cosine similarity of different scenes is hilariously higher than the similar ones, LOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce27a7",
   "metadata": {},
   "source": [
    "# Task2: .json reader (for 3RScan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b39ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by Linda Wang\n",
    "import json\n",
    "PRINT_ALL_JSON = False\n",
    "\n",
    "#load entire json file for raw data\n",
    "def load_json(name):\n",
    "    with open(name) as f:\n",
    "      data = json.load(f)\n",
    "    return data\n",
    "\n",
    "#helper functions\n",
    "def extract_centroid(data):\n",
    "    return data[\"centroid\"]\n",
    "\n",
    "def printing_format(id,centroid,lable):\n",
    "    print(\"===================================\")\n",
    "    print(\"Object ID: {}\".format(id))\n",
    "    print(\"Centoid Info: x: {}, y: {}, z: {}\".format(centroid[0],centroid[1],centroid[2]))\n",
    "    print(\"Label: {}\".format(lable))\n",
    "\n",
    "\n",
    "#extract objectID, label and centroid\n",
    "def extract_segGroup_info(data):\n",
    "\n",
    "    id_dict = {}\n",
    "    label_dict = {}\n",
    "\n",
    "    #loop through all segGroup objects\n",
    "    for object_dict in data[\"segGroups\"]:\n",
    "        #object_dict includes: objectId, id, partId, index, dominantNormal, obb, segments, label\n",
    "\n",
    "        #get needed info\n",
    "        id = object_dict[\"objectId\"]\n",
    "        centroid = extract_centroid(object_dict[\"obb\"])\n",
    "        lable = object_dict[\"label\"]\n",
    "\n",
    "        #print\n",
    "        #printing_format(id,centroid,lable)\n",
    "        id_dict[id] = [lable, centroid]\n",
    "\n",
    "        if lable in label_dict:\n",
    "            label_dict[lable].append([id, centroid])\n",
    "        else:\n",
    "            label_dict[lable] = [[id, centroid]]\n",
    "        #print(\"object id is: {}, the centroid is: {} and the label is: {}\".format(id,centroid,lable))\n",
    "\n",
    "    return id_dict, label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43cc1d",
   "metadata": {},
   "source": [
    "# Task3: 3RScan Library and Renderer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf1f01",
   "metadata": {},
   "source": [
    "## 1) Compare given 3D file against rendered 3D file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1834a9c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join\n\u001b[1;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'open3d'"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from os.path import join\n",
    "\n",
    "data_path = './3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193'\n",
    "given_ply = join(data_path, 'labels.instances.annotated.v2.ply')\n",
    "rendered_ply = join(data_path, 'labels.instances.annotated.v2.align.ply')\n",
    "given_obj = join(data_path, 'mesh.refined.v2.obj')\n",
    "rendered_obj = join(data_path, 'mesh.refined.v2.align.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "pcd = o3d.io.read_point_cloud(rendered_ply)\n",
    "print(pcd)\n",
    "print(np.asarray(pcd.points))\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df30173",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's draw a textured triangle mesh from obj file.\")\n",
    "textured_mesh = o3d.io.read_triangle_mesh(given_obj)\n",
    "textured_mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([textured_mesh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422340a",
   "metadata": {},
   "source": [
    "I can't see any difference, let's use 'diff' to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8887dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff ./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/labels.instances.annotated.v2.ply \\\n",
    "./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/labels.instances.annotated.v2.align.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff ./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/mesh.refined.v2.obj \\\n",
    "./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/mesh.refined.v2.align.obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba59d0",
   "metadata": {},
   "source": [
    "I guess the only difference is orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ece007",
   "metadata": {},
   "source": [
    "## 2) Render for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "ideal = Image.open('./3RScan-master/data/img/frames.png')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Ideal result given by authors')\n",
    "plt.imshow(ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6957a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = './3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/sequence'\n",
    "p1 = Image.open(join(img_path, 'frame-000000.color.jpg'))\n",
    "p2 = Image.open(join(img_path, 'frame-000000.depth.pgm'))\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(121)\n",
    "plt.title('origin rgb')\n",
    "plt.imshow(p1)\n",
    "plt.subplot(122)\n",
    "plt.title('origin d')\n",
    "plt.imshow(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a073f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat ./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/sequence/frame-000000.visibility.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf692b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat ./3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/sequence/frame-000000.bb.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d684fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './3RScan-master/data/3RScan/19eda6f4-55aa-29a0-8893-8eac3a4d8193/semseg.v2.json'\n",
    "data = load_json(file_name)\n",
    "\n",
    "# to print all json info\n",
    "if PRINT_ALL_JSON:\n",
    "    print(data)\n",
    "\n",
    "#printing only object ID, centoid and label\n",
    "id_dict, label_dict = extract_segGroup_info(data)\n",
    "\n",
    "#dictionary organized by id, and dictionary organized by label\n",
    "print(label_dict['chair'])\n",
    "print(id_dict[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d47083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r1 = Image.open(join(img_path, 'frame-000000.rendered.color.jpg'))\n",
    "# r2 = Image.open(join(img_path, 'frame-000000.rendered.depth.png'))\n",
    "r2 = mpimg.imread(join(img_path, 'frame-000000.rendered.depth.png'))\n",
    "r3 = Image.open(join(img_path, 'frame-000000.rendered.instances.png'))\n",
    "r4 = Image.open(join(img_path, 'frame-000000.rendered.labels.png'))\n",
    "r5 = Image.open(join(img_path, 'frame-000000.rendered.color.jpg'))\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.subplot(151)\n",
    "plt.title('rendered rgb')\n",
    "plt.imshow(r1)\n",
    "\n",
    "plt.subplot(152)\n",
    "plt.title('rendered d')\n",
    "plt.imshow(r2)\n",
    "# plt.subplot(152)\n",
    "# plt.title('rendered d')\n",
    "# plt.imshow(r2)\n",
    "\n",
    "plt.subplot(153)\n",
    "plt.title('rendered instances')\n",
    "plt.imshow(r3)\n",
    "\n",
    "plt.subplot(154)\n",
    "plt.title('rendered labels')\n",
    "plt.imshow(r4)\n",
    "\n",
    "plt.subplot(155)\n",
    "plt.title('example bouding box')\n",
    "r5 = np.array(r5)\n",
    "# label:chair id:34 bb:(904 221 1664 898) Note: numpy index is reversed i.e., (x,y) -> (y,x)\n",
    "cv2.rectangle(r5,pt1=(898,1664),pt2=(221,904),color=(255,0,0),thickness=20)\n",
    "plt.imshow(r5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc933bbe",
   "metadata": {},
   "source": [
    "We can also use ./rio_renderer to visualize all the bounding boxes. Below is the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5579dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = Image.open('./Bounding Boxes_screenshot_19.05.2022.png')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(111)\n",
    "plt.title('all bounding boxes')\n",
    "plt.imshow(bb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
